<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Java并发-线程协作机制</title>
    <url>/2021/07/30/Java%E5%B9%B6%E5%8F%91-%E5%90%8C%E6%AD%A5%E5%92%8C%E5%8D%8F%E4%BD%9C%E5%B7%A5%E5%85%B7%E7%B1%BB/</url>
    <content><![CDATA[<h2 id="wait、notify"><a href="#wait、notify" class="headerlink" title="wait、notify"></a>wait、notify</h2><p>属于 Object 类中。</p>
<p>当条件不成立时，线程调用 wait 进入条件等待队列。</p>
<p>另一个线程修改了条件变量后调用 notify，调用 wait 的线程唤醒后需要重新检查条件变量。</p>
<h2 id="显示条件"><a href="#显示条件" class="headerlink" title="显示条件"></a>显示条件</h2><p>sychronized：wait，notify</p>
<p>reentranlock：显式条件-condition 接口：await，signal</p>
<h2 id="线程中断"><a href="#线程中断" class="headerlink" title="线程中断"></a>线程中断</h2><h2 id="协作工具类"><a href="#协作工具类" class="headerlink" title="协作工具类"></a>协作工具类</h2><h3 id="读写锁-reentrantreadwritelock"><a href="#读写锁-reentrantreadwritelock" class="headerlink" title="读写锁 reentrantreadwritelock"></a>读写锁 reentrantreadwritelock</h3><p>读读是并行的。</p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p><img src="https://i.loli.net/2021/08/03/Qdk7pGoAtMq1NmJ.png" alt="image-20210803205028306"></p>
<h3 id="信号量-semaphore"><a href="#信号量-semaphore" class="headerlink" title="信号量 semaphore"></a>信号量 semaphore</h3><p>信号量，用来控制同时访问特定资源的线程数量，它通过协调各个线程以保证合理的使用公共资源，可以用做流量控制，譬如数据库连接场景控制等；</p>
<p>Semaphore 的构造方法 Semaphore(int permits) 接收一个整型参数，表示可用的许可证数量，即<strong>最大并发数量</strong>，使用方法就是在线程里面首先调用 acquire 方法获取一个许可，使用完后接着调用 <strong>release 归还一个许可，</strong>还可以使用 <strong>tryAcquire 尝试获取许可</strong>。</p>
<h3 id="倒计时门栓-countdownlatch"><a href="#倒计时门栓-countdownlatch" class="headerlink" title="倒计时门栓 countdownlatch"></a>倒计时门栓 countdownlatch</h3><p>CountDownLatch <strong>允许 count 个线程阻塞在一个地方</strong>，直至所有线程的任务都执行完毕。</p>
<p>CountDownLatch 是共享锁的一种实现,它默认构造 AQS 的 state 值为 count。</p>
<p>线程使用 <strong>countDown()</strong> 方法时,使用了 tryReleaseShared 方法以 CAS 的操作来<strong>减少 state</strong>,直至 state 为 0 。</p>
<p>当调用 <strong>await() 方法</strong>的时候，如果 state 不为 0，那就证明任务还没有执行完毕，await() 方法就会一直阻塞，也就是说 <strong>await() 方法之后的语句不会被执行</strong>。然后，CountDownLatch 会自旋 CAS 判断 state &#x3D;&#x3D; 0，如果 state &#x3D;&#x3D; 0 的话，就会释放所有等待的线程，await() 方法之后的语句得到执行。</p>
<h4 id="CountDownLatch-的两种典型用法"><a href="#CountDownLatch-的两种典型用法" class="headerlink" title="CountDownLatch 的两种典型用法"></a>CountDownLatch 的两种典型用法</h4><p>1、某一线程在开始运行前等待 n 个线程执行完毕。</p>
<p>将 CountDownLatch 的计数器初始化为 n （new CountDownLatch(n)），每当一个任务线程执行完毕，就将计数器减 1 （countdownlatch.countDown()），当计数器的值变为 0 时，在 CountDownLatch 上 await() 的线程就会被唤醒。一个典型应用场景就是<strong>启动一个服务时，主线程需要等待多个组件加载完毕</strong>，之后再继续执行。</p>
<p>2、实现多个线程开始执行任务的<strong>最大并行性。</strong></p>
<p>注意是并行性，不是并发，强调的是<strong>多个线程在某一时刻同时开始执行</strong>。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 （new CountDownLatch(1)），多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。</p>
<h4 id="CountDownLatch-的不足"><a href="#CountDownLatch-的不足" class="headerlink" title="CountDownLatch 的不足"></a>CountDownLatch 的不足</h4><p>CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。</p>
<h3 id="循环栅栏-cyclicbarrier"><a href="#循环栅栏-cyclicbarrier" class="headerlink" title="循环栅栏 cyclicbarrier"></a>循环栅栏 cyclicbarrier</h3><p>CountDownLatch 的实现是基于 AQS 的，而 CycliBarrier 是基于 ReentrantLock(ReentrantLock 也属于 AQS 同步器)和 Condition 的。</p>
<p>CyclicBarrier 的字面意思是<strong>可循环使用（Cyclic）的屏障（Barrier）</strong>。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。</p>
<p>CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 <strong>await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。</strong></p>
<p>CyclicBarrier 内部通过一个 <strong>count 变量作为计数器</strong>，count 的初始值为 parties 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减一。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。</p>
<h4 id="CyclicBarrier-的应用场景"><a href="#CyclicBarrier-的应用场景" class="headerlink" title="CyclicBarrier 的应用场景"></a>CyclicBarrier 的应用场景</h4><p>CyclicBarrier 可以用于<strong>多线程计算数据，最后合并计算结果的应用场景</strong>。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。</p>
<p>CyclicBarrier 还提供一个更高级的构造函数 CyclicBarrier(int parties, Runnable barrierAction)，用于在线程到达屏障时，优先执行 barrierAction，方便处理更复杂的业务场景。</p>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p><img src="https://i.loli.net/2021/08/03/OP6kMEHuTK14R89.png" alt="image-20210803210950957"></p>
<p>CountDownLatch 是计数器，<strong>只能使用一次</strong>，而 CyclicBarrier 的计数器提供 reset 功能，<strong>可以多次使用</strong>。</p>
<p>CountDownLatch: <strong>一个或者多个线程</strong>，等待<strong>其他多个线程完成某件事情之后</strong>才能执行；</p>
<p>CyclicBarrier : <strong>多个线程互相等待，直到到达同一个同步点，再继续一起执行。</strong></p>
<p>对于 CountDownLatch 来说，重点是“<strong>一个线程（多个线程）等待</strong>”，而其他的 N 个线程在完成“某件事情”之后，可以终止，也可以等待。</p>
<p>而对于 CyclicBarrier，重点是<strong>多个线程，在任意一个线程没有完成，所有的线程都必须等待。</strong></p>
<p>CountDownLatch 是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而 CyclicBarrier 更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。</p>
<h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><p><img src="https://i.loli.net/2021/08/05/vjqPYt4JX1xfGlk.png" alt="image-20210805141923139"></p>
<p>线程 1 往阻塞队列中添加元素，而线程 2 从阻塞队列中移除元素</p>
<p><strong>当阻塞队列是空时</strong>，从队列中获取元素的操作将会被阻塞。</p>
<p><strong>当阻塞队列是满时</strong>，从队列中添加元素的操作将会被阻塞。</p>
<p>试图从空的阻塞队列中获取元素的线程将会阻塞，直到其他的线程往空的队列插入新的元素，同样，试图往已满的阻塞队列添加新元素的线程同样也会阻塞，直到其他的线程从列中移除一个或多个元素或者完全清空队列后继续新增。</p>
<h3 id="为什么要用阻塞队列，有什么好处吗"><a href="#为什么要用阻塞队列，有什么好处吗" class="headerlink" title="为什么要用阻塞队列，有什么好处吗"></a>为什么要用阻塞队列，有什么好处吗</h3><p>在多线程领域：所谓阻塞，是指在某些情况下会<strong>挂起线程（即阻塞）</strong>，一旦条件满足，<strong>被挂起的线程又会自动被唤醒。</strong></p>
<p>好处是我们<strong>不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这些 BlockingQueue 都包办了。</strong></p>
<p>在 concurrent 包发布以前，多线程环境下，我们每个程序员都必须自己去实现这些细节，尤其还要兼顾效率和线程安全，这会给我们的程序带来不小的复杂性。</p>
<p>JDK 提供了 7 个阻塞队列。分别是</p>
<p>ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列<br>LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列<br>PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列<br>DelayQueue：一个使用优先级队列实现的无界阻塞队列<br>SynchronousQueue：一个不存储元素的阻塞队列<br>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列（实现了继承于 BlockingQueue 的 TransferQueue）<br>LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列</p>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><p><img src="https://i.loli.net/2021/08/05/dv943bwnZLAeIKt.png" alt="image-20210805142222849"></p>
<h2 id="future-x2F-futuretask"><a href="#future-x2F-futuretask" class="headerlink" title="future&#x2F;futuretask"></a>future&#x2F;futuretask</h2>]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>工具类</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础-常见问题</title>
    <url>/2021/07/30/Java%E5%9F%BA%E7%A1%80-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="Java-对象判空？"><a href="#Java-对象判空？" class="headerlink" title="Java 对象判空？"></a>Java 对象判空？</h3><p>null：一个对象如果有可能是 null 的话，首先要做的就是判断是否为 null：object &#x3D;&#x3D; null，否则就有可能会出现空指针异常，这个通常是我们在进行数据库的查询操作时，查询结果首先用 object !&#x3D; null，进行非空判断，然后再进行其他的业务逻辑，这样可以避免出现空指针异常。</p>
<p>isempty：此方法可以使用于字符串，数组，集合都可以用。</p>
<p>   plain public boolean isEmpty() {<br>        return value.length &#x3D;&#x3D; 0;<br>    }<br>这里是一个对象的长度，使用这个方法，首先要排除对象不为 null，否则当对象为 null 时，调用 isEmpty 方法就会报空指针了。</p>
<p>要想返回 true，也就是一个对象的长度为 0，也就是说首先这个对象肯定不为 null 了，内容为空时，才能返回 true。</p>
<p>当创建一个新的对象时，栈里面有一个对象，堆里面有一个对象，栈里的对象指向堆里面的对象。对象包含引用对象和实际对象，也就是栈和值的关系，比如 String a &#x3D; new String();，这句代码就在堆内存中产生了一个 String 对象””，和栈内存中一个引用对象 a，也就是 a 指向了一个为空的字符串。当没有再次给引用对象 a 进行赋值时，操作 a 也即是操作这个空字符串。</p>
<h3 id="后端和前端交互接口"><a href="#后端和前端交互接口" class="headerlink" title="后端和前端交互接口"></a>后端和前端交互接口</h3><h3 id="Obiect-类有哪些方法"><a href="#Obiect-类有哪些方法" class="headerlink" title="Obiect 类有哪些方法"></a>Obiect 类有哪些方法</h3><p>1、 getClass()：获取类的 class 对象。<br>2、 hashCode:获取对象的 hashCode 值<br>3、 equals():比较对象是否相等，比较的是值和地址，子类可重写以自定义。<br>4、 clone()：克隆方法。<br>5、 toString():如果没有重写，应用对象将打印的是地址值。<br>6、 notify():随机选择一个在该对象上调用 wait 方法的线程，解除其阻塞状态。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个 IllegalMonitorStateException 异常。<br>7、 notifyall():解除所有那些在该对象上调用 wait 方法的线程的阻塞状态。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个 IllegalMonitorStateException 异常。<br>8、 wait():导致线程进入等待状态，直到它被其他线程通过 notify()或者 notifyAll 唤醒。该方法只能在同步方法中调用。如果当前线程不是锁的持有者，该方法抛出一个 IllegalMonitorStateException 异常。<br>9、 finalize()：对象回收时调用</p>
<h3 id="Java-数据类型"><a href="#Java-数据类型" class="headerlink" title="Java 数据类型"></a>Java 数据类型</h3><p>Java 中有 8 种基本数据类型，分别为：</p>
<p>6 种数字类型 ：byte-1、short-2、int-4、long-8、float-4、double-8<br>1 种字符类型：char-2<br>1 种布尔型：boolean-1 位</p>
<p>这八种基本类型都有对应的包装类分别为：Byte、Short、Integer、Long、Float、Double、Character、Boolean 。</p>
<p>包装类型不赋值就是 Null ，而基本类型有默认值且不是 Null。</p>
<p>基本数据类型直接存放在 <strong>Java 虚拟机栈中的局部变量表</strong>中，而包装类型属于<strong>对象类型</strong>，我们知道对象实例都存在于堆中。相比于对象类型， 基本数据类型占用的空间非常小。</p>
<p><strong>自动装箱与拆箱</strong></p>
<p>装箱：将基本类型用它们对应的引用类型包装起来；<br>拆箱：将包装类型转换为基本数据类型；</p>
<p>从字节码中，我们发现装箱其实就是调用了 <strong>包装类的 valueOf()方法，拆箱其实就是调用了 xxxValue()方法</strong>。</p>
<p>因此，</p>
<p>Integer i &#x3D; 10 等价于 Integer i &#x3D; Integer.valueOf(10)<br>int n &#x3D; i 等价于 int n &#x3D; i.intValue();</p>
<h4 id="为什么存在这两种类型呢？"><a href="#为什么存在这两种类型呢？" class="headerlink" title="为什么存在这两种类型呢？"></a>为什么存在这两种类型呢？</h4><p>我们都知道在 Java 语言中，new 一个对象存储在堆里，我们通过栈中的引用来使用这些对象；但是对于经常用到的一系列类型如 int，如果我们用 new 将其存储在堆里就不是很有效——特别是简单的小的变量。所以就出现了基本类型，同 C++一样，Java 采用了相似的做法，对于这些类型不是用 new 关键字来创建，而是直接将变量的值存储在栈中，因此更加高效。</p>
<h4 id="有了基本类型为什么还要有包装类型呢？"><a href="#有了基本类型为什么还要有包装类型呢？" class="headerlink" title="有了基本类型为什么还要有包装类型呢？"></a>有了基本类型为什么还要有包装类型呢？</h4><p>我们知道 Java 是一个面相对象的编程语言，基本类型并不具有对象的性质，为了让基本类型也具有对象的特征，就出现了包装类型（如我们在使用集合类型 Collection 时就一定要使用包装类型而非基本类型），它相当于将基本类型“包装起来”，使得它具有了对象的性质，并且为其添加了属性和方法，丰富了基本类型的操作。</p>
<p>另外，当需要往 ArrayList，HashMap 中放东西时，像 int，double 这种基本类型是放不进去的，因为容器都是装 object 的，这是就需要这些基本类型的包装器类了。</p>
<h3 id="关键字总结"><a href="#关键字总结" class="headerlink" title="关键字总结"></a>关键字总结</h3><h4 id="final-关键字"><a href="#final-关键字" class="headerlink" title="final 关键字"></a>final 关键字</h4><p>final 关键字，意思是<strong>最终的、不可修改的</strong>，用来修饰类、方法和变量，具有以下特点：</p>
<p>final 修饰的类<strong>不能被继承</strong>，final 类中的所有成员方法都会被隐式的指定为 final 方法；</p>
<p>final 修饰的方法<strong>不能被重写</strong>；</p>
<p>final <strong>修饰的变量是常量</strong>，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能让其指向另一个对象。</p>
<h4 id="static-关键字"><a href="#static-关键字" class="headerlink" title="static 关键字"></a>static 关键字</h4><p>static 关键字主要有以下四种使用场景：</p>
<p><strong>修饰成员变量和成员方法:</strong> 被 static 修饰的<strong>成员属于类</strong>，不属于单个这个类的某个对象，被类中所有对象共享，可以并且建议<strong>通过类名调用</strong>。被 static 声明的成员变量属于静态成员变量，静态变量 存放在 Java 内存区域的方法区。</p>
<p>调用格式：类名.静态变量名 类名.静态方法名()</p>
<p><strong>静态代码块:</strong> 静态代码块定义在<strong>类中方法外</strong>, 静态代码块在非静态代码块之前执行(静态代码块—&gt;非静态代码块—&gt;构造方法)。 该类不管创建多少对象，静态代码块只执行一次.</p>
<p><strong>静态内部类（static 修饰类的话只能修饰内部类</strong>）： 静态内部类与非静态内部类之间存在一个最大的区别: 非静态内部类在编译完成之后会隐含地保存着一个引用，该引用是指向创建它的外围类，但是静态内部类却没有。没有这个引用就意味着：</p>
<ol>
<li><strong>它的创建是不需要依赖外围类的创建。</strong></li>
<li>它<strong>不能使用任何外围类的非 static 成员变量和方法。</strong></li>
</ol>
<p><strong>静态导包</strong>(用来导入类中的静态资源，1.5 之后的新特性): 格式为：import static 这两个关键字连用可以<strong>指定导入某个类中的指定静态资源</strong>，并且不需要使用类名调用类中静态成员，可以直接使用类中静态成员变量和成员方法。</p>
<h4 id="this-关键字"><a href="#this-关键字" class="headerlink" title="this 关键字"></a>this 关键字</h4><p>this 关键字用于<strong>引用类的当前实例</strong>。 例如：<br>此关键字是可选的， 但是，使用此关键字可能会使代码更易读或易懂。</p>
<h4 id="super-关键字"><a href="#super-关键字" class="headerlink" title="super 关键字"></a>super 关键字</h4><p>super 关键字用于<strong>从子类访问父类的变量和方法</strong>。 例如：</p>
<p>使用 this 和 super 要注意的问题：</p>
<p>在构造器中使用 <strong>super() 调用父类中的其他构造方法时</strong>，<strong>该语句必须处于构造器的首行</strong>，否则编译器会报错。另外，<strong>this 调用本类中的其他构造方法时，也要放在首行。</strong></p>
<p><strong>this、super 不能用在 static 方法中。</strong></p>
<p>被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享。</p>
<p><strong>而 this 代表对本类对象的引用，指向本类对象；而 super 代表对父类对象的引用，指向父类对象</strong>；所以， this 和 super 是属于对象范畴的东西，而静态方法是属于类范畴的东西。</p>
<h3 id="权限修饰符"><a href="#权限修饰符" class="headerlink" title="权限修饰符"></a>权限修饰符</h3><p><img src="https://i.loli.net/2021/08/05/Dg8pvr4FJswPIGn.png" alt="image-20210805171804390"></p>
<h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><p>Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了<strong>编译时类型安全检测机制</strong>，该机制允许程序员在编译时检测到非法的类型。泛型的本质是<strong>参数化类型</strong>，也就是说所操作的数据类型被指定为一个参数。</p>
<p>Java 的泛型是伪泛型，这是因为 Java 在编译期间，所有的泛型信息都会被擦掉，这也就是通常所说类型擦除 。</p>
<p>泛型一般有三种使用方式:泛型类、泛型接口、泛型方法。</p>
<p>假定我们有这样一个需求：写一个排序方法，能够对整型数组、字符串数组甚至其他任何类型的数组进行排序，该如何实现？</p>
<p>使用 Java 泛型的概念，我们可以写一个泛型方法来对一个对象数组排序。然后，调用该泛型方法来对整型数组、浮点数数组、字符串数组等进行排序。</p>
<h3 id="x3D-x3D-与-equals"><a href="#x3D-x3D-与-equals" class="headerlink" title="&#x3D;&#x3D;与 equals()?"></a>&#x3D;&#x3D;与 equals()?</h3><p>&#x3D;&#x3D;判断两个对象的<strong>地址</strong>是不是相等，<strong>对于基本数据类型：值。引用数据类型：内存地址。</strong><br>equals()没有被覆盖重写，与&#x3D;&#x3D;一样。</p>
<p><strong>可以覆盖重写比较引用对象值的大小。</strong><br>举例：String 中的 equals 方法是被重写过的。</p>
<h4 id="hashcode（）与-equal（）？hashset-去重？"><a href="#hashcode（）与-equal（）？hashset-去重？" class="headerlink" title="hashcode（）与 equal（）？hashset 去重？"></a>hashcode（）与 equal（）？hashset 去重？</h4><p><strong>为什么要有 hashcode？</strong></p>
<p>当你把对象加⼊ HashSet 时， <strong>HashSet 会先计算对象的 hashcode 值来判断对象加⼊的位置</strong>，同时也会与其他已经加⼊的对象的 hashcode 值比较，如果没有相符的 hashcode， HashSet 会假设对象没有重复出现。</p>
<p>但是如果发现有相同 hashcode 值的对象，这时会调⽤ equals() ⽅法来检查 hashcode 相等的对象是否真的相同。如果两者相同， HashSet 就不会让其加⼊操作成功。如果不同的话，就会重新散列到其他位置。</p>
<p><strong>这样我们就⼤⼤减少了 equals 的次数，相应就⼤⼤提⾼了执⾏速度。</strong><br><strong>hash 优越的查询性能。</strong></p>
<h4 id="为什么重写-equals-必须重写-hashcode-？"><a href="#为什么重写-equals-必须重写-hashcode-？" class="headerlink" title="为什么重写 equals 必须重写 hashcode()？"></a>为什么重写 equals 必须重写 hashcode()？</h4><p>对象相等，hashcode 一定相等，反之不一定（hash 碰撞）。<br>hashcode()默认对堆上面的对象产生独特值，hashcode 不同，对象一定不同。</p>
<p>举例：student s1&#x3D;new student(name&#x3D;”11”);<br>student s2&#x3D;new student(name&#x3D;”11”);</p>
<p>假如只重写 equals 而不重写 hashcode，那么默认的 hashcode 方法是根据对象的内存地址经哈希算法得来的，显然此时 s1!&#x3D;s2。然而重写了 equals，且 s1.equals(s2)返回 true。</p>
<p>根据 hashcode 的规则，<strong>两个对象相等其哈希值一定相等</strong>，所以矛盾就产生了，因此重写 equals 一定要重写 hashcode。</p>
<h3 id="重载与重写"><a href="#重载与重写" class="headerlink" title="重载与重写"></a>重载与重写</h3><ol>
<li><p>重载(overloading) 是在一个类里面，<strong>方法名字相同，而参数不同。返回类型可以相同也可以不同。</strong></p>
<p>每个重载的方法（或者构造函数）都必须<strong>有一个独一无二的参数类型列表</strong>。</p>
<p>最常用的地方就是构造器的重载。</p>
</li>
<li><p>重写（发生于<strong>运行期</strong>）：<strong>子类继承父类的方法，输入一样，做出不同的操作就要覆盖重写父类方法。</strong></p>
</li>
</ol>
<p>  方法名，参数列表必须一样。</p>
<p>  抛出异常范围小于父类。<br>  访问修饰符可以降低限制。</p>
<p>  <strong>父类方法由 private，final，static 修饰时不能被重写。</strong></p>
<h3 id="抽象类与接口"><a href="#抽象类与接口" class="headerlink" title="抽象类与接口"></a>抽象类与接口</h3><p><strong>抽象类和接口的区别</strong></p>
<p>接口(interface)和抽象类(abstract class)是<strong>支持抽象类定义的两种机制。</strong></p>
<p><strong>接口是公开的</strong>，不能有私有的方法或变量，<strong>接口中的所有方法都没有方法体</strong>，通过关键字 interface 实现。</p>
<p><strong>抽象类</strong>是可以有私有方法或私有变量的，通过把类或者类中的方法声明为 abstract 来表示一个类是抽象类，<strong>被声明为抽象的方法不能包含方法体</strong>。子类实现方法必须含有相同的或者更低的访问级别(public-&gt;protected-&gt;private)。抽象类的子类为父类中所有抽象方法的具体实现，否则也是抽象类。</p>
<p><strong>接口可以被看作是抽象类的变体</strong>，接口中所有的方法都是抽象的，<strong>可以通过接口来间接的实现多重继承</strong>。接口中的成员变量都是 static final 类型，<strong>由于抽象类可以包含部分方法的实现</strong>，所以，在一些场合下抽象类比接口更有优势。</p>
<p><strong>相同点</strong></p>
<p><strong>接口的实现类</strong>或<strong>抽象类的子类</strong>都只有实现了接口或抽象类中的方法后才能实例化。</p>
<p><strong>不同点</strong></p>
<p><img src="https://i.loli.net/2021/08/05/thjlgoUynpEJR4P.png" alt="image-20210805171623086"></p>
<p>抽象类就是为了继承而存在的，如果你定义了一个抽象类，却不去继承它，那么等于白白创建了这个抽象类，因为你不能用它来做任何事情。对于一个父类，如果它的某个方法在父类中实现出来没有任何意义，必须根据子类的实际需求来进行不同的实现，那么就可以将这个方法声明为 abstract 方法，此时这个类也就成为 abstract 类了。</p>
<p>在抽象类中，抽象方法本质上是定义接口规范：即规定高层类的接口，从而保证所有子类都有相同的接口实现，这样，多态就能发挥出威力。</p>
<p>如果一个抽象类没有字段，所有方法全部都是抽象方法：就可以把该抽象类改写为接口：interface。</p>
<p><strong>那么接口的作用是什么呢？</strong></p>
<p>1、Java 单继承的原因所以需要曲线救国 作为继承关系的一个补充。</p>
<p>2、把程序模块进行固化的契约,降低偶合。把若干功能拆分出来，按照契约来进行实现和依赖。（依赖倒置原则）</p>
<p>3、定义接口有利于代码的规范。（接口分离原则）</p>
<p><strong>abstract class 表示的是 is a 关系</strong>，<strong>interface 表示的是 like a 关系。</strong></p>
<p><strong>抽象类强调的是从属关系，接口强调的是功能。</strong></p>
<p>抽象类作为很多子类的父类，它是一种<strong>模板式</strong>设计。</p>
<p>而接口是一种<strong>行为规范</strong>，它是一种辐射式设计。</p>
<p>对于抽象类，如果需要添加新的方法，可以直接在抽象类中添加具体的实现，子类可以不进行变更；</p>
<p>而对于接口则不行，如果接口进行了变更，则所有实现这个接口的类都必须进行相应的改动。</p>
<h3 id="成员变量与局部变量？"><a href="#成员变量与局部变量？" class="headerlink" title="成员变量与局部变量？"></a>成员变量与局部变量？</h3><p>根据定义变量位置的不同，可以将变量分为成员变量和局部变量<br>     成员变量是在<strong>类范围</strong>内定义的变量<br>     局部变量是在<strong>一个方法内</strong>定义的变量<br>1，成员变量可以分为：<br>实例属性 （不用 static 修饰）<br>随着实例属性的存在而存在<br>类属性 （static 修饰）<br>随着类的存在而存在<br>成员变量无需显式初始化，系统会自动对其进行默认初始化</p>
<p>2，局部变量可分为：<br>     形参（形式参数）<br>            在整个方法内有效<br>     方法局部变量 （方法内定义）<br>            从定义这个变量开始到方法结束这一段时间内有效<br>     代码块局部变量 （代码块内定义）<br>            从定义这个变量开始到代码块结束这一段时间内有效</p>
<p><strong>局部变量除了形参外</strong>，<strong>都必须显示初始化</strong>，也就是要指定一个初始值，否则不能访问。<br>java 允许局部变量和成员变量重名，<strong>局部变量会覆盖成员变量的值</strong></p>
<h3 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h3><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ol>
<li>单一职责原则（Single Responsibility Principle）</li>
</ol>
<p>每一个类应该专注于做一件事情。</p>
<ol start="2">
<li>里氏替换原则（Liskov Substitution Principle）</li>
</ol>
<p>超类存在的地方，子类是可以替换的。</p>
<ol start="3">
<li>依赖倒置原则（Dependence Inversion Principle）</li>
</ol>
<p>实现尽量依赖抽象，不依赖具体实现。</p>
<ol start="4">
<li>接口隔离原则（Interface Segregation Principle）</li>
</ol>
<p>应当为客户端提供尽可能小的单独的接口，而不是提供大的总的接口。</p>
<ol start="5">
<li>迪米特法则（Law Of Demeter）</li>
</ol>
<p>又叫最少知识原则，一个软件实体应当尽可能少的与其他实体发生相互作用。</p>
<ol start="6">
<li>开闭原则（Open Close Principle）</li>
</ol>
<p>面向扩展开放，面向修改关闭。</p>
<ol start="7">
<li>组合&#x2F;聚合复用原则（Composite&#x2F;Aggregate Reuse Principle CARP）</li>
</ol>
<p>尽量使用合成&#x2F;聚合达到复用，尽量少用继承。原则： 一个类中有另一个类的对象。</p>
<p><strong>面向过程：以事件为中心，一步一步实现每个步骤。以步骤划分。</strong></p>
<p>任务明确</p>
<p>效率高</p>
<p>扩展性差，复用性弱，逻辑需要深入思考。</p>
<p><strong>面向对象：以对象为中心，以功能划分，每个对象都有自己的属性与行为。</strong></p>
<p>程序模块化，结构化。</p>
<p>易于扩展，维护。</p>
<p>性能相对于面向过程低。</p>
<p>java 性能相对低的原因主要在于其是半编译语言。</p>
<p><strong>封装</strong></p>
<p>封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以<strong>提供一些可以被外界访问的方法来操作属性</strong>。</p>
<p>就好像我们看不到挂在墙上的空调的内部的零件信息（也就是属性），但是可以通过遥控器（方法）来控制空调。</p>
<p><strong>继承</strong></p>
<p>不同类型的对象，<strong>相互之间经常有一定数量的共同点</strong>。例如，小明同学、小红同学、小李同学，都共享学生的特性（班级、学号等）。</p>
<p>同时，每一个对象还定义了额外的特性使得他们与众不同。例如小明的数学比较好，小红的性格惹人喜爱；小李的力气比较大。</p>
<p>继承是<strong>使用已存在的类的定义作为基础建立新类的技术</strong>，新类的定义可以<strong>增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承，可以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。</strong></p>
<p>关于继承如下 3 点请记住：</p>
<p>子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是<strong>父类中的私有属性和方法子类是无法访问</strong>，只是拥有。<br>子类可以拥有自己属性和方法，即<strong>子类可以对父类进行扩展。</strong><br>子类可以用自己的方式实现父类的方法。</p>
<p><strong>多态</strong></p>
<p>多态，顾名思义，表示<strong>一个对象具有多种的状态</strong>。一种类型的变量可以引用多种实际类型的对象。实现方式：	  继承（多个子类重写同一方法）<br>      接口（实现接口并覆盖同一方法）</p>
<p><strong>多态的特点:</strong></p>
<p>对象类型和引用类型之间具有<strong>继承（类）&#x2F;实现（接口）的</strong>关系；<br>引用类型变量发出的方法调用的到底是哪个类中的方法，<strong>必须在程序运行期间才能确定；</strong><br>多态不能调用“只在子类存在但在父类不存在”的方法；<br>如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法。</p>
<h3 id="hash-冲突解决"><a href="#hash-冲突解决" class="headerlink" title="hash 冲突解决"></a>hash 冲突解决</h3><p><strong>开放地址法</strong></p>
<p>​	线性探测法：冲突之后，在紧跟着的地方安放数据。（大部分的数据都会聚集）。<br>​	二次探测法：往后找 1,4,9,16,25,…位置有没有空位。<br>​	再哈希法：多个散列函数。</p>
<p>链地址法：</p>
<h3 id="String，StringBuffer，StringBuilder"><a href="#String，StringBuffer，StringBuilder" class="headerlink" title="String，StringBuffer，StringBuilder"></a>String，StringBuffer，StringBuilder</h3><p>String 类中使用 final 关键字修饰字符数组来保存字符串，private final char value[]，所以 String 对象是不可变的。</p>
<p><strong>在 Java 9 之后，String 、StringBuilder 与 StringBuffer 的实现改用 byte 数组存储字符串 private final byte[] value</strong></p>
<p>而 StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串 char[] value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。</p>
<p><strong>线程安全性</strong></p>
<p>String 中的对象是不可变的，也就可以理解为常量<strong>，线程安全。</strong></p>
<p>AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。</p>
<p>StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。</p>
<p>StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。</p>
<p><strong>性能</strong></p>
<p>每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。</p>
<p>StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。</p>
<p>相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。</p>
<p>对于三者使用的总结：</p>
<p>操作少量的数据: 适用 String<br>单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder<br>多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer</p>
<h3 id="异常体系"><a href="#异常体系" class="headerlink" title="异常体系"></a>异常体系</h3><p><img src="https://i.loli.net/2021/08/05/Hb642mCQlxy3M5o.png" alt="image-20210805134232290"></p>
<p>自定义异常：继承 Exception 类。</p>
<p><strong>异常的处理：</strong></p>
<ol>
<li><p>使用 try  catch 捕获异常。可以有多个 catch，总会根据异常的类型优先找到第一个匹配的。因此，基类 exception 放在前面会导致后面的 catch 无法执行。</p>
</li>
<li><p>重新抛出异常。在 catch 中可以 throw 新的或者原来的异常，表示当前代码不能完全处理。可以通过 getCause()获取原始异常。</p>
</li>
<li><p>try catch finally。finally 中语句始终会执行。适合释放资源，比如数据库连接，文件流释放等等。<br>如果 try  catch 中有 return，会在 finally 之后执行，但是 finally 不能改变其返回值。<br>finally 中有 return，try catch 中的 return 会丢失，实际上会返回 finally 中的值。还会掩盖 try catch 中的异常。</p>
</li>
<li><p>try with resourses，用于资源的释放，无需写 finally，会自动执行 close（）。</p>
</li>
<li><p>throws，声明一个方法可能抛出的异常。</p>
</li>
</ol>
<p>  异常体系可以：<strong>对异常集中处理，还可以向上传递，不需要每层都处理，也可以向上传递，也不会被自动忽略。处理异常情况的代码可以大大减少。</strong></p>
<h3 id="IO-流"><a href="#IO-流" class="headerlink" title="IO 流"></a>IO 流</h3><p><img src="https://i.loli.net/2021/08/05/gXcmZMILa2EnuiW.png" alt="image-20210805134331023"></p>
<p>为何有了字节流，还要有字符流？</p>
<p><strong>字符流是由 java 虚拟机将字节流转化而成。这个过程耗时，也容易出错。</strong></p>
<p>所以提供了字符流，对于字符进行流操作。<br>而对于音频，图片等等推荐字节流。</p>
<h4 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">// 以GBK格式,读取文件<br>FileInputStream fis = new FileInputStream(file);<br>InputStreamReader isr = new InputStreamReader(fis, &quot;GBK&quot;);<br>BufferedReader br = new BufferedReader(isr);<br>String str = null;<br>// 创建StringBuffer字符串缓存区<br>StringBuffer sb = new StringBuffer();<br>// 通过readLine()方法遍历读取文件<br>while ((str = br.readLine()) != null) &#123;<br>// 使用readLine()方法无法进行换行,需要手动在原本输出的字符串后面加&quot;\n&quot;或&quot;\r&quot;<br>	str += &quot;\n&quot;;<br>	sb.append(str);<br>&#125;<br>String str2 = sb.toString();<br>// 以UTF-8格式写入文件,file.getAbsolutePath()即该文件的绝对路径,false代表不追加直接覆盖,true代表追加文件<br>FileOutputStream fos = new FileOutputStream(file.getAbsolutePath(), false);<br>OutputStreamWriter osw = new OutputStreamWriter(fos, &quot;UTF-8&quot;);<br>osw.write(str2);<br>osw.flush();<br>osw.close();<br>fos.close();<br>br.close();<br>isr.close();<br>fis.close();<br></code></pre></td></tr></table></figure>



<h3 id="java-8-新特性"><a href="#java-8-新特性" class="headerlink" title="java 8 新特性"></a>java 8 新特性</h3><h4 id="Lambda-表达式"><a href="#Lambda-表达式" class="headerlink" title="Lambda 表达式"></a>Lambda 表达式</h4><p>首先看看在老版本的 Java 中是如何排列字符串的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">List&lt;String&gt; names = Arrays.asList(&quot;peter&quot;, &quot;anna&quot;, &quot;mike&quot;, &quot;xenia&quot;);<br><br>Collections.sort(names, new Comparator&lt;String&gt;() &#123;<br>    @Override<br>    public int compare(String a, String b) &#123;<br>        return b.compareTo(a);<br>    &#125;<br>&#125;);<br></code></pre></td></tr></table></figure>


<p>只需要给静态方法 Collections.sort 传入一个 List 对象以及一个比较器来按指定顺序排列。通常做法都是创建一个匿名的比较器对象然后将其传递给 sort 方法。</p>
<p>在 Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8 提供了更简洁的语法，lambda 表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">Collections.sort(names, (String a, String b) -&gt; &#123;<br>    return b.compareTo(a);<br>&#125;);<br></code></pre></td></tr></table></figure>


<p>看到了吧，代码变得更段且更具有可读性，但是实际上还可以写得更短：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">Collections.sort(names, (String a, String b) -&gt; b.compareTo(a));<br></code></pre></td></tr></table></figure>


<p>对于函数体只有一行代码的，你可以去掉大括号{}以及 return 关键字，但是你还可以写得更短点：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">Collections.sort(names, (a, b) -&gt; b.compareTo(a));<br></code></pre></td></tr></table></figure>

<p>Java 编译器可以自动推导出参数类型，所以你可以不用再写一次类型。</p>
<h4 id="函数式接口"><a href="#函数式接口" class="headerlink" title="函数式接口"></a>函数式接口</h4><p>什么叫函数式编程？</p>
<p>就可以理解成用什么参数执行了一件什么事情，这就是函数式编程，它是匿名内部类进一步的简化，可以让代码更加的简洁。</p>
<p>但它有一个使用的前提，接口得是函数式接口。</p>
<p>有且仅有一个抽象方法需要被重写的接口。</p>
<p>这个怎么理解？很简单，函数式编程和匿名内部类相比，它省略了啥？</p>
<p>它省略了接口中的方法名，为什么可以省略？</p>
<p>因为就只有一个方法，那就算省略了方法名字，也知道是用的那个方法。</p>
<p><strong>函数式接口：</strong> <strong>只有一个方法的接口。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">@FunctionalInterface<br><br>public interface Runnable &#123;<br><br>public abstract void run();<br><br>&#125;<br></code></pre></td></tr></table></figure>

<p>&#x2F;&#x2F; <strong>简化编程模型</strong>，在新版本的框架底层大量应用！</p>
<p><img src="https://i.loli.net/2021/08/05/pbTIZtNPr8Q5v63.png" alt="image-20210805191320866"></p>
<p>　</p>
<p><strong>浏览器在接收到 html 文件后，会分几个步骤 html 文件转化成界面，这个过程就是渲染。</strong></p>
<p>　　1、解析 html</p>
<p>　　2、构建 dom 树</p>
<p>　　3、dom 树结合 css 文件，构建呈现树</p>
<p>　　4、布局</p>
<p>　　5、绘制</p>
<p>1、解析 html 和构建 dom 树是同步进行的，这个过程就是逐行解析代码，包括 html 标签和 js 动态生成的标签，最终生成 dom 树。</p>
<p>2、构建呈现树，就是把 css 文件和 style 标签的中的内容，结合 dom 树的模型，构建一个呈现树，写到内存，等待进一步生成界面。呈现树一定依赖 dom 树，呈现节点一定会有对应的 dom 节点，但是 dom 节点不一定会有对应的呈现节点，比如，被隐藏的一个 div。</p>
<p>3、布局，这一步就是结合呈现树，把 dom 节点的大小、位置计算出来。虽然呈现节点已经附着在都没节点上，会有对元素大小、位置的定义，但是浏览器还需要根据实际窗口大小进行计算，比如对 auto 的处理。</p>
<p>4、绘制，把 css 中有关颜色的设置，背景、字体颜色等呈现出来。</p>
<h3 id="深拷贝浅拷贝"><a href="#深拷贝浅拷贝" class="headerlink" title="深拷贝浅拷贝"></a>深拷贝浅拷贝</h3><p>浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。<br>深拷贝：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝。</p>
<p><img src="https://i.loli.net/2021/08/05/PkHUFX6xJNeTbt2.png" alt="image-20210805200519957"></p>
]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发-常见基础</title>
    <url>/2021/07/30/Java%E5%B9%B6%E5%8F%91-%E5%B8%B8%E8%A7%81%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h3 id="线程与进程与协程"><a href="#线程与进程与协程" class="headerlink" title="线程与进程与协程"></a>线程与进程与协程</h3><p><strong>进程是程序的一次执行过程，是系统资源分配的基本单位</strong>。进程间基本上是独立的。</p>
<p>线程是更小的运行单位。线程是调度执行的基本单位。线程间极有可能相互影响。</p>
<p>多个线程可以共享同一块内存空间与系统资源（<strong>堆，方法区（元空间）</strong>），也有自己独立的<strong>程序计数器与虚拟机栈，本地方法栈</strong>。</p>
<p>线程的切换负担要小很多。也被称为轻量级的进程。</p>
<p>程序计数器：为了线程切换后可以恢复到正确的执行位置。<br>虚拟机栈：方法调用对应着栈帧，存储着局部变量表，操作数栈，常量池。方法调用执行完成对应着栈帧的入栈与出栈。–<strong>保证局部变量私有</strong>。<br>堆：最大的一块，存放对象。<br>方法区：已被<strong>加载的类信息，常量，静态变量</strong>等等。<br>上下文切换：cpu 时间片切换。</p>
<p>一个 java 应用程序实际上至少有三个线程，<strong>main 主线程，gc()垃圾回收机制的运行线程，异常处理线程。</strong></p>
<p><strong>线程分为两类：用户线程和守护线程</strong>。守护线程适用于服务用户线程的。<strong>用户线程结束，守护线程也就结束</strong>，所以守护线程是依赖于用户线程的。举个例子：java 程序中，main 是用户线程，垃圾回收就是守护线程。可以利用 thread.setDaemon(true)将用户线程变成守护线程。</p>
<h4 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h4><p>操作系统在线程等待 IO 的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待 IO 的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。<strong>一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。</strong></p>
<p>协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。协程并没有增加线程数量，<strong>只是在线程的基础之上通过分时复用的方式运行多个协程</strong>，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。</p>
<p>假设协程运行在线程之上，并且协程调用了一个阻塞 IO 操作，这时候会发生什么？</p>
<p>实际上操作系统并不知道协程的存在，它只知道线程，因此在协程调用阻塞 IO 操作的时候，操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度，这往往是不能接受的。</p>
<p><strong>在有大量 IO 操作业务的情况下，</strong>我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。</p>
<p>在协程中尽量不要调用阻塞 IO 的方法，比如打印，读取文件，Socket 接口等，除非改为<strong>异步调用</strong>的方式，并且协程只有在 IO 密集型的任务中才会发挥作用。</p>
<p>协程只有和异步 IO 结合起来才能发挥出最大的威力。</p>
<p><strong>线程的相关方法：</strong></p>
<p>sleep-</p>
<p>yield-让出 cpu，当然实际情况得看调度器</p>
<p>join-调用 join 的线程会让其他线程等待他结束后再结束。</p>
<h4 id="sleep-与-wait-方法的区别"><a href="#sleep-与-wait-方法的区别" class="headerlink" title="sleep()与 wait()方法的区别"></a>sleep()与 wait()方法的区别</h4><ol>
<li>sleep 方法不会释放锁，wait 方法会释放。</li>
<li>都可以暂停线程。</li>
<li>wait 用于线程交互，sleep 用于暂停。</li>
<li>wait 被调用后，线程不会自动苏醒（无超时等待），需要 notify()。</li>
</ol>
<h4 id="java-线程的状态"><a href="#java-线程的状态" class="headerlink" title="java 线程的状态"></a><strong>java 线程的状态</strong></h4><ul>
<li><strong>new</strong>：线程创建，还没调用 start 方法。</li>
<li><strong>runnable</strong>：（操作系统中的就绪，运行）new–调用 start–ready-<strong>-获得 cpu 时间片</strong>–running</li>
<li><strong>blocked</strong>：阻塞。调用同步方法，在没获取到锁的情况下会阻塞。</li>
<li><strong>waitting</strong>：等待其他线程做一些操作。wait</li>
<li><strong>time_waiting</strong>：超时等待。-wait，sleep，超时时间到后，进入 runnable。</li>
<li><strong>terminated</strong>：线程执行完毕。</li>
</ul>
<p><strong>wait&#x2F;notify 属于 Object 类。</strong></p>
<p><img src="https://i.loli.net/2021/08/03/BhDXCyWdjGSMvuR.png" alt="image-20210803151242958"></p>
<h3 id="创建线程的方式"><a href="#创建线程的方式" class="headerlink" title="创建线程的方式"></a>创建线程的方式</h3><p><strong>继承 thread 类</strong>，重写 run（）方法，调用子类的 start（）。</p>
<p>为什么调用的是 start，执行的确是 run?</p>
<p>start 表示启动该线程，进入就绪状态，成为单独的执行流。操作系统会分配相关资源。</p>
<p>直接执行 run 就相当于执行 main 中的普通方法了，就不是多线程了。</p>
<p><strong>实现 runnable 接口</strong>，重写 run，启动 start。</p>
<p>java 只支持单继承，因此引入 runnable 接口。</p>
<p><strong>通过 Callable 和 Future 创建线程。</strong>覆盖 call（）方法。</p>
<p>可以获得任务执行返回值；</p>
<ol>
<li><strong>创建 Callable 接口的实现类</strong>，并实现 call() 方法，该 call() 方法将作为线程执行体，并且有返回值。</li>
<li>创建 <strong>Callable 实现类的实例</strong>，使用 <strong>FutureTask 类来包装 Callable 对象</strong>，该 FutureTask 对象封装了该 Callable 对象的 call() 方法的返回值。</li>
<li>使用 <strong>FutureTask 对象作为 Thread 对象的 target</strong> 创建并启动新线程。</li>
<li>调用 <strong>FutureTask 对象的 get() 方法来获得子线程执行结束后的返回值</strong>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class CallableThreadTest implements Callable&lt;Integer&gt; &#123;<br>    public static void main(String[] args)&#123;  <br>        CallableThreadTest ctt = new CallableThreadTest();  <br>        FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ctt);  <br>        for(int i = 0;i &lt; 100;i++)&#123;  <br>            System.out.println(Thread.currentThread().getName()+&quot; 的循环变量i的值&quot;+i);  <br>            if(i==20)&#123;  <br>                new Thread(ft,&quot;有返回值的线程&quot;).start();  <br>            &#125;  <br>        &#125;try&#123;  <br>            System.out.println(&quot;子线程的返回值：&quot;+ft.get());  <br>        &#125; catch (InterruptedException e)&#123;  <br>            e.printStackTrace();  <br>        &#125; catch (ExecutionException e)&#123;  <br>            e.printStackTrace();  <br>        &#125;  <br>    &#125;<br>    @Override  <br>    public Integer call() throws Exception&#123;  <br>        int i = 0;  <br>        for(;i&lt;100;i++)&#123;  <br>            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  <br>        &#125;  <br>        return i;  <br>    &#125;  <br>&#125;<br></code></pre></td></tr></table></figure>

<p>通过与 Future 的结合，可以实现利用 Future 来跟踪异步计算的结果。</p>
<p>JDK5.0 新特性。需要借助 Future 接口的唯一实现类<strong>FutureTask</strong>辅助线程的对象创建和返回值获取（FutureTask 还实现了 Runnable 接口），再创建 Thread 对象，将 FutureTask 类的对象作为构造器参数传入，完成线程的创建，最后调用 start()方法完成线程启动。</p>
<p><strong>Runnable 和 Callable 的区别：</strong></p>
<p>1、Callable 规定的方法是 call(),  Runnable 规定的方法是 run()<br>2、Callable 的任务执行后可返回值，而 Runnable 的任务是不能返回值<br>3、call 方法可以抛出异常，run 方法不可以<br>4、运行 Callable 任务可以拿到一个 Future 对象，<strong>表示异步计算的结果。</strong>它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过 Future 对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果</p>
<p><strong>使用线程池。</strong></p>
<p>使用线程池，提前创建好多个线程放入线程池中，使用时直接获取，使用完放回线程池中。可以做到提高响应速度（减少线程创建的时间）和降低资源消耗（可重复利用线程）。利用 Executors 工具类创建线程池，然后提供 Runnable(excute())或 Callable(submit())接口的实现类的对象，执行指定线程的操作。最后，关闭线程池 shutdown()。</p>
<h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><h4 id="为什么会有内存屏障"><a href="#为什么会有内存屏障" class="headerlink" title="为什么会有内存屏障"></a>为什么会有内存屏障</h4><p>每个 CPU 都会有自己的缓存（有的甚至 L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显<strong>：不能实时的和内存发生信息交换</strong>，分在不同 CPU 执行的不同线程对同一个变量的缓存值不同。</p>
<p>用 volatile 关键字修饰变量可以解决上述问题，那么 volatile 是如何做到这一点的呢？那就是<strong>内存屏障</strong>，内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不是一样，java 通过屏蔽这些差异，统一由 jvm 来生成内存屏障的指令。</p>
<h4 id="内存屏障是什么"><a href="#内存屏障是什么" class="headerlink" title="内存屏障是什么"></a>内存屏障是什么</h4><p>硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier 即<strong>读屏障和写屏障。</strong></p>
<p><strong>内存屏障有两个作用：</strong></p>
<p>阻止屏障两侧的指令重排序；<br>强制把写缓冲区&#x2F;高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。</p>
<p>对于 Load Barrier 来说，在指令前插入 Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；<br>对于 Store Barrier 来说，在指令后插入 Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。</p>
<h4 id="java-内存屏障"><a href="#java-内存屏障" class="headerlink" title="java 内存屏障"></a>java 内存屏障</h4><p>java 的内存屏障通常所谓的四种即 LoadLoad,StoreStore,LoadStore,StoreLoad 实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。</p>
<p><strong>volatile 语义中的内存屏障</strong></p>
<p>volatile 的内存屏障策略非常严格保守，<strong>非常悲观</strong>：<br>在每个 volatile 写操作前插入 StoreStore 屏障，在写操作后插入 StoreLoad 屏障；<br>在每个 volatile 读操作前插入 LoadLoad 屏障，在读操作后插入 LoadStore 屏障；</p>
<p><strong>由于内存屏障的作用，避免了 volatile 变量和其它指令重排序、线程之间实现了通信，使得 volatile 表现出了锁的特性</strong>。</p>
<h4 id="final-语义中的内存屏障"><a href="#final-语义中的内存屏障" class="headerlink" title="final 语义中的内存屏障"></a>final 语义中的内存屏障</h4><p>对于 final 域，编译器和 CPU 会遵循两个排序规则：</p>
<p>新建对象过程中，构造体中对 final 域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序；</p>
<p>初次读包含 final 域的对象引用和读取这个 final 域，这两个操作不能重排序；（晦涩，意思就是先赋值引用，再调用 final 值）</p>
<p>​	必需保证一个对象的所有 final 域被写入完毕后才能引用和读取。这也是内存屏障的起的作用：</p>
<p>​	写 final 域：在编译器写 final 域完毕，构造体结束之前，会插入一个 StoreStore 屏障，保证前面的对 final 写入对其他线程&#x2F;CPU 可见，并阻止重排序。</p>
<p>​	读 final 域：读 final 域前插入了 LoadLoad 屏障。</p>
]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发-常见关键字</title>
    <url>/2021/07/30/Java%E5%B9%B6%E5%8F%91-%E5%B8%B8%E8%A7%81%E5%85%B3%E9%94%AE%E5%AD%97/</url>
    <content><![CDATA[<h3 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h3><p>见《线程安全的机制》</p>
<h3 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h3><p>CAS 是英文单词 CompareAndSwap 的缩写，中文意思是：比较并替换。CAS 需要有 3 个操作数：内存地址 V，旧的预期值 A，即将要更新的目标值 B。</p>
<p>CAS 指令执行时，当且仅当内存地址 V 的值与预期值 A 相等时，将内存地址 V 的值修改为 B，否则就什么都不做。整个比较并替换的操作是一个原子操作。</p>
<p>CAS 虽然很高效的解决了原子操作问题，但是 CAS 仍然存在三大问题。</p>
<p><strong>循环时间长开销很大。</strong><br><strong>只能保证一个共享变量的原子操作。</strong><br><strong>ABA 问题。</strong></p>
<p><strong>如果 CAS 失败，会一直进行尝试</strong>。如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销。</p>
<p>当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁来保证原子性。</p>
<p>如果值曾经被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。这个漏洞称为 CAS 操作的“ABA”问题。</p>
<p>Java 并发包为了解决这个问题，提供了一个<strong>带有标记的原子引用类“AtomicStampedReference”，</strong>它可以通过<strong>控制变量值的版本</strong>来保证 CAS 的正确性。因此，在使用 CAS 前要考虑清楚“ABA”问题是否会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。</p>
<h3 id="AQS-抽象队列同步器"><a href="#AQS-抽象队列同步器" class="headerlink" title="AQS-抽象队列同步器"></a>AQS-抽象队列同步器</h3><p><img src="https://i.loli.net/2021/08/03/ovkD8F5rExbgpBq.png" alt="image-20210803192200462"></p>
<p><strong>AQS 核心思想是，</strong>如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。<strong>如果被请求的共享资源被占用</strong>，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 <strong>CLH 队列锁</strong>实现的，即将暂时获取不到锁的线程加入到队列中。</p>
<p>CLH(Craig,Landin,and Hagersten)队列是一个<strong>虚拟的双向队列</strong>（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将<strong>每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点</strong>（Node）来实现锁的分配。</p>
<p><img src="https://i.loli.net/2021/08/05/FMUxJCKm7Gkn8Hv.png" alt="image-20210805140155989"></p>
<p>AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。</p>
<h4 id="节点状态"><a href="#节点状态" class="headerlink" title="节点状态"></a>节点状态</h4><p>nt waitStatus：</p>
<p>1、<strong>CANCELLED</strong>，值为 1 。场景：当该线程<strong>等待超时或者被中断，需要从同步队列中取消等待</strong>，则该线程被置 1，即被取消（这里该线程在取消之前是等待状态）。节点进入了取消状态则不再变化；</p>
<p>2、<strong>SIGNAL</strong>，值为-1。场景：<strong>后继的节点处于等待状态</strong>，当前节点的线程如果释放了同步状态或者被取消（当前节点状态置为-1），将会通知后继节点，使后继节点的线程得以运行；</p>
<p>3、<strong>CONDITION</strong>，值为-2。场景：<strong>节点处于等待队列中，节点线程等待在 Condition 上，</strong>当其他线程对 Condition 调用了 signal()方法后，该节点从等待队列中转移到同步队列中，加入到对同步状态的获取中；</p>
<p>4、<strong>PROPAGATE</strong>，值为-3。场景：表示<strong>下一次的共享状态会被无条件的传播下去</strong>；</p>
<p>5、<strong>INITIAL</strong>，值为 0，初始状态。</p>
<h4 id="AQS-对资源的共享方式"><a href="#AQS-对资源的共享方式" class="headerlink" title="AQS 对资源的共享方式"></a>AQS 对资源的共享方式</h4><p><strong>AQS 定义两种资源共享方式</strong></p>
<h5 id="Exclusive（独占）"><a href="#Exclusive（独占）" class="headerlink" title="Exclusive（独占）"></a>Exclusive（独占）</h5><p><strong>只有一个线程能执行</strong>，如 ReentrantLock。又可分为公平锁和非公平锁，ReentrantLock 同时支持两种锁，下面以 ReentrantLock 对这两种锁的定义做介绍：</p>
<p>公平锁 ：<strong>按照线程在队列中的排队顺序，先到者先拿到锁</strong><br>非公平锁 ：当线程要获取锁时，先通过<strong>两次 CAS 操作去抢锁</strong>，如果没抢到，当前线程再加入到队列中等待唤醒。</p>
<p>ReentrantLock 默认采用<strong>非公平锁</strong>，<strong>因为考虑获得更好的性能</strong>，通过 boolean 来决定是否用公平锁（传入 true 用公平锁）。</p>
<p>非公平锁在<strong>调用 lock</strong> 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。<br>非公平锁<strong>在 CAS 失败后</strong>，和公平锁一样都会进入到 <strong>tryAcquire 方法</strong>，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state &#x3D;&#x3D; 0），<strong>非公平锁会直接 CAS 抢锁</strong>，<strong>但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。</strong></p>
<p>公平锁和非公平锁就这两点区别，<strong>如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。</strong></p>
<p>相对来说，<strong>非公平锁会有更好的性能，因为它的吞吐量比较大</strong>。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。</p>
<h5 id="Share（共享）"><a href="#Share（共享）" class="headerlink" title="Share（共享）"></a>Share（共享）</h5><p>多个线程可同时执行，如 Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 。</p>
<p>ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读。</p>
<p>不同的<strong>自定义同步器</strong>争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队&#x2F;唤醒出队等），AQS 已经在上层已经帮我们实现好了。</p>
<h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>Java 实现锁有两种语法<strong>，一种是 synchronized 语句，另外一种是 reentrantlock 关键字</strong>。</p>
<h4 id="公平锁-x2F-非公平锁"><a href="#公平锁-x2F-非公平锁" class="headerlink" title="公平锁&#x2F;非公平锁"></a>公平锁&#x2F;非公平锁</h4><p>公平锁指<strong>多个线程按照申请锁的顺序获得锁。</strong></p>
<p>非公平锁指多个线程获得锁的顺序不按照申请顺序。</p>
<p>Java reentranthlock 通过构造函数来指定锁是公平还是非公平，默认是非公平锁，对于 synchronized 而言，也是一种非公平锁。</p>
<p><strong>非公平锁优点在于吞吐量比公平锁大。</strong></p>
<h4 id="可重入锁"><a href="#可重入锁" class="headerlink" title="可重入锁"></a>可重入锁</h4><p>可重入锁又叫递归锁，是指同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。</p>
<p>Synchronized 也是一个可重入锁。</p>
<p>可重入锁的优点是可以一定程度避免死锁。</p>
<h4 id="独享锁-x2F-共享锁"><a href="#独享锁-x2F-共享锁" class="headerlink" title="独享锁&#x2F;共享锁"></a>独享锁&#x2F;共享锁</h4><p>独享锁是指该锁一次只能被一个线程所持有，共享锁可以被多个线程所持有。</p>
<p>Java reentrantlock 是一个独享锁，但是对于 lock 的另一个实现 readwritelock，其读锁是一个共享锁，写锁是一个独享锁。</p>
<p>对于 synchronized 是一个独享锁。</p>
<h4 id="互斥锁-x2F-读写锁"><a href="#互斥锁-x2F-读写锁" class="headerlink" title="互斥锁&#x2F;读写锁"></a>互斥锁&#x2F;读写锁</h4><p>互斥锁在 Java 中具体实现就是 reentrantlock。</p>
<p>读写锁在 Java 中的具体实现就是 readwritelock。</p>
<h4 id="乐观锁-x2F-悲观锁"><a href="#乐观锁-x2F-悲观锁" class="headerlink" title="乐观锁&#x2F;悲观锁"></a>乐观锁&#x2F;悲观锁</h4><p>乐观锁和悲观锁不是指具体的锁类型，而是对于看待并发编程中加锁问题的角度。</p>
<p>悲观锁认为，对于一个数据的并发操作，一定会改变数据，即使实际上数据没被改变，但是也悲观的认为被改变的可能性比较大，一定要加锁，不加锁早晚要出问题。</p>
<p>乐观锁认为，对于一个数据的并发操作，是不会改变数据的，不加锁也不会出问题。</p>
<p>乐观锁指 java 中的无所编程，适合读操作非常多的场景。</p>
<p>悲观锁就是指 java 中，适合并发下写非常多的场景。</p>
<h4 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h4><p>在 java 中，自旋锁是指尝试获取锁的线程不会立即阻塞，<strong>而是采用循环的方式去尝试获取锁</strong>，当循环条件被其他线程改变时，才能进入临界区。这样的好处是减少线程上下文切换的消耗，<strong>缺点是会消耗 CPU。</strong></p>
<p>由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用 CPU 时间。<strong>如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。</strong></p>
<h4 id="偏向锁-x2F-轻量级锁-x2F-重量级锁"><a href="#偏向锁-x2F-轻量级锁-x2F-重量级锁" class="headerlink" title="偏向锁&#x2F;轻量级锁&#x2F;重量级锁"></a>偏向锁&#x2F;轻量级锁&#x2F;重量级锁</h4><p>这三种锁，就是指锁的状态，针对 synchronized。</p>
<p>偏向锁是<strong>指一段代码一直被一个线程所访问</strong>，那么理论上，这个线程会自动获取这个锁，并一直拥有这个锁，这样就降低了获取锁的代价。</p>
<p>轻量级锁是指当偏向锁的状态下，<strong>被另一个线程访问</strong>，偏向锁就会升级为<strong>轻量级锁</strong>，其他线程会通过自旋形式尝试获取锁，不会阻塞，提高效率。</p>
<p>重量级锁是指在轻量级锁的状态下，<strong>另一个线程虽然自旋</strong>，但不会一直持续下去，当自旋一定次数的时候还没有获取到锁的话，<strong>就会进入阻塞</strong>，该锁就会膨胀为重量级锁，重量级锁会让其他申请的线程陷入阻塞，降低性能。</p>
]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>关键字</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发-并发容器</title>
    <url>/2021/07/30/Java%E5%B9%B6%E5%8F%91-%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<h2 id="同步容器"><a href="#同步容器" class="headerlink" title="同步容器"></a>同步容器</h2><h3 id="collections-中有一些方法"><a href="#collections-中有一些方法" class="headerlink" title="collections 中有一些方法"></a>collections 中有一些方法</h3><p>synchronizedlist：</p>
<p>synchronizedmap：</p>
<p>synchronizedcollection：</p>
<p>在遍历时容器发生了结构性变化，会报错。</p>
<h2 id="写时复制的的-List-和-Set"><a href="#写时复制的的-List-和-Set" class="headerlink" title="写时复制的的 List 和 Set"></a>写时复制的的 List 和 Set</h2><p>copyonwritearraylist</p>
<p>copyonwritearrayset</p>
<p>线程安全</p>
<p>迭代器不支持修改</p>
<p>每次修改时都会新建一个数组，复制进去。读都会访问原来的数组。</p>
<p>基于 reentrantlock 实现</p>
<p>不适合大数组</p>
<p><strong>适合大部分访问都是读的情况</strong></p>
<h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>jdk 以前 concurrenthashmap 是分段的数组+链表实现。<br>实现线程安全的方式：</p>
<p>1，在 JDK1.7 的时候， ConcurrentHashMap （分段锁）对整个桶数组进⾏了分割分段，每⼀把锁只锁容器其中⼀部分数据，<strong>多线程访问容器⾥不同数据段的数据，就不会存在锁竞争，提⾼并发访问率</strong>。<br>一个 concurrenthashmap 里面包含一个 segment 数组。一个 segment 包含一个 hashentry 数组。</p>
<p>核心：</p>
<p><strong>分段锁</strong></p>
<p><strong>读不需要锁</strong></p>
<p><img src="https://i.loli.net/2021/08/03/BJEfHT8bwkLeaMh.png" alt="image-20210803181948397"></p>
<p> 2，JDK1.8 的时候已经摒弃了 Segment 的概念，⽽是直接⽤ <strong>Node 数组+链表&#x2F;红⿊树</strong>的数据结构来实现，并发控制使⽤ synchronized 和 CAS 来操作。<br>synchronized 只会锁定当前链表或者红黑树的首节点。效率大大提高。</p>
<h3 id="迭代器弱一致性？"><a href="#迭代器弱一致性？" class="headerlink" title="迭代器弱一致性？"></a>迭代器弱一致性？</h3><p>遍历时，内部元素变化发生在已经遍历过的部分，不会体现出来。</p>
<p><img src="https://i.loli.net/2021/08/03/zgxDwuEOSZrRkPV.png" alt="image-20210803182140097"></p>
<p>3，hashtable 是同一把锁，全表锁。</p>
<h2 id="基于跳表的-Map-和-Set"><a href="#基于跳表的-Map-和-Set" class="headerlink" title="基于跳表的 Map 和 Set"></a>基于跳表的 Map 和 Set</h2><p>concurrentskiplistmap&#x3D;&#x3D;treemap</p>
<p>concurrentskiplistset&#x3D;&#x3D;treeset</p>
<p>跳表更加容易实现高效并发</p>
<p>没有使用锁，所有的操作都可以并发</p>
<p>他们的 size（）方法复杂度为 o（n），并且结果也不一定准确</p>
<h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>基于链表+多层索引</p>
<p>类似二分查找</p>
<h2 id="并发队列"><a href="#并发队列" class="headerlink" title="并发队列"></a>并发队列</h2><p><strong>无锁非阻塞：不用锁，所有操作都可以立即执行，主要通过循环 CAS 实现并发安全。</strong></p>
<p><strong>阻塞队列：使用锁和条件。很多操作都要获得锁或者满足条件再返回。不满足或者未获得锁就会阻塞。</strong></p>
<p>都是弱一致性的。遍历时遍历过的内容改变了不会显示。</p>
<h4 id="无锁非阻塞并发队列"><a href="#无锁非阻塞并发队列" class="headerlink" title="无锁非阻塞并发队列"></a>无锁非阻塞并发队列</h4><p>concurrentlinkedqueue</p>
<p>cocurrentlinkeddeque</p>
<p>基于链表，没有大小限制</p>
<p>基于循环 cas</p>
<h4 id="普通阻塞队列"><a href="#普通阻塞队列" class="headerlink" title="普通阻塞队列"></a>普通阻塞队列</h4><p>都实现了接口 blockingqueue，在入队出队时可能会等待。</p>
<p><img src="https://i.loli.net/2021/08/03/T1prKxLjmhqob5s.png" alt="image-20210803184553784"></p>
<p>arrayblockingqueue 循环数组</p>
<p>linkedblockingqueue 单向链表</p>
<p>都是使用显示锁 reentrantlock 和显示条件 condition 实现的</p>
<h4 id="优先级阻塞队列"><a href="#优先级阻塞队列" class="headerlink" title="优先级阻塞队列"></a>优先级阻塞队列</h4><p>按照优先级出队。</p>
<h4 id="延时阻塞队列"><a href="#延时阻塞队列" class="headerlink" title="延时阻塞队列"></a>延时阻塞队列</h4><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4>]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>并发容器</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发-线程安全的机制</title>
    <url>/2021/08/03/Java%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2><p><strong>解决多个线程访问资源的同步性。可以保证被他修饰的方法或者代码块在任意时刻只有一个线程执行。</strong></p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>synchronized 同步语句块的实现使⽤的是 <strong>monitorenter 和 monitorexit</strong> 指令，其中 monitorenter 指令指向同步代码块的开始位置， monitorexit 指令则指明同步代码块的结束位置。</p>
<p>当执⾏ monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。<br>在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由 ObjectMonitor 实现的。每个对象中都内置了⼀个 ObjectMonitor 对象。</p>
<p>另外， <strong>wait&#x2F;notify 等⽅法也依赖于 monitor 对象</strong>，这就是为什么只有在同步的块或者⽅法中才能调⽤ wait&#x2F;notify 等⽅法，否则会抛出 java.lang.IllegalMonitorStateException 的异常的原因。</p>
<p>在执⾏ monitorenter 时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。<br>在执⾏ monitorexit 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外⼀个线程释放为⽌。</p>
<p>sc<strong>ACC_SYNCHRONIZED 标识，</strong>该标识指明了该⽅法是⼀个同步⽅法。JVM 通过该访问标志来辨别⼀个⽅法是否声明为同步⽅法，从⽽执⾏相应的同步调⽤。</p>
<p> <strong>两者的本质都是对对象监视器 monitor 的获取 。</strong></p>
<h4 id="sychronized-改进"><a href="#sychronized-改进" class="headerlink" title="sychronized 改进"></a>sychronized 改进</h4><p>java1.6 以后，引入了偏向锁和轻量级锁。</p>
<p>锁有四种状态：无锁，偏向锁，轻量级锁，重量级锁，可以升级，不能降级。</p>
<p><img src="https://i.loli.net/2021/08/13/UcrKuk24wXRVOT8.png" alt="image-20210813150959660"></p>
<h4 id="可重入性"><a href="#可重入性" class="headerlink" title="可重入性"></a>可重入性</h4><p>通过记录锁的持有线程和持有数量实现。</p>
<h4 id="内存可见性"><a href="#内存可见性" class="headerlink" title="内存可见性"></a>内存可见性</h4><p>释放锁时所有的写入操作都会写回内存。获得锁后，都会从内存里读取数据。</p>
<p>如果只是保证内存可见性，volatile 即可（加上后 java 会在操作对应变量时插入特殊指令）</p>
<h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>避免在持有一个锁时申请另一个锁。</p>
<p>jstack 报告死锁</p>
<p>使用方法：</p>
<ul>
<li><p>修饰实例方法。锁的是实例对象（this）。</p>
</li>
<li><p>修饰静态方法。锁的是 Class 类对象。</p>
</li>
<li><p>修饰代码块。指定加锁对象。</p>
</li>
</ul>
<p>如果⼀个线程 A 调⽤⼀个实例对象的<strong>⾮静态 synchronized ⽅法</strong>，⽽线程 B 需要调⽤<strong>这个实例对象所属类的静态 synchronized ⽅法</strong>，是允许的，不会发⽣互斥现象，因为访问<strong>静态 synchronized ⽅法</strong>占⽤的锁是当前类的锁，⽽访问<strong>⾮静态 synchronized ⽅法占⽤的锁</strong>是当前实例对象锁 。</p>
<p><img src="https://i.loli.net/2021/08/03/13xPdpflDO6yBaC.png" alt="image-20210803220907606"></p>
<h2 id="显示锁"><a href="#显示锁" class="headerlink" title="显示锁"></a>显示锁</h2><p>接口：lock，实现类：reentrantlock</p>
<p>接口：readwritelock，实现类：reentrantreadwritelock</p>
<p><img src="https://i.loli.net/2021/08/03/k9nquVjWSlchbTF.png" alt="image-20210803191609899"></p>
<p>显示锁支持非阻塞的方式获取锁，可以响应中断，限时，因此更加灵活。</p>
<p>使用 trylock 可以避免死锁</p>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>依赖于 cas，juc 下的 locksupport</p>
<p>主要方法：park，unpark</p>
<h4 id="对比-sychronized-和-reentrantlock"><a href="#对比-sychronized-和-reentrantlock" class="headerlink" title="对比 sychronized 和 reentrantlock"></a>对比 sychronized 和 reentrantlock</h4><p><img src="https://i.loli.net/2021/08/03/bsiRn2areV5ltPx.png" alt="image-20210803192404150"></p>
<p><img src="https://i.loli.net/2021/08/03/K7TxSYfRDXjFEqi.png" alt="image-20210803220931642"></p>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><p>获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。</p>
<p>它可以用来修饰成员变量和静态成员变量，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。即一个线程对 volatile 变量的修改，对另一个线程可见。</p>
<p>volatile 仅仅保证了共享变量的可见性，让其它线程能够看到最新值，但不能解决指令交错问题（不能保证原子性）</p>
<p>CAS 必须借助 volatile 才能读取到共享变量的最新值来实现【比较并交换】的效果</p>
<p><strong>为什么无锁效率高</strong></p>
<p>无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时候<strong>，发生上下文切换，进入阻塞。</strong></p>
<p>但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入可运行状态，还是会导致上下文切换。（多核）</p>
<p><img src="https://i.loli.net/2021/08/03/Pts1kLSAliZpzXR.png" alt="image-20210803220954272"></p>
<h2 id="原子变量以及-CAS"><a href="#原子变量以及-CAS" class="headerlink" title="原子变量以及 CAS"></a>原子变量以及 CAS</h2><p>结合 CAS 和 volatile 可以实现<strong>无锁并发</strong>，适用于线程数少、多核 CPU 的场景下。</p>
<p><strong>cas+volatile 可以实现原子变量</strong></p>
<p>CAS 是基于<strong>乐观锁</strong>的思想：最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，再重试。</p>
<p>synchronized 是基于悲观锁的思想：最悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。</p>
<p>CAS 体现的是无锁并发、无阻塞并发</p>
<p>因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一<br>但如果<strong>竞争激烈</strong>，可以想到重试必然频繁发生，反而效率会受影响</p>
<h3 id="ABA-问题"><a href="#ABA-问题" class="headerlink" title="ABA 问题"></a>ABA 问题</h3><p>CAS 更新：a-b-a，当前线程的 CAS 操作无法分辨。</p>
<p>解决：时间戳</p>
<p><img src="https://i.loli.net/2021/08/03/Wbrt63ATpcDCyR8.png" alt="image-20210803221011726"></p>
<h2 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h2><p><img src="https://i.loli.net/2021/08/03/TGsg6aUoNSQCP1V.png" alt="image-20210803221023698"></p>
<h2 id="threadlocal"><a href="#threadlocal" class="headerlink" title="threadlocal"></a>threadlocal</h2><p>threadlocal 而是一个线程内部的存储类，可以在指定线程内存储数据，数据存储以后，只有指定线程可以得到存储数据。</p>
<p>ThreadLocal 的作⽤主要是做<strong>数据隔离</strong>，填充的数据只属于当前线程，变量的数据对别的线程⽽⾔是相对隔离的，在多线程环境下，如何防⽌⾃⼰的变量被其它线程篡改。</p>
<p>对于某一 ThreadLocal 来讲，他的索引值 i 是确定的，在不同线程之间访问时访问的是不同的 table 数组的同一位置即都为 table[i]，只不过这个不同线程之间的 table 是独立的。</p>
<p>对于<strong>同一线程的不同 ThreadLocal</strong>来讲，这些 ThreadLocal 实例<strong>共享一个 table 数组</strong>，然后每个 ThreadLocal 实例在 table 中的索引 i 是不同的。</p>
<p>ThreadLocal 和 Synchronized 都是为了解决多线程中相同变量的访问冲突问题，不同的点是：</p>
<p>Synchronized 是通过线程等待，牺牲时间来解决访问冲突<br>ThreadLocal 是通过每个线程单独一份存储空间，牺牲空间来解决冲突，并且相比于 Synchronized，ThreadLocal 具有线程隔离的效果，只有在线程内才能获取到对应的值，线程外则不能访问到想要的值。</p>
<h3 id="ThreadLocalMap-底层结构？"><a href="#ThreadLocalMap-底层结构？" class="headerlink" title="ThreadLocalMap 底层结构？"></a>ThreadLocalMap 底层结构？</h3><p><img src="https://i.loli.net/2021/08/03/a6N28GoWUrV3A1Q.png" alt="计算机生成了可选文字: ThreadLocals ThreadLocalMap  Entry "></p>
<p>未实现 Map 接⼝，⽽且他的 Entry 是继承 WeakReference（弱引⽤）的，也没有 HashMap 中的 next（无链表）</p>
<p><strong>为什么是数组结构？</strong></p>
<p><strong>⼀个线程可以有多个 TreadLocal</strong>来存放不同类型的对象的，但是他们都将放到你当前线程的 ThreadLocalMap⾥，所以肯定要数组。</p>
<p><strong>解决 hash 冲突？</strong></p>
<p><img src="https://i.loli.net/2021/08/03/QCvWehaPHJwrOt6.png" alt="计算机生成了可选文字: Entry  ThreadLocals  Thread  Entry  新 增  如 不 为 空 ， üThreadLocal  不 相 ， 下 一 个 为 空 的 位  不 为 空 判 斷 仆 readLocal  本 身 矍 否 相 等 相 等 翩 新  3 "></p>
<p>在 get 的时候，也会根据 ThreadLocal 对象的 hash 值，定位到 table 中的位置，然后判断该位置 Entry 对象中的 key 是否和 get 的 key⼀致，如果不⼀致，就判断下⼀个位置，set 和 get 如果冲突严重的话，效率还是很低的。</p>
<p><strong>对象存放在哪⾥么？</strong></p>
<p>在 Java 中，栈内存归属于单个线程，每个线程都会有⼀个栈内存，其存储的变量只能在其所属线程中可<br>⻅，即栈内存可以理解成线程的私有内存，⽽堆内存中的对象对所有线程可⻅，堆内存中的对象可以被<br>所有线程访问。</p>
<p><strong>ThreadLocal 的实例以及其值存放在栈上呢？</strong></p>
<p>其实不是的，因为 ThreadLocal 实例实际上也是被其创建的类持有（更顶端应该是被线程持有），⽽<br>ThreadLocal 的值其实也是被线程实例持有，<strong>它们都是位于堆上，只是通过⼀些技巧将可⻅性修改成了</strong><br><strong>线程可⻅。</strong></p>
<p><strong>共享线程的 ThreadLocal 数据怎么办？</strong></p>
<p>使⽤ <strong>InheritableThreadLocal</strong> 可以实现多个线程访问 ThreadLocal 的值，我们在主线程中创建⼀个 InheritableThreadLocal 的实例，然后在⼦线程中得到这个 InheritableThreadLocal 实例设置的值。</p>
<p>如果线程的 inheritThreadLocals 变量不为空，⽽且⽗线程的 inheritThreadLocals 也存在，那么就把⽗线程的 inheritThreadLocals 给当前线程的 inheritThreadLocals 。</p>
<p><strong>问题？</strong></p>
<p>只具有弱引⽤的对象拥有更短暂的⽣命周期，在垃圾回收器线程扫描它所管辖的内存区域的过程中，⼀旦发现了只具有弱引⽤的对象，不管当前内存空间⾜够与否，都会回收它的内存。不过，由于垃圾回收器是⼀个优先级很低的线程，因此不⼀定会很快发现那些只具有弱引⽤的对象。</p>
<p>这就导致了⼀个问题，ThreadLocal 在没有外部强引⽤时，发⽣GC 时会被回收，如果创建 ThreadLocal 的线程⼀直持续运⾏，那么这个 Entry 对象中的 value 就有可能⼀直得不到回收，发⽣内存泄露。<br>就⽐如线程池⾥⾯的线程，线程都是复⽤的，那么之前的线程实例处理完之后，出于复⽤的⽬的线程依然存活，所以，ThreadLocal 设定的 value 值被持有，导致内存泄露。</p>
<p><strong>解决：</strong>⼀个线程使⽤完，ThreadLocalMap 是应该要被清空的，手动调用 remove（）方法。</p>
]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>机制</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础-Java集合框架</title>
    <url>/2021/07/30/Java%E5%9F%BA%E7%A1%80-Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h2 id="集合框架"><a href="#集合框架" class="headerlink" title="集合框架"></a>集合框架</h2><p><img src="https://i.loli.net/2021/08/04/6xejDEtAQKSRpwv.png" alt="image-20210804212935827"></p>
<p><img src="https://i.loli.net/2021/08/04/leZ9CILv4hTbsYz.png" alt="image-20210804213053882"></p>
<h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><p>在 JDK 1.8，HashMap 底层是由 “数组+链表+红黑树” 组成，如下图所示，而在 JDK 1.8 之前是由 “数组+链表” 组成。</p>
<p>使用 “数组+链表” 是为了解决 hash 冲突的问题。</p>
<p>数组和链表有如下特点：</p>
<p>数组：查找容易，通过 index 快速定位；插入和删除困难，需要移动插入和删除位置之后的节点；<br>链表：查找困难，需要从头结点或尾节点开始遍历，直到寻找到目标节点；插入和删除容易，只需修改目标节点前后节点的 next 或 prev 属性即可；</p>
<p>HashMap 巧妙的将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做 “拉链法” 的方式来解决哈希冲突。<br>首先通过 index 快速定位到索引位置，这边利用了数组的优点；然后遍历链表找到节点，进行节点的新增&#x2F;修改&#x2F;删除操作，这边利用了链表的优点。</p>
<h3 id="为什么要改成“数组-链表-红黑树”？"><a href="#为什么要改成“数组-链表-红黑树”？" class="headerlink" title="为什么要改成“数组+链表+红黑树”？"></a>为什么要改成“数组+链表+红黑树”？</h3><p>“数组+链表” 在定位到索引位置后，需要先遍历链表找到节点，这个地方如果链表很长的话，也就是 hash 冲突很严重的时候，会有查找性能问题，因此在 JDK1.8 中，通过引入红黑树，来优化这个问题。<br>使用链表的查找性能是 O(n)，而使用红黑树是 O(logn)。</p>
<h3 id="那在什么时候用链表？什么时候用红黑树？"><a href="#那在什么时候用链表？什么时候用红黑树？" class="headerlink" title="那在什么时候用链表？什么时候用红黑树？"></a>那在什么时候用链表？什么时候用红黑树？</h3><p>对于插入，默认情况下是使用链表节点。当同一个索引位置的节点在新增后超过 8 个（阈值 8）：如果此时数组长度大于等于 64，则会触发链表节点转红黑树节点（treeifyBin）；而如果数组长度小于 64，则不会触发链表转红黑树，而是会进行扩容，因为此时的数据量还比较小。</p>
<p>对于移除，当同一个索引位置的节点在移除后<strong>达到 6 个（阈值 6）</strong>，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点（untreeify）。</p>
<h3 id="为什么链表转红黑树的阈值是-8？"><a href="#为什么链表转红黑树的阈值是-8？" class="headerlink" title="为什么链表转红黑树的阈值是 8？"></a>为什么链表转红黑树的阈值是 8？</h3><p>我们平时在进行方案设计时，必须考虑的两个很重要的因素是：时间和空间。对于 HashMap 也是同样的道理，简单来说，阈值为 8 是在时间和空间上权衡的结果。</p>
<p>红黑树节点大小约为链表节点的 2 倍，在节点太少时，红黑树的查找性能优势并不明显，付出 2 倍空间的代价不值得。</p>
<p>理想情况下，使用随机的哈希码，节点分布在 hash 桶中的频率遵循泊松分布，按照泊松分布的公式计算，链表中<strong>节点个数为 8 时的概率</strong>为 0.00000006，这个概率足够低了，并且到 8 个节点时，红黑树的性能优势也会开始展现出来，因此 8 是一个较合理的数字。</p>
<h3 id="那为什么转回链表节点是用的-6-而不是复用-8？"><a href="#那为什么转回链表节点是用的-6-而不是复用-8？" class="headerlink" title="那为什么转回链表节点是用的 6 而不是复用 8？"></a>那为什么转回链表节点是用的 6 而不是复用 8？</h3><p>如果我们设置节点多于 8 个转红黑树，少于 8 个就马上转链表，<strong>当节点个数在 8 徘徊时，就会频繁进行红黑树和链表的转换，造成性能的损耗。</strong></p>
<h3 id="HashMap-有哪些重要属性？分别用于做什么的？"><a href="#HashMap-有哪些重要属性？分别用于做什么的？" class="headerlink" title="HashMap 有哪些重要属性？分别用于做什么的？"></a>HashMap 有哪些重要属性？分别用于做什么的？</h3><p>除了用来存储我们的节点 table 数组外，HashMap 还有以下几个重要属性：<br>1）size：HashMap 已经存储的节点个数；<br>2）<strong>threshold</strong>：1）扩容阈值（主要），当 HashMap 的个数达到该值，触发扩容。2）初始化时的容量，在我们新建 HashMap 对象时， threshold 还会被用来存初始化时的容量。HashMap 直到我们第一次插入节点时，才会对 table 进行初始化，避免不必要的空间浪费。<br>3）<strong>loadFactor</strong>：负载因子，扩容阈值 &#x3D; 容量 * 负载因子。</p>
<h3 id="HashMap-的默认初始容量是多少？HashMap-的容量有什么限制吗？"><a href="#HashMap-的默认初始容量是多少？HashMap-的容量有什么限制吗？" class="headerlink" title="HashMap 的默认初始容量是多少？HashMap 的容量有什么限制吗？"></a>HashMap 的默认初始容量是多少？HashMap 的容量有什么限制吗？</h3><p>默认初始容量是 16。HashMap 的容量必须是 2 的 N 次方，HashMap 会根据我们传入的容量计算一个“大于等于该容量的最小的 2 的 N 次方”，例如传 16，容量为 16；传 17，容量为 32。</p>
<h3 id="HashMap-的容量必须是-2-的-N-次方，这是为什么？"><a href="#HashMap-的容量必须是-2-的-N-次方，这是为什么？" class="headerlink" title="HashMap 的容量必须是 2 的 N 次方，这是为什么？"></a>HashMap 的容量必须是 2 的 N 次方，这是为什么？</h3><p>计算索引位置的公式为：**(n - 1) &amp; hash**</p>
<p>当 n 为 2 的 N 次方时，n - 1 为低位全是 1 的值，此时任何值跟 n - 1 进行 &amp; 运算的结果为该值的低 N 位，达到了和取模同样的效果，实现了均匀分布。</p>
<p>实际上，这个设计就是基于式：<br><strong>x mod 2^n &#x3D; x &amp; (2^n - 1)，因为 &amp; 运算比 mod 具有更高的效率。</strong></p>
<h3 id="插入流程"><a href="#插入流程" class="headerlink" title="插入流程"></a>插入流程</h3><p><img src="https://i.loli.net/2021/08/04/CDL1MPFjsV5k9Tw.png" alt="image-20210804211704324"></p>
<h3 id="ConcurrenHashMap，1-7-和-1-8-的区别"><a href="#ConcurrenHashMap，1-7-和-1-8-的区别" class="headerlink" title="ConcurrenHashMap，1.7 和 1.8 的区别"></a>ConcurrenHashMap，1.7 和 1.8 的区别</h3><p>ConcurrentHashMap 是 HashMap 的线程安全版本，和 HashMap 一样，在 JDK 1.8 中进行了较大的优化。</p>
<p>JDK1.7：底层结构为：分段的数组+链表；实现线程安全的方式：分段锁（Segment，继承 ReentrantLock），</p>
<p><img src="https://i.loli.net/2021/08/04/FliNj7RXtm2oSv5.png" alt="image-20210804212122257"></p>
<p>JDK1.8：底层结构为：数组+链表+红黑树；实现线程安全的方式：CAS + Synchronized，synchronized 只会锁定当前链表或者红黑树的首节点。效率大大提高。</p>
<p><img src="https://i.loli.net/2021/08/04/uMemQzWqZdTXxK1.png" alt="image-20210804212314272"></p>
<p><strong>区别：</strong></p>
<p>1、JDK1.8 中降低锁的粒度。JDK1.7 版本锁的粒度是基于 Segment 的，包含多个节点（HashEntry），而 JDK1.8 锁的粒度就是单节点（Node）。</p>
<p>2、JDK1.8 版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用 synchronized 来进行同步，所以不需要分段锁的概念，也就不需要 Segment 这种数据结构了，当前还保留仅为了兼容。</p>
<p>3、JDK1.8 使用红黑树来优化链表，跟 HashMap 一样，优化了极端情况下，链表过长带来的性能问题。</p>
<p>4、JDK1.8 使用内置锁 synchronized 来代替重入锁 ReentrantLock，synchronized 是官方一直在不断优化的，现在性能已经比较可观，也是官方推荐使用的加锁方式</p>
<h3 id="map-对比？"><a href="#map-对比？" class="headerlink" title="map 对比？"></a>map 对比？</h3><p><img src="https://i.loli.net/2021/08/04/jIZsbOmcCagN18q.png" alt="image-20210804212504959"></p>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><h3 id="ArrayList-和-Vector-的区别"><a href="#ArrayList-和-Vector-的区别" class="headerlink" title="ArrayList 和 Vector 的区别"></a>ArrayList 和 Vector 的区别</h3><p>Vector 和 ArrayList 的实现几乎是一样的，区别在于：</p>
<p>1）最重要的的区别：Vector 在方法上使用了 synchronized 来保证线程安全，同时由于这个原因，在性能上 ArrayList 会有更好的表现。</p>
<p>2） Vector 扩容后容量默认变为原来 2 倍，而 ArrayList 为原来的 1.5 倍。</p>
<h3 id="ArrayList-和-LinkedList-的区别？"><a href="#ArrayList-和-LinkedList-的区别？" class="headerlink" title="ArrayList 和 LinkedList 的区别？"></a>ArrayList 和 LinkedList 的区别？</h3><h4 id="arraylist-扩容"><a href="#arraylist-扩容" class="headerlink" title="arraylist 扩容"></a>arraylist 扩容</h4><p>第一种情况，当 ArrayList 的容量为 0 时，此时添加元素的话，需要扩容，三种构造方法创建的 ArrayList 在扩容时略有不同：</p>
<p>1.无参构造，创建 ArrayList 后容量为 0，添加第一个元素后，<strong>容量变为 10</strong>，此后若需要扩容，则正常扩容。</p>
<p>2.传容量构造，当参数为 0 时，创建 ArrayList 后容量为 0，添加第一个元素后，容量为 1，此时 ArrayList 是满的，下次添加元素时需正常扩容。</p>
<p>3.传列表构造，当列表为空时，创建 ArrayList 后容量为 0，添加第一个元素后，容量为 1，此时 ArrayList 是满的，下次添加元素时需正常扩容。</p>
<p>第二种情况，当 ArrayList 的容量大于 0，并且 ArrayList 是满的时，此时添加元素的话，进行正常扩容，每次扩容<strong>到原来的 1.5 倍。</strong></p>
<p>1、ArrayList 底层基于<strong>动态数组</strong>实现，LinkedList 底层基于<strong>双向链表</strong>实现。</p>
<p>2、对于<strong>随机访问（按 index 访问，get&#x2F;set 方法）</strong>：ArrayList 通过 index 直接定位到数组对应位置的节点，而 LinkedList 需要从头结点或尾节点开始遍历，直到寻找到目标节点，<strong>在效率上 ArrayList 优于 LinkedList</strong>。</p>
<p>3、对于<strong>随机插入和删除</strong>：ArrayList 需要移动目标节点后面的节点（使用 System.arraycopy 方法移动节点），而 LinkedList 只需修改目标节点前后节点的 next 或 prev 属性即可，因此在效率上 LinkedList 优于 ArrayList。</p>
<p>4、对于<strong>顺序插入和删除：由于 ArrayList 不需要移动节点，因此在效率上比 LinkedList 更好</strong>。这也是为什么在实际使用中 ArrayList 更多，因为<strong>大部分情况下我们的使用都是顺序插入。</strong></p>
<p>5、两者都不是线程安全的。</p>
<p>6、内存空间占用： ArrayList 的空 间浪费主要体现在在 list 列表的结尾会<strong>预留一定的容量空间</strong>，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。</p>
<h3 id="hashmap-对比-hashtable"><a href="#hashmap-对比-hashtable" class="headerlink" title="hashmap 对比 hashtable"></a>hashmap 对比 hashtable</h3><p>线程安全：hashmap 不安全，hashtable 安全（方法被 synchronized 修饰过）。</p>
<p>效率：hashtable 效率很低，被淘汰。</p>
<p>null key value？：hashmap 支持一个 null key。hashtable 不支持。</p>
<p>扩容：hashtable 初始：不指定的话为 11，之后变为原来的 2n+1。hashmap 初始 16，每次扩充两倍。hashmap 在指定了初始容量后会扩充为 2 的幂次大小。</p>
<p>底层：解决 hash 冲突，hashmap 在链表大于 8 会转化成红黑树（如果数组长度小于 64，会先进性扩容）。</p>
<h3 id="List、Set、Map-三者的区别"><a href="#List、Set、Map-三者的区别" class="headerlink" title="List、Set、Map 三者的区别?"></a>List、Set、Map 三者的区别?</h3><p>List（对付<strong>顺序</strong>的好帮手）： 存储的对象是可重复的、有序的。<br>Set（注重<strong>独一无二</strong>的性质）：存储的对象是不可重复的、无序的。<br>Map（<strong>用 Key 来搜索的专业户</strong>）: 存储键值对（key-value），不能包含重复的键（key），每个键只能映射到一个值</p>
<h3 id="map-遍历方式"><a href="#map-遍历方式" class="headerlink" title="map 遍历方式"></a>map 遍历方式</h3><p>HashMap 遍历从大的方向来说，可分为以下 4 类：</p>
<p><strong>迭代器（Iterator）方式遍历；</strong></p>
<p><strong>For Each 方式遍历；</strong></p>
<p><strong>Lambda 表达式遍历（JDK 1.8+）;</strong></p>
<p><strong>Streams API 遍历（JDK 1.8+）。</strong></p>
<p>使用迭代器（Iterator）<strong>EntrySet</strong> 的方式进行遍历；</p>
<p>使用迭代器（Iterator）<strong>KeySet</strong> 的方式进行遍历；</p>
<p>使用 For Each <strong>EntrySet</strong> 的方式进行遍历；</p>
<p>使用 For Each <strong>KeySet</strong> 的方式进行遍历；</p>
<p>使用 Lambda 表达式的方式进行遍历；</p>
<p>使用 Streams API <strong>单线程</strong>的方式进行遍历；</p>
<p>使用 Streams API <strong>多线程</strong>的方式进行遍历</p>
<p><img src="https://i.loli.net/2021/08/05/ZP9ot578UVrd2RN.png" alt="计算机生成了可选文字: Iterator(Map. Entry(Integer, Strlng»  (iterator.hasNext()) {  Map. Strlng) entry  ma p ． entrySet() ． iterator();  iterator ． n 巳 〔 ） ；  Sysæn. out ． println(entry ． getKey());  Sysæn. out ． println(entry ． getVa1ue()) ； "></p>
<p><img src="https://i.loli.net/2021/08/05/jNw9YtiOlCLV2Bf.png" alt="计算机生成了可选文字: map.keyset().iterator();  Iterator(Integer) Iterator  (iterator.hasNext()) {  Integer key  iterator ． n 巳 〔 ） ；  Sysæn. out ． println(key);  Sysæn. out.println(map• get 〔 k ey ） ); "></p>
<p><img src="https://i.loli.net/2021/08/05/7qwG2cHSj514gf3.png" alt="计算机生成了可选文字: (Map.Entry(lnteger, String) entry ： ma p ． entrySet()) {  Sysæn. out ． println(entry ． getKey());  Sysæn. out ． println(entry ． getVa1ue()) ； "></p>
<p><img src="https://i.loli.net/2021/08/05/qfBMmXg3ljFUEko.png" alt="计算机生成了可选文字: 〔 Integer key ： map.keySet()) {  Sysæn. out ． println(key);  Sysæn. out.println(map• get 〔 k ey ） ); "></p>
<p><img src="https://i.loli.net/2021/08/05/hrf2daRyeQqODsx.png" alt="计算机生成了可选文字: map.forEach((key, value) 一 》 {  Sysæn. out ． println(key);  Sysæn. out ． println(ualue) ； "></p>
<p><img src="https://i.loli.net/2021/08/05/oKvs6jBOxzQUZhJ.png" alt="计算机生成了可选文字: ma p ． entrySet().stream(). forEach((entry) 一 》 {  Sysæn. out ． println(entry ． getKey());  Sysæn. out ． println(entry ． getVa1ue()) ； "></p>
<p><img src="https://i.loli.net/2021/08/05/KMzILTYf1nwu8ci.png" alt="计算机生成了可选文字: ma p ． entrySet().para11e1Stream(). forEach((entry) 一 》 {  Sysæn. out ． println(entry ． getKey());  Sysæn. out ． println(entry ． getVa1ue()) ； "></p>
<p><strong>EntrySet</strong> 之所以比 <strong>KeySet</strong> 的性能高是因为，**KeySet 在循环时使用了 map.get(key)**，而 map.get(key) 相当于又遍历了一遍 Map 集合去查询 key 所对应的值。为什么要用“又”这个词？那是因为在使用迭代器或者 for 循环时，其实已经遍历了一遍 Map 集合了，因此再使用 map.get(key) 查询时，相当于遍历了两遍。</p>
<p>而 <strong>EntrySet</strong> 只遍历了一遍 Map 集合，之后通过代码“Entry&lt;Integer, String&gt; entry &#x3D; iterator.next()”把对象的 key 和 value 值都放入到了 Entry 对象中，因此再获取 key 和 value 值时就无需再遍历 Map 集合，只需要从 Entry 对象中取值就可以了。</p>
<p>所以，<strong>EntrySet 的性能比 KeySet 的性能高出了一倍</strong>，因为 KeySet 相当于循环了两遍 Map 集合，而 EntrySet 只循环了一遍。</p>
<p>我们不能在<strong>遍历中使用</strong>集合 map.remove() 来删除数据，这是非安全的操作方式，但我们可以使用迭代器的 <strong>iterator.remove() 的方法来删除数据</strong>，这是安全的删除集合的方式。</p>
<p>同样的我们也可以使用 Lambda 中的 removeIf 来提前删除数据，或者是使用 Stream 中的 filter 过滤掉要删除的数据进行循环，这样都是安全的，当然我们也可以在 for 循环前删除数据在遍历也是线程安全的。</p>
<p>综合性能和安全性来看，我们应该尽量使用<strong>迭代器（Iterator）来遍历 EntrySet 的遍历方式来操作 Map 集合</strong>，这样就会既安全又高效。</p>
<h3 id="Comparable-和-Comparator-比较？"><a href="#Comparable-和-Comparator-比较？" class="headerlink" title="Comparable 和 Comparator 比较？"></a>Comparable 和 Comparator 比较？</h3><p>1、Comparable 是<strong>排序接口</strong>，一个类实现了 Comparable 接口，意味着“该类支持排序”。Comparator 是<strong>比较器，我们可以实现该接口，自定义比较算法，创建一个 “该类的比较器” 来进行排序</strong>。</p>
<p>2、Comparable 相当于“内部比较器”，而 Comparator 相当于“外部比较器”。</p>
<p>3、Comparable 的耦合性更强，<strong>Comparator 的灵活性和扩展性更优。</strong></p>
<p>4、Comparable 可以用作类的默认排序方法，而 Comparator 则用于默认排序不满足时，提供自定义排序</p>
<h3 id="Collection-与-Collections-的区别"><a href="#Collection-与-Collections-的区别" class="headerlink" title="Collection 与 Collections 的区别"></a>Collection 与 Collections 的区别</h3><p>Collection：<strong>集合类的一个顶级接口</strong>，提供了对集合对象进行基本操作的通用接口方法。Collection 接口的意义是为各种具体的集合提供了最大化的统一操作方式，常见的 List 与 Set 就是直接继承 Collection 接口。</p>
<p>Collections：<strong>集合类的一个工具类&#x2F;帮助类</strong>，提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="HashSet-是如何保证不重复的？"><a href="#HashSet-是如何保证不重复的？" class="headerlink" title="HashSet 是如何保证不重复的？"></a>HashSet 是如何保证不重复的？</h3><p>HashSet 底层使用 <strong>HashMap</strong> 来实现，元素放在 HashMap 的 key 里，value 为固定的 Object 对象。</p>
<p>当 add 时调用 HashMap 的 put 方法，如果元素不存在，则返回 null 表示 add 成功，否则 add 失败。</p>
<p>由于 HashMap 的 Key 值本身就不允许重复，HashSet 正好利用 HashMap 中 key 不重复的特性来校验重复元素。<img src="https://i.loli.net/2021/08/04/I2VuKypq5o7xWrd.png" alt="image-20210804213228204"></p>
<h3 id="Map、List、Set-它们有的线程安全类和线程不安全的类？"><a href="#Map、List、Set-它们有的线程安全类和线程不安全的类？" class="headerlink" title="Map、List、Set 它们有的线程安全类和线程不安全的类？"></a>Map、List、Set 它们有的线程安全类和线程不安全的类？</h3><p><strong>Map</strong></p>
<p>线程安全：<strong>CocurrentHashMap、Hashtable</strong><br>线程不安全：HashMap、LinkedHashMap、TreeMap、WeakHashMap</p>
<p><strong>List</strong></p>
<p>线程安全<strong>：Vector（线程安全版的 ArrayList）、Stack（继承 Vector，增加 pop、push 方法）、CopyOnWriteArrayList</strong><br>线程不安全：ArrayList、LinkedList</p>
<p><strong>Set</strong></p>
<p><strong>线程安全：CopyOnWriteArraySet（底层使用 CopyOnWriteArrayList，通过在插入前判断是否存在实现 Set 不重复的效果</strong></p>
<p>线程不安全：HashSet（基于 HashMap）、LinkedHashSet（基于 LinkedHashMap）、TreeSet（基于 TreeMap）、EnumSe</p>
]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发-线程池</title>
    <url>/2021/07/30/Java%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
    <content><![CDATA[<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>降低资源消耗。通过重复利⽤已创建的线程降低线程创建和销毁造成的消耗。 </li>
<li>提⾼响应速度。当任务到达时，任务可以不需要的等到线程创建就能⽴即执⾏。 </li>
<li>提⾼线程的可管理性。线程是稀缺资源，如果⽆限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使⽤线程池可以进⾏统⼀的分配，调优和监控</li>
</ul>
<h2 id="创建的两种方式"><a href="#创建的两种方式" class="headerlink" title="创建的两种方式"></a>创建的两种方式</h2><h3 id="实现-Runnable-接⼝和-Callable-接⼝的区别"><a href="#实现-Runnable-接⼝和-Callable-接⼝的区别" class="headerlink" title="实现 Runnable 接⼝和 Callable 接⼝的区别"></a>实现 Runnable 接⼝和 Callable 接⼝的区别</h3><p>Runnable ⾃ Java 1.0 以来⼀直存在，但 Callable 仅在 Java 1.5 中引⼊,⽬的就是为了来处理 Runnable 不⽀持的⽤例。</p>
<p>Runnable 接⼝<strong>不会返回结果或抛出检查异常</strong>，但是 Callable 接⼝可以。所以，如果任务不需要返回结果或抛出异常推荐使⽤ Runnable 接⼝，这样代码看起来会更加简洁。</p>
<p>⼯具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。<br>（ Executors.callable（Runnable task ）或 Executors.callable（Runnable task，Object resule）。</p>
<h3 id="执⾏-execute-⽅法和-submit-⽅法的区别是什么呢？"><a href="#执⾏-execute-⽅法和-submit-⽅法的区别是什么呢？" class="headerlink" title="执⾏ execute()⽅法和 submit()⽅法的区别是什么呢？"></a>执⾏ execute()⽅法和 submit()⽅法的区别是什么呢？</h3><ol>
<li>execute() ⽅法⽤于<strong>提交不需要返回值的任务</strong>，所以⽆法判断任务是否被线程池执⾏成功与否；</li>
<li>submit() ⽅法⽤于<strong>提交需要返回值的任务</strong>。线程池会<strong>返回⼀个 Future 类型的对象</strong>，通过这个 Future 对象可以判断任务是否执⾏成功，并且可以通过 Future 的 <strong>get() ⽅法来获取返回值</strong>， <strong>get() ⽅法会阻塞当前线程直到任务完成</strong>，⽽使⽤ get（long timeout，TimeUnitunit）⽅法则会阻塞当前线程⼀段时间后⽴即返回，这时候有可能任务没有执⾏完。</li>
</ol>
<p>《阿⾥巴巴 Java 开发⼿册》中强制线程池<strong>不允许使⽤ Executors 去创建，⽽是通 ThreadPoolExecutor 的⽅式，</strong>这样的处理⽅式让写的同学更加明确线程池的运⾏规则，规避资源耗尽的⻛险。</p>
<p><strong>Executors 返回线程池对象的弊端如下：</strong></p>
<p>FixedThreadPool 和 SingleThreadExecutor ： 允许请求的<strong>队列⻓度为 Integer.MAX_VALUE</strong> ，可能堆积⼤量的请求，从⽽导致 OOM。<br>CachedThreadPool 和 ScheduledThreadPool ： 允许<strong>创建的线程数量为 Integer.MAX_VALUE</strong> ，可能会创建⼤量线程，从⽽导致 OOM。</p>
<h3 id="创建线程池的方式"><a href="#创建线程池的方式" class="headerlink" title="创建线程池的方式"></a>创建线程池的方式</h3><ol>
<li>构造方法：new Threadpoolexecutor(七大参数)。</li>
<li>工具类：executors.new ……</li>
</ol>
<ul>
<li><strong>FixedThreadPool</strong> ： 该⽅法返回⼀个<strong>固定线程数量</strong>的线程池。该线程池中的线程数量始终不变。当有⼀个新的任务提交时，线程池中若有空闲线程，则⽴即执⾏。若没有，则新的任务会被暂存在⼀个任务队列中，待有线程空闲时，便处理在任务队列中的任务。</li>
<li><strong>SingleThreadExecutor</strong>： ⽅法返回⼀个<strong>只有⼀个线程的线程池</strong>。若多余⼀个任务被提交到该线程池，任务会被保存在⼀个任务队列中，待线程空闲，按先⼊先出的顺序执⾏队列中的任务。</li>
<li><strong>CachedThreadPool</strong>： (适合于<strong>负载不高，每个线程时间较短</strong>)该⽅法返回⼀个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复⽤，则会优先使⽤可复⽤的线程。若所有线程均在⼯作，⼜有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执⾏完毕后，将返回线程池进⾏复⽤。</li>
<li><strong>newScheduledThreadPool</strong>：创建一个以延迟或定时的方式来执行任务的线程池，工作队列为 DelayedWorkQueue。适用于<strong>需要多个后台线程执行周期任务</strong>。</li>
</ul>
<h2 id="核心参数"><a href="#核心参数" class="headerlink" title="核心参数"></a>核心参数</h2><p><img src="https://i.loli.net/2021/08/03/uW46RI2PSrstC8M.png" alt="image-20210803222327559"></p>
<p><strong>3 个最重要的参数：</strong></p>
<ul>
<li><strong>corePoolSize</strong> : 当线程池运行的线程少于 corePoolSize 时，将创建一个新线程来处理请求，即使其<br>他工作线程处于空闲状态，核⼼线程数线程数定义了最⼩可以同时运⾏的线程数量。</li>
<li><strong>maximumPoolSize</strong> : 当队列中存放的任务达到队列容量的时候，当前可以同时运⾏的线程数量变为最⼤线程数。</li>
<li><strong>workQueue</strong> : 当新任务来的时候会先判断当前运⾏的线程数量是否达到核⼼线程数，如果达到的话，新任务就会被存放在队列中。<br>其他常⻅参数:</li>
<li><strong>keepAliveTime</strong> :当线程池中的线程数量⼤于 corePoolSize 的时候，如果这时没有新的任务提交，核⼼线程外的线程不会⽴即销毁，⽽是会等待，直到等待的时间超过了 keepAliveTime 才会被回收销毁；</li>
<li><strong>unit</strong> : keepAliveTime 参数的时间单位。</li>
<li><strong>threadFactory</strong> :executor 创建新线程的时候会⽤到。</li>
<li><strong>handler</strong> :饱和策略。</li>
</ul>
<h3 id="ThreadPoolExecutor-饱和策略定义"><a href="#ThreadPoolExecutor-饱和策略定义" class="headerlink" title="ThreadPoolExecutor 饱和策略定义"></a>ThreadPoolExecutor 饱和策略定义</h3><p> 如果当前<strong>同时运⾏的线程数量达到最⼤线程数量并且队列也已经被放满了任务时</strong>，   ThreadPoolTaskExecutor 定义⼀些策略:</p>
<ul>
<li><p>ThreadPoolExecutor.AbortPolicy ：抛出 RejectedExecutionException 来拒绝新任务的处理。</p>
</li>
<li><p>ThreadPoolExecutor.CallerRunsPolicy ：<strong>调⽤执⾏⾃⼰的线程运⾏任务</strong>。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应⽤程序可以承受此延迟并且你不能任务丢弃任何⼀个任务请求的话，你可以选择这个策略。</p>
</li>
<li><p>ThreadPoolExecutor.DiscardPolicy ： 不处理新任务，直接丢弃掉。</p>
</li>
<li><p>ThreadPoolExecutor.DiscardOldestPolicy ： 此策略将<strong>丢弃最早的未处理的任务请求</strong>。</p>
</li>
</ul>
<h3 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h3><p><img src="https://i.loli.net/2021/08/03/md8cqo3w9B1KaLM.png" alt="image-20210803222534163"></p>
<h3 id="线程池状态"><a href="#线程池状态" class="headerlink" title="线程池状态"></a>线程池状态</h3><p><img src="https://i.loli.net/2021/08/03/3zusmt1HMqZ24D5.png" alt="image-20210803223448446"></p>
<h3 id="ctl"><a href="#ctl" class="headerlink" title="ctl"></a>ctl</h3><p>ctl 是一个<strong>打包两个概念字段的原子整数。</strong><br>1）workerCount：指示<strong>线程的有效数量</strong>；<br>2）runState：指示<strong>线程池的运行状态</strong>，有 RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED 等状态。<br>int 类型有 32 位，其中 ctl 的低 29 为用于表示 workerCount，高 3 位用于表示 runState，如下图所示。</p>
<p>这么设计的主要好处是将对 runState 和 workerCount 的操作<strong>封装成了一个原子操作</strong>。</p>
<p>runState 和 workerCount 是线程池正常运转中的 2 个最重要属性，线程池在某一时刻该做什么操作，取决于这 2 个属性的值。</p>
<p>因此无论是查询还是修改，我们必须保证对这 2 个属性的操作是属于“同一时刻”的，也就是原子操作，否则就会出现错乱的情况。如果我们使用 2 个变量来分别存储，要保证原子性则需要额外进行加锁操作，这显然会带来额外的开销，而将这 2 个变量封装成 1 个 AtomicInteger 则不会带来额外的加锁开销，而且<strong>只需使用简单的位操作</strong>就能分别得到 runState 和 workerCount。</p>
<p>由于这个设计，workerCount 的上限 CAPACITY &#x3D; (1 &lt;&lt; 29) - 1，对应的二进制原码为：0001 1111 1111 1111 1111 1111 1111 1111（不用数了，29 个 1）。<br>通过 ctl 得到 runState，只需通过位操作：ctl &amp; <del>CAPACITY。<br>~（按位取反），于是“</del>CAPACITY”的值为：1110 0000 0000 0000 0000 0000 0000 0000，只有高 3 位为 1，与 ctl 进行 &amp; 操作，结果为 ctl 高 3 位的值，也就是 runState。</p>
<p>通过 ctl 得到 workerCount 则更简单了，只需通过位操作：c &amp; CAPACITY</p>
<h3 id="在我们实际使用中，线程池的大小配置多少合适？"><a href="#在我们实际使用中，线程池的大小配置多少合适？" class="headerlink" title="在我们实际使用中，线程池的大小配置多少合适？"></a>在我们实际使用中，线程池的大小配置多少合适？</h3><p>要想合理的配置线程池大小，首先我们需要区分任务是<strong>计算密集型还是 I&#x2F;O 密集型</strong>。</p>
<p>对于计算密集型，设置 线程数 &#x3D; <strong>CPU 数 + 1</strong>，通常能实现最优的利用率。</p>
<p>对于 I&#x2F;O 密集型，网上常见的说法是设置 线程数 &#x3D; <strong>CPU 数 * 2</strong> ，这个做法是可以的，但个人觉得不是最优的。</p>
<p>在我们日常的开发中，我们的任务几乎是离不开 I&#x2F;O 的，常见的网络 I&#x2F;O（RPC 调用）、磁盘 I&#x2F;O（数据库操作），并且 I&#x2F;O 的等待时间通常会占整个任务处理时间的很大一部分，在这种情况下，开启更多的线程可以让 CPU 得到更充分的使用，一个较合理的计算公式如下：<br>线程数 &#x3D; <strong>CPU 数 * CPU 利用率 * (任务等待时间 &#x2F; 任务计算时间 + 1)</strong></p>
<p>例如我们有个定时任务，部署在 4 核的服务器上，该任务有 100ms 在计算，900ms 在 I&#x2F;O 等待，则线程数约为：4 * 1 * (1 + 900 &#x2F; 100) &#x3D; 40 个。</p>
<p>当然，具体我们还要结合实际的使用场景来考虑。如果要求比较精确，可以通过压测来获取一个合理的值。</p>
]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机-String-table</title>
    <url>/2021/08/02/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-String-table/</url>
    <content><![CDATA[<h3 id="String-的基本特性"><a href="#String-的基本特性" class="headerlink" title="String 的基本特性"></a>String 的基本特性</h3><p>String：字符串，使用一对 “” 引起来表示<br>String s1 &#x3D; “qweq” ;               &#x2F;&#x2F; 字面量的定义方式<br>String s2 &#x3D;  new String(“hello”);     &#x2F;&#x2F; new 对象的方式</p>
<p>String 被声明为 final 的，不可被继承</p>
<p>String 实现了 Serializable 接口：表示字符串是支持序列化的。实现了 Comparable 接口：表示 String 可以比较大小</p>
<p><strong>String 在 jdk8 及以前内部定义了 final char value[]用于存储字符串数据。JDK9 时改为 byte[]</strong></p>
<h4 id="为什么-JDK9-改变了-String-的结构"><a href="#为什么-JDK9-改变了-String-的结构" class="headerlink" title="为什么 JDK9 改变了 String 的结构"></a>为什么 JDK9 改变了 String 的结构</h4><p>为什么改为 byte[] 存储？<br>String 类的当前实现将字符存储在 char 数组中，<strong>每个字符使用两个字节(16 位)。</strong><br>从许多不同的应用程序收集的数据表明，字符串是堆使用的主要组成部分，而且大多数字符串对象只包含拉丁字符（Latin-1）。这些字符只需要一个字节的存储空间，因此这些字符串对象的内部 char 数组中有一半的空间将不会使用，产生了大量浪费。</p>
<p>之前 String 类使用 UTF-16 的 char[] 数组存储，现在改为 byte[] 数组，<strong>外加一个编码标识存储。该编码表示如果你的字符是 ISO-8859-1 或者 Latin-1，那么只需要一个字节存。如果你是其它字符集，比如 UTF-8，你仍然用两个字节存。</strong><br>结论：String 再也不用 char[] 来存储了，改成了 byte [] 加上编码标记，<strong>节约了一些空间</strong><br>同时基于 String 的数据结构，例如 StringBuffer 和 StringBuilder 也同样做了修改。</p>
<p>String：代表不可变的字符序列。简称：<strong>不可变性。</strong></p>
<p>当对字符串重新赋值时，<strong>需要重写指定内存区域赋值</strong>，不能使用原有的 value 进行赋值。</p>
<p>当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的 value 进行赋值。</p>
<p>当调用 String 的 replace()方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的 value 进行赋值。</p>
<p>通过<strong>字面量的方式（区别于 new）给一个字符串赋值</strong>，此时的字符串值声明在<strong>字符串常量池</strong>中。<br>当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的 value 进行赋值</p>
<h3 id="String-的底层结构"><a href="#String-的底层结构" class="headerlink" title="String 的底层结构"></a>String 的底层结构</h3><p>字符串常量池是<strong>不会存储相同内容的字符串的</strong></p>
<p>String 的 String Pool（字符串常量池）是一个<strong>固定大小的 Hashtable，默认值大小长度是 60013</strong>。如果放进 String Pool 的 String 非常多，就会造成 Hash 冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用 String.intern()方法时性能会大幅下降。</p>
<p>使用-XX:StringTablesize可设置 StringTable 的长度<br>在 JDK6 中 StringTable 是固定的，就是 1009 的长度，所以如果常量池中的字符串过多就会导致效率下降很快，StringTablesize 设置没有要求<br>在 JDK7 中，StringTable 的长度默认值是 60013，StringTablesize 设置没有要求<br>在 JDK8 中，StringTable 的长度默认值是 60013，StringTable 可以设置的最小值为 1009</p>
<h3 id="String-的内存分配"><a href="#String-的内存分配" class="headerlink" title="String 的内存分配"></a>String 的内存分配</h3><p>在 Java 语言中有 8 种基本数据类型和一种比较特殊的类型 String。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种<strong>常量池</strong>的概念。</p>
<p>常量池就类似一个<strong>Java 系统级别提供的缓存</strong>。8 种基本数据类型的常量池都是系统协调的，String 类型的常量池比较特殊。</p>
<p>它的主要使用方法有两种。<br>直接使用双引号声明出来的 String 对象会直接存储在常量池中。比如：String info&#x3D;”xy.com”;<br>如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern()方法。</p>
<p>Java 6 及以前，字符串常量池存放在<strong>永久代</strong><br>Java 7 中 Oracle 的工程师对字符串池的逻辑做了很大的改变，即将字符串常量池的位置<strong>调整到 Java 堆内</strong><br><strong>所有的字符串都保存在堆（Heap）中</strong>，和其他普通对象一样，这样可以让你在进行调优应用时仅需要调整堆大小就可以了。<br>字符串常量池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在 Java 7 中使用 String.intern()。<br>Java8<strong>元空间，字符串常量在堆</strong></p>
<h3 id="StringTable-为什么要调整？"><a href="#StringTable-为什么要调整？" class="headerlink" title="StringTable 为什么要调整？"></a>StringTable 为什么要调整？</h3><p>为什么要调整位置？</p>
<p>1，永久代的默认空间大小比较小<br>2，永久代垃圾回收频率低，大量的字符串无法及时回收，容易进行 Full GC 产生 STW 或者容易产生 OOM：PermGen Space<br><strong>堆中空间足够大，字符串可被及时回收</strong></p>
<h3 id="字符串拼接操作"><a href="#字符串拼接操作" class="headerlink" title="字符串拼接操作"></a>字符串拼接操作</h3><p><strong>常量与常量的拼接结果在常量池，原理是编译期优化</strong></p>
<p>常量池中不会存在相同内容的变量<br>拼接前后，只要其中有一个是变量，结果就在堆中。变量拼接的原理是 StringBuilder<br>如果拼接的结果调用 intern()方法，根据该字符串是否在常量池中存在，分为：</p>
<p>如果存在，则返回字符串在常量池中的地址。<br>如果字符串常量池中不存在该字符串，则在常量池中创建一份，并返回此对象的地址。</p>
<p>1、常量与常量的拼接结果在常量池，原理是编译期优化。</p>
<p>2、拼接前后，只要其中有一个是变量，结果就在堆中<br>调用 intern() 方法，则主动将字符串对象存入字符串常量池中，并将其地址返回</p>
<p><strong>通过 StringBuilder 的 append()的方式添加字符串的效率要远高于使用 String 的字符串拼接方式！</strong></p>
<p>原因：</p>
<p><strong>StringBuilder 的 append()的方式：</strong><br>自始至终中只创建过一个 StringBuilder 的对象<br><strong>使用 String 的字符串拼接方式：</strong><br>创建过多个 StringBuilder 和 String（调的 toString 方法）的对象，内存占用更大；</p>
<p>如果进行 GC，需要花费额外的时间（在拼接的过程中产生的一些中间字符串可能永远也用不到，会产生大量垃圾字符串）。</p>
<p>改进的空间：</p>
<p>在实际开发中，如果基本确定要前前后后添加的字符串长度不高于某个限定值 highLevel 的情况下，建议使用构造器实例化：<br>StringBuilder s &#x3D; new StringBuilder(highLevel); &#x2F;&#x2F;new char[highLevel]<br>这样可以避免频繁扩容</p>
<h3 id="intern-的使用"><a href="#intern-的使用" class="headerlink" title="intern() 的使用"></a>intern() 的使用</h3><p>intern() 方法的说明<br>public native String intern();</p>
<p>intern 是一个 native 方法，调用的是底层 C 的方法</p>
<p>字符串常量池池最初是空的，由 String 类私有地维护。<strong>在调用 intern 方法时，如果池中已经包含了由 equals(object)方法确定的与该字符串内容相等的字符串，则返回池中的字符串地址。否则，该字符串对象将被添加到池中，并返回对该字符串对象的地址。</strong>（这是源码里的大概翻译）</p>
<p>如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法：intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。比如：<br>String myInfo &#x3D; new string(“I love atguigu”).intern();<br>也就是说，如果在任意字符串上调用 String.intern 方法，那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同。因此，下列表达式的值必定是 true<br>(“a”+”b”+”c”).intern()&#x3D; &#x3D;”abc”<br>通俗点讲，<strong>Interned String 就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。</strong>注意，这个值会被存放在字符串内部池（String Intern Pool）</p>
<h3 id="new-String-“a”-new-String-“b”-？"><a href="#new-String-“a”-new-String-“b”-？" class="headerlink" title="new String(“a”) + new String(“b”)？"></a>new String(“a”) + new String(“b”)？</h3><p>对象 1：new StringBuilder()<br>对象 2： new String(“a”)<br>对象 3： 常量池中的”a”<br>对象 4： new String(“b”)<br>对象 5： 常量池中的”b”<br>深入剖析： StringBuilder 的 toString():<br>对象 6 ：new String(“ab”)<br>强调一下，toString()的调用，在字符串常量池中，没有生成”ab”</p>
<p>可能是 4，5，6 个。</p>
<p><strong>如何保证变量 s 指向的是字符串常量池中的数据呢？</strong></p>
<p>有两种方式：</p>
<ul>
<li>方式一： String s &#x3D; “shkstart”;&#x2F;&#x2F;字面量定义的方式</li>
<li>方式二： 调用 intern()</li>
<li>plain     String s &#x3D; new String(“shkstart”).intern();</li>
<li>plain     String s &#x3D; new StringBuilder(“shkstart”).toString().intern();</li>
</ul>
<p>对于程序中大量存在存在的字符串，尤其其中存在很多重复字符串时，使用 intern()可以节省内存空间。</p>
<p>1、直接 new String ：由于每个 String 对象都是 new 出来的，所以程序需要维护大量存放在堆空间中的 String 实例，程序内存占用也会变高<br>2、使用 intern() 方法：由于数组中字符串的引用都指向字符串常量池中的字符串，所以程序需要维护的 String 对象更少，内存占用也更低</p>
<p>&#x2F;&#x2F;<strong>调用了 intern()方法使用了字符串常量池里的字符串，那么前面堆里的字符串便会被 GC 掉</strong>，这也是 intern 省内存的关键原因</p>
<p>对于程序中大量使用存在的字符串时，尤其存在很多<strong>已经重复的字符</strong>串时，使用 intern()方法能够节省很大的内存空间。<br>大的网站平台，需要内存中存储大量的字符串。比如社交网站，很多人都存储：北京市、海淀区等信息。这时候如果字符串都调用 intern() 方法，就会很明显降低内存的大小。</p>
<h3 id="StringTable-的垃圾回收"><a href="#StringTable-的垃圾回收" class="headerlink" title="StringTable 的垃圾回收"></a>StringTable 的垃圾回收</h3><h4 id="G1-中的-String-去重操作"><a href="#G1-中的-String-去重操作" class="headerlink" title="G1 中的 String 去重操作"></a>G1 中的 String 去重操作</h4><p>String 去重操作的背景</p>
<p>注意不是字符串常量池的去重操作，<strong>字符串常量池本身就没有重复的</strong><br>背景：对许多 Java 应用（有大的也有小的）做的测试得出以下结果：<br>堆存活数据集合里面 String 对象占了 25%<br>堆存活数据集合里面重复的 String 对象有 13.5%<br>String 对象的平均长度是 45</p>
<p>许多大规模的 Java 应用的瓶颈在于内存，测试表明，在这些类型的应用里面，<strong>Java 堆中存活的数据集合差不多 25%是 String 对象。更进一步，这里面差不多一半 String 对象是重复的</strong>，重复的意思是说：str1.equals(str2)&#x3D; true。堆上存在重复的 String 对象必然是一种内存的浪费。</p>
<p>这个项目将在 G1 垃圾收集器中实现自动持续对重复的 String 对象进行去重，这样就能避免浪费内存。</p>
<h4 id="String-去重的的实现"><a href="#String-去重的的实现" class="headerlink" title="String 去重的的实现"></a>String 去重的的实现</h4><p>当垃圾收集器工作的时候，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的 String 对象。<br>如果是，把<strong>这个对象的一个引用插入到队列中等待后续的处理。</strong>一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去重它引用的 String 对象。</p>
<p>使用一个 Hashtable 来记录所有的被 String 对象使用的不重复的 char 数组。当去重的时候，会查这个 Hashtable，来看堆上是否已经存在一个一模一样的 char 数组。</p>
<p>如果存在，String 对象会被调整引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉。<br>如果查找失败，<strong>char 数组会被插入到 Hashtable，这样以后的时候就可以共享这个数组了。</strong></p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机-垃圾回收器</title>
    <url>/2021/07/30/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</url>
    <content><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><h4 id="评估-GC-的性能指标"><a href="#评估-GC-的性能指标" class="headerlink" title="评估 GC 的性能指标"></a>评估 GC 的性能指标</h4><p><strong>吞吐量</strong>：运行用户代码的时间占总运行时间的比例（总运行时间 &#x3D; 程序的运行时间 + 内存回收的时间）<br>垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例。<br><strong>暂停时间</strong>：执行垃圾收集时，程序的工作线程被暂停的时间。<br>收集频率：相对于应用程序的执行，收集操作发生的频率。<br>内存占用：Java 堆区所占的内存大小。<br>快速：一个对象从诞生到被回收所经历的时间。</p>
<p><strong>吞吐量、暂停时间、内存占用</strong>这三者共同构成一个“不可能三角”。三者总体的表现会随着技术进步而越来越好。一款优秀的收集器通常最多同时满足其中的两项。</p>
<p>这三项里，<strong>暂停时间的重要性日益凸显</strong>。因为随着硬件发展，内存占用多些越来越能容忍，硬件性能的提升也有助于降低收集器运行时对应用程序的影响，即提高了吞吐量。而内存的扩大，对延迟反而带来负面效果。</p>
<p>简单来说，主要抓住两点：<br><strong>吞吐量</strong><br><strong>暂停时间</strong></p>
<h4 id="吞吐量-vs-暂停时间"><a href="#吞吐量-vs-暂停时间" class="headerlink" title="吞吐量 vs 暂停时间"></a>吞吐量 vs 暂停时间</h4><p><strong>高吞吐量较好</strong>因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上，吞吐量越高程序运行越快。</p>
<p><strong>低暂停时间（低延迟）较好</strong>，是从最终用户的角度来看，不管是 GC 还是其他原因导致一个应用被挂起始终是不好的。这取决于应用程序的类型，有时候甚至短暂的 200 毫秒暂停都可能打断终端用户体验。因此，具有较低的暂停时间是非常重要的，特别是对于一个<strong>交互式应用程序</strong>（就是和用户交互比较多的场景）。</p>
<p>不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标（矛盾）。</p>
<p>因为如果选择以<strong>吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致 GC 需要更长的暂停时间来执行内存回收。</strong><br>相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。<br>在设计（或使用）GC 算法时，我们必须确定我们的目标：一个 GC 算法只可能针对两个目标之一（即只专注于较大吞吐量或最小暂停时间），或尝试找到一个二者的折中。</p>
<p>现在标准：<strong>在最大吞吐量优先的情况下，降低停顿时间。</strong></p>
<p>1999 年随 JDK1.3.1 一起来的是串行方式的 Serial GC，它是第一款 GC。ParNew 垃圾收集器是 Serial 收集器的多线程版本<br>2002 年 2 月 26 日，Parallel GC 和 Concurrent Mark Sweep GC 跟随 JDK1.4.2 一起发布 Parallel GC 在 JDK6 之后成为 HotSpot 默认 GC。<br>2012 年，在 JDK1.7u4 版本中，G1 可用。<br>2017 年，<strong>JDK9 中 G1 变成默认的垃圾收集器，以替代 CMS。</strong><br>2018 年 3 月，JDK10 中 G1 垃圾回收器的并行完整垃圾回收，实现并行性来改善最坏情况下的延迟。<br>2018 年 9 月，JDK11 发布。引入 Epsilon 垃圾回收器，又被称为 “No-Op(无操作)“ 回收器。同时，引入 ZGC：可伸缩的低延迟垃圾回收器（Experimental）<br>2019 年 3 月，JDK12 发布。增强 G1，自动返回未用堆内存给操作系统。同时，引入 Shenandoah GC：低停顿时间的 GC（Experimental）。<br>2019 年 9 月，JDK13 发布。增强 ZGC，自动返回未用堆内存给操作系统。<br><strong>2020 年 3 月，JDK14 发布。删除 CMS 垃圾回收器</strong>。扩展 ZGC 在 macOS 和 Windows 上的应用</p>
<p>7 款经典的垃圾收集器<br><strong>串行回收器：Serial、Serial old</strong><br><strong>并行回收器：ParNew、Parallel Scavenge、Parallel old</strong><br><strong>并发回收器：CMS、G1</strong></p>
<p><img src="https://i.loli.net/2021/08/05/DeJERlKAhL34BoQ.png" alt="image-20210802151315089"></p>
<p><img src="https://i.loli.net/2021/08/05/9rHwzoCX1SKYuag.png" alt="image-20210802151245677"></p>
<p>为什么要有很多收集器，一个不够吗？因为 Java 的使用场景很多，移动端，服务器等。所以就需要针对不同的场景，提供不同的垃圾收集器，提高垃圾收集的性能。</p>
<p>JDK 8 中默认使用 ParallelGC 和 ParallelOldGC 的组合。</p>
<h3 id="Serial"><a href="#Serial" class="headerlink" title="Serial"></a>Serial</h3><p>串行的。</p>
<h3 id="Parnew"><a href="#Parnew" class="headerlink" title="Parnew"></a>Parnew</h3><p>如果说 Serial GC 是年轻代中的单线程垃圾收集器，那么<strong>ParNew 收集器则是 Serial 收集器的多线程版本。</strong><br>Par 是 Parallel 的缩写，New：只能处理新生代<br>ParNew 收集器除了采用<strong>并行回收</strong>的方式执行内存回收外，两款垃圾收集器之间几乎没有任何区别。ParNew 收集器在年轻代中同样也是采用复制算法、”Stop-the-World”机制。<br>ParNew 是很多 JVM 运行在 Server 模式下新生代的默认垃圾收集器。</p>
<p>对于新生代，回收次数频繁，<strong>使用并行方式高效</strong>。<br>对于老年代，回收次数少，<strong>使用串行方式节省资源</strong>。（CPU 并行需要切换线程，串行可以省去切换线程的资源）</p>
<p><strong>ParNew 回收器与 Serial 回收器比较</strong></p>
<p>Q：由于 ParNew 收集器基于并行回收，那么是否可以断定 ParNew 收集器的回收效率在任何场景下都会比 Serial 收集器更高效？</p>
<p>A：不能<br>ParNew 收集器运行在多 CPU 的环境下，由于可以充分利用多 CPU、多核心等物理硬件资源优势，可以更快速地完成垃圾收集，提升程序的吞吐量。<br>但是在单个 CPU 的环境下，ParNew 收集器不比 Serial 收集器更高效。虽然 Serial 收集器是基于串行回收，但是由于 CPU 不需要频繁地做任务切换，因此可以有效避免多线程交互过程中产生的一些额外开销。<br><strong>除 Serial 外，目前只有 ParNew GC 能与 CMS 收集器配合工作</strong></p>
<h3 id="Parallel"><a href="#Parallel" class="headerlink" title="Parallel"></a>Parallel</h3><p>HotSpot 的年轻代中除了拥有 ParNew 收集器是基于并行回收的以外，Parallel Scavenge 收集器同样也采用了复制算法、并行回收和”Stop the World”机制。</p>
<p><strong>那么 Parallel 收集器的出现是否多此一举？</strong></p>
<p>和 ParNew 收集器不同，Parallel Scavenge 收集器的目标则是达到一个<strong>可控制的吞吐量（Throughput）</strong>，它也被称为<strong>吞吐量优先的垃圾收集器。</strong></p>
<p><strong>自适应调节策略</strong>也是 Parallel Scavenge 与 ParNew 一个重要区别。（<strong>动态调整内存分配情况，以达到一个最优的吞吐量或低延迟</strong>）</p>
<p>高吞吐量则可以高效率地利用 CPU 时间，<strong>尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。因此，常见在服务器环境中使用。</strong>例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。</p>
<p>Parallel 收集器在 JDK1.6 时提供了用于执行老年代垃圾收集的 Parallel Old 收集器，用来代替老年代的 Serial Old 收集器。</p>
<p>Parallel Old 收集器采用了<strong>标记-压缩算</strong>法，但同样也是基于并行回收和”Stop-the-World”机制。</p>
<p>在程序吞吐量优先的应用场景中，Parallel 收集器和 Parallel Old 收集器的组合，在 server 模式下的内存回收性能很不错。</p>
<p><strong>在 Java8 中，默认是此垃圾收集器。</strong></p>
<h3 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h3><p>在 JDK1.5 时期，Hotspot 推出了一款在<strong>强交互应用</strong>中（就是和用户打交道的引用）几乎可认为有划时代意义的垃圾收集器：CMS（Concurrent-Mark-Sweep）收集器，这款收集器是 HotSpot 虚拟机中第一款真正意义上的并发收集器，<strong>它第一次实现了让垃圾收集线程与用户线程同时工作。</strong></p>
<p>CMS 收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短（低延迟）就越适合与用户交互的程序，良好的响应速度能提升用户体验。</p>
<p>目前很大一部分的 Java 应用集中在互联网站或者 B&#x2F;S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。</p>
<p>CMS 的垃圾收集算法采用<strong>标记-清除算法</strong>，并且也会”Stop-the-World”，不幸的是，CMS 作为老年代的收集器，却无法与 JDK1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作（因为实现的框架不一样，没办法兼容使用），<strong>所以在 JDK1.5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或者 Serial 收集器中的一个。</strong><br>在 G1 出现之前，CMS 使用还是非常广泛的。一直到今天，仍然有很多系统使用 CMS GC。</p>
<p><img src="https://i.loli.net/2021/08/05/u6cqdol4AvgW8eK.png" alt="image-20210802151828157"></p>
<h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p>CMS 整个过程比之前的收集器要复杂，整个过程分为 4 个主要阶段，即初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段。(涉及 STW 的阶段主要是：初始标记 和 重新标记)</p>
<p><strong>初始标记（Initial-Mark）阶段</strong>：在这个阶段中，程序中所有的工作线程都将会因为“Stop-the-World”机制而出现<strong>短暂的暂停</strong>，这个阶段的主要任务仅仅只是标记出 GC Roots 能直接关联到的对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较小，所以这里的速度非常快。</p>
<p><strong>并发标记（Concurrent-Mark）阶段</strong>：从 GC Roots 的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行。</p>
<p><strong>重新标记（Remark）阶段</strong>：由于在并发标记阶段中，<strong>程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了修正并发标记期间</strong>，因用户程序继续运作而<strong>导致标记产生变动的那一部分对象的标记记录</strong>，这个阶段的停顿时间通常会比初始标记阶段稍长一些，并且也会导致“Stop-the-World”的发生，但也远比并发标记阶段的时间短。</p>
<p><strong>并发清除（Concurrent-Sweep）阶段</strong>：此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的</p>
<p>CMS 分析</p>
<p>尽管 CMS 收集器采用的是并发回收（非独占式），<strong>但是在其初始化标记和再次标记这两个阶段中仍然需要执行“Stop-the-World”机制暂停程序中的工作线程，不过暂停时间并不会太长</strong>，因此可以说明目前所有的垃圾收集器都做不到完全不需要“Stop-the-World”，只是尽可能地缩短暂停时间。</p>
<p>由于<strong>最耗费时间的并发标记与并发清除阶段</strong>都不需要暂停工作，所以整体的回收是低停顿的。</p>
<p>CMS 收集器的垃圾收集算法采用的是<strong>标记清除算法</strong>，这意味着每次执行完内存回收后，由于被执行内存回收的无用对象所占用的内存空间极有可能是不连续的一些内存块，不可避免地将会产生一些内存碎片。那么 CMS 在为新对象分配内存空间时，将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择<strong>空闲列表（Free List）执行内存分配。</strong></p>
<p><strong>为什么 CMS 不采用标记-压缩算法呢？</strong></p>
<p>答案其实很简答，因为当并发清除的时候，用 Compact 整理内存的话，原来的用户线程使用的内存还怎么用呢？要保证用户线程能继续执行，前提的它运行的资源不受影响。Mark Compact 更适合“stop the world”这种场景下使用。</p>
<h4 id="CMS-的优点与弊端"><a href="#CMS-的优点与弊端" class="headerlink" title="CMS 的优点与弊端"></a>CMS 的优点与弊端</h4><p>优点</p>
<p><strong>并发收集</strong><br><strong>低延迟</strong></p>
<p>弊端</p>
<p><strong>会产生内存碎片</strong>，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得不提前触发 Full GC。</p>
<p>CMS 收集器对<strong>CPU 资源非常敏感</strong>。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。<br>CMS 收集器<strong>无法处理浮动垃圾</strong>。可能出现“Concurrent Mode Failure”失败而导致另一次 Full GC 的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS 将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾对象没有被及时回收，从而只能在下一次执行 GC 时释放这些之前未被回收的内存空间。</p>
<h3 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h3><p>G1 回收器：<strong>区域化分代式</strong></p>
<p>应用程序所应对的业务越来越庞大、复杂，用户越来越多，没有 GC 就不能保证应用程序正常进行，而经常造成 STW 的 GC 又跟不上实际的需求，所以才会不断地尝试对 GC 进行优化。<br>G1（Garbage-First）垃圾回收器是在 Java7 update4 之后引入的一个新的垃圾回收器，是当今收集器技术发展的最前沿成果之一。<br>与此同时，<strong>为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。</strong><br>官方给 G1 设定的目标是<strong>在延迟可控的情况下获得尽可能高的吞吐量</strong>，所以才担当起“全功能收集器”的重任与期望。</p>
<p>为什么名字叫**Garbage First(G1)**呢？</p>
<p>因为 G1 是一个并行回收器，它把堆内存分割为很多不相关的区域（Region）（物理上不连续的）。使用不同的 Region 来表示 Eden、幸存者 0 区，幸存者 1 区，老年代等。<br>G1 GC 有计划地避免在整个 Java 堆中进行全区域的垃圾收集。<strong>G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。</strong><br>由于这种方式的侧重点在于回收垃圾最大量的区间（Region），所以我们给 G1 一个名字：垃圾优先（Garbage First）。</p>
<p>G1（Garbage-First）是一款<strong>面向服务端应用</strong>的垃圾收集器，主要针对配备<strong>多核 CPU 及大容量内存的机器</strong>，以极高概率满足 GC 停顿时间的同时，还兼具高吞吐量的性能特征。</p>
<p>在 JDK1.7 版本正式启用，移除了 Experimental 的标识，是 JDK9 以后的默认垃圾回收器，取代了 CMS 回收器以及 Parallel+Parallel Old 组合。被 Oracle 官方称为“全功能的垃圾收集器”。<br>与此同时，CMS 已经在 JDK9 中被标记为废弃（deprecated）。G1 在 JDK8 中还不是默认的垃圾回收器，需要使用-XX:+UseG1GC 来启用。</p>
<h4 id="G1-回收器的优势"><a href="#G1-回收器的优势" class="headerlink" title="G1 回收器的优势"></a>G1 回收器的优势</h4><p>与其他 GC 收集器相比，G1 使用了全新的分区算法，其特点如下所示：</p>
<p><strong>1，并行与并发兼备</strong></p>
<p>并行性：G1 在回收期间，可以有多个 GC 线程同时工作，有效利用多核计算能力。此时用户线程 STW<br>并发性：G1 拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况<br><strong>2，分代收集</strong></p>
<p>从分代上看，G1 依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有 Eden 区和 Survivor 区。但从堆的结构上看，它不要求整个 Eden 区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。<br>将堆空间分为若干个区域（Region），这些区域中包含了逻辑上的年轻代和老年代。<br><strong>和之前的各类回收器不同，它同时兼顾年轻代和老年代。</strong>对比其他回收器，或者工作在年轻代，或者工作在老年代；</p>
<p><img src="https://i.loli.net/2021/08/05/KFNiqT1SUnylwGc.png" alt="image-20210802152854640"></p>
<p><strong>3，空间整合</strong><br>CMS：“标记-清除”算法、内存碎片、若干次 GC 后进行一次碎片整理</p>
<p>G1 将内存划分为一个个的 region。<strong>内存的回收是以 region 作为基本单位的</strong>。Region 之间是复制算法，但整体上实际可看作是标记-压缩（Mark-Compact）算法，两种算法都可以避免内存碎片。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC。<strong>尤其是当 Java 堆非常大的时候，G1 的优势更加明显。</strong></p>
<p><strong>4，可预测的停顿时间模型（软实时 soft real-time）</strong></p>
<p>这是 G1 相对于 CMS 的另一大优势，G1 除了追求低停顿外，<strong>还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。</strong></p>
<p>由于分区的原因，G1 可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。</p>
<p>G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。</p>
<p>相比于 CMS GC，G1 未必能做到 CMS 在最好情况下的延时停顿，但是最差情况要好很多。</p>
<h4 id="G1-回收器的缺点"><a href="#G1-回收器的缺点" class="headerlink" title="G1 回收器的缺点"></a>G1 回收器的缺点</h4><p>相较于 CMS，G1 还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1 无论是<strong>为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（overload）都要比 CMS 要高</strong>。</p>
<p>从经验上来说，在小内存应用上 CMS 的表现大概率会优于 G1，而 G1 在大内存应用上则发挥其优势。平衡点在 6-8GB 之间。</p>
<h4 id="G1-的适用场景"><a href="#G1-的适用场景" class="headerlink" title="G1 的适用场景"></a>G1 的适用场景</h4><p>面向服务端应用，针对具有<strong>大内存、多处理器</strong>的机器。<br>最主要的应用是需要低 GC 延迟，并具有大堆的应用程序提供解决方案；</p>
<p>如：在堆大小约 6GB 或更大时，可预测的暂停时间可以低于 0.5 秒；（G1 通过每次只清理一部分而不是全部的 Region 的增量式清理来保证每次 GC 停顿时间不会过长）。</p>
<p>用来替换掉 JDK1.5 中的 CMS 收集器；在下面的情况时，使用 G1 可能比 CMS 好：</p>
<p>超过 50%的 Java 堆被活动数据占用；<br>对象分配频率或年代提升频率变化很大；<br>GC 停顿时间过长（长于 0.5 至 1 秒）</p>
<p>HotSpot 垃圾收集器里，除了 G1 以外，其他的垃圾收集器均使用内置的 JVM 线程执行 GC 的多线程操作，而 G1 GC 可以采用应用线程承担后台运行的 GC 工作，即当 JVM 的 GC 线程处理速度慢时，系统会调用应用程序线程帮助加速垃圾回收过程。</p>
<p><strong>分区 Region：化整为零</strong></p>
<p>使用 G1 收集器时，它将整个 Java 堆划分成<strong>约 2048 个大小相同的独立 Region 块</strong>，每个 Region 块大小根据堆空间的实际大小而定，<strong>整体被控制在 1MB 到 32MB 之间</strong>，<strong>且为 2 的 N 次幂，即 1MB，2MB，4MB，8MB，16MB，32MB。</strong>可以通过 XX:G1HeapRegionSize设定。所有的 Region 大小相同，且在 JVM 生命周期内不会被改变。</p>
<p>虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region（不需要连续）的集合。通过 Region 的动态分配方式实现逻辑上的连续。</p>
<p>一个 Region 有可能属于 Eden，Survivor 或者 Old&#x2F;Tenured 内存区域。但是一个 Region 只可能属于一个角色。</p>
<p>G1 垃圾收集器还增加了一种新的内存区域，<strong>叫做 Humongous 内存区域</strong>，如图中的 H 块。主要用于存储大对象，<strong>如果超过 0.5 个 Region，就放到 H。</strong></p>
<p><img src="https://i.loli.net/2021/08/05/Drv4WB8nqwNjigm.png" alt="image-20210802153249024"></p>
<h4 id="设置-H-的原因"><a href="#设置-H-的原因" class="headerlink" title="设置 H 的原因"></a>设置 H 的原因</h4><p>对于堆中的大对象，默认直接会被分配到老年代，但是如果它是一个短期存在的大对象就会对垃圾收集器造成负面影响。</p>
<p>为了解决这个问题，G1 划分了一个 Humongous 区，它用来专门存放大对象。如果一个 H 区装不下一个大对象，那么 G1 会寻找连续的 H 区来存储。为了能找到连续的 H 区，有时候不得不启动 Full GC。<strong>G1 的大多数行为都把 H 区作为老年代的一部分来看待。</strong></p>
<p><strong>每个 Region 都是通过指针碰撞来分配空间</strong></p>
<p>G1 为每一个 Region 设 计了两个名为 TAMS（Top at Mark Start）的指针，把 Region 中的一部分空间划分出来用于并发回收过程中的新对象分配，并发回收时新分配的对象地址都必须要在这两个指针位置以上。</p>
<h4 id="G1-GC-的垃圾回收过程"><a href="#G1-GC-的垃圾回收过程" class="headerlink" title="G1 GC 的垃圾回收过程"></a>G1 GC 的垃圾回收过程</h4><p>年轻代 GC（Young GC）</p>
<p>老年代并发标记过程（Concurrent Marking）</p>
<p>混合回收（Mixed GC）<br>（如果需要，单线程、独占式、高强度的 Full GC 还是继续存在的。它针对 GC 的评估失败提供了一种失败保护机制，即强力回收。）</p>
<p>应用程序分配内存，当年轻代的 Eden 区用尽时开始年轻代回收过程；<strong>G1 的年轻代收集阶段是一个并行的独占式收集器。</strong>在年轻代回收期，G1 GC 暂停所有应用程序线程，启动多线程执行年轻代回收。然后从年轻代区间移动存活对象到 Survivor 区间或者老年区间，也有可能是两个区间都会涉及。</p>
<p><strong>当堆内存使用达到一定值（默认 45%）时，开始老年代并发标记过程。</strong></p>
<p>标记完成马上开始<strong>混合回收过程</strong>。对于一个混合回收期，G1 GC 从老年区间移动存活对象到空闲区间，这些空闲区间也就成为了老年代的一部分。和年轻代不同，老年代的 G1 回收器和其他 GC 不同，G1 的老年代回收器不需要整个老年代被回收，一次只需要扫描&#x2F;回收一小部分老年代的 Region 就可以了。同时，这个老年代 Region 是和年轻代一起被回收的。</p>
<h4 id="Remembered-Set（记忆集）"><a href="#Remembered-Set（记忆集）" class="headerlink" title="Remembered Set（记忆集）"></a>Remembered Set（记忆集）</h4><p>无论 G1 还是其他分代收集器，JVM 都是使用<strong>Remembered Set 来避免全堆扫描；</strong><br>每个 Region 都有一个对应的<strong>Remembered Set</strong><br>每次 Reference 类型数据写操作时，都会产生一个 Write Barrier 暂时中断操作；<br>然后检查<strong>将要写入的引用指向的对象是否和该 Reference 类型数据在不同的 Region</strong>（其他收集器：检查老年代对象是否引用了新生代对象）；<br>如果不同，通过 CardTable 把相关引用信息记录到引用指向对象的所在 Region 对应的 Remembered Set 中；<br>当进行垃圾收集时，<strong>在 GC 根节点的枚举范围加入 Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。</strong></p>
<h4 id="G1-回收过程一：年轻代-GC"><a href="#G1-回收过程一：年轻代-GC" class="headerlink" title="G1 回收过程一：年轻代 GC"></a>G1 回收过程一：年轻代 GC</h4><p>JVM 启动时，G1 先准备好 Eden 区，程序在运行过程中不断创建对象到 Eden 区，当 Eden 空间耗尽时，G1 会启动一次年轻代垃圾回收过程。<br>年轻代回收<strong>只回收 Eden 区和 Survivor 区</strong><br>YGC 时，首先 G1 停止应用程序的执行（Stop-The-World），G1 创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含<strong>年轻代 Eden 区和 Survivor 区所有的内存分段。</strong></p>
<p>第一阶段，<strong>扫描根</strong><br>根是指 GC Roots，根引用连同 RSet 记录的外部引用作为扫描存活对象的入口。</p>
<p>第二阶段，<strong>更新 RSet</strong></p>
<p>第三阶段，<strong>处理 RSet</strong><br><strong>识别被老年代对象指向的 Eden 中的对象，这些被指向的 Eden 中的对象被认为是存活的对象。</strong></p>
<p>第四阶段，<strong>复制对象。</strong><br>此阶段，对象树被遍历，Eden 区内存段中存活的对象会被复制到 Survivor 区中空的内存分段，Survivor 区内存段中存活的对象，如果年龄未达阈值，年龄会加 1，达到阀值会被会被复制到 Old 区中空的内存分段。如果 Survivor 空间不够，Eden 空间的部分数据会直接晋升到老年代空间。</p>
<p>第五阶段，<strong>处理引用</strong><br>处理 Soft，Weak，Phantom，Final，JNI Weak 等引用。<strong>最终 Eden 空间的数据为空，GC 停止工作</strong>，而目标内存中的对象都是连续存储的，没有碎片，所以复制过程可以达到内存整理的效果，减少碎片。</p>
<h4 id="G1-回收过程二：并发标记过程"><a href="#G1-回收过程二：并发标记过程" class="headerlink" title="G1 回收过程二：并发标记过程"></a>G1 回收过程二：并发标记过程</h4><p><strong>初始标记阶段</strong>：标记从根节点直接可达的对象。这个阶段是 STW 的，并且会触发一次年轻代 GC。正是由于该阶段时 STW 的，所以我们只扫描根节点可达的对象，以节省时间。</p>
<p><strong>根区域扫描（Root Region Scanning）</strong>：G1 GC 扫描 Survivor 区直接可达的老年代区域对象，并标记被引用的对象。这一过程必须在 Young GC 之前完成，因为 Young GC 会使用复制算法对 Survivor 区进行 GC。</p>
<p><strong>并发标记（Concurrent Marking）</strong>：在整个堆中进行并发标记（和应用程序并发执行），此过程可能被 Young GC 中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那这个区域会被立即回收。同时，并发标记过程中，<strong>会计算每个区域的对象活性（区域中存活对象的比例）。</strong></p>
<p><strong>再次标记（Remark）：</strong>由于应用程序持续进行，<strong>需要修正上一次的标记结果</strong>。是 STW 的。G1 中采用了比 CMS 更快的原始快照算法：<strong>Snapshot-At-The-Beginning（SATB）。</strong></p>
<p><strong>独占清理（cleanup，STW）</strong>：<strong>计算各个区域的存活对象和 GC 回收比例，并进行排序，识别可以混合回收的区域</strong>。为下阶段做铺垫。是 STW 的。这个阶段并不会实际上去做垃圾的收集</p>
<p><strong>并发清理阶段：</strong>识别并清理完全空闲的区域。</p>
<h4 id="G1-回收过程三：混合回收过程"><a href="#G1-回收过程三：混合回收过程" class="headerlink" title="G1 回收过程三：混合回收过程"></a>G1 回收过程三：混合回收过程</h4><p>当越来越多的对象晋升到老年代 Old Region 时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即 Mixed GC，该算法并不是一个 Old GC，<strong>除了回收整个 Young Region，还会回收一部分的 Old Region。</strong>这里需要注意：<strong>是一部分老年代，而不是全部老年代</strong>。可以选择哪些 Old Region 进行收集，从而可以对垃圾回收的耗时时间进行控制。也要注意的是 Mixed GC 并不是 Full GC。</p>
<p><strong>混合回收的细节</strong></p>
<p>并发标记结束以后，老年代中百分百为垃圾的内存分段被回收了，部分为垃圾的内存分段被计算了出来。默认情况下，这些老年代的内存分段会分 8 次（可以通过-XX:G1MixedGCCountTarget设置）被回收。【意思就是一个 Region 会被分为 8 个内存段】</p>
<p>混合回收的回收集（Collection Set）包括<strong>八分之一的老年代内存分段，Eden 区内存分段，Survivor 区内存分段</strong>。混合回收的算法和年轻代回收的算法完全一样，只是回收集多了老年代的内存分段。具体过程请参考上面的年轻代回收过程。</p>
<p>由于老年代中的内存分段默认分 8 次回收，G1 会优先回收垃圾多的内存分段。<strong>垃圾占内存分段比例越高的，越会被先回收。</strong></p>
<p>并且有一个阈值会决定内存分段是否被回收。XX:G1MixedGCLiveThresholdPercent，默认为 65%<strong>，意思是垃圾占内存分段比例要达到 65%才会被回收</strong>。如果垃圾占比太低，意味着存活的对象占比高，在复制的时候会花费更多的时间。</p>
<p>混合回收并不一定要进行 8 次。有一个阈值-XX:G1HeapWastePercent，默认值为 10%，<strong>意思是允许整个堆内存中有 10%的空间被浪费</strong>，意味着如果发现可以回收的垃圾占堆内存的比例低于 10%，则不再进行混合回收。因为 GC 会花费很多的时间但是回收到的内存却很少。</p>
<h4 id="G1-回收可选的过程四：Full-GC"><a href="#G1-回收可选的过程四：Full-GC" class="headerlink" title="G1 回收可选的过程四：Full GC"></a>G1 回收可选的过程四：Full GC</h4><p>G1 的初衷就是要避免 Full GC 的出现。但是如果上述方式不能正常工作，G1 会停止应用程序的执行（Stop-The-World），使用单线程的内存回收算法进行垃圾回收，性能会非常差，应用程序停顿时间会很长。</p>
<p>要避免 Full GC 的发生，一旦发生 Full GC，需要对 JVM 参数进行调整。什么时候会发生 Ful1GC 呢？比如堆内存太小，当 G1 在复制存活对象的时候没有空的内存分段可用，则会回退到 Full GC，这种情况可以通过增大内存解决。</p>
<p>导致 G1 Full GC 的原因可能有两个：<br><strong>EVacuation 的时候没有足够的 to-space 来存放晋升的对象；</strong><br><strong>并发处理过程完成之前空间耗尽。</strong></p>
<p><strong>G1 回收器的优化建议</strong></p>
<p>年轻代大小<br>避免使用-Xmn 或-XX:NewRatio等相关选项显式设置年轻代大小，因为固定年轻代的大小会覆盖可预测的暂停时间目标。<strong>我们让 G1 自己去调整</strong></p>
<p><strong>暂停时间目标不要太过严苛</strong></p>
<p>G1 GC 的吞吐量目标是 90%的应用程序时间和 10%的垃圾回收时间<br>评估 G1 GC 的吞吐量时，暂停时间目标不要太严苛。目标太过严苛表示你愿意承受更多的垃圾回收开销，而这些会直接影响到吞吐量。</p>
<p><strong>第一步：开启 G1 垃圾收集器</strong><br><strong>第二步：设置堆的最大内存</strong><br><strong>第三步：设置最大的停顿时间</strong></p>
<h3 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC?"></a>ZGC?</h3><p>ZGC 收集器是一款<strong>基于 Region 内存布局</strong>的，（暂时）不设分代的，使用了<strong>读屏障、染色指针和内存多重映射</strong>等技术来实现可并发的标记-压缩算法的，以低延迟为首要目标的一款垃圾收集器。</p>
<p>ZGC 的工作过程可以分为 4 个阶段：<strong>并发标记 - 并发预备重分配 - 并发重分配 - 并发重映射</strong> 等。</p>
<p>ZGC 几乎在所有地方并发执行的，<strong>除了初始标记的是 STW 的</strong>。所以停顿时间几乎就耗费在初始标记上，这部分的实际时间是非常少的。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2021/08/05/haoOkViNCXmSW6Z.png" alt="image-20210802154953900"></p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>实现</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机-垃圾回收算法</title>
    <url>/2021/07/30/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><h4 id="垃圾？"><a href="#垃圾？" class="headerlink" title="垃圾？"></a>垃圾？</h4><p>Java 和 C++语言的区别，就在于<strong>垃圾收集技术和内存动态分配</strong>上，C++语言没有垃圾收集技术，需要程序员手动的收集。</p>
<p><strong>什么是垃圾？</strong></p>
<p>垃圾是指在运行程序中<strong>没有任何指针指向的对象</strong>，这个对象就是需要被回收的垃圾。</p>
<p>如果不及时对内存中的垃圾进行清理，那么，这些垃圾对象所占的内存空间会一直保留到应用程序结束，被保留的空间无法被其他对象使用。甚至可能导致内存溢出。</p>
<h4 id="System-gc-的理解"><a href="#System-gc-的理解" class="headerlink" title="System.gc() 的理解"></a>System.gc() 的理解</h4><p>在默认情况下，通过 System.gc()者 Runtime.getRuntime().gc() 的调用，会显式触发 Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。</p>
<p>然而 System.gc()调用附带一个免责声明，<strong>无法保证对垃圾收集器的调用(不能确保立即生效)</strong></p>
<p>JVM 实现者可以通过 System.gc() 调用来决定 JVM 的 GC 行为。而一般情况下，垃圾回收应该是自动进行的，无须手动触发，否则就太过于麻烦了。在一些特殊情况下，如我们正在编写一个性能基准，我们可以在运行之间调用 System.gc()</p>
<h4 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h4><p>Javadoc 中对 OutofMemoryError 的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。</p>
<p><strong>内存溢出（OOM）原因分析</strong></p>
<p>首先说没有空闲内存的情况：说明 Java 虚拟机的堆内存不够。原因有二：<br><strong>Java 虚拟机的堆内存设置不够。</strong><br>比如：可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定 JVM 堆大小或者指定数值偏小。我们可以通过参数-Xms 、-Xmx 来调整。</p>
<p><strong>代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用）</strong><br>对于老版本的 Oracle JDK，因为永久代的大小是有限的，并且 JVM 对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现 OutOfMemoryError 也非常多见。尤其是在运行时存在大量动态类型生成的场合；类似 intern 字符串缓存占用太多空间，也会导致 OOM 问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError:PermGen space”。</p>
<p>随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的 OOM 有所改观，出现 OOM，异常信息则变成了：“java.lang.OutofMemoryError:Metaspace”。直接内存不足，也会导致 OOM。<br>这里面隐含着一层意思是，在抛出 OutofMemoryError 之前，通常垃圾收集器会被触发，尽其所能去清理出空间。</p>
<p>当然，也不是在任何情况下垃圾收集器都会被触发的<br>比如，我们去分配一个超大对象，类似一个超大数组超过堆的最大值，JVM 可以判断出垃圾收集并不能解决这个问题，所以直接抛出 OutofMemoryError。</p>
<h4 id="内存泄漏（leak）"><a href="#内存泄漏（leak）" class="headerlink" title="内存泄漏（leak）"></a>内存泄漏（leak）</h4><p>也称作“存储渗漏”。严格来说，<strong>只有对象不会再被程序用到了，但是 GC 又不能回收他们的情况，</strong>才叫内存泄漏。</p>
<p>但实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致 OOM，也可以叫做宽泛意义上的“内存泄漏”。</p>
<p>尽管内存泄漏并不会立刻引起程序崩溃，<strong>但是一旦发生内存泄漏，程序中的可用内存就会被逐步蚕食</strong>，直至耗尽所有内存，最终出现 OutofMemory 异常，导致程序崩溃。</p>
<p><strong>单例模式</strong><br>单例的生命周期和应用程序是一样长的，所以在单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生。</p>
<p><strong>一些提供 close()的资源未关闭导致内存泄漏</strong><br>数据库连接 dataSourse.getConnection()，网络连接 socket 和 io 连接必须手动 close，否则是不能被回收的。</p>
<h4 id="Stop-the-World"><a href="#Stop-the-World" class="headerlink" title="Stop the World"></a>Stop the World</h4><p>Stop-the-World，简称 STW，指的是 GC 事件发生过程中，会产生应用程序的停顿。停顿产生时整个应用程序线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为 STW。</p>
<p>可达性分析算法中枚举根节点（GC Roots）会导致所有 Java 执行线程停顿，为什么需要停顿所有 Java 执行线程呢？</p>
<p>分析工作必须在一个能确保一致性的快照中进行<br>一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上<br>如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证</p>
<p>被 STW 中断的应用程序线程会在完成 GC 之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样，所以我们需要减少 STW 的发生。</p>
<p>STW 事件和采用哪款 GC 无关，所有的 GC 都有这个事件。</p>
<p>哪怕是 G1 也不能完全避免 Stop-the-world 情况发生，只能说垃圾回收器越来越优秀，回收效率越来越高，尽可能地缩短了暂停时间。</p>
<p>STW 是 JVM 在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。</p>
<p>开发中不要用 System.gc() ，这会导致 Stop-the-World 的发生。</p>
<h4 id="安全点（Safepoint）"><a href="#安全点（Safepoint）" class="headerlink" title="安全点（Safepoint）"></a>安全点（Safepoint）</h4><p>程序执行时并非在所有地方都能停顿下来开始 GC，<strong>只有在特定的位置才能停顿下来开始 GC，这些位置称为“安全点（Safepoint）”。</strong></p>
<p>Safe Point 的选择很重要，如果太少可能导致 GC 等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会根据“是否具有让程序长时间执行的特征”为标准。比如：<strong>选择一些执行时间较长的指令作为 Safe Point</strong>，如方法调用、循环跳转和异常跳转等。</p>
<p>如何在 GC 发生时，检查所有线程都跑到最近的安全点停顿下来呢？</p>
<p>抢先式中断：（目前没有虚拟机采用了）首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。</p>
<p>主动式中断：<strong>设置一个中断标志</strong>，各个线程运行到 Safe Point 的时候主动轮询这个标志，如果中断标志为真，则将自己进行中断挂起。</p>
<h4 id="安全区域（Safe-Region）"><a href="#安全区域（Safe-Region）" class="headerlink" title="安全区域（Safe Region）"></a>安全区域（Safe Region）</h4><p>Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入 GC 的 Safepoint。但是，程序“不执行”的时候呢？</p>
<p>例如<strong>线程处于 Sleep 状态或 Blocked 状态</strong>，这时候线程无法响应 JVM 的中断请求，JVM 也不太可能等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。<br>安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始 GC 都是安全的。我们也可以把 Safe Region 看做是被扩展了的 Safepoint。</p>
<p>安全区域的执行流程</p>
<p>当线程运行到 Safe Region 的代码时，首先标识已经进入了 Safe Region，如果这段时间内发生 GC，JVM 会忽略标识为 Safe Region 状态的线程（开始 GC）<br>当线程即将离开 Safe Region 时，会检查 JVM 是否已经完成根节点枚举（即 GC Roots 的枚举），如果完成了，则继续运行用户线程，否则线程必须等待直到收到可以安全离开 Safe Region 的信号为止；</p>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><p>我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是很紧张，则可以抛弃这些对象。</p>
<p>强引用、软引用、弱引用、虚引用有什么区别？具体使用场景是什么？</p>
<p>在 JDK1.2 版之后，Java 对引用的概念进行了扩充，将引用分为：</p>
<p>强引用（Strong Reference）<br>软引用（Soft Reference）<br>弱引用（Weak Reference）<br>虚引用（Phantom Reference）<br>这 4 种引用强度依次逐渐减弱。除强引用外，其他 3 种引用均可以在 java.lang.ref 包中找到它们的身影。如下图，显示了这 3 种引用类型对应的类，开发人员可以在应用程序中直接使用它们。</p>
<p>Reference 子类中只有终结器引用是包内可见的，其他 3 种引用类型均为 public，可以在应用程序中直接使用。</p>
<p><strong>强引用（StrongReference）</strong>：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“object obj&#x3D;new Object()”这种引用关系。无论任何情况下，<strong>只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。</strong></p>
<p><strong>软引用（SoftReference）</strong>：在系统将要发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。</p>
<p><strong>弱引用（WeakReference）</strong>：被弱引用关联的对象<strong>只能生存到下一次垃圾收集之前。当垃圾收集器工作时，无论内存空间是否足够，都会回收掉被弱引用关联的对象。</strong></p>
<p><strong>虚引用（PhantomReference）</strong>：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。为<strong>一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。</strong></p>
<p><strong>再谈引用：强引用</strong></p>
<p>在 Java 程序中，最常见的引用类型是强引用（普通系统 99%以上都是强引用），也就是我们最常见的普通对象引用，也是默认的引用类型。</p>
<p>当在 Java 语言中使用 new 操作符创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。</p>
<p>只要强引用的对象是可触及的，垃圾收集器就永远不会回收掉被引用的对象。只要强引用的对象是可达的，jvm 宁可报 OOM，也不会回收强引用。</p>
<p>对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。</p>
<p>相对的，软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成 Java 内存泄漏的主要原因之一。</p>
<p>强引用具备以下特点：</p>
<p>强引用可以直接访问目标对象。<br>强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出 OOM 异常，也不会回收强引用所指向对象。<br>强引用可能导致内存泄漏。</p>
<p><strong>再谈引用：软引用</strong><br>软引用（Soft Reference）：<strong>内存不足即回收</strong></p>
<p>软引用是用来描述一些还有用，但非必需的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。注意，这里的第一次回收是不可达的对象</p>
<p>软引用通常用来实现内存敏感的缓存。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。</p>
<p>垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列（Reference Queue）。</p>
<p>类似弱引用，只不过 Java 虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。</p>
<p>一句话概括：当内存足够时，不会回收软引用可达的对象。内存不够时，会回收软引用的可达对象</p>
<p><strong>再谈引用：弱引用</strong><br>弱引用（Weak Reference）<strong>发现即回收</strong></p>
<p>弱引用也是用来描述那些非必需对象，只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统 GC 时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。</p>
<p>但是，由于垃圾回收器的线程通常优先级很低，因此，并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。</p>
<p>弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。</p>
<p>软引用、弱引用都非常适合来保存那些可有可无的缓存数据。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。</p>
<p>在 JDK1.2 版之后提供了 WeakReference 类来实现弱引用</p>
<p>弱引用对象与软引用对象的最大不同就在于，当 GC 在进行回收时，需要通过算法检查是否回收软引用对象，而对于弱引用对象，GC 总是进行回收。弱引用对象更容易、更快被 GC 回收。</p>
<p>WeakHashMap？弱引用！</p>
<p><strong>再谈引用：虚引用</strong><br>虚引用（Phantom Reference）：<strong>对象回收跟踪</strong></p>
<p>也称为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个</p>
<p>一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收。</p>
<p>它不能单独使用，也无法通过虚引用来获取被引用的对象。当试图通过虚引用的 get()方法取得对象时，总是 null 。即通过虚引用无法获取到我们的数据</p>
<p>为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如：能在这个对象被收集器回收时收到一个系统通知。</p>
<p>虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。</p>
<p>由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。</p>
<p>在 JDK1.2 版之后提供了 PhantomReference 类来实现虚引用。</p>
<h3 id="标记阶段"><a href="#标记阶段" class="headerlink" title="标记阶段"></a>标记阶段</h3><p><strong>标记阶段的目的</strong><br>垃圾标记阶段：主要是为了判断对象是否存活</p>
<p>在堆里存放着几乎所有的 Java 对象实例，在 GC 执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC 才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为垃圾标记阶段。<br>那么在 JVM 中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。</p>
<h4 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h4><p>引用计数算法（Reference Counting）比较简单，对每个对象保存一个整型的<strong>引用计数器属性</strong>。用于记录对象被引用的情况。</p>
<p>对于一个对象 A，只要有任何一个对象引用了 A，则 A 的引用计数器就加 1；当引用失效时，引用计数器就减 1。只要对象 A 的引用计数器的值为 0，即表示对象 A 不可能再被使用，可进行回收。<br>优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。</p>
<p><strong>缺点：</strong><br>它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。<br>每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。<br>引用计数器有一个严重的问题，即<strong>无法处理循环引用的情况。这是一条致命缺陷，导致在 Java 的垃圾回收器中没有使用这类算法。</strong></p>
<p><img src="https://i.loli.net/2021/08/05/gWaOJqmfQGdnPV6.png" alt="image-20210802142919765"></p>
<p>当 p 的指针断开的时候，内部的引用形成一个循环，计数器都还算 1，无法被回收，这就是循环引用，从而造成<strong>内存泄漏。</strong></p>
<p><strong>小结：</strong></p>
<p>引用计数算法，是很多语言的资源回收选择，例如因人工智能而更加火热的 Python，它更是同时支持引用计数和垃圾收集机制。<br>具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。<br>Java 并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。</p>
<p>Python 如何解决循环引用？<br>手动解除：很好理解，就是在合适的时机，解除引用关系。<br>使用弱引用 weakref，weakref 是 Python 提供的标准库，旨在解决循环引用。</p>
<h4 id="可达性分析法"><a href="#可达性分析法" class="headerlink" title="可达性分析法"></a>可达性分析法</h4><p>可达性分析算法：也可以称为<strong>根搜索算法、追踪性垃圾收集</strong></p>
<p>相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。<br>相较于引用计数算法，这里的可达性分析就是 Java、C#选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集（Tracing Garbage Collection）</p>
<p><strong>其基本思路如下：</strong></p>
<p>可达性分析算法是以<strong>根对象集合（GCRoots）</strong>为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。<br>使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）<br>如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象。<br>在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。</p>
<p>堆空间的周边，比如：<strong>虚拟机栈、本地方法栈、方法区、字符串常量池</strong>等地方对堆空间进行引用的，都可以作为 GC Roots 进行可达性分析。</p>
<h5 id="GCroots-可以是什么？"><a href="#GCroots-可以是什么？" class="headerlink" title="GCroots 可以是什么？"></a>GCroots 可以是什么？</h5><p>1，虚拟机栈中引用的对象：各个线程被调用方法中使用的参数局部变量。<br>2，本地方法中引用的对象。<br>3，静态属性的对象<br>4，常量池里的引用<br>5，被 sychronized 持有的对象<br>6，系统内部的引用，异常的类等等。</p>
<p>除了这些固定的 GC Roots 集合以外，根据<strong>用户所选用的垃圾收集器以及当前回收的内存区域不同</strong>，还可以有其他对象“临时性”地加入，共同构成完整 GC Roots 集合。比如：<strong>分代收集和局部回收（PartialGC）</strong>。</p>
<p>如果只针对 Java 堆中的某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到内存区域是虚拟机自己的实现细节，更不是孤立封闭的，<strong>这个区域的对象完全有可能被其他区域的对象所引用</strong>，这时候就需要一并将关联的区域对象也加入 GC Roots 集合中去考虑，才能保证可达性分析的准确性。</p>
<p>如果要使用可达性分析算法来判断内存是否可回收，那么<strong>分析工作必须在一个能保障一致性的快照中进行</strong>。这点不满足的话分析结果的准确性就无法保证。</p>
<p>这点也是导致 GC 进行时必须“Stop The World”的一个重要原因。即使是号称（几乎）不会发生停顿的 CMS 收集器中，枚举根节点时也是必须要停顿的。</p>
<h5 id="对象的-finalization-机制"><a href="#对象的-finalization-机制" class="headerlink" title="对象的 finalization 机制"></a>对象的 finalization 机制</h5><p>finalize() 方法机制<br>对象销毁前的回调函数：finalize()</p>
<p>Java 语言提供了<strong>对象终止（finalization）机制</strong>来允许开发人员提供对象被销毁之前的自定义处理逻辑。</p>
<p>当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的 finalize()方法。</p>
<p>finalize() 方法允许在子类中被重写，用于在对象被回收时进行资源释放。通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等。</p>
<p>Object 类中 finalize() 源码<br>&#x2F;&#x2F; 等待被重写<br>protected void finalize() throws Throwable { }</p>
<p>永远不要主动调用某个对象的 finalize()方法，应该交给垃圾回收机制调用。理由包括下面三点：<br>在 finalize()时可能会导致对象复活。<br>finalize()方法的执行时间是没有保障的，它完全由 GC 线程决定，极端情况下，若不发生 GC，则 finalize()方法将没有执行机会。<br>一个糟糕的 finalize()会严重影响 GC 的性能。比如 finalize 是个死循环</p>
<p>从功能上来说，finalize()方法与 C++中的<strong>析构函数</strong>比较相似，但是 Java 采用的是基于垃圾回收器的自动内存管理机制，所以 finalize()方法在本质上不同于 C++中的析构函数。<br>finalize()方法对应了一个 finalize 线程，<strong>因为优先级比较低，即使主动调用该方法，也不会因此就直接进行回收</strong></p>
<p>由于 finalize()方法的存在，虚拟机中的对象一般处于三种可能的状态。</p>
<p>如果从所有的根节点都无法访问到某个对象，说明对象己经不再使用了。一般来说，此对象需要被回收。但事实上，也并非是“非死不可”的，这时候它们暂时处于“<strong>缓刑</strong>”阶段。一个无法触及的对象有可能在某一个条件下“复活”自己，如果这样，那么对它立即进行回收就是不合理的。为此，定义虚拟机中的对象可能的三种状态。如下：<br><strong>可触及的：</strong>从根节点开始，可以到达这个对象。<br><strong>可复活的：</strong>对象的所有引用都被释放，但是对象有可能在 finalize()中复活。<br><strong>不可触及的：</strong>对象的 finalize()被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，因为 finalize()只会被调用一次。</p>
<p>以上 3 种状态中，是由于 finalize()方法的存在，进行的区分。只有在对象不可触及时才可以被回收。</p>
<h5 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a><strong>具体过程</strong></h5><p>判定一个对象 objA 是否可回收，至少要经历<strong>两次标记</strong>过程：</p>
<p>如果对象 objA 到 GC Roots 没有引用链，则进行第一次标记。</p>
<p>进行筛选，<strong>判断此对象是否有必要执行 finalize()方法</strong><br>如果对象 objA 没有重写 finalize()方法，或者 finalize()方法已经被虚拟机调用过，则虚拟机视为“没有必要执行”，objA 被判定为不可触及的。</p>
<p>如果对象 objA 重写了 finalize()方法，且还未执行过，那么 objA 会被插入到<strong>F-Queue 队列</strong>中，由一个虚拟机自动创建的、低优先级的 Finalizer 线程触发其 finalize()方法执行。</p>
<p>finalize()方法是<strong>对象逃脱死亡的最后机会</strong>，稍后 GC 会对 F-Queue 队列中的对象进行第二次标记。如果 objA 在 finalize()方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA 会被移出“即将回收”集合。之后，对象会再次出现没有引用存在的情况。在这个情况下，finalize()方法不会被再次调用，对象会直接变成不可触及的状态，也就是说，一个对象的 finalize()方法只会被调用一次。</p>
<h3 id="清除阶段"><a href="#清除阶段" class="headerlink" title="清除阶段"></a>清除阶段</h3><h4 id="标记清除"><a href="#标记清除" class="headerlink" title="标记清除"></a>标记清除</h4><p><strong>执行过程</strong><br>当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为 stop the world），然后进行两项工作，第一项则是标记，第二项则是清除</p>
<p>标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象。<br>标记的是被引用的对象，也就是可达对象，并非标记的是即将被清除的垃圾对象</p>
<p>清除：Collector 对堆内存从头到尾进行线性的遍历，如果发现某个对象在其 Header 中没有标记为可达对象，则将其回收</p>
<h5 id="标记-清除算法的缺点"><a href="#标记-清除算法的缺点" class="headerlink" title="标记-清除算法的缺点"></a>标记-清除算法的缺点</h5><p>标记清除算法的效率不算高<br>在进行 GC 的时候，需要停止整个应用程序，用户体验较差（stw）<br>这种方式清理出来的空闲内存是不连续的，<strong>产生内碎片</strong>，需要维护一个空闲列表</p>
<h5 id="何为清除？"><a href="#何为清除？" class="headerlink" title="何为清除？"></a>何为清除？</h5><p>这里所谓的清除并不是真的置空，<strong>而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放（也就是覆盖原有的地址）</strong>。</p>
<p>关于空闲列表是在为对象分配内存的时候：<br><strong>如果内存规整，采用指针碰撞的方式进行内存分配</strong><br><strong>如果内存不规整，虚拟机需要维护一个空闲列表采用空闲列表分配内存</strong></p>
<h4 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h4><p>将活着的内存空间分为两块，<strong>每次只使用其中一块</strong>，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。</p>
<p><strong>新生代里面就用到了复制算法，Eden 区和 S0 区存活对象整体复制到 S1 区。</strong></p>
<h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><p>没有标记和清除过程，实现简单，运行高效<br>复制过去以后保证空间的连续性，不会出现“碎片”问题。</p>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><p>此算法的缺点也是很明显的，<strong>就是需要两倍的内存空间。</strong><br>对于 G1 这种分拆成为大量 region 的 GC，复制而不是移动，意味着 GC 需要维护 region 之间对象引用关系，不管是内存占用或者时间开销也不小</p>
<p><strong>特别：</strong><br>如果系统中的垃圾对象很多，<strong>复制算法需要复制的存活对象数量太大，效率变低。</strong></p>
<p>在新生代，对象，朝生夕死，一次通常可以回收 70% - 99% 的内存空间。回收性价比很高。所以现在的商业虚拟机都是用这种收集算法回收新生代。</p>
<h4 id="标记压缩"><a href="#标记压缩" class="headerlink" title="标记压缩"></a>标记压缩</h4><p><strong>标记-压缩（或标记-整理、Mark - Compact）算法</strong></p>
<p>复制算法的高效性是建立在<strong>存活对象少、垃圾对象多</strong>的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。</p>
<p>标记-清除算法的确可以<strong>应用在老年代</strong>中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片，所以 JVM 的设计者需要在此基础之上进行改进。标记-压缩（Mark-Compact）算法由此诞生。</p>
<p>执行过程<br>第一阶段和标记清除算法一样，<strong>从根节点开始标记所有被引用对象</strong><br>第二阶段将<strong>所有的存活对象压缩到内存的一端，按顺序排放。之后，清理边界外所有的空间。</strong></p>
<h5 id="标记-压缩算法与标记-清除算法的比较"><a href="#标记-压缩算法与标记-清除算法的比较" class="headerlink" title="标记-压缩算法与标记-清除算法的比较"></a>标记-压缩算法与标记-清除算法的比较</h5><p>标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为<strong>标记-清除-压缩</strong>（Mark-Sweep-Compact）算法。</p>
<p>二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。</p>
<p>可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当我们需要给新对象分配内存时，<strong>JVM 只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。</strong></p>
<p><strong>优点</strong></p>
<p>消除了标记-清除算法当中，内存区域分散的缺点，我们需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可。<br>消除了复制算法当中，内存减半的高额代价。</p>
<p><strong>缺点</strong></p>
<p>从效率上来说，<strong>标记-整理算法要低于复制算法。</strong><br><strong>移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址</strong>（因为 HotSpot 虚拟机采用的不是句柄池的方式，而是直接指针）<br>移动过程中，需要全程暂停用户应用程序。即：STW</p>
<p><img src="https://i.loli.net/2021/08/05/M7nHWifTIFvLU8o.png" alt="image-20210802144424767"></p>
<h3 id="分带收集算法"><a href="#分带收集算法" class="headerlink" title="分带收集算法"></a>分带收集算法</h3><p>前面所有这些算法中，并没有一种算法可以完全替代其他算法，<strong>它们都具有自己独特的优势和特点。</strong>分代收集算法应运而生。</p>
<p>分代收集算法，是基于这样一个事实：<strong>不同的对象的生命周期是不一样的</strong>。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。</p>
<p>在 Java 程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关:<br>比如 Http 请求中的 Session 对象、线程、Socket 连接，这类对象跟业务直接挂钩，因此生命周期比较长。</p>
<p>但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String 对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。<br>目前几乎所有的 GC 都采用分代收集算法 执行垃圾回收的</p>
<p>在 HotSpot 中，基于分代的概念，GC 所使用的内存回收算法必须结合年轻代和老年代各自的特点。</p>
<p><strong>年轻代（Young Gen）</strong><br>年轻代特点：区域相对老年代较小，<strong>对象生命周期短、存活率低，回收频繁。</strong><br>这种情况<strong>复制算法的回收整理，速度是最快的。</strong>复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。<strong>而复制算法内存利用率不高的问题，通过 hotspot 中的两个 survivor 的设计得到缓解</strong>。</p>
<p><strong>老年代（Tenured Gen）</strong><br>老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。<br>这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由<strong>标记-清除或者是标记-清除与标记-整理的混合实现。</strong></p>
<p>Mark 阶段的开销与<strong>存活对象的数量成正比。</strong>（遍历所有对象）<br>Sweep 阶段的开销与所<strong>管理区域的大小成正相关</strong>。<br>Compact 阶段的开销与<strong>存活对象的数量成正比。</strong></p>
<p>以 HotSpot 中的<strong>CMS 回收器为例，CMS 是基于 Mark-Sweep 实现的</strong>，对于对象的回收效率很高。对于碎片问题，CMS 采用基于<strong>Mark-Compact 算法的 Serial Old 回收器作为补偿措施</strong>：当内存回收不佳（碎片导致的 Concurrent Mode Failure 时），将采用 Serial Old 执行 Full GC 以达到对老年代内存的整理。</p>
<p>分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。</p>
<h3 id="增量收集算法"><a href="#增量收集算法" class="headerlink" title="增量收集算法"></a>增量收集算法</h3><p>如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，<strong>垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。</strong></p>
<p>总的来说，增量收集算法的基础仍是<strong>传统的标记-清除和复制算法</strong>。增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作</p>
<p><strong>增量收集算法的缺点</strong><br>使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。<strong>但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。</strong></p>
<h3 id="分区算法"><a href="#分区算法" class="headerlink" title="分区算法"></a>分区算法</h3><p><strong>主要针对 G1 收集器来说的</strong></p>
<p>一般来说，在相同条件下，堆空间越大，一次 GC 时所需要的时间就越长，有关 GC 产生的停顿也越长。为了更好地控制 GC 产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次 GC 所产生的停顿。</p>
<p>分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。</p>
<p><img src="https://i.loli.net/2021/08/05/iIkWjETN43rCoFX.png" alt="image-20210802144806782"></p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机-内存结构</title>
    <url>/2021/07/30/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2021/08/05/y2G1hPE34wWgxtm.png" alt="image-20210805143306994"></p>
<h3 id="jvm-内存分配"><a href="#jvm-内存分配" class="headerlink" title="jvm 内存分配"></a>jvm 内存分配</h3><p>-Xms	初始堆大小	<strong>物理内存的 1&#x2F;64</strong>(&lt;1GB)	</p>
<p>-Xmx	最大堆大小	<strong>物理内存的 1&#x2F;4(&lt;1GB)</strong>	</p>
<p>-Xmn	年轻代大小    <strong>整个堆的 3&#x2F;8</strong>    （eden+ 2 survivor space)</p>
<p>-Xss	<strong>每个线程的堆栈大小</strong>	 	JDK5.0 以后每个线程堆栈大小为**1M,**以前每个线程堆栈大小为 256K<br>一般小的应用， 如果栈不是很深， 应该是 128k 够用的 大的应用建议使用 256k。这个选项对性能影响比较大，需要严格的测试</p>
<p>-XX:NewRatio	年轻代与年老代的比值	&#x3D;4 年轻代占整个堆栈的 1&#x2F;5</p>
<p>-XX:SurvivorRatio	Eden 区与 Survivor 区的大小比值	设置为 8,则两个 Survivor 区与一个 Eden 区的比值为 2:8</p>
<p>-XX:TLABWasteTargetPercent	TLAB 占 eden 区的百分比	1%</p>
<h3 id="jvm-与-java-体系结构"><a href="#jvm-与-java-体系结构" class="headerlink" title="jvm 与 java 体系结构"></a>jvm 与 java 体系结构</h3><h4 id="跨平台的语言"><a href="#跨平台的语言" class="headerlink" title="跨平台的语言"></a>跨平台的语言</h4><p><img src="https://i.loli.net/2021/08/05/i34EhPRJe9w6j1y.png" alt="image-20210805143331921"></p>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>一次编译，到处运行<br>自动内存管理<br>自动垃圾回收功能<br>JVM 是运行在操作系统之上的，它与硬件没有直接的交互。</p>
<h3 id="运行时数据区以及线程"><a href="#运行时数据区以及线程" class="headerlink" title="运行时数据区以及线程"></a>运行时数据区以及线程</h3><p><strong>线程独有：独立包括程序计数器、栈、本地方法栈</strong><br><strong>线程间共享：堆、堆外内存（永久代或元空间、代码缓存（方法区））</strong></p>
<p><strong>Runtime 类</strong><br>每个 JVM 只有一个 Runtime 实例。即为运行时环境，相当于内存结构的中间的那个框框：运行时环境。</p>
<h4 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h4><p>1，线程是一个程序里的<strong>运行单元</strong>。JVM 允许一个应用有多个线程并行的执行<br>2，在 Hotspot JVM 里，<strong>每个线程都与操作系统的本地线程直接映射</strong><br>当一个 Java 线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java 线程执行终止后，本地线程也会回收<br>3，操作系统负责将线程安排调度到任何一个可用的 CPU 上。一旦本地线程初始化成功，它就会调用 Java 线程中的 run()方法</p>
<h4 id="JVM-系统线程"><a href="#JVM-系统线程" class="headerlink" title="JVM 系统线程"></a>JVM 系统线程</h4><p>如果你使用 jconsole 或者是任何一个调试工具（内存监控工具），都能看到在后台有许多线程在运行。这些后台线程不包括调用 public static void main(String[])的 main 线程以及所有这个 main 线程自己创建的线程。</p>
<p>这些主要的后台系统线程在 Hotspot JVM 里主要是以下几个：<br><strong>虚拟机线程：</strong>这种线程的操作是需要 JVM 达到安全点才会出现。这些操作必须在不同的线程中发生的原因是他们都需要 JVM 达到安全点，这样堆才不会变化。这种线程的执行类型括”stop-the-world”的垃圾收集，线程栈收集，线程挂起以及偏向锁撤销<br><strong>周期任务线程：</strong>这种线程是时间周期事件的体现（比如中断），他们一般用于周期性操作的调度执行<br><strong>GC 线程：</strong>这种线程对在 JVM 里不同种类的垃圾收集行为提供了支持<br><strong>编译线程：</strong>这种线程在运行时会将字节码编译成到本地代码<br><strong>信号调度线程：</strong>这种线程接收信号并发送给 JVM，在它内部通过调用适当的方法进行处理</p>
<h3 id="机器慢了怎么查"><a href="#机器慢了怎么查" class="headerlink" title="机器慢了怎么查"></a>机器慢了怎么查</h3><h4 id="使用-top-命令检查-CPU-负载"><a href="#使用-top-命令检查-CPU-负载" class="headerlink" title="使用 top 命令检查 CPU 负载"></a>使用 top 命令检查 CPU 负载</h4><p>除了上述检查的情况之外，还可以使用命令 top 来检查 CPU 负载，将实时显示 process 的动态。资源使用最高的进程排在最前面。</p>
<h4 id="机器的-io-读写和网络情况，sar"><a href="#机器的-io-读写和网络情况，sar" class="headerlink" title="机器的 io 读写和网络情况，sar"></a>机器的 io 读写和网络情况，sar</h4><h4 id="查看具体是哪个进程有占用资源高的问题，ps"><a href="#查看具体是哪个进程有占用资源高的问题，ps" class="headerlink" title="查看具体是哪个进程有占用资源高的问题，ps"></a>查看具体是哪个进程有占用资源高的问题，ps</h4><p>Ps -mp pid -o THREAD,tid,time</p>
<p>再通过 ps 命令查看这个程序的线程信息,tid 代码线程 ID，time 代表这个线程的已运行时间</p>
<h4 id="jstack-查看进程信息"><a href="#jstack-查看进程信息" class="headerlink" title="jstack 查看进程信息"></a>jstack 查看进程信息</h4><p>有了线程 ID 的 16 进制后，再在 jstack 中查看进程堆栈信息(之所有拿到 TID 信息，主要是为了查找方便)</p>
<p>通过 jstack -pid 再 grep 查询。</p>
<h4 id="本地代码问题排查"><a href="#本地代码问题排查" class="headerlink" title="本地代码问题排查"></a>本地代码问题排查</h4>]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机-对象相关</title>
    <url>/2021/08/02/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AF%B9%E8%B1%A1%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<h3 id="对象的实例化"><a href="#对象的实例化" class="headerlink" title="对象的实例化"></a>对象的实例化</h3><h4 id="创建对象的方式"><a href="#创建对象的方式" class="headerlink" title="创建对象的方式"></a>创建对象的方式</h4><p>new：最常见的方式、单例类中调用 getInstance 的静态类方法，XXXFactory 的静态方法</p>
<p>Class 的 newInstance()方法：在 JDK9 里面被标记为过时的方法，因为只能调用空参构造器，并且权限必须为 public</p>
<p>Constructor 的 newInstance(Xxxx)：反射的方式，可以调用空参的，或者带参的构造器</p>
<p>使用 clone()：不调用任何的构造器，要求当前的类需要实现 Cloneable 接口中的 clone 方法</p>
<p>使用序列化：从文件中，从网络中获取一个对象的二进制流，序列化一般用于 Socket 的网络传输</p>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><p><strong>1、判断对象对应的类是否加载、链接、初始化</strong></p>
<p>虚拟机遇到一条 new 指令，首先去检查这个指令的参数能否在<strong>Metaspace 的常量池中定位到一个类的符号引用</strong>，并且检查这个符号引用代表的类是否已经被加载，解析和初始化。（即判断类元信息是否存在）。</p>
<p>如果该类没有加载，那么在双亲委派模式下，使用当前类加载器以 ClassLoader + 包名 + 类名为 key 进行查找对应的.class 文件，如果没有找到文件，则抛出 ClassNotFoundException 异常，如果找到，则进行类加载，并生成对应的 Class 对象。</p>
<p><strong>2、为对象分配内存</strong></p>
<p>首先计算对象占用空间的大小，接着在堆中划分一块内存给新对象。如果实例成员变量是引用变量，仅分配引用变量空间即可，即 4 个字节大小</p>
<p><strong>如果内存是规整的，那么虚拟机将采用的是指针碰撞法</strong>（Bump The Point）来为对象分配内存。<strong>意思是所有用过的内存在一边，空闲的内存放另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针往空闲内存那边挪动一段与对象大小相等的距离罢了。</strong><br>如果垃圾收集器选择的是 Serial ，ParNew 这种基于压缩算法的，虚拟机采用这种分配方式。<strong>一般使用带 Compact（整理）过程的收集器时，使用指针碰撞。</strong></p>
<p>标记压缩（整理）算法会整理内存碎片，堆内存一存对象，另一边为空闲区域</p>
<p><strong>如果内存不是规整的</strong>，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是<strong>空闲列表</strong>来为对象分配内存。<br><strong>意思是虚拟机维护了一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式成为了 “空闲列表（Free List）”</strong></p>
<p>选择哪种分配方式由 Java 堆是否规整所决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定</p>
<p><strong>3、处理并发问题</strong><br>采用 CAS+失败重试，区域加锁保证更新的原子性<br>每个线程预先分配 TLAB - 通过设置 -XX:+UseTLAB 参数来设置（区域加锁机制）<br>在 Eden 区给每个线程分配一块区域</p>
<p><strong>4、初始化分配到的空间</strong><br>所有属性设置默认值，保证对象实例字段在不赋值可以直接使用<br>给对象属性赋值的顺序：<br>属性的默认值初始化<br>显示初始化&#x2F;代码块初始化（并列关系，谁先谁后看代码编写的顺序）<br>构造器初始化</p>
<p><strong>5、设置对象的对象头</strong><br>将对象的<strong>所属类（即类的元数据信息）、对象的 HashCode 和对象的 GC 信息、锁信息</strong>等数据存储在对象的对象头中。这个过程的具体设置方式取决于 JVM 实现。</p>
<p><strong>6、执行 init 方法进行初始化</strong><br>在 Java 程序的视角看来，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量<br>因此一般来说（由字节码中跟随 invokespecial 指令所决定），new 指令之后会接着就是执行 init 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完成创建出来。</p>
<p><strong>① 加载类元信息 - ② 为对象分配内存 - ③ 处理并发问题  - ④ 属性的默认初始化（零值初始化）⑤ 设置对象头的信息 - ⑥ 属性的显式初始化、代码块中初始化、构造器中初始化</strong></p>
<h3 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h3><h4 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h4><p>1，运行时元数据：<strong>哈希值，gc 分代年龄，锁状态标志，偏向线程 id</strong><br>2，<strong>类型指针：指向类元数据，确定对象的所属的类型</strong></p>
<p>如果是数组。<strong>还要记录数组长度。</strong><br>实例数据：<strong>对象真正存储的有效信息。先加载父类。</strong><br>对齐填充<strong>：不是必须的，占位符。</strong></p>
<h4 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h4><p><strong>1、句柄访问</strong></p>
<p>缺点：在堆空间中开辟了一块空间作为<strong>句柄池</strong>，句柄池本身也会占用空间；通过两次指针访问才能访问到堆中的对象，效率低<br>优点：reference 中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针即可，reference 本身不需要被修改</p>
<p><img src="https://i.loli.net/2021/08/04/EyzuL51SHXlnjsa.png" alt="image-20210804214040761"></p>
<p><strong>2、直接指针（HotSpot 采用）</strong></p>
<p>优点：直接指针是局部变量表中的引用，直接指向堆中的实例，在对象实例中有类型指针，指向的是方法区中的对象类型数据<br>缺点：对象被移动（垃圾收集时移动对象很普遍）时需要修改 reference 的值</p>
<p><img src="https://i.loli.net/2021/08/04/zPn2hVUtgM4miOo.png" alt="image-20210804214056219"></p>
]]></content>
  </entry>
  <entry>
    <title>Java虚拟机-类加载子系统</title>
    <url>/2021/07/30/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h3 id="初始化顺序？"><a href="#初始化顺序？" class="headerlink" title="初始化顺序？"></a>初始化顺序？</h3><p>（非静态：默认初始化-显示初始化-代码块初始化-无参构造初始化 or 有参构造初始化）</p>
<p>（静态：默认-显示-静态代码块-非静态代码块-无参构造初始化 or 有参构造初始化）</p>
<h3 id="A-类引用了-B-C-C-引用-B，程序入口-A，类加载顺序？"><a href="#A-类引用了-B-C-C-引用-B，程序入口-A，类加载顺序？" class="headerlink" title="A 类引用了 B,C,C 引用 B，程序入口 A，类加载顺序？"></a>A 类引用了 B,C,C 引用 B，程序入口 A，类加载顺序？</h3><p>BCA，先加载父类。</p>
<h3 id="怎样将两个全路径相同的类加载到内存？"><a href="#怎样将两个全路径相同的类加载到内存？" class="headerlink" title="怎样将两个全路径相同的类加载到内存？"></a>怎样将两个全路径相同的类加载到内存？</h3><p>类相同还需类加载器相同，自定义类加载器即可</p>
<h3 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h3><h4 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h4><p>通过一个<strong>类的全限定名</strong>获取定义此类的二进制字节流<br>将这个字节流所代表的静态存储结构转化为<strong>方法区的运行时数据结构</strong><br>在内存中生成一个代表这个类的<strong>java.lang.Class 对象</strong>，作为方法区这个类的各种数据的访问入口</p>
<p><strong>加载 class 文件的方式：</strong></p>
<p>从<strong>本地系统</strong>中直接加载<br>通过<strong>网络获取</strong>，典型场景：Web Applet<br>从 zip 压缩包中读取，成为日后 jar、war 格式的基础<br><strong>运行时计算生成</strong>，使用最多的是：动态代理技术<br>由其他文件生成，典型场景：JSP 应用从专有数据库中提取.class 文件，比较少见<br>从<strong>加密文件中获取</strong>，典型的防 Class 文件被反编译的保护措施</p>
<h4 id="链接（验证-准备-解析）"><a href="#链接（验证-准备-解析）" class="headerlink" title="链接（验证-准备-解析）"></a>链接（验证-准备-解析）</h4><p>链接分为三个子阶段：<strong>验证 —&gt; 准备 —&gt; 解析</strong></p>
<p><strong>验证(Verify)</strong></p>
<p>目的在于确保 Class 文件的字节流中<strong>包含信息符合当前虚拟机要求</strong>，保证被加载类的正确性，不会危害虚拟机自身安全<br>主要包括四种验证，<strong>文件格式验证，元数据验证，字节码验证，符号引用验证</strong>。</p>
<p><strong>准备(Prepare)</strong></p>
<p>为<strong>类变量（static 变量）分配内存并且设置该类变量的默认初始值，即零值</strong><br>这里<strong>不包含用 final 修饰</strong>的 static，因为<strong>final 在编译的时候就会分配好了默认值</strong>，准备阶段会显式初始化<br>注意：这里不会为实例变量分配初始化，<strong>类变量会分配在方法区</strong>中，而<strong>实例变量是会随着对象一起分配到 Java 堆中</strong></p>
<p><strong>解析(Resolve)</strong></p>
<p>将常量池内的<strong>符号引用转换为直接引用</strong>的过程<br>事实上，解析操作往往会伴随着 JVM 在执行完初始化之后再执行<br>符号引用就是<strong>一组符号来描述所引用的目标</strong>。符号引用的字面量形式明确定义在《java 虚拟机规范》的 class 文件格式中。<strong>直接引用</strong>就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄</p>
<p>解析动作主要针对<strong>类或接口、字段、类方法、接口方法、方法类型</strong>等。对应常量池中的 CONSTANT Class info、CONSTANT Fieldref info、CONSTANT Methodref info 等</p>
<h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>java 类的初始化时机（对类的使用）：<br><strong>主动使用：</strong><br><strong>创建类的实例</strong><br><strong>访问某个类或接口的静态变量</strong>，或者对该静态变量赋值<br><strong>调用类的静态方法</strong><br><strong>反射</strong>（比如：Class.forName(“com.atguigu.Test”)）<br><strong>初始化一个类的子类</strong><br>Java 虚拟机启动时被标明为启动类的类<br>JDK7 开始提供的动态语言支持：</p>
<p>java.lang.invoke.MethodHandle 实例的解析结果 REF_getStatic、REF putStatic、REF_invokeStatic 句柄对应的类没有初始化，则初始化<br>除了以上七种情况，其他使用 Java 类的方式都被看作是<strong>对类的被动使用</strong>，都不会导致类的初始化，会加载，不会初始化。即不会执行初始化阶段（<strong>不会调用 clinit() 方法和 init() 方法</strong>）</p>
<p><strong>clinit()</strong><br>初始化阶段就是执行类构造器方法**<clinit>()**的过程<br>此方法不需定义，是 javac 编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。也就是说，当我们代码中包含 static 变量的时候，就会有 clinit 方法<br><clinit>()方法中的指令按语句在源文件中出现的顺序执行<br><clinit>()不同于类的构造器。（关联：构造器是虚拟机视角下的<init>()）</p>
<p><strong>若该类具有父类，</strong>JVM 会保证子类的<clinit>()执行前，父类的<clinit>()已经执行完毕（父类先执行）。Son 类的父类是 Father 类，所以<strong>需要先执行 Father 类的加载，再执行 Son 类的加载</strong></p>
<h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>JVM 严格来讲支持两种类型的类加载器 。分别为<strong>引导类加载器</strong>（Bootstrap ClassLoader）和<strong>自定义类加载器</strong>（User-Defined ClassLoader）</p>
<h4 id="虚拟机自带的加载器"><a href="#虚拟机自带的加载器" class="headerlink" title="虚拟机自带的加载器"></a>虚拟机自带的加载器</h4><p><strong>启动类加载器（引导类加载器，Bootstrap ClassLoader）</strong><br>这个类加载使用 C&#x2F;C++语言实现的，嵌套在 JVM 内部<br>它用来加载<strong>Java 的核心库</strong>（JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar、resources.jar 或 sun.boot.class.path 路径下的内容），用于提供 JVM 自身需要的类<br>并不继承自 java.lang.ClassLoader，没有父加载器<br>加载扩展类和应用程序类加载器，并作为他们的父类加载器<br>出于安全考虑，Bootstrap 启动类加载器只加载包名为<strong>java、javax、sun</strong>等开头的类</p>
<p><strong>扩展类加载器（Extension ClassLoader）</strong><br>Java 语言编写，由 sun.misc.Launcher$ExtClassLoader 实现<br>派生于 ClassLoader 类<br>父类加载器为启动类加载器<br>从<strong>java.ext.dirs</strong>系统属性所指定的目录中加载类库，或从 JDK 的安装目录的<strong>jre&#x2F;lib&#x2F;ext</strong>子目录（扩展目录）下加载类库。如果用户创建的 JAR 放在此目录下，也会自动由扩展类加载器加载</p>
<p><strong>应用程序类加载器（也称为系统类加载器，AppClassLoader）</strong><br>Java 语言编写，由 sun.misc.LaunchersAppClassLoader 实现<br>派生于 ClassLoader 类<br>父类加载器为扩展类加载器<br>它负责加载<strong>环境变量 classpath 或系统属性 java.class.path 指定路径下的类库</strong><br>该类加载是程序中默认的类加载器，一般来说，<strong>Java 应用的类都是由它来完成加载</strong><br>通过 classLoader.getSystemclassLoader()方法可以获取到该类加载器</p>
<p><strong>用户自定义类加载器</strong></p>
<p><strong>什么时候需要自定义类加载器？</strong><br>在 Java 的日常应用程序开发中，类的加载几乎是由上述 3 种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。那为什么还需要自定义类加载器？</p>
<p><strong>隔离加载类</strong>（比如说我假设现在 Spring 框架，和 RocketMQ 有包名路径完全一样的类，类名也一样，这个时候类就冲突了。不过<strong>一般的主流框架和中间件都会自定义类加载器，实现不同的框架，中间价之间是隔离的</strong>）</p>
<p><strong>修改类加载的方式</strong><br>扩展加载源（还可以考虑从数据库中加载类，路由器等等不同的地方）<br><strong>防止源码泄漏</strong>（对字节码文件进行解密，自己用的时候通过自定义类加载器来对其进行解密）</p>
<p><strong>如何自定义类加载器？</strong><br>开发人员可以通过继承抽象类<strong>java.lang.ClassLoader 类</strong>的方式，实现自己的类加载器，以满足一些特殊的需求<br>在 JDK1.2 之前，在自定义类加载器时，总会去继承 ClassLoader 类并重写 loadClass()方法，从而实现自定义的类加载类，但是在 JDK1.2 之后已不再建议用户去覆盖 loadClass()方法，而是建议把自定义的类加载逻辑写在<strong>findclass()方法中</strong><br>在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承 URIClassLoader 类，这样就可以避免自己去编写 findclass()方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。<br>ClassLoader 类，它是一个抽象类，其后所有的类加载器都继承自 ClassLoader（不包括启动类加载器）</p>
<h3 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h3><p>Java 虚拟机对 class 文件采用的是<strong>按需加载</strong>的方式，也就是说当需要使用该类时才会将它的 class 文件加载到内存生成 class 对象。而且加载某个类的 class 文件时，Java 虚拟机采用的是双亲委派模式，即把请求交由父类处理，它是一种任务委派模式。</p>
<p>1，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行；<br>2，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器；<br>3，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。</p>
<p>父类加载器一层一层往下分配任务，如果子类加载器能加载，则加载此类，如果将加载任务分配至系统类加载器也无法加载此类，则抛出异常。</p>
<h4 id="双亲委派机制优势"><a href="#双亲委派机制优势" class="headerlink" title="双亲委派机制优势"></a>双亲委派机制优势</h4><p><strong>避免类的重复加载</strong><br>保护程序安全，防止<strong>核心 API</strong>被随意篡改<br>自定义类：自定义 java.lang.String 没有被加载。<br>自定义类：java.lang.ShkStart（报错：阻止创建 java.lang 开头的类）</p>
<h4 id="如何判断两个-class-对象是否相同？"><a href="#如何判断两个-class-对象是否相同？" class="headerlink" title="如何判断两个 class 对象是否相同？"></a>如何判断两个 class 对象是否相同？</h4><p>在 JVM 中表示两个 class 对象是否为同一个类存在两个必要条件：<br>1，<strong>类的完整类名必须一致，包括包名</strong><br>2，加载这个类的<strong>ClassLoader（指 ClassLoader 实例对象）必须相同</strong></p>
<p>换句话说，在 JVM 中，即使这两个类对象（class 对象）来源同一个 Class 文件，被同一个虚拟机所加载，但只要加载它们的 ClassLoader 实例对象不同，那么这两个类对象也是不相等的</p>
<p><strong>对类加载器的引用</strong><br>JVM 必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的<br>如果一个类型是由用户类加载器加载的，那么 JVM 会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中<br>当解析一个类型到另一个类型的引用的时候，<strong>JVM 需要保证这两个类型的类加载器是相同的。</strong></p>
<h4 id="打破双亲委派机制？"><a href="#打破双亲委派机制？" class="headerlink" title="打破双亲委派机制？"></a>打破双亲委派机制？</h4><p>打破双亲委派机制的场景有很多：JDBC、Tomcat 等</p>
<p>为什么 JDBC 需要破坏双亲委派模式，原因是原生的 JDBC 中 Driver 驱动本身只是一个接口，并没有具体的实现，具体的实现是由不同数据库类型去实现的。例如，MySQL 的 mysql-connector-.jar 中的 Driver 类具体实现的。 </p>
<p>原生的 JDBC 中的类是放在 rt.jar 包的，是由<strong>启动类加载器</strong>进行类加载的，在 JDBC 中的 Driver 类中需要动态去加载不同数据库类型的 Driver 类，而 mysql-connector-.jar 中的 Driver 类是用户自己写的代码，那启动类加载器肯定是不能进行加载的，既然是自己编写的代码，那就需要由<strong>应用程序启动类去进行类加载</strong>。</p>
<p>于是乎，这个时候就<strong>引入线程上下文件类加载器(Thread Context ClassLoader</strong>)。有了这个东西之后，程序就可以把原本需要由启动类加载器进行加载的类，由应用程序类加载器去进行加载了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">private static Connection getConnection(<br>        String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException &#123;<br>        /*<br>         * When callerCl is null, we should check the application&#x27;s<br>         * (which is invoking this class indirectly)<br>         * classloader, so that the JDBC driver class outside rt.jar<br>         * can be loaded from here.<br>         */<br>        //callerCL为空的时候，其实说明这个ClassLoader是启动类加载器，但是这个启动类加载并不能识别rt.jar之外的类，这个时候就把callerCL赋值为Thread.currentThread().getContextClassLoader();也就是应用程序启动类<br>        ClassLoader callerCL = caller != null ? caller.getClassLoader() : null;<br>        synchronized(DriverManager.class) &#123;<br>            // synchronize loading of the correct classloader.<br>            if (callerCL == null) &#123;<br>                callerCL = Thread.currentThread().getContextClassLoader();<br>            &#125;<br>        &#125;<br><br>        if(url == null) &#123;<br>            throw new SQLException(&quot;The url cannot be null&quot;, &quot;08001&quot;);<br>        &#125;<br><br>        println(&quot;DriverManager.getConnection(\&quot;&quot; + url + &quot;\&quot;)&quot;);<br><br>        // Walk through the loaded registeredDrivers attempting to make a connection.<br>        // Remember the first exception that gets raised so we can reraise it.<br>        SQLException reason = null;<br><br>        for(DriverInfo aDriver : registeredDrivers) &#123;<br>            // If the caller does not have permission to load the driver then<br>            // skip it.<br>            //继续看这里 <br>            if(isDriverAllowed(aDriver.driver, callerCL)) &#123;<br>                try &#123;<br>                    println(&quot;    trying &quot; + aDriver.driver.getClass().getName());<br>                    Connection con = aDriver.driver.connect(url, info);<br>                    if (con != null) &#123;<br>                        // Success!<br>                        println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName());<br>                        return (con);<br>                    &#125;<br>                &#125; catch (SQLException ex) &#123;<br>                    if (reason == null) &#123;<br>                        reason = ex;<br>                    &#125;<br>                &#125;<br><br>            &#125; else &#123;<br>                println(&quot;    skipping: &quot; + aDriver.getClass().getName());<br>            &#125;<br><br>        &#125;<br><br>        // if we got here nobody could connect.<br>        if (reason != null)    &#123;<br>            println(&quot;getConnection failed: &quot; + reason);<br>            throw reason;<br>        &#125;<br><br>        println(&quot;getConnection: no suitable driver found for &quot;+ url);<br>        throw new SQLException(&quot;No suitable driver found for &quot;+ url, &quot;08001&quot;);<br>    &#125;<br><br>    private static boolean isDriverAllowed(Driver driver, ClassLoader classLoader) &#123;<br>        boolean result = false;<br>        if(driver != null) &#123;<br>            Class&lt;?&gt; aClass = null;<br>            try &#123;<br>                //这一步会对类进行初始化的动作，而初始化之前自然也要进行的类的加载工作<br>                aClass =  Class.forName(driver.getClass().getName(), true, classLoader);<br>            &#125; catch (Exception ex) &#123;<br>                result = false;<br>            &#125;<br><br>             result = ( aClass == driver.getClass() ) ? true : false;<br>        &#125;<br><br>        return result;<br>    &#125;<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql-sql常见语法与优化</title>
    <url>/2021/07/30/Mysql-sql%E5%B8%B8%E8%A7%81%E8%AF%AD%E6%B3%95%E4%B8%8E%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="sql-语法举例"><a href="#sql-语法举例" class="headerlink" title="sql 语法举例"></a>sql 语法举例</h2><p>有一张表，三列：name,course(课程)，score，查询出每个学生的总成绩并按从高到低排序。</p>
<p>SELECT NAME,SUM(score) FROM chengji</p>
<p>GROUP BY NAME</p>
<p>ORDER BY SUM(score) DESC;</p>
<h3 id="顺序"><a href="#顺序" class="headerlink" title="顺序"></a>顺序</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">Select <br>From<br>Join on<br>Where<br>Group by<br>Having<br>Order by<br>Limit<br></code></pre></td></tr></table></figure>



<h3 id="单表"><a href="#单表" class="headerlink" title="单表"></a>单表</h3><p><img src="https://i.loli.net/2021/08/04/1WtTkRxDCL96fSI.png" alt="image-20210804132616343">1,</p>
<p>查找面积超过 3,000,000 或者人口数超过 25,000,000 的国家。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT name,<br>    population,<br>    area<br>FROM<br>    World<br>WHERE<br>    area &gt; 3000000<br>    OR population &gt; 25000000;<br></code></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/04/V7tN63gewq8cWoz.png" alt="image-20210804132827111"></p>
<p>查找 id 为奇数，并且 description 不是 boring 的电影，按 rating 降序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT<br>    *<br>FROM<br>    cinema<br>WHERE<br>    id % 2 = 1<br>    AND description != &#x27;boring&#x27;<br>ORDER BY<br>    rating DESC;<br></code></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/04/hAqr8muJgKMHdXl.png" alt="image-20210804132946054"></p>
<p>查找有五名及以上 student 的 class。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT<br>    class<br>FROM<br>    courses<br>GROUP BY<br>    class<br>HAVING<br>    count( DISTINCT student ) &gt;= 5;<br></code></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/04/n2l8UXRjZWYgEVb.png" alt="image-20210804133126602"></p>
<p>重复的 email。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT<br>    Email<br>FROM<br>    Person<br>GROUP BY<br>    Email<br>HAVING<br>    COUNT( * ) &gt;= 2;<br></code></pre></td></tr></table></figure>



<h3 id="多表"><a href="#多表" class="headerlink" title="多表"></a>多表</h3><p><img src="https://i.loli.net/2021/08/04/uiLUs7CpH4Bn1mq.png" alt="image-20210804133312954"></p>
<p>查找 FirstName, LastName, City, State 数据，而不管一个用户有没有填地址信息。</p>
<p>涉及到 Person 和 Address 两个表，在对这两个表执行连接操作时，<strong>因为要保留 Person 表中的信息</strong>，即使在 Address 表中没有关联的信息也要保留。此时可以用左外连接，<strong>将 Person 表放在 LEFT JOIN 的左边。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT<br>    FirstName,<br>    LastName,<br>    City,<br>    State<br>FROM<br>    Person P<br>    LEFT JOIN Address A<br>    ON P.PersonId = A.PersonId;<br></code></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/04/VB8OXqrEd5FAUlb.png" alt="image-20210804133630796"></p>
<p>没有订单的客户信息？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT<br>    C.Name AS Customers<br>FROM<br>    Customers C<br>    LEFT JOIN Orders O<br>    ON C.Id = O.CustomerId<br>WHERE<br>    O.CustomerId IS NULL;<br> ----------------------------------------------------------------------------   <br>SELECT<br>    Name AS Customers<br>FROM<br>    Customers<br>WHERE<br>    Id NOT IN ( <br>        SELECT CustomerId <br>        FROM Orders <br>    );<br></code></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/04/Jai1wMqE6ZLFjzu.png" alt="image-20210804133923061"></p>
<p>查找一个 Department 中收入最高者的信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT<br>    D.NAME Department,<br>    E.NAME Employee,<br>    E.Salary<br>FROM<br>    Employee E,<br>    Department D,<br>    ( SELECT DepartmentId, MAX( Salary ) Salary <br>     FROM Employee <br>     GROUP BY DepartmentId ) M<br>WHERE<br>    E.DepartmentId = D.Id<br>    AND E.DepartmentId = M.DepartmentId<br>    AND E.Salary = M.Salary;<br></code></pre></td></tr></table></figure>



<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p><strong>sql 优化？</strong></p>
<p><strong>索引合理？</strong></p>
<p><strong>读写分离？</strong></p>
<p><strong>垂直分区？按照列</strong></p>
<p><strong>水平分区？</strong></p>
<p>1、*<em>查询 SQL 尽量不要使用 select <em>，而是 select 具体字段</em></em></p>
<p>只取需要的字段，节省资源、减少网络开销。<br>select * 进行查询时，很可能就不会使用到覆盖索引了，就会造成回表查询。</p>
<p>2、<strong>如果知道查询结果只有一条或者只要最大&#x2F;最小一条记录，建议用 limit 1</strong><br>Select  id，name  from employee wherename&#x3D;’jay’limit1;<br>加上 limit 1 后,只要找到了对应的一条记录,就不会继续向下扫描了,效率将会大大提高。<br>当然，如果 name 是唯一索引的话，是不必要加上 limit 1 了，因为 limit 的存在主要就是为了防止全表扫描，从而提高性能,如果一个语句本身可以预知不用全表扫描，有没有 limit ，性能的差别并不大。</p>
<p>3、<strong>应尽量避免在 where 子句中使用 or 来连接条件</strong><br>select * from userwhere userid&#x3D;1or age &#x3D;18<br>假设它走了 userId 的索引，但是走到 age 查询条件时，它还得全表扫描，也就是需要三步过程：全表扫描+索引扫描+合并 如果它一开始就走全表扫描，直接一遍扫描就完事。</p>
<p>4、<strong>优化 limit 分页</strong><br>当<strong>偏移量特别大的时候，查询效率就变得低下</strong>。<br>当偏移量最大的时候，查询效率就会越低，因为 Mysql 并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。<br>&#x2F;&#x2F;方案一 ：返回上次查询的最大记录(偏移量)<br>Select id，name from employee where id&gt;10000 limit 10.<br>&#x2F;&#x2F;方案二：order by + 索引<br>Select id，name from employee order by id limit 10000，10</p>
<p>如果使用优化方案一，返回上次最大查询记录（偏移量），这样可以跳过偏移量，效率提升不少。<br>方案二使用 order by+索引，也是可以提高查询效率的。</p>
<p>5、优化你的 like 语句<br>把%放前面，并不走索引。</p>
<p>6、<strong>使用 where 条件限定要查询的数据，避免返回多余的行</strong><br>查询某个用户是否是会员<br>select user Id from user where userId&#x3D;’userId’ and isVip&#x3D;’1’</p>
<p>7、<strong>尽量避免在索引列上使用 mysql 的内置函数</strong><br>索引列上使用 mysql 的内置函数，索引失效</p>
<p>8<strong>、应尽量避免在 where 子句中对字段进行表达式操作，这将导致系统放弃使用索引而进行全表扫描</strong><br>select * from user where age-1 &#x3D;10</p>
<p>9、Inner join 、left join、right join，<strong>优先使用 Inner join，如果是 left join，左边表结果尽量小</strong></p>
<p>10、应尽量<strong>避免在 where 子句中使用!&#x3D;或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描</strong><br><strong>!&#x3D;和&lt;&gt;很可能会让索引失效</strong></p>
<p>11、<strong>使用联合索引时，注意索引列的顺序，一般遵循最左匹配原则</strong><br>KEY idx_userid_age (userId,age&#96;) USING BTREE</p>
<p>&#x2F;&#x2F;符合最左匹配原则<br>select * from user where userid&#x3D;10 and age &#x3D;10；<br>&#x2F;&#x2F;符合最左匹配原则<br>select * from user where userid &#x3D;10;<br>当我们创建一个联合索引的时候，<strong>如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。</strong><br>联合索引不满足最左原则，索引一般会失效，但是这个还跟 Mysql 优化器有关的。</p>
<p>12、对查询进行优化，<strong>应考虑在 where 及 order by 涉及的列上建立索引，尽量避免全表扫描</strong><br>select * from user where address &#x3D;’深圳’ order by age ;<br>alter table user add index idx_address_age (address,age)</p>
<p>13<strong>、在适当的时候，使用覆盖索引</strong><br>&#x2F;&#x2F;id 为主键，name 为普通索引，即覆盖索引登场了。<br>select id,name from user where userid like ‘%123%’;</p>
<p>14、<strong>慎用 distinct 关键字</strong><br>字段很多的时候使用，却会大大降低查询效率。<br>使用 distinct，数据库引擎就会对数据进行比较，过滤掉重复数据，然而这个比较，过滤的过程会占用系统资源，cpu 时间。</p>
<p>15、<strong>删除冗余和重复索引</strong></p>
<p>16、<strong>where 子句中考虑使用默认值代替 null</strong><br>如果 mysql 优化器发现，走索引比不走索引成本还要高，肯定会放弃索引，这些条件！&#x3D;，&gt;is null，is not null 经常被认为让索引失效，其实是因为一般情况下，查询的成本高，优化器自动放弃的。</p>
<p>如果把 null 值，换成默认值，很多时候让走索引成为可能，同时，表达意思会相对清晰一点。</p>
<p>17、<strong>尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型</strong><br>连表越多，编译的时间和开销也就越大。<br>把连接表拆开成较小的几个执行，可读性更高。<br>如果一定需要连接很多表才能得到数据，那么意味着糟糕的设计了。</p>
<p>18、<strong>索引不适合建在有大量重复数据的字段上，如性别这类型数据库字段</strong><br>SQL 优化器是根据表中数据量来进行查询优化的，如果索引列有大量重复数据，Mysql 查询优化器推算发现不走索引的成本更低，很可能就放弃索引了。</p>
<p>19、尽量避免向客户端返回过多数据量，为了提高 group by 语句的效率，可以在执行到该语句前，把不需要的记录过滤掉</p>
<p>20、<strong>使用 explain 分析你 SQL 的计划</strong></p>
<h3 id="explain-各个字段代表的意思"><a href="#explain-各个字段代表的意思" class="headerlink" title="explain 各个字段代表的意思"></a>explain 各个字段代表的意思</h3><p>id ：select 查询的序列号，包含一组数字，表示查询中执行 select 子句或操作表的顺序</p>
<p>select_type ：查询类型 或者是 其他操作类型</p>
<p>table ：正在访问哪个表</p>
<p>type ：访问的类型</p>
<p>possible_keys ：显示可能应用在这张表中的索引，一个或多个，但不一定实际使用到</p>
<p>key ：实际使用到的索引，如果为 NULL，则没有使用索引</p>
<p>key_len ：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度</p>
<p>ref ：显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值</p>
<p>rows ：根据表统计信息及索引选用情况，大致估算出找到所需的记录所需读取的行数</p>
<p>Extra ：包含不适合在其它列中显示但十分重要的额外信息</p>
<p><strong>id 与 table 字段</strong><br>通过这两个字段可以完全判断出你的每一条 SQL 语句的执行顺序和表的查询顺序。<br>id 相同，从上到下<br>id 越大，优先级越高</p>
<p><strong>select_type 字段</strong></p>
<p>主要是用于区别普通查询、联合查询、子查询等的复杂查询</p>
<p><strong>Type</strong></p>
<p>显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是：<br><strong>system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;ALL</strong></p>
<p>system &#x3D;表只有一行记录（等于系统表），这是 const 类型的特列，平时不会出现，这个也可以忽略不计。</p>
<p><strong>const</strong> &#x3D;表示通过索引一次就找到了,const 用于比较 primary key 或者 unique 索引。因为只匹配一行数据，所以很快如将主键置于 where 列表中，MySQL 就能将该查询转换为一个常量。</p>
<p><strong>eq_ref</strong> &#x3D;<strong>唯一性索引扫描</strong>，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。<br>SELECT * FROM student AS S JOIN stu_course AS SC ON  S.id&#x3D; SC.cid</p>
<p><strong>ref</strong> &#x3D;非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，<strong>它可能会找到多个符合条件的行</strong>，所以他应该属于查找和扫描的混合体。</p>
<p><strong>range(尽量保证)</strong>&#x3D; 只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引，一般就是在你的 where 语句中出现了 between、&lt;、&gt;、in 等的查询。<strong>这种范围扫描索引扫描比全表扫描要好</strong>，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部索引。</p>
<p><strong>index&#x3D;</strong> Full Index Scan，index 与 ALL 区别为<strong>index 类型只遍历索引树</strong>。这通常比 ALL 快，因为索引文件通常比数据文件小。（也就是说虽然 all 和 Index 都是读全表，但 index 是从索引中读取的，而 all 是从硬盘中读的）。</p>
<p><strong>ALL</strong>&#x3D; Full Table Scan，将遍历全表以找到匹配的行。<br>一般来说，得保证查询至少达到 range 级别，最好能达到 ref。</p>
<p><strong>extra</strong></p>
<p><img src="https://i.loli.net/2021/08/04/twSDImsCXHxWE2a.png" alt="image-20210804135035776"></p>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机-虚拟机栈，堆，方法区</title>
    <url>/2021/07/30/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%EF%BC%8C%E5%A0%86%EF%BC%8C%E6%96%B9%E6%B3%95%E5%8C%BA/</url>
    <content><![CDATA[<h3 id="PC-寄存器（程序计数器）"><a href="#PC-寄存器（程序计数器）" class="headerlink" title="PC 寄存器（程序计数器）"></a>PC 寄存器（程序计数器）</h3><p>它是一块<strong>很小的内存空间</strong>，几乎可以忽略不记。也是<strong>运行速度最快的存储区域</strong>。</p>
<p>在 JVM 规范中，<strong>每个线程都有它自己的程序计数器</strong>，是线程私有的，生命周期与线程的生命周期保持一致。</p>
<p>任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的 Java 方法的 JVM 指令地址；或者，如果是在执行 native 方法，则是未指定值（undefned）。</p>
<p>它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p>
<p>字节码解释器工作时就是<strong>通过改变这个计数器的值来选取下一条需要执行的字节码指令。</strong><br>它是唯一一个在 Java 虚拟机规范中<strong>没有规定任何 OutofMemoryError 情况的区域。没有垃圾回收。</strong></p>
<h4 id="PC-寄存器的作用"><a href="#PC-寄存器的作用" class="headerlink" title="PC 寄存器的作用"></a><strong>PC 寄存器的作用</strong></h4><p>PC 寄存器用来<strong>存储指向下一条指令的地址</strong>，也即将要执行的指令代码。由执行引擎读取下一条指令，并执行该指令。</p>
<p><strong>使用 PC 寄存器存储字节码指令地址有什么用呢？或者问为什么使用 PC 寄存器来记录当前线程的执行地址呢？</strong></p>
<p>因为 CPU 需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。<br>JVM 的字节码解释器就需要通过改变 PC 寄存器的值来明确下一条应该执行什么样的字节码指令。</p>
<p><strong>PC 寄存器为什么被设定为私有的？</strong></p>
<p>我们都知道所谓的多线程在一个特定的时间段内只会执行其中某一个线程的方法，CPU 会不停地做任务切换，这样必然导致经常中断或恢复，如何保证分毫无差呢？为了能够准确地记录各个线程正在执行的当前字节码指令地址，<strong>最好的办法自然是为每一个线程都分配一个 PC 寄存器，这样一来各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。</strong></p>
<h3 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>由于<strong>跨平台性</strong>的设计，Java 的指令都是根据<strong>栈来设计的</strong>。不同平台 CPU 架构不同，所以不能设计为<strong>基于寄存器</strong>的【如果设计成基于寄存器的，耦合度高，性能会有所提升，因为可以对具体的 CPU 架构进行优化，但是跨平台性大大降低】。<br>优点是跨平台，指令集小，编译器容易实现，缺点是<strong>性能下降，实现同样的功能需要更多的指令。</strong></p>
<p><strong>内存中的栈与堆</strong><br>首先栈是运行时的单位，而堆是存储的单位。<br>即：栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放，放哪里</p>
<p><strong>Java 虚拟机栈是什么？</strong><br>Java 虚拟机栈（Java Virtual Machine Stack），早期也叫 Java 栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存<strong>一个个的栈帧（</strong>Stack Frame），<strong>对应着一次次的 Java 方法调用，栈是线程私有的</strong></p>
<p><strong>虚拟机栈的生命周期</strong></p>
<p>生命周期和线程一致，也就是线程结束了，该虚拟机栈也销毁了</p>
<p><strong>虚拟机栈的作用</strong></p>
<p>主管 Java 程序的运行，它<strong>保存方法的局部变量（8 种基本数据类型、对象的引用地址）、部分结果，并参与方法的调用和返回。</strong><br>局部变量，它是相比于成员变量来说的（或属性）<br>基本数据类型变量 VS 引用类型变量（类、数组、接口）</p>
<p><strong>虚拟机栈的特点</strong></p>
<p>栈是一种快速有效的分配存储方式，<strong>访问速度仅次于程序计数器。</strong><br>JVM 直接对 Java 栈的操作只有两个：<br>每个方法执行，伴随着进栈（入栈、压栈）<br>执行结束后的出栈工作<br>对于栈来说不存在垃圾回收问题<br><strong>栈不需要 GC，但是可能存在 OOM</strong></p>
<h4 id="虚拟机栈的异常"><a href="#虚拟机栈的异常" class="headerlink" title="虚拟机栈的异常"></a>虚拟机栈的异常</h4><p>Java 虚拟机规范允许 Java 栈的大小是动态的或者是固定不变的。<br>1，如果采用<strong>固定大小的 Java 虚拟机栈</strong>，那每一个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个<strong>StackoverflowErro</strong>r 异常。<br>2，如果 Java 虚拟机栈可以<strong>动态扩展，</strong>并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 <strong>OutofMemoryError</strong> 异常。<br>我们可以使用参数 -Xss 选项来设置<strong>线程的最大栈空间</strong>，栈的大小直接决定了<strong>函数调用的最大可达深度。</strong></p>
<h4 id="栈中存储什么？"><a href="#栈中存储什么？" class="headerlink" title="栈中存储什么？"></a>栈中存储什么？</h4><p>每个线程都有自己的栈，栈中的数据都是以<strong>栈帧</strong>（Stack Frame）的格式存在<br>在这个线程上正在执行的<strong>每个方法都各自对应一个栈帧</strong>（Stack Frame）。<br>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。</p>
<h4 id="栈运行原理"><a href="#栈运行原理" class="headerlink" title="栈运行原理"></a>栈运行原理</h4><p>JVM 直接对 Java 栈的操作只有两个，就是对栈帧的压栈和出栈，遵循先进后出（后进先出）原则。<br>在一条活动线程中，一个时间点上，只会有一个活动的栈帧。<strong>即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的。</strong>这个栈帧被称为当前栈帧（Current Frame），与当前栈帧相对应的方法就是当前方法（Current Method），定义这个方法的类就是当前类（Current Class）<br>执行引擎运行的所有字节码指令只针对当前栈帧进行操作。<br><strong>如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前帧</strong>。</p>
<p><img src="https://i.loli.net/2021/08/06/j8AtPN7dDumSIwV.png" alt="image-20210801231432286">1，不同线程中所包含的栈帧是<strong>不允许存在相互引用的</strong>，即不可能在一个栈帧之中引用另外一个线程的栈帧。<br>2，如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，<strong>使得前一个栈帧重新成为当前栈帧。</strong><br>3，Java 方法有两种返回函数的方式。<br>一种是正常的函数返回，使用 return 指令。<br>另一种是方法执行中出现未捕获处理的异常，以抛出异常的方式结束。<br>但不管使用哪种方式，都会导致栈帧被弹出。</p>
<h4 id="栈帧的内部结构"><a href="#栈帧的内部结构" class="headerlink" title="栈帧的内部结构"></a>栈帧的内部结构</h4><p><img src="C:\Users\26431\AppData\Roaming\Typora\typora-user-images\image-20210806105335465.png" alt="image-20210806105335465"></p>
<p>每个栈帧中存储着：<br><strong>局部变量表</strong>（Local Variables）LV</p>
<p>1，局部变量表也被称之为<strong>局部变量数组或本地变量表</strong><br>2，定义为一个数字数组，主要用于<strong>存储方法参数和定义在方法体内的局部变量</strong>，这些数据类型包括各类基本数据类型、对象引用（reference），以及 returnAddress 返回值类型。<br>3，由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题<br>4，局部变量表所需的容量大小是在编译期确定下来的，并保存在方法的 Code 属性的 maximum local variables 数据项中。在方法运行期间是不会改变局部变量表的大小的。<br>5，方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。<br>对一个函数而言，<strong>它的参数和局部变量越多，使得局部变量表膨胀，</strong>它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。<br>进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。<br>6，局部变量表中的变量<strong>只在当前方法调用中有效。</strong><br>在方法执行时，虚拟机通过使用局部变量表<strong>完成参数值到参数变量列表的传递过程。</strong><br>当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。</p>
<p><strong>关于 Slot 的理解</strong><br>参数值的存放总是从局部变量数组索引 0 的位置开始，到数组长度-1 的索引结束。<br><strong>局部变量表，最基本的存储单元是 Slot（变量槽）</strong>，局部变量表中存放编译期可知的各种基本数据类型（8 种），引用类型（reference），returnAddress 类型的变量。<br>在局部变量表里，32 位以内的类型只占用一个 slot（包括 returnAddress 类型），64 位的类型占用两个 slot（<strong>long 和 double 8 字节</strong>）。<br>byte、short、char 在储存前被转换为 int，boolean 也被转换为 int，0 表示 false，非 0 表示 true<br>long 和 double 则占据两个 slot</p>
<p>JVM 会为局部变量表中的<strong>每一个 Slot 都分配一个访问索引</strong>，通过这个索引即可成功访问到局部变量表中指定的局部变量值<br>当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个 slot 上<br><strong>如果需要访问局部变量表中一个 64bit 的局部变量值时，只需要使用前一个索引即可</strong>。（比如：访问 long 或 double 类型变量）<br>如果当前帧是由<strong>构造方法或者实例方法</strong>创建的，那么该对象引用 this 将会存放在 index 为 0 的 slot 处，其余的参数按照参数表顺序继续排列。（this 也相当于一个变量）<br><strong>静态方法中不可使用 this，因为 this 方法变量不存在与当前方法的局部变量表中。</strong></p>
<p><strong>变量的分类：</strong></p>
<p>1、按照数据类型分：① 基本数据类型  ② 引用数据类型<br>2、按照在类中声明的位置分：<br>2-1、成员变量：在使用前，都经历过默认初始化赋值<br>2-1-1、类变量: linking 的 prepare 阶段：给类变量默认赋值<br>—&gt; initial 阶段：给类变量显式赋值即静态代码块赋值<br>2-1-2、实例变量：随着对象的创建，会在堆空间中分配实例变量空间，并进行默认赋值<br>2-2、局部变量：在使用前，必须要进行显式赋值的！否则，编译不通过。</p>
<p>参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配。<br>我们知道成员变量有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。<br>和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。</p>
<p><strong>补充：</strong><br>在栈帧中，与性能调优关系最为密切的部分就是前面提到的<strong>局部变量表</strong>。在方法执行时，虚拟机使用局部变量表完成方法的传递。<br><strong>局部变量表中的变量也是重要的垃圾回收根节点</strong>，只要被局部变量表中直接或间接引用的对象都不会被回收。</p>
<p><strong>Slot 的重复利用</strong></p>
<p>栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明新的局部变量变就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。</p>
<p><strong>操作数栈</strong>（Operand Stack）（或表达式栈）</p>
<p><strong>操作数栈的特点</strong></p>
<p>每一个独立的栈帧除了包含局部变量表以外，还包含一个后进先出（Last - In - First -Out）的 操作数栈，也可以称之为表达式栈（Expression Stack）</p>
<p>操作数栈，<strong>在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈（push）和 出栈（pop）</strong><br>某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈，<br>比如：执行复制、交换、求和等操作</p>
<p><strong>操作数栈的作用</strong></p>
<p>操作数栈，主要用于<strong>保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。</strong><br>操作数栈就是 JVM 执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，这时方法的操作数栈是空的。<br>每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的 Code 属性中，为 maxstack 的值。<br>栈中的任何一个元素都是可以任意的 Java 数据类型<br>32bit 的类型占用一个栈单位深度<br>64bit 的类型占用两个栈单位深度<br><strong>操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问。只不过操作数栈是用数组这个结构来实现的而已</strong><br>如果被调用的方法带有返回值的话，<strong>其返回值将会被压入当前栈帧的操作数栈中，并更新 PC 寄存器中下一条需要执行的字节码指令。</strong><br>操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译器期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证。<br>另外，我们说 Java 虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。</p>
<p><strong>栈顶缓存技术</strong></p>
<p>Top Of Stack Cashing（tos）<br>前面提过，基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候<strong>必然需要使用更多的入栈和出栈指令</strong>，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数（也就是你会发现指令很多）和导致内存读&#x2F;写次数多，效率不高。</p>
<p>由于操作数是存储在内存中的，因此频繁地执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM 的设计者们提出了<strong>栈顶缓存（Tos，Top-of-Stack Cashing）技术</strong>，将<strong>栈顶元素全部缓存在物理 CPU 的寄存器中</strong>，以此降低对内存的读&#x2F;写次数，提升执行引擎的执行效率。<br>寄存器的主要优点：指令更少，执行速度快，但是指令集（也就是指令种类）很多</p>
<p><strong>动态链接（或指向运行时常量池的方法引用）</strong></p>
<p>每一个栈帧内部都包含一个<strong>指向运行时常量池中该栈帧所属方法的引用</strong>。包含这个引用的目的就是为了支持当前方法的代码能够实现<strong>动态链接</strong>（Dynamic Linking），比如：invokedynamic 指令</p>
<p>在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为<strong>符号引用（</strong>Symbolic Reference）保存在 class 文件的常量池里。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是<strong>为了将这些符号引用转换为调用方法的直接引用</strong></p>
<p><strong>方法返回地址</strong>（Return Address）（或方法正常退出或者异常退出的定义）</p>
<p>存放<strong>调用该方法的 pc 寄存器的值。</strong></p>
<p>一个方法的结束，有两种方式：</p>
<p>正常执行完成<br>出现未处理的异常，非正常退出</p>
<p>无论通过哪种方式退出，在方法退出后<strong>都返回到该方法被调用的位置</strong>。方法正常退出时，调用者的 pc 计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。</p>
<p>本质上，方法的退出就是<strong>当前栈帧出栈的过程</strong>。此时，需要<strong>恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置 PC 寄存器值等</strong>，让调用者方法继续执行下去。<br>正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。</p>
<p><strong>一些附加信息</strong></p>
<p>并行每个线程下的<strong>栈都是私有的</strong>，因此每个线程都有自己各自的栈，并且每个栈里面都有很多栈帧，栈帧的大小主要由<strong>局部变量表 和 操作数栈</strong>决定的</p>
<h4 id="OOM-垃圾回收区域"><a href="#OOM-垃圾回收区域" class="headerlink" title="OOM 垃圾回收区域"></a>OOM 垃圾回收区域</h4><p><img src="https://i.loli.net/2021/08/06/cFv9Y7izj52xyU4.png" alt="image-20210802104057341"></p>
<h4 id="方法中定义的局部变量是否线程安全？"><a href="#方法中定义的局部变量是否线程安全？" class="headerlink" title="方法中定义的局部变量是否线程安全？"></a>方法中定义的局部变量是否线程安全？</h4><p>如果只有一个线程才可以操作此数据，则必是线程安全的。<br>如果有多个线程操作此数据，则此数据是共享数据。如果不考虑同步机制的话，会存在线程安全问题。<br>如果对象是在内部产生，并在内部消亡，没有返回到外部，那么它就是线程安全的，反之则是线程不安全的。</p>
<h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p><strong>一个运行时数据区只有一个堆和一个方法区。但是进程包含多个线程，他们是共享同一堆空间的。</strong></p>
<p>一个 JVM 实例只存在一个堆内存，堆也是 Java 内存管理的核心区域。</p>
<p>Java 堆区在 JVM 启动的时候即被创建，其空间大小也就确定了，堆是 JVM 管理的最大一块内存空间，并且堆内存的大小是可以调节的。-Xms  -Xms </p>
<p>《Java 虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。<br>所有的线程共享 Java 堆，在这里还可以划分<strong>线程私有的缓冲区</strong>（Thread Local Allocation Buffer，TLAB）。</p>
<p>从实际使用角度看：“几乎”所有的对象实例都在堆分配内存，但并非全部。<strong>因为还有一些对象是在栈上分配的（逃逸分析，标量替换）</strong></p>
<p>数组和对象可能永远不会存储在栈上（不一定），因为栈帧中保存引用（局部变量表），这个引用指向对象或者数组在堆中的位置。</p>
<h4 id="堆详细组成"><a href="#堆详细组成" class="headerlink" title="堆详细组成"></a>堆详细组成</h4><p><img src="https://i.loli.net/2021/08/06/CUuzaty7VlhNKYx.png" alt="image-20210802104533244"></p>
<p>-Xms 用于表示堆区的起始内存，等价于**-XX:InitialHeapSize**<br>-Xmx 则用于表示堆区的最大内存，等价于**-XX:MaxHeapSize**</p>
<p>一旦堆区中的内存大小超过“-Xmx”所指定的最大内存时，将会抛出 OutofMemoryError 异常。</p>
<p><strong>通常会将-Xms 和-Xmx 两个参数配置相同的值</strong></p>
<p>原因：假设两个不一样，初始内存小，最大内存大。在运行期间如果堆内存不够用了，会一直扩容直到最大内存。如果内存够用且多了，也会不断的缩容释放。<strong>频繁的扩容和释放造成不必要的压力，避免在 GC 之后调整堆内存给服务器带来压力。</strong></p>
<p><strong>默认情况下:</strong><br>初始内存大小：物理电脑内存大小&#x2F;64<br>最大内存大小：物理电脑内存大小&#x2F;4</p>
<h4 id="堆的分区？"><a href="#堆的分区？" class="headerlink" title="堆的分区？"></a>堆的分区？</h4><p><strong>配置新生代与老年代在堆结构的占比</strong></p>
<p>默认**-XX:NewRatio**&#x3D;2，表示<strong>新生代占 1，老年代占 2</strong>，新生代占整个堆的 1&#x2F;3</p>
<p>可以修改**-XX:NewRatio**&#x3D;4，表示新生代占 1，老年代占 4，新生代占整个堆的 1&#x2F;5</p>
<p>在 HotSpot 中，Eden 空间和另外两个 survivor 空间缺省所占的比例是<strong>8 : 1 : 1</strong></p>
<p>当然开发人员可以通过选项**-XX:SurvivorRatio**调整这个空间比例。比如-XX:SurvivorRatio&#x3D;8</p>
<p><strong>几乎所有的 Java 对象都是在 Eden 区被 new 出来的。</strong></p>
<p>绝大部分的 Java 对象的销毁都在新生代进行了（有些大的对象在 Eden 区无法存储时候，将直接进入老年代），IBM 公司的专门研究表明，新生代中 80%的对象都是“朝生夕死”的。<br>可以使用选项”-Xmn”设置新生代最大内存大小，但这个参数一般使用默认值就可以了。</p>
<h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><p><strong>new 的对象先放伊甸园区。</strong>此区有大小限制。</p>
<p>当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（<strong>MinorGC</strong>），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区。</p>
<p>然后将伊甸园中的<strong>剩余对象移动到幸存者 0 区。</strong></p>
<p>如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区的，如果没有回收，就会放到幸存者 1 区。<br>如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区。</p>
<p>啥时候能去养老区呢？<strong>可以设置次数。默认是 15 次。</strong>可以设置新生区进入养老区的年龄限制，设置 JVM 参数：**-XX:MaxTenuringThreshold**&#x3D;N 进行设置</p>
<p>在养老区，相对悠闲。当养老区内存不足时，再次触发 GC：<strong>Major GC，进行养老区的内存清理</strong><br>若养老区执行了 Major GC 之后，发现依然无法进行对象的保存，就会产生 OOM 异常。</p>
<p><strong>关于垃圾回收：频繁在新生区收集，很少在养老区收集，几乎不在永久区&#x2F;元空间收集。</strong><br><strong>幸存者 s0，s1 区，复制之后有交换，谁空谁是 to</strong></p>
<h4 id="特殊情况"><a href="#特殊情况" class="headerlink" title="特殊情况"></a>特殊情况</h4><p>对象分配的特殊情况</p>
<p>1，如果来了一个新对象，先看看 Eden 是否放的下？<br>如果 Eden 放得下，则直接放到 Eden 区<br>如果 Eden 放不下，则<strong>触发 YGC</strong> ，执行垃圾回收，看看还能不能放下？</p>
<p>2，将对象放到老年区又有两种情况：<br>如果 Eden 执行了 YGC 还是无法放不下该对象，那没得办法，只能说明是超大对象，<strong>只能直接放到老年代</strong><br>那万一老年代都放不下，则先触发 FullGC ，再看看能不能放下，放得下最好，但如果还是放不下，那只能报 OOM</p>
<p>3，如果 Eden 区满了，将对象往幸存区拷贝时，发现幸存区放不下啦，那只能便宜了某些新对象，<strong>让他们直接晋升至老年区</strong></p>
<p><img src="https://i.loli.net/2021/08/06/J83YveI9lOK5HEU.png" alt="image-20210802105500931"></p>
<p>JVM 的调优的一个环节，也就是垃圾收集，我们需要尽量的避免垃圾回收，因为在垃圾回收的过程中，容易出现 STW（Stop the World）的问题，而 <strong>Major GC 和 Full GC 出现 STW 的时间，是 Minor GC 的 10 倍以上</strong>。</p>
<p>JVM 在进行 GC 时，并非每次都对上面三个内存区域（新生代，老年代：方法区（元空间））一起回收的，大部分时候回收的都是指新生代。针对 Hotspot VM 的实现，它里面的 GC 按照回收区域又分为两大种类型：一种是部分收集（Partial GC），一种是整堆收集（FullGC）</p>
<p>部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为：<br><strong>新生代收集（Minor GC&#x2F;Young GC）：只是新生代（Eden，s0，s1）的垃圾收集</strong><br><strong>老年代收集（Major GC&#x2F;Old GC）：只是老年代的圾收集。</strong><br>目前，只有<strong>CMS GC 会有单独收集老年代的行为</strong>。</p>
<p>注意，很多时候 Major GC 会和 Full GC 混淆使用，需要具体分辨是老年代回收还是整堆回收。</p>
<p>混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。目前，只有 G1 GC 会有这种行为<br>整堆收集（Full GC）：收集整个 java 堆和方法区的垃圾收集。</p>
<h4 id="触发-Full-GC-执行的情况有如下五种"><a href="#触发-Full-GC-执行的情况有如下五种" class="headerlink" title="触发 Full GC 执行的情况有如下五种"></a>触发 Full GC 执行的情况有如下五种</h4><p>调用 System.gc()时，系统建议执行 FullGC，<strong>但是不必然执行</strong></p>
<p>老年代空间不足</p>
<p>方法区（元空间，永久代）空间不足</p>
<p>通过 Minor GC 后进入老年代的平均大小大于老年代的可用内存</p>
<p>由 Eden 区、survivor space0（From Space）区向 survivor space1（To Space）区复制时，对象大小大于 To Space 可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小</p>
<h4 id="TLAB-为对象分配内存（保证线程安全）"><a href="#TLAB-为对象分配内存（保证线程安全）" class="headerlink" title="TLAB 为对象分配内存（保证线程安全）"></a>TLAB 为对象分配内存（保证线程安全）</h4><p>堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据<br>由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的<br>为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度。</p>
<p><strong>TLAB（Thread Local Allocation Buffer）（buffer 缓冲区）</strong></p>
<p>从内存模型而不是垃圾收集的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域，它包含在 Eden 空间内。<br>多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为快速分配策略。</p>
<p>尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，<strong>但 JVM 确实是将 TLAB 作为内存分配的首选。</strong><br>在程序中，开发人员可以通过选项“**-XX:UseTLAB**”设置是否开启 TLAB 空间。</p>
<p>默认情况下，<strong>TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，</strong>当然我们可以通过选项“**-XX:TLABWasteTargetPercent**”设置 TLAB 空间所占用 Eden 空间的百分比大小。</p>
<p>一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过<strong>使用加锁机制确保数据操作的原子性</strong>，从而直接在 Eden 空间中分配内存。</p>
<h4 id="堆是分配对象的唯一选择么？"><a href="#堆是分配对象的唯一选择么？" class="headerlink" title="堆是分配对象的唯一选择么？"></a>堆是分配对象的唯一选择么？</h4><p>在《深入理解 Java 虚拟机》中关于 Java 堆内存有这样一段描述：<br>随着 JIT 编译期的发展与逃逸分析技术逐渐成熟，<strong>栈上分配、标量替换优化技术</strong>将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。</p>
<p>在 Java 虚拟机中，对象是在 Java 堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果<strong>经过逃逸分析（Escape Analysis）后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配</strong>。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。</p>
<p>此外，前面提到的基于 OpenJDK 深度定制的 TaoBao VM，其中创新的 GCIH（GC invisible heap）技术实现 off-heap，<strong>将生命周期较长的 Java 对象从 heap 中移至 heap 外，并且 GC 不能管理 GCIH 内部的 Java 对象，以此达到降低 GC 的回收频率和提升 GC 的回收效率的目的。</strong></p>
<h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p>如何将堆上的对象分配到栈，需要使用逃逸分析手段。<br>这是一种可以有效减少 Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。<br>通过逃逸分析，Java Hotspot 编译器能够<strong>分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。</strong></p>
<p>逃逸分析的基本行为就是<strong>分析对象动态作用域：</strong></p>
<p>当一个对象在方法中被定义后，<strong>对象只在方法内部使用，则认为没有发生逃逸</strong>。<br>当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中。</p>
<p><strong>如何快速的判断是否发生了逃逸分析，大家就看 new 的对象实体是否有可能在方法外被调用</strong>。</p>
<h4 id="逃逸分析的不足"><a href="#逃逸分析的不足" class="headerlink" title="逃逸分析的不足"></a>逃逸分析的不足</h4><p>其根本原因就是<strong>无法保证逃逸分析的性能消耗一定能高于他的消耗</strong>。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。</p>
<p>一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。</p>
<p>虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段。</p>
<p>注意到有一些观点，认为通过逃逸分析，JVM 会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于 JVM 设计者的选择。据我所知，Oracle Hotspot JVM 中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确在 HotSpot 虚拟机上，所有的对象实例都是创建在堆上。</p>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p><img src="https://i.loli.net/2021/08/06/Vteg5IxdSWq3YzB.png" alt="image-20210802111019642"></p>
<p><strong>方法区可以看作是一块独立于 Java 堆的内存空间。</strong></p>
<p>方法区主要存放的是 <strong>Class</strong>，而堆中主要存放的是<strong>实例化的对象</strong></p>
<p>它用于存储已被虚拟机<strong>加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。</strong></p>
<p><img src="https://i.loli.net/2021/08/06/pV7TD1gZ9F2G5Hf.png" alt="image-20210802111459872">方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域。多个线程同时加载统一个类时，只能有一个线程能加载该类，其他线程只能等等待该线程加载完毕，然后直接使用该类，即类只能加载一次。</p>
<p>方法区在 JVM 启动的时候被创建，并且它的实际的物理内存空间中和 Java 堆区一样都可以是不连续的。<br>方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。</p>
<p>方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutofMemoryError:PermGen space 或者 java.lang.OutOfMemoryError:Metaspace</p>
<p>加载大量的第三方的 jar 包<br>Tomcat 部署的工程过多（30~50 个）<br>大量动态的生成反射类<br>关闭 JVM 就会释放这个区域的内存。</p>
<p><strong>类型信息</strong><br>对每个加载的类型（类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息：<br>这个类型的完整有效名称（全名&#x3D;包名.类名）<br>这个类型直接父类的完整有效名（对于 interface 或是 java.lang.Object，都没有父类）<br>这个类型的修饰符（public，abstract，final 的某个子集）<br>这个类型直接接口的一个有序列表</p>
<p><strong>域（Field）信息</strong><br>也就是我们常说的<strong>成员变量</strong>，域信息是比较官方的称呼<br>JVM 必须在方法区中保存类型的所有域的相关信息以及域的声明顺序。<br>域的相关信息包括：<strong>域名称，域类型，域修饰符</strong>（public，private，protected，static，final，volatile，transient 的某个子集）</p>
<p><strong>方法（Method）信息</strong><br>JVM 必须保存所有方法的以下信息，同域信息一样包括声明顺序：<br>方法名称<br>方法的返回类型（包括 void 返回类型），void 在 Java 中对应的为 void.class<br>方法参数的数量和类型（按顺序）<br>方法的修饰符（public，private，protected，static，final，synchronized，native，abstract 的一个子集）<br>方法的字节码（bytecodes）、操作数栈、局部变量表及大小（abstract 和 native 方法除外）<br>异常表（abstract 和 native 方法除外），异常表记录每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引</p>
<p><strong>non-final 类型的类变量</strong><br><strong>静态变量和类关联在一起，随着类的加载而加载，他们成为类数据在逻辑上的一部分</strong><br>类变量被类的所有实例共享，即使没有类实例时，你也可以访问它</p>
<p><strong>全局常量：static final</strong><br>全局常量就是使用 static final 进行修饰<br>被声明为 final 的类变量的处理方法则不同，每个全局常量在编译的时候就会被分配了。<br><strong>staitc 和 final 同时修饰的 number 的值在编译上的时候已经写死在字节码文件中了。</strong></p>
<h4 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h4><p>运行时常量池 VS 常量池</p>
<p>方法区，内部包含了运行时常量池<br><strong>字节码文件，内部包含了常量池。（</strong>之前的字节码文件中已经看到了很多 Constant pool 的东西，这个就是常量池）<br>要弄清楚方法区，需要理解清楚 ClassFile，因为加载类的信息都在方法区。<br>要弄清楚方法区的运行时常量池，需要理解清楚 ClassFile 中的常量池。</p>
<h5 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a><strong>常量池</strong></h5><p>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述符信息外。还包含一项信息就是常量池表（Constant Pool Table），包括各种字面量和对类型、域和方法的符号引用。</p>
<p><strong>为什么需要常量池？</strong></p>
<p>一个 java 源文件中的类、接口，编译后产生一个字节码文件。而 Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池。<strong>这个字节码包含了指向常量池的引用。</strong>在动态链接的时候会用到运行时常量池。<br>public class SimpleClass {<br>public void sayHello() {<br>System.out.println(“hello”);<br>}<br>}<br>虽然上述代码只有 194 字节，但是里面却使用了 String、System、PrintStream 及 Object 等结构。<br>比如说我们这个文件中有 6 个地方用到了”hello”这个字符串，如果不用常量池，就需要在 6 个地方全写一遍，造成臃肿。我们可以将”hello”等所需用到的结构信息记录在常量池中，并通过引用的方式，来加载、调用所需的结构</p>
<p><strong>常量池总结</strong><br>常量池、可以看做是一张表，虚拟机指令<strong>根据这张常量表找到要执行的类名、方法名、参数类型、字面量</strong>等类型。</p>
<h5 id="运行时常量池-1"><a href="#运行时常量池-1" class="headerlink" title="运行时常量池"></a>运行时常量池</h5><p>运行时常量池（Runtime Constant Pool）是方法区的一部分。<br>常量池表（Constant Pool Table）是 Class 字节码文件的一部分，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。（运行时常量池就是常量池在程序运行时的称呼）</p>
<p>运行时常量池，在加载类和接口到虚拟机后，就会创建对应的运行时常量池。<br>JVM 为<strong>每个已加载的类型（类或接口）都维护一个常量池。</strong>池中的数据项像数组项一样，是通过索引访问的。<br>运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，这里换为真实地址。</p>
<p>运行时常量池，相对于 Class 文件常量池的另一重要特征是：<strong>具备动态性。</strong><br>运行时常量池类似于传统编程语言中的符号表（symbol table），但是它所包含的数据却比符号表要更加丰富一些。<br>当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛 OutofMemoryError 异常。</p>
<h4 id="演变"><a href="#演变" class="headerlink" title="演变"></a>演变</h4><p><img src="https://i.loli.net/2021/08/06/mRx7bBa6FAvY4VW.png"></p>
<p><img src="https://i.loli.net/2021/08/06/KRXj9QPzFIArn5V.png" alt="image-20210802112157518"></p>
<p><img src="https://i.loli.net/2021/08/06/sWImGdC3lBzveau.png" alt="image-20210802112217395"></p>
<h4 id="永久代为什么要被元空间替代？"><a href="#永久代为什么要被元空间替代？" class="headerlink" title="永久代为什么要被元空间替代？"></a>永久代为什么要被元空间替代？</h4><p>随着 Java8 的到来，HotSpot VM 中再也见不到永久代了。但是这并不意味着类的元数据信息也消失了。这些数据被<strong>移到了一个与堆不相连的本地内存区域，这个区域叫做元空间（Metaspace）。</strong></p>
<p>由于类的元数据分配在本地内存中，元空间的最大可分配空间就是<strong>系统可用内存空间</strong>。</p>
<p>这项改动是很有必要的，原因有：<br><strong>1，永久代设置空间大小是很难确定的。</strong>在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。比如某个实际 Web 工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误。Exception in thread ‘dubbo client x.x connector’ java.lang.OutOfMemoryError:PermGen space 而元空间和永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。 因此，默认情况下，元空间的大小仅受本地内存限制。</p>
<p><strong>2，对永久代进行调优是很困难的。</strong>方法区的垃圾收集主要回收两部分内容：<strong>常量池中废弃的常量和不再用的类型</strong>，方法区的调优主要是为了降低 Full GC</p>
<p>有些人认为方法区（如 HotSpot 虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java 虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如 JDK11 时期的 ZGC 收集器就不支持类卸载）。<br>一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前 Sun 公司的 Bug 列表中，曾出现过的若干个严重的 Bug 就是由于低版本的 HotSpot 虚拟机对此区域未完全回收而导致内存泄漏。</p>
<h4 id="字符串常量池"><a href="#字符串常量池" class="headerlink" title="字符串常量池"></a>字符串常量池</h4><p>字符串常量池 StringTable 为什么要调整位置？<br>JDK7 中将 StringTable 放到了堆空间中。因为<strong>永久代的回收效率很低</strong>，在 Full GC 的时候才会执行永久代的垃圾回收，而 Full GC 是老年代的空间不足、永久代不足时才会触发。<br>这就导致 StringTable 回收效率不高，而我们<strong>开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。放到堆里，能及时回收内存。</strong></p>
<h4 id="静态变量放在哪里"><a href="#静态变量放在哪里" class="headerlink" title="静态变量放在哪里"></a>静态变量放在哪里</h4><p><strong>对象实体在哪里放着？</strong><br>private static byte[] arr &#x3D; new byte[1024 * 1024 * 100];&#x2F;&#x2F;100MB<br>静态引用对应的对象实体(也就是这个 new byte[1024 * 1024 * 100])<strong>始终都存在堆空间</strong>，</p>
<p>只是那个<strong>变量(相当于下面的 arr 变量名)在 JDK6,JDK7,JDK8 存放位置</strong>中有所变化</p>
<p><strong>变量(名)存放在哪里？</strong></p>
<p>从《Java 虚拟机规范》所定义的概念模型来看，所有 Class 相关的信息都应该存放在<strong>方法区</strong>之中，但方法区该如何实现，《Java 虚拟机规范》并未做出规定，这就成了一件允许不同虚拟机自己灵活把握的事情。JDK7 及其以后版本的 HotSpot 虚拟机选择把静态变量与类型在 Java 语言一端的映射 Class 对象存放在一起，存储于 Java 堆之中</p>
<h4 id="方法区的垃圾回收"><a href="#方法区的垃圾回收" class="headerlink" title="方法区的垃圾回收"></a>方法区的垃圾回收</h4><p>方法区的垃圾收集主要回收两部分内容：<strong>常量池中废弃的常量和不再使用的类型。</strong><br>先来说说方法区内常量池之中主要存放的两大类常量：<strong>字面量和符号引用</strong>。字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final 的常量值等。而<strong>符号引用</strong>则属于编译原理方面的概念，包括下面三类常量：<br>类和接口的全限定名<br>字段的名称和描述符<br>方法的名称和描述符</p>
<p>HotSpot 虚拟机对常量池的回收策略是很明确的，<strong>只要常量池中的常量没有被任何地方引用，就可以被回收。</strong><br>回收废弃常量与回收 Java 堆中的对象非常类似。（关于常量的回收比较简单，重点是类的回收）</p>
<p><strong>下面也称作类卸载</strong><br>1、判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。需要同时满足下面三个条件：</p>
<p><strong>该类所有的实例都已经被回收</strong>，也就是 Java 堆中不存在该类及其任何派生子类的实例。<br><strong>加载该类的类加载器已经被回收</strong>，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常是很难达成的。<br><strong>该类对应的 java.lang.Class 对象没有在任何地方被引用</strong>，无法在任何地方通过反射访问该类的方法。</p>
<p>2、Java 虚拟机被允许对满足上述三个条件的无用类进行回收，<strong>这里说的仅仅是“被允许”，</strong>而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot 虚拟机提供了-Xnoclassgc 参数进行控制，还可以使用-verbose:class 以及 -XX：+TraceClass-Loading、-XX：+TraceClassUnLoading 查看类加载和卸载信息</p>
<p>3、在大量使用反射、动态代理、CGLib 等字节码框架，动态生成 JSP 以及 OSGi 这类频繁自定义类加载器的场景中，通常都需要 Java 虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>宏观</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql-事务</title>
    <url>/2021/07/30/Mysql-%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<h2 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a>事务特性</h2><ul>
<li><p><strong>原子性</strong>： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</p>
</li>
<li><p><strong>一致性</strong>： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；</p>
</li>
<li><p><strong>隔离性</strong>： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</p>
</li>
<li><p><strong>持久性</strong>： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</p>
</li>
<li><p><strong>脏读（Dirty read</strong>）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。</p>
</li>
<li><p><strong>丢失修改（Lost to modify</strong>）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A&#x3D;20，事务 2 也读取 A&#x3D;20，事务 1 修改 A&#x3D;A-1，事务 2 也修改 A&#x3D;A-1，最终结果 A&#x3D;19，事务 1 的修改被丢失。</p>
</li>
<li><p><strong>不可重复读（Unrepeatableread</strong>）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。</p>
</li>
<li><p><strong>幻读（Phantom read）</strong>: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。</p>
</li>
</ul>
<h2 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h2><ul>
<li>**READ-UNCOMMITTED(读取未提交)**： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li>**READ-COMMITTED(读取已提交)**： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li><strong>REPEATABLE-READ(可重复读)：</strong> 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。</li>
<li><strong>SERIALIZABLE(可串行化)：</strong> 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ul>
<p>MySQL InnoDB 存储引擎的默认支持的隔离级别是 <strong>REPEATABLE-READ（可重读）</strong><br>与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下，<strong>允许应用使用  MVCC 和 Next-key Lock 锁算法来避免幻读的产生。</strong></p>
<h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><h3 id="什么是-MVCC"><a href="#什么是-MVCC" class="headerlink" title="什么是 MVCC?"></a><strong>什么是 MVCC?</strong></h3><p>MVCC MVCC，全称 Multi-Version Concurrency Control，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p>
<p>MVCC 在 MySQL InnoDB 中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读</p>
<h3 id="什么是当前读和快照读？"><a href="#什么是当前读和快照读？" class="headerlink" title="什么是当前读和快照读？"></a><strong>什么是当前读和快照读？</strong></h3><ul>
<li><p>当前读 像 select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。</p>
</li>
<li><p>快照读 像不加锁的 select 操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本</p>
</li>
</ul>
<p>MVCC 就是为了<strong>实现读-写冲突不加锁，</strong>而这个读指的就是<strong>快照读</strong>, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现</p>
<p><strong>当前读，快照读和 MVCC 的关系</strong></p>
<ul>
<li>准确的说，MVCC 多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。</li>
<li>而在 MySQL 中，实现这么一个 MVCC 理想概念，我们就需要 MySQL 提供具体的功能去实现它，而快照读就是 MySQL 为我们实现 MVCC 理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现</li>
</ul>
<h3 id="MVCC-能解决什么问题，好处是？"><a href="#MVCC-能解决什么问题，好处是？" class="headerlink" title="MVCC 能解决什么问题，好处是？"></a><strong>MVCC 能解决什么问题，好处是？</strong></h3><p>数据库并发场景有三种，分别为：</p>
<ul>
<li>读-读：不存在任何问题，也不需要并发控制</li>
<li>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读</li>
<li>写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失</li>
</ul>
<h3 id="MVCC-带来的好处是？"><a href="#MVCC-带来的好处是？" class="headerlink" title="MVCC 带来的好处是？"></a><strong>MVCC 带来的好处是？</strong></h3><p>多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以 MVCC 可以为数据库解决以下问题</p>
<ul>
<li>在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能</li>
<li>同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题</li>
</ul>
<p>总之，MVCC 就是不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了 MVCC，所以我们可以形成两个组合：</p>
<ul>
<li>MVCC + 悲观锁 MVCC 解决读写冲突，悲观锁解决写写冲突</li>
<li>MVCC + 乐观锁 MVCC 解决读写冲突，乐观锁解决写写冲突 这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题</li>
</ul>
<p>在 InnoDB 存储引擎中，多版本控制 (multi versioning) 就是对非锁定读的实现。如果<strong>读取的行正在执行 DELETE 或 UPDATE 操作</strong>，这时读取操作不会去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据，<strong>对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)</strong></p>
<p>在 Repeatable Read 下 MVCC 实现了可重复读和防止部分幻读。</p>
<p>如果执行的是下列语句，就是 <strong>锁定读（Locking Reads）</strong></p>
<ul>
<li><p>select … lock in share mode</p>
</li>
<li><p>select … for update</p>
</li>
<li><p>insert、update、delete 操作</p>
<p><strong>在锁定读下，读取的是数据的最新版本</strong>，这种读也被称为 <strong>当前读</strong>（current read）。锁定读会对读取到的记录加锁。<br>在 Repeatable Read 下 MVCC 防止了部分幻读，这边的 “部分” 是指在 一致性非锁定读 情况下，只能读取到第一次查询之前所插入的数据。</p>
</li>
</ul>
<p><strong>但如果是当前读 ，每次读取的都是最新数据</strong>，这时如果两次查询中间有其它事务插入数据，就会产生幻读。</p>
<p>所以 InnoDB 在实现 Repeatable Read 时，如果执行的是<strong>当前读，则会对读取的记录使用 Next-key Lock ，来防止其它事务在间隙间插入数据。</strong></p>
<h3 id="MVCC-的实现依赖于：隐藏字段、Read-View、undo-log"><a href="#MVCC-的实现依赖于：隐藏字段、Read-View、undo-log" class="headerlink" title="MVCC 的实现依赖于：隐藏字段、Read View、undo log"></a><strong>MVCC 的实现依赖于：隐藏字段、Read View、undo log</strong></h3><p>在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。</p>
<p>每个事务读到的数据版本可能是不一样的，在同一个事务中，<strong>用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改。</strong></p>
<h4 id="隐藏字段"><a href="#隐藏字段" class="headerlink" title="隐藏字段"></a>隐藏字段</h4><p>在内部，InnoDB 存储引擎为每行数据添加了三个 隐藏字段：</p>
<p><strong>DB_TRX_ID（6 字节）</strong>：表示<strong>最后一次插入或更新该行的事务 id</strong>。此外，delete 操作在内部被视为更新，只不过会在记录头 Record header 中的 deleted_flag 字段将其标记为已删除<br><strong>DB_ROLL_PTR（7 字节）</strong> <strong>回滚指针，指向该行的 undo log</strong> 。如果该行未被更新，则为空<br><strong>DB_ROW_ID（6 字节）</strong>：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该 id 来生成聚簇索引</p>
<h4 id="ReadView"><a href="#ReadView" class="headerlink" title="ReadView"></a>ReadView</h4><p>Read View 主要是用来做<strong>可见性判断</strong>，里面保存了 “<strong>当前对本事务不可见的其他活跃事务</strong>”</p>
<h4 id="undo-log"><a href="#undo-log" class="headerlink" title="undo-log"></a>undo-log</h4><p><strong>undo log 主要有两个作用：</strong></p>
<p>当事务回滚时用于将数据恢复到修改前的样子</p>
<p>另一个作用是 MVCC ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 <strong>undo log 读取之前的版本数据，以此实现非锁定读</strong></p>
<p>在 InnoDB 存储引擎中 undo log 分为两种： <strong>insert undo log 和 update undo log：</strong></p>
<p>不同事务或者相同事务的对同一记录行的修改，会使该<strong>记录行的 undo log 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。</strong></p>
<p>在 InnoDB 存储引擎中，创建一个新事务后，<strong>执行每个 select 语句前，都会创建一个快照（Read View），快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号。</strong></p>
<p>其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）。当用户在这个事务中要读取某个记录行的时候，InnoDB 会将该记录行的 DB_TRX_ID 与 Read View 中的一些变量及当前事务 ID 进行比较，<strong>判断是否满足可见性条件。</strong></p>
<p><strong>RC 和 RR 隔离级别下 MVCC 的差异</strong></p>
<p>在事务隔离级别 RC 和 RR （InnoDB 存储引擎的默认事务隔离级别）下， InnoDB 存储引擎使用 MVCC（非锁定一致性读），但它们<strong>生成 Read View 的时机却不同</strong></p>
<p>在 RC 隔离级别下的 <strong>每次 select 查询前</strong>都生成一个 Read View (m_ids 列表)<br>在 RR 隔离级别下<strong>只在事务开始后 第一次 select 数据前生成一个 Read View（m_ids 列表）</strong></p>
<h4 id="！！！！MVCC-Next-key-Lock-防止幻读"><a href="#！！！！MVCC-Next-key-Lock-防止幻读" class="headerlink" title="！！！！MVCC+Next-key-Lock 防止幻读"></a>！！！！MVCC+Next-key-Lock 防止幻读</h4><p>InnoDB 存储引擎在 RR 级别下通过 MVCC 和 Next-key Lock 来解决幻读问题：</p>
<p>执行普通 select，此时会以 MVCC <strong>快照读</strong>的方式读取数据</p>
<p>在<strong>快照读</strong>的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，<strong>并使用到事务提交</strong>。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”。</p>
<p>执行 select…for update&#x2F;lock in share mode、insert、update、delete 等当前读。</p>
<p>在<strong>当前读</strong>下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lock 来防止这种情况。<strong>当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。</strong></p>
<h4 id="InnoDB-存储引擎的锁的算法有三种"><a href="#InnoDB-存储引擎的锁的算法有三种" class="headerlink" title="InnoDB 存储引擎的锁的算法有三种"></a>InnoDB 存储引擎的锁的算法有三种</h4><ul>
<li>Record lock：记录锁，单个行记录上的锁</li>
<li>Gap lock：间隙锁，锁定一个范围，不包括记录本身</li>
<li>Next-key lock：record+gap 临键锁，锁定一个范围，包含记录本身</li>
</ul>
<h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>基于锁的属性分类：共享锁、排他锁。</p>
<p>基于锁的粒度分类：表锁、行锁、（记录锁、间隙锁、临键锁）</p>
<p>乐观锁，悲观锁</p>
<p>死锁</p>
<h5 id="记录锁（Record-Locks）"><a href="#记录锁（Record-Locks）" class="headerlink" title="记录锁（Record Locks）"></a>记录锁（Record Locks）</h5><p>记录锁就是为<strong>某行记录</strong>加锁，它封锁该行的索引记录：</p>
<p>– id 列为主键列或唯一索引列<br>SELECT * FROM t_user WHERE id &#x3D; 1 <strong>FOR UPDATE;</strong><br>id 为 1 的记录行会被锁住。</p>
<p>需要注意的是：<strong>id 列必须为唯一索引列或主键列</strong>，<strong>否则上述语句加的锁就会变成临键锁。</strong></p>
<p>同时查询语句必须为精准匹配（&#x3D;），不能为 &gt;、&lt;、like 等，否则也会退化成临键锁。</p>
<p>我们也可以在通过 主键索引 与 唯一索引 对数据行进行 UPDATE 操作时，也会对该行数据加记录锁：</p>
<p>– id 列为主键列或唯一索引列<br>UPDATE t_user SET age &#x3D; 50 WHERE id &#x3D; 1;</p>
<h5 id="间隙锁（Gap-Locks）"><a href="#间隙锁（Gap-Locks）" class="headerlink" title="间隙锁（Gap Locks）"></a>间隙锁（Gap Locks）</h5><p>间隙锁基于<strong>非唯一索引</strong>，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的 Next-Key Locking 算法，请务必牢记：<strong>使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。</strong></p>
<p>SELECT * FROM t_user WHERE id BETWEN 1 AND 10 FOR UPDATE;<br>即所有在（1，10）区间内的记录行都会被锁住，所有 id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。</p>
<p>除了手动加锁外，在执行完某些 SQL 后，InnoDB 也会自动加间隙锁。</p>
<h5 id="临键锁（Next-Key-Locks）"><a href="#临键锁（Next-Key-Locks）" class="headerlink" title="临键锁（Next-Key Locks）"></a>临键锁（Next-Key Locks）</h5><p>临键锁是一种特殊的间隙锁，也可以理解为一种特殊的算法。<strong>通过临建锁可以解决幻读的问题。</strong>每个数据行上的<strong>非唯一索引列</strong>上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段<strong>左开右闭</strong>区间的数据。需要强调的一点是，<strong>InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。</strong></p>
<p>比如：表信息 t_user(id PK, age KEY, name)</p>
<p><img src="https://i.loli.net/2021/08/18/PQEZqVyf8vijJlU.png" alt="image-20210818113227557"></p>
<p>在事务 A 中执行如下命令：</p>
<p>– 根据非唯一索引列 UPDATE 某条记录<br>UPDATE t_user SET name &#x3D; Vladimir WHERE age &#x3D; 24;<br>– 或根据非唯一索引列 锁住某条记录<br>SELECT * FROM t_user WHERE age &#x3D; 24 FOR UPDATE;<br>不管执行了上述 SQL 中的哪一句，之后如果在事务 B 中执行以下命令，则该命令会被阻塞：</p>
<p>INSERT INTO t_user VALUES(100, 26, ‘tian’);</p>
<p>很明显，事务 A 在对 age 为 24 的列进行 UPDATE 操作的同时，也获取了 (24, 32] 这个区间内的临键锁。</p>
<p>不仅如此，在执行以下 SQL 时，也会陷入阻塞等待：</p>
<p>INSERT INTO table VALUES(100, 30, ‘zhang’);</p>
<p>那最终我们就可以得知，在根据非唯一索引 对记录行进行 UPDATE \ FOR UPDATE \ LOCK IN SHARE MODE 操作时，<strong>InnoDB 会获取该记录行的 临键锁 ，并同时获取该记录行下一个区间的间隙锁。</strong></p>
<p>即事务 A 在执行了上述的 SQL 后，最终被锁住的记录区间为 (10, 32)。</p>
<h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p><img src="https://i.loli.net/2021/08/18/wcGgvB3aXy8nOA1.png" alt="image-20210818113411266"></p>
<p>从死锁的定义来看，MySQL 出现死锁的几个要素为：</p>
<p>两个或者两个以上事务<br>每个事务都已经持有锁并且申请新的锁<br>锁资源同时只能被同一个事务持有或者不兼容<br>事务之间因为持有锁和申请锁导致彼此循环等待</p>
<p><strong>死锁分析思路</strong><br>大致分为两个步骤：</p>
<p>查看<strong>死锁日志</strong>时，首先看一下<strong>发生死锁的事务等待获取锁的语句都是啥。</strong><br>找到发生死锁的事务中所有的语句之后，对照着事务获取到的锁和正在等待的锁的信息来分析死锁发生过程。</p>
<p><strong>如何预防死锁?</strong></p>
<p>innodb_lock_wait_timeout 等待锁超时回滚事务</p>
<p>直观方法是在两个事务相互等待时，<strong>当一个等待时间超过设置的某一阀值时，对其中一个事务进行回滚，另一个事务就能继续执行。</strong></p>
<p>wait-for graph 算法来主动进行死锁检测</p>
<p>每当加锁请求无法立即满足需要并进入等待时，wait-for graph 算法都会被触发。</p>
<p>wait-for graph 要求数据库保存以下两种信息：</p>
<p><strong>锁的信息链表</strong><br><strong>事务等待链表</strong></p>
<p>那么如何解决死锁？</p>
<p><strong>1.等待事务超时，主动回滚。</strong></p>
<p><strong>2.进行死锁检查，主动回滚某条事务，让别的事务能继续走下去。</strong></p>
<p>下面提供一种方法，解决死锁的状态:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;--查看正在被锁的事务<br><br>kill trx_mysql_thread_id；--（上图trx_mysql_thread_id列的值）<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql-架构与存储引擎</title>
    <url>/2021/07/30/Mysql-%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
    <content><![CDATA[<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="https://i.loli.net/2021/08/04/AotCLWx597J4FnN.png" alt="image-20210804135513993"></p>
<h3 id="Mysql-逻辑架构图主要分三层"><a href="#Mysql-逻辑架构图主要分三层" class="headerlink" title="Mysql 逻辑架构图主要分三层"></a><strong>Mysql 逻辑架构图主要分三层</strong></h3><p>（1）第一层负责连接处理，授权认证，安全等等<br>（2）第二层负责编译并优化 SQL<br>（3）第三层是存储引擎。</p>
<h3 id="sql-语句执行流程"><a href="#sql-语句执行流程" class="headerlink" title="sql 语句执行流程"></a>sql 语句执行流程</h3><ul>
<li><p>查询语句的执行流程如下：权限校验（如果命中缓存）—&gt;查询缓存—&gt;分析器—&gt;优化器—&gt;权限校验—&gt;执行器—&gt;引擎</p>
</li>
<li><p>更新语句执行流程如下：分析器—-&gt;权限校验—-&gt;执行器—&gt;引擎—redo log(prepare 状态)—&gt;binlog—&gt;redo log(commit 状态)</p>
</li>
<li><p>MySQL 自带的日志模块是 <strong>binlog（归档日志）</strong> ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 <strong>redo log（重做日志）</strong>，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">update tb_student A set A.age=&#x27;19&#x27; where A.name=&#x27; 张三 &#x27;;<br></code></pre></td></tr></table></figure>

<p>然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，<strong>此时 redo log 进入 prepare 状态</strong>，然后告诉执行器，执行完成了，随时可以提交。<br><strong>执行器收到通知后记录 binlog，然后调用引擎接口</strong>，提交 redo log 为提交状态。<br>更新完成。</p>
</li>
</ul>
<p>为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？</p>
<p><strong>先写 redo log 直接提交，然后写 binlog</strong>，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。</p>
<p><strong>先写 binlog，然后写 redo log</strong>，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。</p>
<p>如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。</p>
<p>那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：</p>
<p><strong>判断 redo log 是否完整，如果判断是完整的，就立即提交。</strong><br>如果 redo log 只是预提交但不是 commit 状态，<strong>这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。</strong><br>这样就解决了数据一致性的问题。</p>
<p><strong>Server 层</strong>：主要包括<strong>连接器、查询缓存、分析器、优化器、执行器</strong>等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。<br><strong>存储引擎</strong>： 主要<strong>负责数据的存储和读取</strong>，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。</p>
<h2 id="存储引擎对比"><a href="#存储引擎对比" class="headerlink" title="存储引擎对比"></a>存储引擎对比</h2><h3 id="innodb-vs-myisam"><a href="#innodb-vs-myisam" class="headerlink" title="innodb vs myisam"></a>innodb vs myisam</h3><h4 id="是否支持行级锁"><a href="#是否支持行级锁" class="headerlink" title="是否支持行级锁"></a>是否支持行级锁</h4><p>MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。</p>
<h4 id="是否支持事务"><a href="#是否支持事务" class="headerlink" title="是否支持事务"></a>是否支持事务</h4><p>MyISAM 不提供事务支持。<br>InnoDB 提供事务支持，具有提交(commit)和回滚(rollback)事务的能力。</p>
<h4 id="是否支持外键"><a href="#是否支持外键" class="headerlink" title="是否支持外键"></a>是否支持外键</h4><p>MyISAM 不支持，而 InnoDB 支持。</p>
<h4 id="是否支持数据库异常崩溃后的安全恢复"><a href="#是否支持数据库异常崩溃后的安全恢复" class="headerlink" title="是否支持数据库异常崩溃后的安全恢复"></a>是否支持数据库异常崩溃后的安全恢复</h4><p>MyISAM 不支持，而 InnoDB 支持。<br>使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 <strong>redo log</strong> 。<br>MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。</p>
<p>MySQL InnoDB 引擎通过 锁机制、MVCC 等手段来保证事务的隔离性（ 默认支持的隔离级别是 REPEATABLE-READ ）。<br>保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。</p>
<h4 id="是否支持-MVCC"><a href="#是否支持-MVCC" class="headerlink" title="是否支持 MVCC"></a>是否支持 MVCC</h4><p>MyISAM 不支持，而 InnoDB 支持。</p>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty-NIO三大组件</title>
    <url>/2021/07/30/Netty-NIO%E4%B8%89%E5%A4%A7%E7%BB%84%E4%BB%B6/</url>
    <content><![CDATA[<h3 id="channel：双向数据传输通道"><a href="#channel：双向数据传输通道" class="headerlink" title="channel：双向数据传输通道"></a>channel：双向数据传输通道</h3><p>filechannel：文件</p>
<p>datagramchannel：</p>
<p>socketchannel：</p>
<p>serversocketchannel：</p>
<h3 id="buffer：内存缓冲区"><a href="#buffer：内存缓冲区" class="headerlink" title="buffer：内存缓冲区"></a>buffer：内存缓冲区</h3><p>bytebuffer：</p>
<h3 id="selector"><a href="#selector" class="headerlink" title="selector"></a>selector</h3><p>选择器？</p>
<p>服务器端早期–多个客户端连接&#x3D;&#x3D;多线程：</p>
<p><strong>缺点：</strong></p>
<p>内存占用高。</p>
<p>线程上下文切换成本高。</p>
<p>只适合连接数较少。</p>
<p><strong>线程池版本设计：</strong></p>
<p>缺点：</p>
<p>线程同一时间只能处理一个 socket。</p>
<p>仅适合短连接（长连接–一直保持连接）场景。</p>
<p><strong>selector 设计：</strong></p>
<p>一个线程管理多个 channel。</p>
<p><img src="https://i.loli.net/2021/08/04/SveWTQN1dHVsoRh.png" alt="image-20210804200403644"></p>
<p>调用 selector 的 select() 会阻塞直到 channel 发生了读写就绪事件，这些事件发生，select 方法就会返回这些事件交给 thread 来处理。</p>
<p><strong>基本使用</strong></p>
<ol>
<li><p>向 buffer <strong>写入数据</strong>，例如调用 channel.read(buffer)</p>
</li>
<li><p>调用 <strong>flip()</strong> 切换至读模式</p>
</li>
<li><p>从 buffer 读取数据，例如调用 <strong>buffer.get()</strong></p>
</li>
<li><p>调用 <strong>clear() 或 compact()</strong> 切换至写模式</p>
</li>
<li><p>重复 1~4 步骤</p>
</li>
</ol>
<p><img src="https://i.loli.net/2021/08/04/SPu5WniEZm8Ncv1.png" alt="image-20210804200504999"></p>
<p>分配空间：</p>
<p><strong>bytebuffer.allocate().</strong>&#x3D;&#x3D;堆内存&#x3D;读写效率低&#x3D;受到 GC 影响</p>
<p><strong>Bytebuffer.allocatedirect()&#x3D;</strong>&#x3D;直接内存&#x3D;读写效率高&#x3D;分配内存的效率低</p>
<p>写入：write（）</p>
<p>读取：get（）</p>
<p>get 方法会让 position 读指针向后走，如果想<strong>重复读取数据</strong></p>
<p>可以调用 <strong>rewind</strong> 方法将 position 重新置为 0</p>
<p>调用 <strong>get(int i) 方法</strong>获取索引 i 的内容，它不会移动读指针</p>
<p><strong>mark 和 reset</strong></p>
<p>mark 是在读取时，做一个标记，即使 position 改变，只要<strong>调用 reset 就能回到 mark 的位置</strong></p>
<p> <strong>rewind 和 flip 都会清除 mark 位置</strong></p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>阻塞 IO（同步）：</p>
<p>非阻塞 IO（同步）：read 为例，在等待数据阶段用户线程不阻塞（多次内存空间的切换）。复制数据阶段阻塞。</p>
<p>多路复用（同步）：select（）为例，两个阶段都是阻塞的。好处在于：可以一次性的处理多个 channel 上的事件。</p>
<p>信号驱动：不常用</p>
<p>异步 IO：<br>异步（线程自己不去获得结果，而是由其他的线程送来结果）</p>
<p><strong>异步情况下一定是非阻塞的。</strong></p>
<p>异步意味着：在进行读写操作时，线程不必等待结果，而是通过回调的方式由另外的线程来获取。</p>
<p>linux 在 2.6 底层通过多路复用模拟了异步 IO。</p>
<p>windows 通过 IOCP 真正实现了异步 IO。</p>
<p>netty 废弃了异步 IO。</p>
<h4 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h4><p><img src="https://i.loli.net/2021/08/04/NocGmtUjEZikle8.png" alt="image-20210804200720036"></p>
<p>4 次数据拷贝<br>用户态内核态切换三次</p>
<h4 id="NIO-优化"><a href="#NIO-优化" class="headerlink" title="NIO 优化"></a>NIO 优化</h4><p>通过 <strong>DirectByteBuf</strong> </p>
<p><img src="https://i.loli.net/2021/08/04/PKkHasXvjMlozdy.png" alt="image-20210804200821683"></p>
<ul>
<li><p>ByteBuffer.allocate(10) HeapByteBuffer 使用的还是 <strong>java 内存</strong></p>
</li>
<li><p>ByteBuffer.allocateDirect(10) DirectByteBuffer 使用的是<strong>操作系统内存</strong><br>java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用</p>
</li>
<li><p>这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写</p>
</li>
<li><p>java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步</p>
<ul>
<li>DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列</li>
<li>通过专门线程访问引用队列，根据虚引用释放堆外内存</li>
</ul>
</li>
<li><p>减少了一次数据拷贝，用户态与内核态的切换次数没有减少</p>
</li>
</ul>
<p><strong>进一步（linux2.1 之后的 sendfile 方法）</strong></p>
<p><img src="https://i.loli.net/2021/08/04/dXP4Fosj5ZmeiuD.png" alt="image-20210804200844338"></p>
<p>java 中对应着两个 channel 调用 transferTo&#x2F;transferFrom 方法拷贝数据</p>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 <strong>DMA</strong>将数据读入内核缓冲区，不会使用 cpu</li>
<li>数据从内核缓冲区传输到 socket 缓冲区，cpu 会参与拷贝</li>
<li>最后使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 cpu</li>
</ol>
<ul>
<li><p>只发生了一次用户态与内核态的切换</p>
</li>
<li><p>数据拷贝了 3 次</p>
</li>
</ul>
<p>进一步（linux2.4 之后的 sendfile 方法）</p>
<p><img src="https://i.loli.net/2021/08/04/Hn7ASzdyuaqgOjW.png" alt="image-20210804200932305"></p>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 DMA 将数据读入内核缓冲区，不会使用 cpu</li>
<li>只会将一些 offset 和 length 信息拷入 socket 缓冲区，几乎无消耗</li>
<li>使用 DMA 将内核缓冲区的数据写入网卡，不会使用 cpu<br>整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。<br>所谓的【零拷贝】&#x3D;linux&#x3D;sendfile 方法，并不是真正无拷贝，而是在<strong>不会拷贝重复数据到 jvm 内存中。</strong></li>
</ol>
<h4 id="零拷贝的优点有"><a href="#零拷贝的优点有" class="headerlink" title="零拷贝的优点有"></a>零拷贝的优点有</h4><ul>
<li>更少的用户态与内核态的切换</li>
<li>不利用 cpu 计算，减少 cpu 缓存伪共享（使用 DMA 硬件）</li>
<li>零拷贝适合<strong>小文件传输&#x3D;大文件没有缓冲的作用</strong>。（缓冲区比较小）</li>
</ul>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql-索引</title>
    <url>/2021/07/30/Mysql-%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有:<strong>B+树和 Hash</strong>。<br>Hash 索引不支持顺序和范围查询。</p>
<h3 id="主键索引-vs-唯一索引"><a href="#主键索引-vs-唯一索引" class="headerlink" title="主键索引 vs 唯一索引"></a>主键索引 vs 唯一索引</h3><p>主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。</p>
<p>主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。</p>
<p>唯一性索引列允许空值，而主键列不允许为空值。</p>
<p>主键列在创建时，已经默认为空值 + 唯一索引了。</p>
<p>主键可以被其他表引用为外键，而唯一索引不能。</p>
<p>一个表最多只能创建一个主键，但可以创建多个唯一索引。</p>
<p>主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。</p>
<h2 id="B-树-amp-B-树两者有何异同呢？"><a href="#B-树-amp-B-树两者有何异同呢？" class="headerlink" title="B 树&amp; B+树两者有何异同呢？"></a>B 树&amp; B+树两者有何异同呢？</h2><p>B 树的所有节点<strong>既存放键(key) 也存放 数据(data)<strong>，而 B+树</strong>只有叶子节点存放 key 和 data</strong>，其他内节点只存放 key。</p>
<p>B 树的叶子节点都是独立的;</p>
<p>B+树的<strong>叶子节点有一条引用链指向与它相邻的叶子节点</strong>。</p>
<p><img src="https://i.loli.net/2021/08/04/dm9kpsbhzaX8M2D.png" alt="image-20210804144530896"></p>
<p>B 树的检索的过程相当于对范围内的每个节点的关键字做<strong>二分查找</strong>，可能还没有到达叶子节点，检索就结束了。</p>
<p>而 <strong>B+树的检索效率就很稳定</strong>了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。</p>
<p>MyISAM 引擎中，B+Tree 叶节点的 <strong>data 域存放的是数据记录的地址</strong>。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。</p>
<p>InnoDB 引擎中，其<strong>数据文件本身就是索引文件</strong>。<br>相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，<strong>因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）</strong>”，而其余的索引都作为<strong>辅助索引</strong>。</p>
<p>辅助索引的 <strong>data 域存储相应记录主键的值而不是地址</strong>，这也是和 MyISAM 不同的地方。</p>
<p>在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引。 </p>
<p>因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。</p>
<h3 id="B-树磁盘"><a href="#B-树磁盘" class="headerlink" title="B+树磁盘"></a>B+树磁盘</h3><p>所以一次访盘请求（读&#x2F;写）完成过程由三个动作组成：</p>
<p>寻道（时间）：磁头移动定位到指定磁道<br>旋转延迟（时间）：等待指定扇区从磁头下旋转经过<br>数据传输（时间）：数据在磁盘与内存之间的实际传输<br>而总时间就是 寻到时间+旋转延迟+n×数据传输时间。</p>
<p>但是这个节点到底应该多大?虽然磁盘是以<strong>扇区</strong>为大小进行读写的，但是磁盘和操作系统却是用块为单位进行交互的。<br>块的大小必须是扇区大小的 2 的 n 次方。比如<strong>4k</strong>，一个页的大小也 4k。</p>
<p>所以 b 树基本上可以说是为机械硬盘量身定制的，<strong>b 树的层数决定了在磁盘上查找的次数</strong>，而越小的次数，带来的就是更高的效率。</p>
<p>然而在固态硬盘中，虽然也是以整数倍读写，但是它并不用移动磁头之类的机械操作，固态硬盘使用闪存进行存储，所以它的寻址效率和内存是一个数量级的，使用电位进行寻址，类似内存本身每一个存储空间都有一个地址，直接通过电门运算就找到那个地址了 。</p>
<p>但是从数据结构上来说，索引毕竟是索引，肯定要比遍历快很多，<strong>所以虽然 ssd 的随机读写很快，但是毕竟没有内存快。所以使用 b 树还是很有意义</strong>，再加上很多优化的算法都是基于磁盘的，这种历史包袱也不是说丢就能丢的。</p>
<p>因为旋转的受限，所以就算是顺序读写，固态硬盘也要比机械硬盘快，但是快的不是特别明显，毕竟如果是顺序读写，都可以有预判，可以提前做优化。这也就是为什么即使是固态硬盘本身，顺序读也要比随机读快。</p>
<h2 id="为什么-MySQL-数据库要用-B-树存储索引？而不用红黑树、Hash、B-树？"><a href="#为什么-MySQL-数据库要用-B-树存储索引？而不用红黑树、Hash、B-树？" class="headerlink" title="为什么 MySQL 数据库要用 B+树存储索引？而不用红黑树、Hash、B 树？"></a>为什么 MySQL 数据库要用 B+树存储索引？而不用红黑树、Hash、B 树？</h2><p><strong>红黑树</strong>：如果在内存中，红黑树的<strong>查找效率比 B 树更高</strong>，但是涉及到磁盘操作，B 树就更优了。因为红黑树是二叉树，数据量大时树的层数很高，从树的根结点向下寻找的过程，每读 1 个节点，都相当于一次 IO 操作，因此红黑树的 <strong>I&#x2F;O 操作会比 B 树多的多</strong>。</p>
<p><strong>B 树索引</strong>：B 树索相比于 B+树，在进行范围查询时，需要做<strong>局部的中序遍历</strong>，<strong>可能要跨层访问</strong>，跨层访问代表着要进行额外的磁盘 I&#x2F;O 操作；另外，B 树的非叶子节点存放了数据记录的地址，会导致存放的节点更少，树的层数变高。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="主键索引-Primary-Key"><a href="#主键索引-Primary-Key" class="headerlink" title="主键索引(Primary Key)"></a>主键索引(Primary Key)</h3><p>数据表的主键列使用的就是主键索引。</p>
<p>一张数据表有只能有一个主键，并且主键不能为 null，不能重复。</p>
<p>在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有<strong>唯一索引</strong>的字段，如果有，则选择该字段为默认的主键，否则 <strong>InnoDB 将会自动创建一个 6Byte 的自增主键。</strong></p>
<h3 id="二级索引-辅助索引"><a href="#二级索引-辅助索引" class="headerlink" title="二级索引(辅助索引)"></a>二级索引(辅助索引)</h3><p>二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，<strong>通过二级索引，可以定位主键的位置。</strong><br>唯一索引，普通索引，前缀索引等索引属于二级索引。</p>
<h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>MyISAM: B+Tree 叶节点的<strong>data 域存放的是数据记录的地址</strong>。在索引检索的时候，⾸先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 <strong>data 域的值为地址</strong>读取相应的数据记录。这被称为“⾮聚簇索引”。</p>
<p>InnoDB: 其数据⽂件本身就是索引⽂件。相⽐MyISAM，<strong>索引⽂件和数据⽂件是分离的</strong>，其表数据⽂件本身就是按 B+Tree 组织的⼀个索引结构，<strong>树的叶节点 data 域保存了完整的数据记录</strong>。<strong>这个索引的 key 是数据表的主键</strong>，因此 InnoDB 表数据⽂件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。</p>
<p>⽽其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值⽽不是地址，这也是和 MyISAM 不同的地⽅。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；再根据辅助索引查找时，则需要先取出主键的值，再⾛⼀遍主索引。因此，在设计表的时候，不建议使⽤过⻓的字段作为主键，也不建议使⽤⾮单调的字段作为主键，这样会造成主索引频繁分裂。 </p>
<h3 id="聚集索引的缺点"><a href="#聚集索引的缺点" class="headerlink" title="聚集索引的缺点"></a>聚集索引的缺点</h3><p><strong>依赖于有序的数据</strong> ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 <strong>UUID</strong> 这种又长又难比较的数据，插入或查找的速度肯定比较慢。</p>
<p><strong>更新代价大</strong> ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。</p>
<p>非聚集索引的叶子节点并不一定存放数据的指针， <strong>因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。</strong></p>
<h3 id="什么是回表查询？"><a href="#什么是回表查询？" class="headerlink" title="什么是回表查询？"></a>什么是回表查询？</h3><p>InnoDB 中，对于<strong>主键索引，只需要走一遍主键索引的查询就能在叶子节点拿到数据。</strong><br>而对于普通索引，叶子节点存储的是 key + 主键值，因此需要再走一次主键索引，通过主键索引找到行记录，这就是所谓的回表查询，先定位主键值，再定位行记录。</p>
<h3 id="走普通索引，一定会出现回表查询吗？"><a href="#走普通索引，一定会出现回表查询吗？" class="headerlink" title="走普通索引，一定会出现回表查询吗？"></a>走普通索引，一定会出现回表查询吗？</h3><p>不一定，如果查询语句所要求的字段全部命中了索引，那么就不必再进行回表查询。<br>有一个 user 表，主键为 id，name 为普通索引，则再执行：<br>select id, name from user where name &#x3D;’joonwhee’ 时，通过 name 的索引就能拿到 id 和 name。</p>
<h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>当索引上<strong>包含了查询语句中的所有列</strong>时，我们无需进行回表查询就能拿到所有的请求数据，因此速度会很快。当 explain 的输出结果 Extra 字段为 <strong>Using index</strong> 时，则代表触发覆盖索引。</p>
<h3 id="联合索引（复合索引）的底层实现？最佳左前缀原则？"><a href="#联合索引（复合索引）的底层实现？最佳左前缀原则？" class="headerlink" title="联合索引（复合索引）的底层实现？最佳左前缀原则？"></a>联合索引（复合索引）的底层实现？最佳左前缀原则？</h3><p>联合索引底层还是使用 B+树索引，并且还是只有<strong>一棵树</strong>，只是此时的排序会：首先按照第一个索引排序，在第一个索引相同的情况下，再按第二个索引排序，依次类推。</p>
<p>这也是为什么有“最佳左前缀原则”的原因，<strong>因为右边（后面）的索引都是在左边（前面）的索引排序的基础上进行排序的，如果没有左边的索引，单独看右边的索引，其实是无序的</strong></p>
<h3 id="B-树中一个节点到底多大合适？"><a href="#B-树中一个节点到底多大合适？" class="headerlink" title="B+树中一个节点到底多大合适？"></a>B+树中一个节点到底多大合适？</h3><p>1 页或页的倍数最为合适。因为如果一个节点的大小小于 1 页，那么读取这个节点的时候其实也会读出 1 页，造成资源的浪费。所以为了不造成浪费，所以最后把一个节点的大小控制在 1 页、2 页、3 页等倍数页大小最为合适。</p>
<p>这里说的“页”是 MySQL 自定义的单位（和操作系统类似），MySQL 的 Innodb 引擎中 <strong>1 页的默认大小是 16k。</strong></p>
<h3 id="为什么一个节点为-1-页就够了？"><a href="#为什么一个节点为-1-页就够了？" class="headerlink" title="为什么一个节点为 1 页就够了？"></a>为什么一个节点为 1 页就够了？</h3><p>Innodb 中，B+树中的一个节点存储的内容是：</p>
<ul>
<li>非叶子节点：key + 指针</li>
<li>叶子节点：数据行（key 通常是数据的主键）<br>对于叶子节点：我们假设 1 行数据大小为 1k（对于普通业务绝对够了），那么 1 页能存 16 条数据。对于非叶子节点：key 使用 bigint 则为 8 字节，指针在 MySQL 中为 6 字节，一共是 14 字节，则 16k 能存放 16 * 1024 &#x2F; 14 &#x3D; 1170 个。那么一颗高度为 3 的 B+树能存储的数据为：1170 * 1170 * 16 &#x3D; 21902400（千万级）。</li>
</ul>
<h3 id="什么是-Buffer-Pool？"><a href="#什么是-Buffer-Pool？" class="headerlink" title="什么是 Buffer Pool？"></a>什么是 Buffer Pool？</h3><p>Buffer Pool 是 InnoDB 维护的一个<strong>缓存区域</strong>，用来<strong>缓存数据和索引在内存中</strong>，主要用来加速数据的读写，如果 BufferPool 越大，那么 MySQL 就越像一个内存数据库，默认大小为 <strong>128M</strong>。<br>InnoDB 会将那些热点数据和一些 InnoDB 认为即将访问到的数据存在 Buffer Pool 中，以提升数据的读取性能。<br>InnoDB 在修改数据时，如果数据的页在 Buffer Pool 中，则会直接修改 Buffer Pool，此时我们称这个页为脏页，InnoDB 会以一定的频率将脏页刷新到磁盘，这样可以尽量减少磁盘 I&#x2F;O，提升性能。</p>
<h3 id="非聚集索引不一定回表查询"><a href="#非聚集索引不一定回表查询" class="headerlink" title="非聚集索引不一定回表查询"></a>非聚集索引不一定回表查询</h3><p>用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。<br> SELECT name FROM table WHERE name&#x3D;’guang19’;<br>那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。</p>
<h3 id="联合索引命中规则"><a href="#联合索引命中规则" class="headerlink" title="联合索引命中规则"></a>联合索引命中规则</h3><ol>
<li>MySQL 联合索引遵循最<strong>左前缀匹配规则</strong>，即从联合索引的最左列开始向右匹配，直到遇到匹配终止条件。</li>
<li>例如联合索引(col1, col2, col3), where 条件为 col1&#x3D;a AND col2&#x3D;b 可命中该联合索引的(col1,col2)前缀部分, where 条件为 col2&#x3D;b AND col3&#x3D;c 不符合最左前缀匹配，不能命中该联合索引。</li>
<li>**匹配终止条件为范围操作符(如&gt;, &lt;, between, like 等)或函数等不能应用索引的情况**。例如联合索引(col1, col2, col3), where 条件为 col1&#x3D;a AND col2&gt;1 AND col3&#x3D;c, 在 col2 列上为范围查询，匹配即终止，只会匹配到 col1，不能匹配到(col1, col2, col3)。</li>
<li><strong>where 条件中的顺序不影响索引命中</strong>。例如联合索引(col1, col2, col3), where 条件为 col3&#x3D;c AND col2&#x3D;b AND col1&#x3D;a, MySQL 优化器会自行进行优化，可命中联合索引(col1, col2, col3)。</li>
</ol>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="共享锁和排他锁？"><a href="#共享锁和排他锁？" class="headerlink" title="共享锁和排他锁？"></a>共享锁和排他锁？</h3><p><strong>共享锁</strong>又称为<strong>读锁，简称 S 锁</strong>，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。</p>
<p><strong>排他锁</strong>又称为<strong>写锁，简称 X 锁，</strong>顾名思义，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务可以对数据就行读取和修改。<br>常见的几种 SQL 语句的加锁情况如下：<br>select * from table：不加锁<br>update&#x2F;insert&#x2F;delete：排他锁<br> select * from table where id &#x3D; 1 for update：id 为索引，加排他锁<br> select * from table where id &#x3D; 1 lock in share mode：id 为索引，加共享锁</p>
<h3 id="MySQL-如何实现悲观锁和乐观锁？"><a href="#MySQL-如何实现悲观锁和乐观锁？" class="headerlink" title="MySQL 如何实现悲观锁和乐观锁？"></a>MySQL 如何实现悲观锁和乐观锁？</h3><p>乐观锁：<strong>更新时带上版本号（cas 更新）</strong><br>悲观锁：<strong>使用共享锁和排它锁</strong>，select…lock in share mode，select……for update。</p>
<h3 id="避免死锁？"><a href="#避免死锁？" class="headerlink" title="避免死锁？"></a>避免死锁？</h3><h5 id="事务之间对资源访问顺序的交替"><a href="#事务之间对资源访问顺序的交替" class="headerlink" title="事务之间对资源访问顺序的交替"></a>事务之间对资源访问顺序的交替</h5><p>一个用户 A 访问表 A（锁住了表 A），然后又访问表 B；另一个用户 B 访问表 B（锁住了表 B），然后企图访问表 A；这时用户 A 由于用户 B 已经锁住表 B，它必须等待用户 B 释放表 B 才能继续，同样用户 B 要等用户 A 释放表 A 才能继续，这就死锁就产生了。</p>
<h5 id="并发修改同一记录"><a href="#并发修改同一记录" class="headerlink" title="并发修改同一记录"></a>并发修改同一记录</h5><p>主要是由于没有一次性申请够权限的锁导致的。</p>
<p>用户 A 查询一条纪录，然后修改该条纪录；这时用户 B 修改该条纪录，这时用户 A 的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户 B 里的独占锁由于 A 有共享锁存在所以必须等 A 释放掉共享锁，而 A 由于 B 的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。</p>
<p>乐观锁，实现写-写并发</p>
<h4 id="何尽可能的避免死锁呢？"><a href="#何尽可能的避免死锁呢？" class="headerlink" title="何尽可能的避免死锁呢？"></a>何尽可能的避免死锁呢？</h4><p>1）以固定的顺序访问表和行。即按顺序申请锁，这样就不会造成互相等待的场面。</p>
<p>2）大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。</p>
<p>3）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。</p>
<p>4）降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从 RR 调整为 RC，可以避免掉很多因为 gap 锁造成的死锁。</p>
<p>5）为表添加合理的索引。如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。</p>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty-优点，应用场景</title>
    <url>/2021/07/30/Netty-%E4%BC%98%E7%82%B9%EF%BC%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<h3 id="netty-优点"><a href="#netty-优点" class="headerlink" title="netty 优点"></a>netty 优点</h3><p><strong>异步的</strong>（采用多线程实现了调用方法与返回结果的分离）<br><strong>基于事件驱动（本质上基于 IO 多路复用）</strong></p>
<p><strong>优势：</strong></p>
<p>基于 NIO，但是改善了 NIO<br>1，需要自己构建协议<br>2，需要解决 TCP 传输问题，粘包半包。<br>3，NIO 中有 epoll 空轮询 bug。<br>4，对 API 增强了。bytebuff。</p>
<p>现在是 4.0<br>5.0 已经废弃，引入 AIO，性能未提升。</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>涉及到网络通信就会用到 netty<br>rpc 框架-dubbo，grpc<br>聊天室？<br>spring</p>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>应用</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty-核心组件</title>
    <url>/2021/07/30/Netty-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="观念理解"><a href="#观念理解" class="headerlink" title="观念理解"></a>观念理解</h2><ul>
<li>channel：数据的传输通道。</li>
<li>msg：流动的数据。</li>
<li>pipeline：流水线，上面有多道工序。</li>
<li>handler：数据处理的工序。分为 inbound，outbound。</li>
<li>eventloop：处理数据的工人。<ul>
<li>工人可以管理多个 channel 的 io 操作（一个工人内部有 selector 和 thread）。一旦工人负责了某个 channel，就要负责到底。（线程安全）。</li>
<li>工人既可以执行 io 操作，还可以进行任务处理，工人都有自己的任务队列。</li>
<li>工人按照 pipeline 的顺序，依次按照对应的 handler 进行。</li>
</ul>
</li>
</ul>
<h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="Eventloop（事件循环对象）"><a href="#Eventloop（事件循环对象）" class="headerlink" title="Eventloop（事件循环对象）"></a>Eventloop（事件循环对象）</h3><ul>
<li>本质上是一个<strong>单线程执行器</strong>（同时维护了一个 selector）。</li>
<li>用来处理 channel 上源源不断的 io 事件。（监听网络事件并调用事件处理器进行相关的 IO 操作）</li>
<li>eventloop 负责处理注册到其上的 channel 的 io 操作。</li>
<li>继承了 juc 下的 scheduledExecutorService（包含了线程池的方法）</li>
<li>继承了 netty 自己的 oedereventexecutor（判断一个线程是否属于此 eventloop，判断一个 eventloop 属于哪个 eventloopgroup）</li>
</ul>
<h3 id="EventloopGroup（事件循环组）"><a href="#EventloopGroup（事件循环组）" class="headerlink" title="EventloopGroup（事件循环组）"></a>EventloopGroup（事件循环组）</h3><ul>
<li><strong>一组 eventloop。</strong></li>
<li>channel 会调用他的 register 方<strong>法绑定一个 eventloop</strong>，后续 io 操作由他负责到底。</li>
<li>EventLoop 处理的 I&#x2F;O 事件都将在它专有的 Thread 上被处理，即 Thread 和 EventLoop 属于 1 : 1 的关系，从⽽保证线程安全</li>
<li>NioEventLoopGroup 默认的构造函数实际会起的<strong>线程数为 CPU 核心*2 。</strong><br>每个 NioEventLoopGroup 对象内部都会分配⼀组 NioEventLoop ，其⼤⼩是 nThreads , 这样就构成了⼀个线程池， <strong>⼀个 NIOEventLoop 和⼀个线程相对应。</strong></li>
</ul>
<h3 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h3><p>传送数据的传输通道，或者说对网络操作的抽象。<br>包括 bind（），connect（），read（），write（）等方法。<br>常用 nioserversocketchannel 与 niosocketchannel。<br>close（）；<br>closefuture（）；<br>pipeline（）；<br>write（）；<br>writeandflush（）；数据写入并刷出。</p>
<p>Netty 是异步⾮阻塞的，我们不能⽴刻得到操作是否执⾏成功，但是，<strong>你可以通过 ChannelFuture 接⼝addListener() ⽅法注册⼀个 ChannelFutureListener ，当操作执⾏成功或者失败时，监听就会⾃动触发返回结果。并且，你还可以通过 ChannelFuture 的 channel() ⽅法获取关联的 Channel。</strong></p>
<ul>
<li><strong>channlefuture 异步非阻塞</strong>的解决：<br>1，<strong>sync（）；</strong><br>2，<strong>addlistener（回调对象）异步处理结果。（等待结果的也不是主线程）</strong></li>
</ul>
<p><strong>为什么要异步？</strong></p>
<p>必须多线程，多核 cpu。<br>并没有缩短响应时间，而是吞吐量。<br><strong>必须合理的任务拆分</strong>。</p>
<h3 id="future-amp-promise"><a href="#future-amp-promise" class="headerlink" title="future&amp;promise"></a>future&amp;promise</h3><p>future 继承 jdk 的 future。<br>promise 继承自 future。<br>jdk：只能同步等待任务结束。</p>
<p>netty future：可以异步等待方法结束。也要等待任务结束。</p>
<p>promise：只作为两个线程传递结果的容器。</p>
<h3 id="handler-amp-pipeline"><a href="#handler-amp-pipeline" class="headerlink" title="handler&amp;pipeline"></a>handler&amp;pipeline</h3><ul>
<li>handler：用来处理 channel 上各种事件，分为入站和出站。</li>
<li>注意：只有向 channel 中写数据才会触发出站 handler。</li>
<li><strong>出站顺序是从后往前。</strong></li>
<li>ctx.writeansflush()，<strong>会从那个入站向前找。后面的出站处理器就不会执行了。</strong></li>
<li>1-2-3-6-5-4。</li>
</ul>
<h3 id="Bootstrap-和-ServerBootstrap"><a href="#Bootstrap-和-ServerBootstrap" class="headerlink" title="Bootstrap 和 ServerBootstrap"></a>Bootstrap 和 ServerBootstrap</h3><p><img src="https://i.loli.net/2021/08/04/1PX7lzRvHGAZ3qp.png" alt="image-20210804201619460"></p>
<p><img src="https://i.loli.net/2021/08/04/UMuZ4JIyYnO7fQL.png" alt="image-20210804201633173"></p>
<p>Bootstrap 通常使⽤ <strong>connet()</strong> ⽅法连接到远程的主机和端⼝，作为⼀个 Netty TCP 协议通<br>信中的客户端。另外， Bootstrap 也可以通过 bind() ⽅法绑定本地的⼀个端⼝，作为 UDP<br>协议通信中的⼀端。</p>
<ol>
<li>ServerBootstrap 通常使⽤ bind() ⽅法绑定本地的端⼝上，然后等待客户端的连接。</li>
<li>Bootstrap 只需要配置⼀个线程组— EventLoopGroup 。⽽ ServerBootstrap 需要配置两个线<br> 程组— EventLoopGroup ，⼀个⽤于处理连接，⼀个⽤于具体的处理。</li>
</ol>
<h3 id="bytebuf"><a href="#bytebuf" class="headerlink" title="bytebuf"></a>bytebuf</h3><p>对 nio 中的增强。</p>
<p>支持：<br>1，直接内存。创建销毁比较昂贵。读写性能高。（默认）<br>堆内存。受到 GC 影响。<br>2，<strong>池化的最大意义在于可以重用 ByteBuf。</strong></p>
<ul>
<li>没有池化，则每次都得创建新的 ByteBuf 实例，这个操作对直接内存代价昂贵，就算是堆内存，也会增加 GC 压力</li>
<li>有了池化，则可以重用池中 ByteBuf 实例，并且采用了与 jemalloc 类似的内存分配算法提升分配效率</li>
<li>高并发时，池化功能更节约内存，减少内存溢出的可能<br>4.1 之后非安卓默认池化。<br>参数设定：netty.allocator.type&#x3D;{polled|unpolled}</li>
</ul>
<p><strong>组成：</strong></p>
<p><img src="https://i.loli.net/2021/08/04/uVCU9FcGnJsHeDm.png" alt="image-20210804201545205"></p>
<p>可以指定最大容量。</p>
<p><strong>内存回收</strong><br>由于 Netty 中有堆外内存的 ByteBuf 实现，堆外内存最好是手动来释放，而不是等 GC 垃圾回收。</p>
<ul>
<li>UnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收内存即可</li>
<li>UnpooledDirectByteBuf 使用的就是直接内存了，需要特殊的方法来回收内存</li>
<li>PooledByteBuf 和它的子类使用了池化机制，需要更复杂的规则来回收内存</li>
</ul>
<p><strong>Netty 这里采用了引用计数法来控制回收内存，每个 ByteBuf 都实现了 ReferenceCounted 接口</strong></p>
<ul>
<li>每个 ByteBuf 对象的初始计数为 1</li>
<li>调用 release 方法计数减 1，如果计数为 0，ByteBuf 内存被回收</li>
<li>调用 retain 方法计数加 1，表示调用者没用完之前，其它 handler 即使调用了 release 也不会造成回收</li>
<li>当计数为 0 时，底层内存会被回收，这时即使 ByteBuf 对象还在，其各个方法均无法正常使用<br>扩容</li>
<li>如何写入后数据大小未超过 512，则选择下一个 16 的整数倍，例如写入后大小为 12 ，则扩容后 capacity 是 16</li>
<li>如果写入后数据大小超过 512，则选择下一个 2^n，例如写入后大小为 513，则扩容后 capacity 是 2^10&#x3D;1024（2^9&#x3D;512 已经不够了）</li>
<li>扩容不能超过 max capacity 会报错</li>
</ul>
<h4 id="ByteBuf-优势"><a href="#ByteBuf-优势" class="headerlink" title="ByteBuf 优势"></a>ByteBuf 优势</h4><ul>
<li>池化 - 可以重用池中 ByteBuf 实例，更节约内存，减少内存溢出的可能</li>
<li>读写指针分离，不需要像 ByteBuffer 一样切换读写模式</li>
<li>可以自动扩容</li>
<li>支持链式调用，使用更流畅</li>
<li>很多地方体现零拷贝，例如 slice、duplicate、CompositeByteBuf</li>
</ul>
<h2 id="netty-服务端与客户端启动过程"><a href="#netty-服务端与客户端启动过程" class="headerlink" title="netty 服务端与客户端启动过程"></a>netty 服务端与客户端启动过程</h2><h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">new ServerBootstrap()<br>    .group(new NioEventLoopGroup()) <br>    .channel(NioServerSocketChannel.class) <br>    .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; <br>        protected void initChannel(NioSocketChannel ch) &#123;<br>            ch.pipeline().addLast(new StringDecoder()); <br>            ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;String&gt;() &#123; <br>                @Override<br>                protected void channelRead0(ChannelHandlerContext ctx, String msg) &#123;<br>                    System.out.println(msg);<br>                &#125;<br>            &#125;);<br>        &#125;<br>    &#125;)<br>    .bind(8080); // 4<br></code></pre></td></tr></table></figure>

<p>1，创建两个 NioEventLoopGroup 对象实例： bossGroup 和 workerGroup 。<br>bossGroup : ⽤于处理客户端的 TCP 连接请求。<br>workerGroup ： 负责每⼀条连接的具体读写数据的处理逻辑，真正负责 I&#x2F;O 读写操作，交<br>由对应的 Handler 处理。<br>2，创建了⼀个服务端启动引导&#x2F;辅助类： ServerBootstrap ，这个类将引导我们进⾏服<br>务端的启动⼯作。<br>3，通过 .group() ⽅法给引导类 ServerBootstrap 配置两⼤线程组，确定了线程模型。<br>4，通过 channel() ⽅法给引导类 ServerBootstrap 指定了 IO 模型为 NIO<br>5，通过 .childHandler() 给引导类创建⼀个 ChannelInitializer ，然后指定了服务端消息的业务<br>处理逻辑 HelloServerHandler 对象<br>6，调⽤ ServerBootstrap 类的 bind() ⽅法绑定端⼝</p>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">new Bootstrap()<br>    .group(new NioEventLoopGroup()) // 1<br>    .channel(NioSocketChannel.class) // 2<br>    .handler(new ChannelInitializer&lt;Channel&gt;() &#123; // 3<br>        @Override<br>        protected void initChannel(Channel ch) &#123;<br>            ch.pipeline().addLast(new StringEncoder()); // 8<br>        &#125;<br>    &#125;)<br>    .connect(&quot;127.0.0.1&quot;, 8080) // 4<br>    .sync() // 5<br>    .channel() // 6<br>    .writeAndFlush(new Date() + &quot;: hello world!&quot;); // 7<br></code></pre></td></tr></table></figure>

<p>1.创建⼀个 NioEventLoopGroup 对象实例<br>2.创建客户端启动的引导类是 Bootstrap<br>3.通过 .group() ⽅法给引导类 Bootstrap 配置⼀个线程组<br>4.通过 channel() ⽅法给引导类 Bootstrap 指定了 IO 模型为 NIO<br>5.通过 .childHandler() 给引导类创建⼀个 ChannelInitializer ，然后指定了客户端消息的业务处理<br>逻辑 HelloClientHandler 对象<br>6.调⽤ Bootstrap 类的 connect() ⽅法进⾏连接，这个⽅法需要指定两个参数：<br>inetHost : ip 地址<br>inetPort : 端⼝号</p>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty-线程模型</title>
    <url>/2021/07/30/Netty-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p><strong>⼤部分⽹络框架都是基于 Reactor 模式设计开发的。</strong></p>
<p>Reactor 模式基于事件驱动，采⽤多路复⽤将事件分发给相应的 Handler 处理，⾮常适合处理海量 IO 的场景。</p>
<p>在 Netty 主要靠 NioEventLoopGroup 线程池来实现具体的线程模型的 。</p>
<p>我们实现服务端的时候，⼀般会初始化两个线程组：</p>
<ol>
<li>bossGroup :接收连接。</li>
<li>workerGroup ：负责具体的处理，交由对应的 Handler 处理。</li>
</ol>
<p>拥有一个 Acceptor 专门用来监听请求的 I&#x2F;O 类型<br>使用专门线程池可以提高 acceptor 的并发量，并且可以将同一个 SocketChannel 放于同一个 I&#x2F;O 线程处理，同一个 I&#x2F;O 线程可以处理多个 SocketChannel 的 READ&#x2F;WRITE 事件</p>
<p><strong>线程模型：</strong></p>
<p>⼀个 Acceptor 线程只负责监听客户端的连接，⼀个 NIO 线程池负责具体处理：</p>
<p><img src="https://i.loli.net/2021/08/04/cRva4kPzHwBpjOW.png" alt="image-20210804202010279"></p>
<p>从⼀个 <strong>主线程 NIO 线程池</strong>中选择⼀个线程作为 Acceptor 线程，绑定监听端⼝，接收客户端连接<br>的连接，<strong>其他线程负责后续的接⼊认证等⼯作</strong>。连接建⽴完成后，Sub NIO 线程池负责具体处理<br>I&#x2F;O 读写。</p>
<p><img src="https://i.loli.net/2021/08/04/TXCUqymgReK3oNW.png" alt="image-20210804202045874"></p>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty-长连接，心跳机制</title>
    <url>/2021/07/30/Netty-%E9%95%BF%E8%BF%9E%E6%8E%A5%EF%BC%8C%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h3 id="tcp-粘包？netty-解决办法？"><a href="#tcp-粘包？netty-解决办法？" class="headerlink" title="tcp 粘包？netty 解决办法？"></a>tcp 粘包？netty 解决办法？</h3><ul>
<li>使⽤ Netty ⾃带的解码器</li>
</ul>
<ol>
<li>LineBasedFrameDecoder : 发送端发送数据包的时候，每个数据包之间以换⾏符作为分隔， LineBasedFrameDecoder 的⼯作原理是它依次遍历 ByteBuf 中的可读字节，判断是否有换⾏符，然后进⾏相应的截取。</li>
<li>DelimiterBasedFrameDecoder : 可以⾃定义分隔符解码器， LineBasedFrameDecoder 实际上是⼀种特殊的 DelimiterBasedFrameDecoder 解码器。</li>
<li>FixedLengthFrameDecoder : 固定⻓度解码器，它能够按照指定的⻓度对消息进⾏相应的拆包。</li>
<li>LengthFieldBasedFrameDecoder ：</li>
</ol>
<ul>
<li><strong>⾃定义序列化编解码器</strong><br><strong>头部有长度。</strong></li>
</ul>
<h3 id="netty-长连接，心跳机制？"><a href="#netty-长连接，心跳机制？" class="headerlink" title="netty 长连接，心跳机制？"></a>netty 长连接，心跳机制？</h3><p><strong>tcp 长连接短连接</strong></p>
<p>TCP 在进⾏读写之前，server 与 client 之间必须提前建⽴⼀个连接。建⽴连接的过程，需要我们常说的三次握⼿，释放&#x2F;关闭连接的话需要四次挥⼿。这个过程是比较消耗⽹络资源并且有时间延迟的。<br>短连接说的就是 server 端 与 client 端建⽴连接之后，读写完成之后就关闭掉连接，如果下⼀次再要互相发送消息，就要重新连接。</p>
<ol>
<li><p>短连接的有点很明显，就是管理和实现都⽐较简单，</p>
</li>
<li><p>缺点也很明显，每⼀次的读写都要建⽴连接必然会带来⼤量⽹络资源的消耗，并且连接的建⽴也需要耗费时间。</p>
</li>
</ol>
<p>⻓连接说的就是 client 向 server 双⽅建⽴连接之后，即使 client 与 server 完成⼀次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使⽤这个连接。⻓连接的可以省去较多的 TCP 建⽴和关闭的操作，降低对⽹络资源的依赖，节约时间。</p>
<p>对于频繁请求资源的客户来说，⾮常适⽤⻓连接</p>
<h3 id="心跳机制"><a href="#心跳机制" class="headerlink" title="心跳机制"></a>心跳机制</h3><p>在 TCP 保持⻓连接的过程中，可能会出现断⽹等⽹络异常出现，异常发⽣的时候， client 与 server 之间如果没有交互的话，它们是⽆法发现对⽅已经掉线的。为了解决这个问题, 我们就需要引⼊⼼跳机制 。</p>
<p>⼼跳机制的⼯作原理是: 在 client 与 server 之间在⼀定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送⼀个特殊的数据包给对⽅, 当接收⽅收到这个数据报⽂后, 也⽴即发送⼀个特殊的数据报⽂, 回应发送⽅, 此即⼀个 PING-PONG 交互。</p>
<ol>
<li>所以, 当某⼀端收到⼼跳消息后, 就知道了对⽅仍然在线, 这就确保 TCP 连接的有效性。</li>
<li>TCP 实际上⾃带的就有⻓连接选项，本身是也有⼼跳包机制，也就是 TCP 的选项：SO_KEEPALIVE 。 </li>
<li>但是，TCP 协议层⾯的⻓连接灵活性不够。所以，⼀般情况下我们都是在应⽤层协议上实现⾃定义⼼跳机制的，也就是在 Netty 层⾯通过编码实现。通过 Netty 实现⼼跳机制的话，核⼼类是 IdleStateHandler 。</li>
</ol>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>机制</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty-零拷贝</title>
    <url>/2021/07/30/Netty-%E9%9B%B6%E6%8B%B7%E8%B4%9D/</url>
    <content><![CDATA[<p>零拷⻉技术是指计算机执⾏操作时，CPU 不需要先将数 据从某处内存复制到另⼀个特定区域。这种技术通常⽤于通过⽹络传输⽂件时节省 CPU 周期和内存带宽。 </p>
<p>在 OS 层⾯上的 Zero-copy 通常指避免在用户态和内核态之间来回 拷⻉数据。</p>
<p>⽽在 Netty 层⾯ ，零拷⻉主要体现在对于数据操作的优化。 </p>
<ol>
<li>使⽤ Netty 提供的 CompositeByteBuf 类, 可以将多个 ByteBuf 合并为⼀个逻辑上的 ByteBuf , 避免了各个 ByteBuf 之间的拷⻉。 </li>
<li>ByteBuf ⽀持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同⼀个存储区域的 ByteBuf , 避免了内存的拷⻉。 </li>
<li>通过 FileRegion 包装的 FileChannel.tranferTo 实现⽂件传输（底层是 sendfile 方法）, 可以直接将⽂件缓冲区的数据发送到⽬标 Channel , 避免了传统通过循环 write ⽅式导致的内存拷⻉问题 。</li>
<li>duplicate。逻辑上的复制。</li>
</ol>
<h3 id="slice（si-lai-si）"><a href="#slice（si-lai-si）" class="headerlink" title="slice（si lai si）"></a>slice（si lai si）</h3><p>对原始 ByteBuf 进行切片成多个 ByteBuf，切片后的 ByteBuf 并没有发生内存复制，还是使用原始 ByteBuf 的内存，切片后的 ByteBuf 维护独立的 read，write 指针</p>
<p><img src="https://i.loli.net/2021/08/04/XkAyOUa6xiMPqV8.png" alt="image-20210804201821413"></p>
<h3 id="duplicate"><a href="#duplicate" class="headerlink" title="duplicate"></a>duplicate</h3><p>就好比截取了原始 ByteBuf 所有内容，并且没有 max capacity 的限制，也是与原始 ByteBuf 使用同一块底层内存，只是读写指针是独立的。</p>
<p><img src="https://i.loli.net/2021/08/04/2sbl13NIuMo5jwZ.png" alt="image-20210804201834603"></p>
<h3 id="CompositeByteBuf（composite）"><a href="#CompositeByteBuf（composite）" class="headerlink" title="CompositeByteBuf（composite）"></a>CompositeByteBuf（composite）</h3><p>可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免拷贝。</p>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-数据类型</title>
    <url>/2021/07/30/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<p><strong>redis 总是键值对存储。</strong></p>
<p><strong>key 总是 string。</strong></p>
<p><strong>value 有五种类型。</strong></p>
<h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p>string 数据结构是简单的 <strong>key-value</strong> 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串（simple dynamic string，SDS）</strong>。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据<strong>还可以保存二进制数据</strong>，并且**获取字符串长度复杂度为 O(1)**（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。</p>
<p><img src="https://i.loli.net/2021/08/04/zkHrifPgLS46UeR.png" alt="image-20210804150655994"></p>
<p>常用命令： <strong>set,get,strlen,exists,decr,incr,setex</strong> 等等。</p>
<p>应用场景： <strong>一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。</strong></p>
<p>127.0.0.1:6379&gt; set key value #设置 key-value 类型的值<br>127.0.0.1:6379&gt; get key # 根据 key 获得对应的 value<br>127.0.0.1:6379&gt; exists key  # 判断某个 key 是否存在<br>127.0.0.1:6379&gt; strlen key # 返回 key 所储存的字符串值的长度。<br>127.0.0.1:6379&gt; del key # 删除某个 key 对应的值<br>127.0.0.1:6379&gt; get key</p>
<p>批量设置 :<br>127.0.0.1:6379&gt; mset key1 value1 key2 value2 # 批量设置 key-value 类型的值<br>127.0.0.1:6379&gt; mget key1 key2 # 批量获取多个 key 对应的 value</p>
<p>计数器（字符串的内容为整数的时候可以使用）：<br>127.0.0.1:6379&gt; set number 1<br>127.0.0.1:6379&gt; incr number # 将 key 中储存的数字值增一<br>127.0.0.1:6379&gt; get number<br>127.0.0.1:6379&gt; decr number # 将 key 中储存的数字值减一<br>127.0.0.1:6379&gt; get number</p>
<p>过期（默认为永不过期）：<br>127.0.0.1:6379&gt; <strong>expire</strong> key  60 # 数据在 60s 后过期<br>127.0.0.1:6379&gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)<br>127.0.0.1:6379&gt; ttl key # 查看数据还有多久过期</p>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list 即是 <strong>链表</strong>。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且可以灵活调整链表长度，但是链表的随机访问困难。Redis 的 list 的实现为一个 <strong>双向链表</strong>，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p>
<p>常用命令**: rpush,lpop,lpush,rpop,lrange,llen** 等。</p>
<p>应用场景: <strong>发布与订阅或者说消息队列、慢查询。</strong></p>
<p>通过 rpush&#x2F;lpop 实现队列：<br>127.0.0.1:6379&gt; rpush myList value1 # 向 list 的头部（右边）添加元素<br>127.0.0.1:6379&gt; rpush myList value2 value3 # 向 list 的头部（最右边）添加多个元素<br>127.0.0.1:6379&gt; lpop myList # 将 list 的尾部(最左边)元素取出<br>127.0.0.1:6379&gt; lrange myList 0 1 # 查看对应下标的 list 列表， 0 为 start,1 为 end<br>127.0.0.1:6379&gt; lrange myList 0 -1 # 查看列表中的所有元素，-1 表示倒数第一</p>
<p>通过 rpush&#x2F;rpop 实现栈：<br>127.0.0.1:6379&gt; rpush myList2 value1 value2 value3<br>127.0.0.1:6379&gt; rpop myList2 # 将 list 的头部(最右边)元素取出</p>
<p>通过 lrange 查看对应下标范围的列表元素：<br>127.0.0.1:6379&gt; rpush myList value1 value2 value3<br>127.0.0.1:6379&gt; lrange myList 0 1 # 查看对应下标的 list 列表， 0 为 start,1 为 end<br>127.0.0.1:6379&gt; lrange myList 0 -1 # 查看列表中的所有元素，-1 表示倒数第一<br>通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！</p>
<p>通过 llen 查看链表长度：<br>127.0.0.1:6379&gt; llen myList</p>
<h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p>hash 类似于 JDK1.8 前的 HashMap，**内部实现也差不多(数组 + 链表)**。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。</p>
<h4 id="渐进式-rehash（）"><a href="#渐进式-rehash（）" class="headerlink" title="渐进式 rehash（）"></a><strong>渐进式 rehash（）</strong></h4><p>hash 对象在扩容时使用了一种叫“<strong>渐进式 rehash</strong>”的方式，步骤如下：</p>
<p>1）计算新表 size（*2 且为 2 的幂次）、掩码，为新表 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。<br>2）将 rehash <strong>索引计数器变量 rehashidx</strong> 的值设置为 0，表示 rehash 正式开始。<br>3）在 rehash 进行期间，每次对字典执行添加、删除、査找、更新操作时，程序除了执行指定的操作以外，还会触发额外的 rehash 操作，在源码中的 _dictRehashStep 方法。</p>
<p>_dictRehashStep：从名字也可以看出来，大意是 rehash 一步，也就是 rehash 一个索引位置。</p>
<p>该方法会从 <strong>ht[0] 表的 rehashidx 索引位置上开始向后查找，找到第一个不为空的索引位置，将该索引位置的所有节点 rehash 到 ht[1]，当本次 rehash 工作完成之后，将 ht[0] 索引位置为 rehashidx 的节点清空，同时将 rehashidx 属性的值加一。</strong></p>
<p>4）将 rehash 分摊到每个操作上确实是非常妙的方式，但是万一此时服务器比较空闲，一直没有什么操作，难道 redis 要一直持有两个哈希表吗？<br>答案当然不是的。我们知道，redis 除了文件事件外，还有时间事件，<strong>redis 会定期触发时间事件，这些时间事件用于执行一些后台操作，其中就包含 rehash 操作</strong>：当 redis 发现有字典正在进行 rehash 操作时，会花费 1 毫秒的时间，一起帮忙进行 rehash。</p>
<p>5）随着操作的不断执行，最终在某个时间点上，<strong>ht[0] 的所有键值对都会被 rehash 至 ht[1]<strong>，此时 rehash 流程完成，会执行最后的清理工作：</strong>释放 ht[0] 的空间、将 ht[0] 指向 ht[1]、重置 ht[1]、重置 rehashidx</strong></p>
<h4 id="渐进式-rehash-的优点"><a href="#渐进式-rehash-的优点" class="headerlink" title="渐进式 rehash 的优点"></a>渐进式 rehash 的优点</h4><p>渐进式 rehash 的好处在于它采取<strong>分而治之</strong>的方式，将 rehash 键值对所需的计算工作<strong>均摊到对字典的每个添加、删除、查找和更新操作上</strong>，从而避免了<strong>集中式 rehash 而带来的庞大计算量</strong>。</p>
<p>在进行渐进式 rehash 的过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间，字典的删除、査找、更新等操作会在两个哈希表上进行。例如，要在字典里面査找一个键的话，程序会先在 ht[0] 里面进行査找，如果没找到的话，就会继续到 ht[1] 里面进行査找，诸如此类。</p>
<p>另外，在渐进式 rehash 执行期间，<strong>新增的键值对会被直接保存到 ht[1], ht[0] 不再进行任何添加操作，这样就保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。</strong></p>
<p>常用命令： <strong>hset,hmset,hexists,hget,hgetall,hkeys,hvals 等</strong>。</p>
<p>应用场景: 系统中对象数据的存储。 hash 数据结构来存储用户信息，商品信息等等。</p>
<h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是一种<strong>无序集合</strong>，集合中的元素没有先后顺序。<strong>当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择</strong>，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。</p>
<p><strong>可以基于 set 轻易实现交集、并集、差集的操作。</strong></p>
<p>常用命令： <strong>sadd,spop,smembers,sismember,scard,sinterstore,sunion</strong> 等。</p>
<p>应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如<strong>共同关注、共同粉丝、共同喜好等功能。</strong><br>127.0.0.1:6379&gt; smembers mySet # 查看 set 中所有的元素<br>127.0.0.1:6379&gt; scard mySet # 查看 set 的长度<br>127.0.0.1:6379&gt; sismember mySet value1 # 检查某个元素是否存在 set 中，只能接收单个元素<br>127.0.0.1:6379&gt; sadd mySet2 value2 value3<br>127.0.0.1:6379&gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中</p>
<h3 id="sorted-set"><a href="#sorted-set" class="headerlink" title="sorted set"></a>sorted set</h3><p>和 set 相比，sorted set 增加了一个<strong>权重参数 score</strong>，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。</p>
<p>常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。</p>
<p>应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种<strong>礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息</strong>。</p>
<h4 id="Sorted-Set-为什么同时使用字典和跳跃表？"><a href="#Sorted-Set-为什么同时使用字典和跳跃表？" class="headerlink" title="Sorted Set 为什么同时使用字典和跳跃表？"></a>Sorted Set 为什么同时使用字典和跳跃表？</h4><p>主要是为了提升性能。</p>
<p>单独使用字典：在执行范围型操作，比如 zrank、zrange，字典需要进行排序，至少需要 O(NlogN) 的时间复杂度及额外 O(N) 的内存空间。<br>单独使用跳跃表：根据成员查找分值操作的复杂度从 O(1) 上升为 O(logN）</p>
<h4 id="Sorted-Set-为什么使用跳跃表，而不是红黑树？"><a href="#Sorted-Set-为什么使用跳跃表，而不是红黑树？" class="headerlink" title="Sorted Set 为什么使用跳跃表，而不是红黑树？"></a>Sorted Set 为什么使用跳跃表，而不是红黑树？</h4><p>主要有以下几个原因：<br>1）跳表的性能和红黑树差不多。<br>2）<strong>跳表更容易实现和调试</strong>。</p>
<h3 id="bitmap"><a href="#bitmap" class="headerlink" title="bitmap"></a>bitmap</h3><p>bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间。</p>
<p>常用命令： setbit 、getbit 、bitcount、bitop</p>
<p>应用场景： 适合需要保存状态信息（比如是否签到、是否登录…）并需要进一步对这些信息进行分析的场景。比如<strong>用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）</strong>。</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-线程模型,事务</title>
    <url>/2021/07/30/Redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="redis-为什么快"><a href="#redis-为什么快" class="headerlink" title="redis 为什么快"></a>redis 为什么快</h2><p><strong>1、基于内存的操作</strong><br><strong>2、使用了 I&#x2F;O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器</strong><br><strong>3、单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。</strong><br><strong>4、以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字符串、压缩列表等</strong></p>
<h3 id="完全基于内存"><a href="#完全基于内存" class="headerlink" title="完全基于内存"></a>完全基于内存</h3><p>Redis<strong>完全基于内存</strong>，大部分都是简单的存取操作，大量的时间花费在 IO 上。Redis 绝大部分操作时间复杂度为 O(1)，所以速度十分快。</p>
<h3 id="非阻塞-IO、多路-IO-复用模型"><a href="#非阻塞-IO、多路-IO-复用模型" class="headerlink" title="非阻塞 IO、多路 IO 复用模型"></a>非阻塞 IO、多路 IO 复用模型</h3><p>Redis 采用<strong>多路 IO 复用</strong>模型，在内部采用<strong>epoll 代理</strong>。多路是指多个网络连接，IO 复用是指复用同一个线程。<strong>epoll 会同时监察多个流的 IO 事件，</strong>在空闲时，当前线程进入阻塞，如果有 IO 事件时，线程会被唤醒，并且 epoll 会通知线程是哪个流发生了 IO 事件，然后按照顺序处理，减少了网络 IO 的时间消耗，避免了大量的无用操作。</p>
<h3 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h3><p>对于单线程来讲，<strong>不存在上下文切换问题，也不用考虑锁的问题，不存在加锁释放锁的操作，没有因为可能出现死锁而导致的性能消耗</strong>。虽然单线程无法发挥出多个 CPU 的性能，但是可以<strong>在单机开启多个 Redis 实例解决这个问题。</strong>reids 的单线程是指<strong>处理网络请求只有一个线程</strong>。</p>
<p>每次上下文切换都需要花费几十纳秒到数微秒的 CPU 时间，也就是说如果<strong>频繁的进行上下文切换会导致 CPU 大部分时间被浪费。</strong></p>
<p>在关系型数据库中，会通过加锁来保证数据的一致性，这种锁被称为悲观锁。Redis 为了近可能的减少客户端等待，使用 WATCH 命令对数据加锁，<strong>只会在数据被其他客户端修改时，才会通知执行 WATCH 的客户端</strong>，之后的事务不会执行。这种加锁方式被称为乐观锁，极大的提升了 Redis 的性能。</p>
<h3 id="数据结构简单"><a href="#数据结构简单" class="headerlink" title="数据结构简单"></a>数据结构简单</h3><p>数据结构设计简单，对数据的操作也简单，Redis 中的数据结构是专门进行设计的。Redis 的数据结构有<strong>简单动态字符串、链表、字典、跳跃表、整数集合、压缩字典。</strong></p>
<p>简单动态字符串<br>Redis 并没有使用 C 语言的字符串，而是使用了简单动态字符串(SDS)。相对于 C 语言的字符串来讲，SDS 记录了自身使用和未使用的长度，时间复杂度为 O(1),而 C 语言则要遍历整个空间，时间复杂度为 O(N)。<br>SDS 可以通过自身长度来判断字符串是否结束，这样可以实现二进制数据的存储。</p>
<p>链表<br>Redis 的链表为双端链表，链表节点带有 perv 和 next 指针，链表还带有 head 和 tail 指针，使得获取链表某节点前后置节点的时间复杂度都是 O(1)。并且 Redis 链表无环，prev 和 next 指针指向 null，对链表的访问以 null 作为截至的判断条件。<br>链表中有记录自身长度的属性 len，并且链表使用 void*指针来保存节点值，可以通过 list 结构的 dup、free、match 三个属性为节点值设置类型特定函数，所以链表可以用来保存各种不同类型的值。</p>
<p>字典<br>字典由哈希表组成，而哈希表又由哈希结点组成。</p>
<p>跳跃表<br>跳跃表是一种有序数据结构，通过在每个结点中维持多个指向其它结点的指针，从而达到快速访问结点的目的。Redis 中在有序集合键和集群结点中的内部数据结构都用到了跳跃表。</p>
<p>整数集合<br>Redis 用于保存整数值的集合抽象数据结构，它可以保存类型为 int16_t、int32_t 或者 int64_t 的整数值，并且保证集合中不会出现重复元素。</p>
<p>压缩列表<br>压缩列表是 Redis 为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的<strong>顺序型数据结构</strong>。一个压缩列表可以包含任意个结点，每个结点可以保存一个字节数或者一个整数值。</p>
<h3 id="Redis-优秀的过期策略和内存淘汰机制"><a href="#Redis-优秀的过期策略和内存淘汰机制" class="headerlink" title="Redis 优秀的过期策略和内存淘汰机制"></a>Redis 优秀的过期策略和内存淘汰机制</h3><p><strong>定时删除</strong>：在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，<strong>对 CPU 时间最不友好。</strong></p>
<p><strong>惰性删除</strong>：<strong>放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键</strong>；如果没有过期，就返回该键。对 CPU 时间最优化，对内存最不友好。</p>
<p><strong>定期删除</strong>：<strong>每隔一段时间，默认 100ms，程序就对数据库进行一次检査，删除里面的过期键</strong>。至 于要删除多少过期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。</p>
<p>Redis 使用<strong>惰性删除和定期删除</strong></p>
<h4 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h4><p>Redis 的内存淘汰机制有六种：</p>
<p>volatile-lru：内存不足时，删除<strong>设置了过期时间的键空间</strong>中最近最少使用的 key<br>allkeys-lru：内存不足时，在<strong>键空间</strong>中删除最少使用的 key<br>volatile-random：内存不足时，随机删除在<strong>设置了过期时间</strong>的键空间中的 key<br>allkeys-random：内存不足时，随即删除在<strong>键空间</strong>中的 key<br>volatile-ttl：内存不足时，在设<strong>置了过期时间</strong>的键空间中，优先移除<strong>更早过期时间的 key</strong><br>noeviction：永不过期，返回错误</p>
<p><strong>还有两种 4.0 新增的：基于 LFU.</strong></p>
<p>在以上的淘汰策略中，使用 allkeys-lru 较好。</p>
<h3 id="在-redis-6-0-之前，redis-的核心操作是单线程的"><a href="#在-redis-6-0-之前，redis-的核心操作是单线程的" class="headerlink" title="在 redis 6.0 之前，redis 的核心操作是单线程的"></a>在 redis 6.0 之前，redis 的核心操作是单线程的</h3><p>因为 redis 是完全基于内存操作的，通常情况下 CPU 不会是 redis 的瓶颈，redis 的瓶颈最有可能是机器内存的大小或者网络带宽。<br>既然 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。<br>而随着近些年互联网的不断发展，大家对于缓存的性能要求也越来越高了，因此 redis 也开始在逐渐往多线程方向发展。</p>
<p>最近的 <strong>6.0 版本</strong>就对核心流程引入了多线程，主要用于解决 redis 在<strong>网络 I&#x2F;O 上的性能瓶颈。而对于核心的命令</strong><br><strong>执行阶段，目前还是单线程的。</strong></p>
<h2 id="Redis-的网络事件处理器（Reactor-模式）"><a href="#Redis-的网络事件处理器（Reactor-模式）" class="headerlink" title="Redis 的网络事件处理器（Reactor 模式）"></a>Redis 的网络事件处理器（Reactor 模式）</h2><p>redis 基于 reactor 模式开发了自己的网络事件处理器，由 4 个部分组成：<strong>套接字、I&#x2F;O 多路复用程序、文件事件分 派器（dispatcher）、以及事件处理器。</strong></p>
<p><img src="https://i.loli.net/2021/08/04/fG5ONWZAVCUr69X.png" alt="image-20210804153454233"></p>
<p><strong>套接字</strong>：socket 连接，也就是客户端连接。当一个套接字准备好执行连接、写入、读取、关闭等操作时， 就会产生一个相应的文件事件。因为一个服务器通常会连接多个套接字， 所以多个文件事件有可能会并发地出现。</p>
<p><strong>I&#x2F;O 多路复用程序</strong>：提供 select、epoll、evport、kqueue 的实现，会根据当前系统自动选择最佳的方式。负责监听多个套接字，当套接字产生事件时，会向文件事件分派器传送那些产生了事件的套接字。当多个文件事件并发出现时， <strong>I&#x2F;O 多路复用程序会将所有产生事件的套接字都放到一个队列里面，</strong>然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后，才会继续传送下一个套接字。</p>
<p><strong>文件事件分派器</strong>：接收 I&#x2F;O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。</p>
<p><strong>事件处理器：</strong>事件处理器就是一个个函数， 定义了某个事件发生时， 服务器应该执行的动作。例如：建立连接、命令查询、命令写入、连接关闭等等</p>
<h2 id="Redis-事务的实现"><a href="#Redis-事务的实现" class="headerlink" title="Redis 事务的实现"></a>Redis 事务的实现</h2><p>一个事务从开始到结束通常会经历以下 3 个阶段：</p>
<p>1）事务开始：<strong>multi</strong> 命令将执行该命令的客户端从非事务状态切换至事务状态，底层通过 flags 属性标识。<br>2）命令入队：当客户端处于事务状态时，服务器会根据客户端发来的命令执行不同的操作：<br>exec、discard、watch、multi 命令会被立即执行<br>其他命令不会立即执行，而是将命令放入到一个事务队列，然后向客户端返回 QUEUED 回复。<br>3）事务执行：当一个处于事务状态的客户端向服务器发送 <strong>exec</strong> 命令时，服务器会遍历事务队列，执行队列中的所有命令，最后将结果全部返回给客户端。</p>
<p><strong>WATCH 命令可以监控一个或多个键</strong>，一旦其中有一个键被修改（或删除），<strong>之后的事务就不会执行。</strong></p>
<p>监控一直持续到<strong>EXEC 命令（</strong>事务中的命令是在 EXEC 之后才执行的，所以在 MULTI 命令后<strong>可以修改 WATCH 监控的键值</strong>）</p>
<p>不过 redis 的事务<strong>并不推荐在实际中使用</strong>，如果要使用事务，推荐使用 Lua 脚本，redis 会保证一个 Lua 脚本里的所有命令的原子性。</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-持久化</title>
    <url>/2021/07/30/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/</url>
    <content><![CDATA[<p>Redis 的持久化机制有：<strong>RDB、AOF、混合持久化（RDB+AOF，Redis 4.0 引入）。</strong></p>
<h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><p>类似于快照。在某个时间点，<strong>将 Redis 在内存中的数据库状态（数据库的键值对等信息）保存到磁盘里面</strong>。<br>RDB 持久化功能生成的 RDB 文件是<strong>经过压缩的二进制文件。</strong></p>
<p>命令：有两个 Redis 命令可以用于生成 RDB 文件<strong>，一个是 SAVE，另一个是 BGSAVE</strong>。<br>开启：使用 save point 配置，满足 save point 条件后会触发 BGSAVE <strong>来存储一次快照</strong>。</p>
<p>save point 格式：save <seconds> <changes>，含义是 Redis 如果<strong>在 seconds 秒内数据发生了 changes 次改变，就保存快照文件。</strong></p>
<p>SAVE：生成 RDB 快照文件，<strong>但是会阻塞主进程</strong>，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。</p>
<p>BGSAVE：<strong>fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候</strong>，之后主进程可以正常处理请求。</p>
<p>fork：在 Linux 系统中，调用 fork() 时，会创建出一个新进程，称为子进程，子进程会拷贝父进程的 page table。如果进程占用的内存越大，进程的 page table 也会越大，那么 fork 也会占用更多的时间。如果 Redis 占用的内存很大，那么在 fork 子进程时，则会出现明显的停顿。</p>
<h4 id="RDB-的优点"><a href="#RDB-的优点" class="headerlink" title="RDB 的优点"></a>RDB 的优点</h4><p>RDB 文件是是经过压缩的二进制文件，<strong>占用空间很小</strong>，它保存了 Redis 某个时间点的数据集，很适合用于做备<br>份。</p>
<p>RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。</p>
<p>RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进<br>程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I&#x2F;O 操作。</p>
<p>RDB 在<strong>恢复大数据集时的速度比 AOF 的恢复速度要快</strong>。</p>
<h4 id="RDB-的缺点"><a href="#RDB-的缺点" class="headerlink" title="RDB 的缺点"></a>RDB 的缺点</h4><p>RDB 在服务器故障时<strong>容易造成数据的丢失</strong>。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。</p>
<p>RDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，<strong>fork 可能会非常耗时</strong>，造成 Redis 停<br>止处理服务 N 毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。</p>
<p>Linux fork 子进程采用的是 <strong>copy-on-write</strong> 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的 2 倍。刚 fork 时，主进程和子进程共享内存，<strong>但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改</strong>。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的 2 倍。</p>
<h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>保存 Redis 服务器所执行的所有写操作命令来记录数据库状态，并在服务器启动时，通过重新执行这些命令<br>来还原数据集。<br>开启：AOF 持久化默认是关闭的，可以通过配置：<strong>appendonly yes</strong> 开启。<br>关闭：使用配置 appendonly no 可以关闭 AOF 持久化。</p>
<p>AOF 持久化功能的实现可以分为三个步骤：<strong>命令追加、文件写入、文件同步</strong>。</p>
<p>命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态的 <strong>aof 缓冲区（aof_buf）</strong>的末尾。<br>文件写入与文件同步：可能有人不明白为什么将 aof_buf 的内容写到磁盘上需要两步操作，这边简单解释一下。</p>
<p>Linux 操作系统中为了提升性能，使用了<strong>页缓存（page cache）</strong>。当我们将 aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 page cache 中，为了将 page cache 中的数据真正落盘，需要执行 fsync &#x2F; fdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。</p>
<p>appendfsync 参数值，来决定<strong>是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件</strong>。</p>
<h4 id="appendfsync-参数有三个选项"><a href="#appendfsync-参数有三个选项" class="headerlink" title="appendfsync 参数有三个选项"></a><strong>appendfsync 参数有三个选项</strong></h4><p>always：<strong>每处理一个命令</strong>都将 aof_buf 缓冲区中的所有内容写入并同步到 AOF 文件，即每个命令都刷盘。</p>
<p>everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超<br>过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，<br>即<strong>每秒刷盘 1 次。</strong></p>
<p>no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作<br>系统来决定。即不执行刷盘，<strong>让操作系统自己执行刷盘。</strong></p>
<h4 id="AOF-的优点"><a href="#AOF-的优点" class="headerlink" title="AOF 的优点"></a>AOF 的优点</h4><ol>
<li><strong>AOF 比 RDB 可靠。</strong>你可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。</li>
<li><strong>AOF 文件是一个纯追加的日志文件</strong>。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘<br>已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。</li>
<li><strong>当 AOF 文件太大时，Redis 会自动在后台进行重写</strong>：重写后的新 AOF 文件包含了恢复当前数据集所需的最<br>小命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追<br>加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。</li>
<li>AOF 文件<strong>有序地保存了对数据库执行的所有写入操作以 Redis 协议的格式保存</strong>， 因此 AOF 文件的<strong>内容非</strong><br> <strong>常容易被人读懂</strong>， 对文件进行分析（parse）也很轻松。如果你不小心执行了 FLUSHALL 命令把所有数据刷<br> 掉了，但只要 AOF 文件没有被重写，那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并<br> 重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</li>
</ol>
<h4 id="AOF-的缺点"><a href="#AOF-的缺点" class="headerlink" title="AOF 的缺点"></a>AOF 的缺点</h4><p>对于相同的数据集，<strong>AOF 文件的大小一般会比 RDB 文件大。</strong></p>
<p>根据所使用的 fsync 策略，<strong>AOF 的速度可能会比 RDB 慢</strong>。通常 fsync 设置为每秒一次就能获得比较高的<br>性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。</p>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h3><p>混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化<strong>只发生于 AOF 重写</strong>过程。<br>使用了混合持久化，<strong>重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据</strong>。</p>
<p>开启：混合持久化的配置参数为 <strong>aof-use-rdb-preamble</strong>，配置为 yes 时开启混合持久化，在 redis 4 刚引入时，默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。</p>
<p>关闭：使用 aof-use-rdb-preamble no 配置即可关闭混合持久化。</p>
<p>混合持久化本质是<strong>通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区的增量命令以 AOF 方式写入到文件</strong>，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>优点：结合 RDB 和 AOF 的优点, <strong>更快的重写和恢复。</strong><br>缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。</p>
<h4 id="为什么需要-AOF-重写"><a href="#为什么需要-AOF-重写" class="headerlink" title="为什么需要 AOF 重写"></a>为什么需要 AOF 重写</h4><p>AOF 持久化是通过保存<strong>被执行的写命令</strong>来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，<strong>文件的体积也会越来越大。</strong></p>
<p>举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。<br>然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。<br>为了处理这种情况， Redis 引入了 AOF 重写：可以在不打断服务端处理请求的情况下， 对 AOF 文件进行重建<br>（rebuild）。</p>
<h4 id="介绍下-AOF-重写的过程、AOF-后台重写存在的问题、如何解决-AOF-后台重写存在的数据不一致问题"><a href="#介绍下-AOF-重写的过程、AOF-后台重写存在的问题、如何解决-AOF-后台重写存在的数据不一致问题" class="headerlink" title="介绍下 AOF 重写的过程、AOF 后台重写存在的问题、如何解决 AOF 后台重写存在的数据不一致问题"></a>介绍下 AOF 重写的过程、AOF 后台重写存在的问题、如何解决 AOF 后台重写存在的数据不一致问题</h4><p>Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件<strong>包含重建当前数据集所需的最少命令。</strong></p>
<p>具体过程是<strong>遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。</strong></p>
<p>命令：有两个 Redis 命令可以用于触发 AOF 重写，一个是 <strong>BGREWRITEAOF</strong> 、另一个是 <strong>REWRITEAOF</strong> 命令；<br>开启：AOF 重写由两个参数共同控制，auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size，同时满足这两个条件，则触发 AOF 后台重写 BGREWRITEAOF。</p>
<ol>
<li><p>&#x2F;&#x2F; 当前 AOF 文件比上次重写后的 AOF 文件大小的增长比例超过 100</p>
<p>auto-aof-rewrite-percentage 100</p>
</li>
<li><p>&#x2F;&#x2F; 当前 AOF 文件的文件大小大于 64MB</p>
<p>auto-aof-rewrite-min-size 64mb</p>
</li>
</ol>
<p>BGREWRITEAOF：fork 子进程来进行 AOF 重写，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。<br><strong>REWRITEAOF 和 BGREWRITEAOF 的关系与 SAVE 和 BGSAVE 的关系类似。</strong></p>
<h4 id="AOF-后台重写存在的问题"><a href="#AOF-后台重写存在的问题" class="headerlink" title="AOF 后台重写存在的问题"></a>AOF 后台重写存在的问题</h4><p>AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：</p>
<p>子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，<strong>新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。</strong></p>
<h4 id="如何解决-AOF-后台重写存在的数据不一致问题"><a href="#如何解决-AOF-后台重写存在的数据不一致问题" class="headerlink" title="如何解决 AOF 后台重写存在的数据不一致问题"></a>如何解决 AOF 后台重写存在的数据不一致问题</h4><p>为了解决上述问题，Redis 引入了 <strong>AOF 重写缓冲区</strong>（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。</p>
<p> 1、现有 AOF 文件的处理工作会如常进行。这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。<br> 2、从创建子进程开始，也就是 AOF 重写开始，服务器执行的所有写命令会被记录到 AOF 重写缓冲区里面。</p>
<p> 这样，<strong>当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束</strong>，则会执行以下工作：<br> 1、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。<br> 2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。</p>
<h4 id="RDB、AOF、混合持久，用哪一个？"><a href="#RDB、AOF、混合持久，用哪一个？" class="headerlink" title="RDB、AOF、混合持久，用哪一个？"></a>RDB、AOF、混合持久，用哪一个？</h4><p>如果想尽量保证数据安全性， 你应该同时使用 RDB 和 AOF 持久化功能，同时可以开启混合持久化。</p>
<p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。</p>
<p>如果你的数据是可以丢失的，则可以关闭持久化功能，在这种情况下，Redis 的性能是最高的。</p>
<p>使用 Redis 通常都是为了提升性能，而如果为了不丢失数据而将 appendfsync 设置为 always 级别时，对 Redis 的性能影响是很大的，在这种不能接受数据丢失的场景，其实可以考虑直接选择 MySQL 。</p>
<h4 id="同时开启-RDB-和-AOF，服务重启时如何加载"><a href="#同时开启-RDB-和-AOF，服务重启时如何加载" class="headerlink" title="同时开启 RDB 和 AOF，服务重启时如何加载"></a>同时开启 RDB 和 AOF，服务重启时如何加载</h4><p>简单来说，如果同时启用了 AOF 和 RDB，Redis 重新启动时，<strong>会使用 AOF 文件来重建数据集</strong>，因为通常来说， AOF 的数据会更完整。</p>
<p>而在引入了混合持久化之后，使用 AOF 重建数据集时，会通过文件开头是否为“REDIS”来判断是否为混合持久化。</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-缓存一致性</title>
    <url>/2021/08/04/Redis-%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    <content><![CDATA[<h2 id="如何保证数据库和缓存的数据一致性"><a href="#如何保证数据库和缓存的数据一致性" class="headerlink" title="如何保证数据库和缓存的数据一致性"></a>如何保证数据库和缓存的数据一致性</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化，串到一个内存队列里去</strong>。</p>
<p><strong>串行化</strong>可以保证<strong>一定不会出现不一致的情况</strong>，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<h2 id="Cache-Aside-Pattern-旁路缓存模式"><a href="#Cache-Aside-Pattern-旁路缓存模式" class="headerlink" title="Cache Aside Pattern 旁路缓存模式"></a><strong>Cache Aside Pattern 旁路缓存模式</strong></h2><p>最经典的缓存+数据库读写的模式，就是 <strong>Cache Aside Pattern。</strong></p>
<blockquote>
<p><strong>读的时候，先读缓存</strong>，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。<br><strong>更新的时候，先更新数据库，成功后，然后再删除缓存。</strong></p>
<p>如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。</p>
</blockquote>
<h3 id="在写数据的过程中，可以先删除-cache-，后更新-DB-？"><a href="#在写数据的过程中，可以先删除-cache-，后更新-DB-？" class="headerlink" title="在写数据的过程中，可以先删除 cache ，后更新 DB ？"></a>在写数据的过程中，可以先删除 cache ，后更新 DB ？</h3><p>请求 1 先把 cache 中的 A 数据删除 -&gt; 请求 2 从 DB 中读取数据-&gt;请求 1 再把 DB 中的 A 数据更新。</p>
<h3 id="在写数据的过程中，先更新-DB，后删除-cache-就没有问题了？"><a href="#在写数据的过程中，先更新-DB，后删除-cache-就没有问题了？" class="headerlink" title="在写数据的过程中，先更新 DB，后删除 cache 就没有问题了？"></a>在写数据的过程中，先更新 DB，后删除 cache 就没有问题了？</h3><p>理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为<strong>缓存的写入速度是比数据库的写入速度快很多</strong></p>
<p>比如请求 1 先读数据 A，请求 2 随后写数据 A，并且数据 A 不在缓存中的话也有可能产生数据不一致性的问题。这个过程可以简单描述为：</p>
<p>请求 1 从 DB 读数据 A-&gt;请求 2 写更新数据 A 到数据库并把删除 cache 中的 A 数据-&gt;请求 1 将数据 A 写入 cache。</p>
<h3 id="为什么是删除缓存，而不是更新缓存？"><a href="#为什么是删除缓存，而不是更新缓存？" class="headerlink" title="为什么是删除缓存，而不是更新缓存？"></a>为什么是删除缓存，而不是更新缓存？</h3><p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p>
<p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p>
<p>另外<strong>更新缓存的代价有时候是很高的</strong>。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。<strong>如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。</strong>但是问题在于，这个缓存到底会不会被频繁访问到？</p>
<p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；<strong>但是这个缓存在 1 分钟内只被读取了 1 次</strong>，有大量的冷数据。实际上，<strong>如果你只是删除缓存的话</strong>，那么在 1 分钟内，这个缓存不过就重新计算一次而已，<strong>开销大幅度降低</strong>。用到缓存才去算缓存。</p>
<p><strong>其实删除缓存，而不是更新缓存</strong>，就是一个 <strong>lazy 计算</strong>的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。</p>
<p>但实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的<strong>写操作会比读操作慢得多，而且还要锁表</strong>，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。</p>
<p>所以，要么通过 2PC 或是 Paxos 协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而 Facebook 使用了这个降低概率的玩法，因为 2PC 太慢，而 Paxos 太复杂。当然，<strong>最好还是为缓存设置上过期时间。</strong></p>
<h2 id="Read-x2F-Write-Through-Pattern（读写穿透）"><a href="#Read-x2F-Write-Through-Pattern（读写穿透）" class="headerlink" title="Read&#x2F;Write Through Pattern（读写穿透）"></a>Read&#x2F;Write Through Pattern（读写穿透）</h2><p>Read&#x2F;Write Through 套路是把更新数据库（Repository）的操作由<strong>缓存自己代理</strong>，可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的 Cache。</p>
<p><strong>Read Through</strong><br>Read Through 套路就是在<strong>查询操作中更新缓存</strong>，也就是说，当缓存失效的时候（过期或 LRU 换出），Cache Aside 是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载，从而对应用方是透明的。</p>
<p><strong>Write Through</strong><br>Write Through 套路和 Read Through 相仿，不过是在更新数据时发生。<strong>当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回</strong>。<strong>如果命中了缓存，则更新缓存，然后再由 Cache 自己更新数据库（这是一个同步操作）</strong></p>
<p><img src="https://i.loli.net/2021/08/04/UgD7uS9WeIimzxR.png" alt="image-20210804192802967"></p>
<h2 id="Write-Behind-Caching-Pattern"><a href="#Write-Behind-Caching-Pattern" class="headerlink" title="Write Behind Caching Pattern"></a>Write Behind Caching Pattern</h2><p>Write Behind 又叫 Write Back。</p>
<p>Write Back 套路，<strong>在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。</strong>这个设计的好处就是让数据的 I&#x2F;O 操作飞快无比，因为异步，write backg 还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。</p>
<p>但是，其带来的问题是，<strong>数据不是强一致性的</strong>，而且可能会丢失。</p>
<p>另外，Write Back 实现逻辑比较复杂，因为他需要 track 有哪数据是被更新了的，需要刷到持久层上。操作系统的 write back 会在仅当这个 cache 需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫 lazy write。</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>思想</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-缓存击穿，雪崩，穿透</title>
    <url>/2021/07/30/Redis-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%EF%BC%8C%E9%9B%AA%E5%B4%A9%EF%BC%8C%E7%A9%BF%E9%80%8F/</url>
    <content><![CDATA[<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下<br>一次同样会打到数据库上。此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一样，起不到任何作用。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>1）接口校验。在正常业务流程中可能会存在少量访问不存在 key 的情况，但是一般不会出现大量的情况，所以这种场景最大的可能性是遭受了非法攻击。可以在最外层先做一层校验：用户鉴权、数据合法性校验等，例如商品查询中，商品的 ID 是正整数，则可以直接对非正整数直接过滤等等。</p>
<p>2）缓存空值。当访问缓存和 DB 都没有查询到值时，可以将空值写进缓存，但是设置较短的过期时间，该时间需要根据产品业务特性来设置。</p>
<p>3）布隆过滤器。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库</p>
<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><p>布隆过滤器的特点是<strong>判断不存在的，则一定不存在</strong>；<strong>判断存在的，大概率存在</strong>，但也有小概率不存在。并且这个概率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。</p>
<p>布隆过滤器<strong>由一个 bitSet 和 一组 Hash 函数（算法）组成</strong>，是一种空间效率极高的概率型算法和数据结构，主要用来判断<strong>一个元素是否在海量数据集合中存在</strong>。</p>
<p>在初始化时，bitSet 的每一位被初始化为 0，同时会定义 Hash 函数，例如有 3 组 Hash 函数：hash1、hash2、hash3。</p>
<h3 id="写入流程"><a href="#写入流程" class="headerlink" title="写入流程"></a>写入流程</h3><p>当我们要写入一个值时，过程如下，以“x”为例：<br>1）首先将“x”跟 3 组 Hash 函数分别计算，得到 bitSet 的下标为：1、7、10。<br>2）将 bitSet 的这 3 个下标标记为 1。</p>
<p>假设我们还有另外两个值：java 和 q，按上面的流程跟 3 组 Hash 函数分别计算，结果如下：<br>java：Hash 函数计算 bitSet 下标为：1、7、11<br>q 函数计算 bitSet 下标为：4、10、11</p>
<h3 id="查询流程"><a href="#查询流程" class="headerlink" title="查询流程"></a>查询流程</h3><p>当我们要查询一个值时，过程如下，同样以“x”为例：：<br>1）首先将“x”跟 3 组 Hash 函数分别计算，得到 bitSet 的下标为：1、7、10。<br>2）查看 bitSet 的这 3 个下标是否都为 1，如果这 3 个下标不都为 1，则说明该值必然不存在，如果这 3 个下标都为 1，则只能说明可能存在，并不能说明一定存在。</p>
<p><img src="https://i.loli.net/2021/08/04/nZqz2gG4hsDHpwm.png" alt="image-20210804194430890"></p>
<p>其根本原因是，<strong>不同的值在跟 Hash 函数计算后，可能会得到相同的下标</strong>，所以某个值的标记位，可能会被其他值给标上了。<br>这也是为啥布隆过滤器只能判断某个值可能存在，无法判断必然存在的原因。但是反过来，如果该值根据 Hash 函数计算的标记位没有全部都为 1，那么则说明必然不存在，这个是肯定的。</p>
<p>降低这种误判率的思路也比较简单：<br>一个是<strong>加大 bitSet 的长度</strong>，这样不同的值出现“冲突”的概率就降低了，从而误判率也降低。<br><strong>提升 Hash 函数的个数</strong>，Hash 函数越多，每个值对应的 bit 越多，从而误判率也降低。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>某一个<strong>热点 key，在缓存过期的一瞬间，同时有大量的请求打进来</strong>，由于此时缓存过期了，所以请求最终都<br>会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。</p>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><p><strong>预先准备</strong>，以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息 key 的过期时长。</p>
<p><strong>现场调整</strong><br>监控访问量，对自然流量激增的数据延长过期时间或设置为永久性 key</p>
<p><strong>后台刷新数据</strong><br>启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</p>
<p><strong>二级缓存</strong><br><strong>设置不同的失效时间，保障不会被同时淘汰就行</strong></p>
<p><strong>加锁</strong><br>分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</p>
<p><strong>总结</strong><br>缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中 redis 后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个 key 的过期监控难度较高，配合雪崩处理策略即可。</p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力<br>骤增，引起雪崩，甚至导致数据库被打挂。<br>缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。</p>
<h3 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h3><p><strong>过期时间打散</strong>。既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过期时间时加上一个<strong>随机值时间</strong>，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。</p>
<p><strong>热点数据不过期</strong>。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。</p>
<p><strong>加互斥锁</strong>。该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算，其他线程原<br>地阻塞等待第一个线程的计算结果，然后直接走缓存即可</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-集群</title>
    <url>/2021/07/30/Redis-%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。</p>
<p>slaveof 命令</p>
<p>部分复制：偏移量，积压缓冲区，服务器运行 id</p>
<h3 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h3><ul>
<li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li>
<li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li>
<li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。</li>
<li>高可用基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis 高可用的基础。</li>
</ul>
<h3 id="主从复制实现原理"><a href="#主从复制实现原理" class="headerlink" title="主从复制实现原理"></a>主从复制实现原理</h3><p>Redis 的复制分为全量同步和增量同步。</p>
<p>如果主库发现从库传来的复制 id 和自己的 replid、replid2 都不同，或者复制偏移不在复制积压缓冲中，则判定需要进行全量复制。</p>
<p>master 发送 fullresync 响应，附带 replid 及复制偏移。然后， master 根据需要构建 rdb，并将 rdb 及复制缓冲发送给 slave。</p>
<p><img src="https://i.loli.net/2021/08/05/HeojUDSBxl2mPvg.png" alt="image-20210805212150709"></p>
<h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><p>Redis 的主从复制模式下，一旦主节点由于故障不能提供服务，需要手动将从节点晋升为主节点，同时还要通知客户端更新主节点地址，这种故障处理方式从一定程度上是无法接受的。</p>
<p>Redis Sentinel 是 Redis 高可用的实现方案。Sentinel 是一个管理多个 Redis 实例的工具，它可以实现对 Redis 的监控、通知、自动故障转移。</p>
<h3 id="哨兵模式的原理"><a href="#哨兵模式的原理" class="headerlink" title="哨兵模式的原理"></a>哨兵模式的原理</h3><p>哨兵模式的主要作用在于它能够自动完成故障发现和故障转移，并通知客户端，从而实现高可用。哨兵模式通常由一组 Sentinel 节点和一组（或多组）主从复制节点组成。</p>
<h4 id="心跳机制"><a href="#心跳机制" class="headerlink" title="心跳机制"></a>心跳机制</h4><p>（1）Sentinel 与 Redis Node</p>
<p>Redis Sentinel 是一个特殊的 Redis 节点。在哨兵模式创建时，需要通过配置指定 Sentinel 与 Redis Master Node 之间的关系，然后 Sentinel 会从主节点上获取所有从节点的信息，之后 Sentinel 会定时向主节点和从节点发送 info 命令获取其拓扑结构和状态信息。<br>（2）Sentinel 与 Sentinel</p>
<p>基于 Redis 的订阅发布功能， 每个 Sentinel 节点会向主节点的 sentinel：hello 频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息 ，同时每个 Sentinel 节点也会订阅该频道， 来获取其他 Sentinel 节点的信息以及它们对主节点的判断。<br>通过以上两步所有的 Sentinel 节点以及它们与所有的 Redis 节点之间都已经彼此感知到，之后每个 Sentinel 节点会向主节点、从节点、以及其余 Sentinel 节点定时发送 ping 命令作为心跳检测， 来确认这些节点是否可达。</p>
<h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>每个 Sentinel 都会定时进行心跳检查，当发现主节点出现心跳检测超时的情况时，此时认为该主节点已经不可用，这种判定称为主观下线。</p>
<p>之后该 Sentinel 节点会通过 sentinel ismaster-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断， 当 quorum（法定人数） 个 Sentinel 节点都认为该节点故障时，则执行客观下线，即认为该节点已经不可用。这也同时解释了为什么必须需要一组 Sentinel 节点，因为单个 Sentinel 节点很容易对故障状态做出误判。</p>
<p>这里 quorum 的值是我们在哨兵模式搭建时指定的，后文会有说明，通常为 Sentinel 节点总数&#x2F;2+1，即半数以上节点做出主观下线判断就可以执行客观下线。</p>
<p>因为故障转移的工作只需要一个 Sentinel 节点来完成，所以 Sentinel 节点之间会再做一次选举工作， 基于 Raft 算法选出一个 Sentinel 领导者来进行故障转移的工作。</p>
<h4 id="被选举出的-Sentinel-领导者进行故障转移的具体步骤如下"><a href="#被选举出的-Sentinel-领导者进行故障转移的具体步骤如下" class="headerlink" title="被选举出的 Sentinel 领导者进行故障转移的具体步骤如下"></a>被选举出的 Sentinel 领导者进行故障转移的具体步骤如下</h4><p>（1）在从节点列表中选出一个节点作为新的主节点<br>        过滤不健康或者不满足要求的节点；<br>        选择 slave-priority（优先级）最高的从节点， 如果存在则返回， 不存在则继续；<br>        选择复制偏移量最大的从节点 （主从复制的多的）， 如果存在则返回， 不存在则继续；<br>        选择 runid 最小的从节点。<br>（2）Sentinel 领导者节点会对选出来的从节点执行 slaveof no one 命令让其成为主节点。<br>（3）Sentinel 领导者节点会向剩余的从节点发送命令，让他们从新的主节点上复制数据。<br>（4）Sentinel 领导者会将原来的主节点更新为从节点， 并对其进行监控， 当其恢复后命令它去复制新的主节点。</p>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>哨兵模式最大的缺点就是<strong>所有的数据都放在一台服务器</strong>上，无法较好的进行水平扩展。</p>
<p>为了解决哨兵模式存在的问题，集群模式应运而生。在高可用上，集群基本是直接复用的哨兵模式的逻辑，并且针对水平扩展进行了优化。</p>
<p><img src="https://i.loli.net/2021/08/04/GfF65HaBPXZeYUD.png" alt="image-20210804171645855"></p>
<h4 id="集群模式具备的-4-特点如下"><a href="#集群模式具备的-4-特点如下" class="headerlink" title="集群模式具备的 4 特点如下"></a>集群模式具备的 4 特点如下</h4><ol>
<li>采取<strong>去中心化</strong>的集群模式，将数据按<strong>槽</strong>存储分布在多个 Redis 节点上。集群共有 <strong>16384</strong> 个槽，每个节点负<br>责处理部分槽。</li>
<li>使用 CRC16 算法来计算 key 所属的槽：crc16(key,keylen) &amp; 16383。</li>
<li>所有的 Redis 节点彼此互联，通过 <strong>PING-PONG</strong> 机制来进行节点间的心跳检测。</li>
<li>分片内采用<strong>一主多从保证高可用</strong>，并提供复制和故障恢复功能。在实际使用中，通常会将主从分布在不同<br>机房，避免机房出现故障导致整个分片出问题。</li>
<li>客户端与 Redis 节点直连，不需要中间代理层（proxy）。客户端不需要连接集群所有节点，连接集群中任<br>何一个可用节点即可。</li>
</ol>
<p>通过算法设计，计算出 key 应该保存的位置<br>所有的存储空间计划切割成<strong>16384</strong>份，每台主机保存一部分，每份代表的是一个存储空间，不是一个 key 的保存空间，将 key 按照计算出的结果放到对应的存储空间。</p>
<h4 id="集群内部通讯设计"><a href="#集群内部通讯设计" class="headerlink" title="集群内部通讯设计"></a>集群内部通讯设计</h4><p><img src="https://i.loli.net/2021/08/04/LwtvuDC3nEzQmjl.png" alt="image-20210804171410944"></p>
<p>Key—计算槽在哪？&#x3D;&#x3D;命中？未命中？最多两次</p>
<h4 id="如何保证集群在线扩容的安全性？（Redis-集群要增加分片，槽的迁移怎么保证无损）"><a href="#如何保证集群在线扩容的安全性？（Redis-集群要增加分片，槽的迁移怎么保证无损）" class="headerlink" title="如何保证集群在线扩容的安全性？（Redis 集群要增加分片，槽的迁移怎么保证无损）"></a>如何保证集群在线扩容的安全性？（Redis 集群要增加分片，槽的迁移怎么保证无损）</h4><p>集群已经对外提供服务，原来有 3 分片，准备新增 2 个分片，怎么在不下线的情况下，无损的从原有的 3 个<br>分片指派若干个槽给这 2 个分片？</p>
<p>Redis 使用了 <strong>ASK 错误</strong>来保证在线扩容的安全性。</p>
<p>在槽的迁移过程中若有客户端访问，依旧先访问源节点，源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</p>
<p>如果没找到，说明该键可能已经被迁移到目标节点了，源节点将向客户端返回一个 ASK 错误，该错误会指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常用命令</title>
    <url>/2021/08/05/a-Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h3 id="使⽤两种命令创建⼀个⽂件？"><a href="#使⽤两种命令创建⼀个⽂件？" class="headerlink" title="使⽤两种命令创建⼀个⽂件？"></a>使⽤两种命令创建⼀个⽂件？</h3><p>a. touch a.txt</p>
<p>b. vi a.txt</p>
<p>c. mkdir abc</p>
<p>d. cat &gt; a.txt 建⽴⼀⽂件，然后把接下来的键盘输⼊写⼊⽂件，直到按 Ctrl+D 为⽌.</p>
<h3 id="linux-常⽤命令有哪些？"><a href="#linux-常⽤命令有哪些？" class="headerlink" title="linux 常⽤命令有哪些？"></a>linux 常⽤命令有哪些？</h3><p>查找关闭端⼝进程 netstat -nlp | grep :3306 kill pid</p>
<p>删除⽂件 rm -rf</p>
<p>查找⽇志 cat xx.log | grep ‘xxx’ | more</p>
<p>解压 tar.gz tar -xzvf file.tar.gz</p>
<p>创建⽂件 touch filename cat &gt; filename</p>
<p>修改⽂件 vi</p>
<h3 id="怎么查看⼀个-java-线程的资源耗⽤？"><a href="#怎么查看⼀个-java-线程的资源耗⽤？" class="headerlink" title="怎么查看⼀个 java 线程的资源耗⽤？"></a>怎么查看⼀个 java 线程的资源耗⽤？</h3><p>linux 下，所有的 java 内部线程，其实都对应了⼀个进程 id，也就是说，linux 上的 jvm 将 java 程序中的线程映射为操作系统进 程。</p>
<p>1、jps -lvm 或者 ps -ef | grep java 查看当前机器上运⾏的 Java 应⽤进程</p>
<p>2、top -Hp pid 可以查看 Java 所有线程的资源耗⽤</p>
<p>3、printf “%x\n”pid 等到线程 ID 的 16 进制</p>
<p>4、jstack Java 应⽤进程 ID | grep 线程 ID 的 16 进制</p>
<h3 id="Load-过⾼的可能性有哪些？"><a href="#Load-过⾼的可能性有哪些？" class="headerlink" title="Load 过⾼的可能性有哪些？"></a>Load 过⾼的可能性有哪些？</h3><p>cpu load 的飙升，⼀⽅⾯可能和 full gc 的次数增⼤有关，⼀⽅⾯可能和死循环有关系</p>
<h3 id="如何在-log⽂件中搜索找出-error-的⽇志？"><a href="#如何在-log⽂件中搜索找出-error-的⽇志？" class="headerlink" title="如何在 log⽂件中搜索找出 error 的⽇志？"></a>如何在 log⽂件中搜索找出 error 的⽇志？</h3><p>cat xx.log | grep ‘error’</p>
<h3 id="发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件"><a href="#发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件" class="headerlink" title="发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件?"></a>发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件?</h3><p>find . -type f -size +100M | xargs du -h | sort -nr</p>
<h3 id="Java-服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）？"><a href="#Java-服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）？" class="headerlink" title="Java 服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）？"></a>Java 服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）？</h3><p>a. 业务⽇志相关：</p>
<p>i. less 或者 moreii. grep</p>
<p>iii. tail -f filename</p>
<p>ps:切忌 vim 直接打开⼤⽇志⽂件，因为会直接加载到内存的</p>
<p>b. 数据库相关：</p>
<p>i. 登录线上库，show processlist 查看数据库连接情况</p>
<p>c. jvm 相关：</p>
<p>i. jps 显示 java 进程</p>
<p>ii. jinfo 实时查看和调整 jvm 参数</p>
<p>iii. jstat 监控 jvm 各种运⾏状态信息；</p>
<p>iv. jstack(Stack Trace for Java)命令⽤于⽣成 JVM 进程当前时刻的线程的调⽤堆栈，可以⽤来定位线程间死锁、</p>
<p>锁等待、等待外部资源等</p>
<p>v. jmap(Memory Map for Java) 命令⽤于⽣成堆转储快照 dump⽂件，除了这种⽅式还可以通过- XX:HeapDumpOnOutOfMemoryError参数，可以在虚拟机发⽣OOM 的时候⾃动⽣成堆的 dump⽂件，或者 kill -3 命令发出进程退出信号”吓唬”⼀下虚拟机，也能拿到 dump⽂件。</p>
<p>d. oom 问题：</p>
<p>i. 配置了-XX:+HeapDumpOnOutOfMemoryError, 在发⽣OOM 的时候会在-XX:HeapDumpPath⽣成堆的 dump⽂件，结合 MAT，可以对 dump⽂件进⾏分析，查找出发⽣OOM 的原因。</p>
<p>ii. 另外⼿动 dump 堆快照，可以使⽤命令 jmap -dump:format&#x3D;b,file&#x3D;file_name pid 或者 kill -3 pid</p>
<p>e. 死锁：</p>
<p>i. jps -v</p>
<p>ii. jstack -l pid</p>
<p>f. 线程 block、线程数暴涨：</p>
<p>i. jstack -l pid |wc -l</p>
<p>ii. jstack -l pid |grep “BLOCKED”|wc -l</p>
<p>iii. jstack -l pid |grep “Waiting on condition”|wc -l</p>
<p>线程 block 问题⼀般是等待 io、等待⽹络、等待监视器锁等造成，可能会导致请求超时、造成造成线程数暴涨导致系统 502 等。</p>
<p>g. 服务器问题：</p>
<p>i. cpu：top</p>
<p>ii. 内存：</p>
<ol>
<li>free -m -c10 -s1：</li>
</ol>
<p>a. -m：以 MB 为单位显示，其他的有-k -g -b</p>
<p>b. -s: 间隔多少秒持续观察内存使⽤状况</p>
<p>c. -c:观察多少次</p>
<ol start="2">
<li>vmstat 1 10：1 表示每隔 1s 输出⼀次,10 表示输出 10 次</li>
</ol>
<p>a. r: 运⾏队列中进程数量，这个值也可以判断是否需要增加 CPU。（⻓期⼤于 1）</p>
<p>b. b: 等待 IO 的进程数量。</p>
<p>h. io：</p>
<p>i. iostat -m 1 10：</p>
<ol>
<li>-m：某些使⽤block 为单位的列强制使⽤MB 为单位</li>
<li>1 10：数据显示每隔 1 秒刷新⼀次，共显示 10 次</li>
</ol>
<p>i. ⽹络：</p>
<p>i. netstat -antp：</p>
<ol>
<li><p>-a (all)显示所有选项，默认不显示 LISTEN 相关</p>
</li>
<li><p>-t (tcp)仅显示 tcp 相关选项</p>
</li>
<li><p>-u (udp)仅显示 udp 相关选项</p>
</li>
<li><p>-n 拒绝显示别名，能显示数字的全部转化成数字。</p>
</li>
<li><p>-l 仅列出有在 Listen (监听) 的服服务状态</p>
</li>
<li><p>-p 显示建⽴相关链接的程序名</p>
</li>
<li><p>Java 常⽤问题排查⼯具及⽤法（top,iostat,vmstat,sar,tcpdump,jvisualvm,jmap,jconsole）</p>
</li>
<li><p>Thread dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程 id 关联）</p>
</li>
</ol>
<p>a. Thread Dump 能诊断的问题</p>
<p>i. 查找内存泄露，常⻅的是程序⾥load⼤量的数据到缓存；</p>
<p>ii. 发现死锁线程；</p>
<p>b. 如何抓取 Thread Dump 信息：</p>
<p>i. ⼀般当服务器挂起,崩溃或者性能底下时,就需要抓取服务器的线程堆栈(Thread Dump)⽤于后续的分析。 在实际 运⾏中，往往⼀次 dump 的信息，还不⾜以确认问题。为了反映线程状态的动态变化，需要接连多次做 threaddump，每次间隔 10-20s，建议⾄少产⽣三次 dump 信息，如果每次 dump 都指向同⼀个问题，我们才确 定问题的典型性。</p>
<p>ii. linux 命令获取：</p>
<p>ps –ef | grep java</p>
<p>kill -&lt; pid &gt;</p>
<p>iii. jdk⾃带⼯具获取：</p>
<p>jps 或 ps –ef|grepjava (获取 PID)</p>
<p>jstack [-l ]&lt; pid &gt;| tee -a jstack.log (获取 ThreadDump)</p>
<h3 id="如何查看-Java-应⽤的线程信息？"><a href="#如何查看-Java-应⽤的线程信息？" class="headerlink" title="如何查看 Java 应⽤的线程信息？"></a>如何查看 Java 应⽤的线程信息？</h3><p>通过 top 命令拿到线程的 pid 后使⽤jstack 命令</p>
]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>golang</title>
    <url>/2023/07/11/golang-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>语言学习</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC-概述</title>
    <url>/2021/07/06/a-RPC-%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>RPC（Remote Procedure Call）即<strong>远程过程调用</strong>。</p>
<p>为什么要 RPC  ？因为，两个不同的服务器上的服务提供的方法不在一个内存空间，所以，<strong>需要通过网络编程才能传递方法调用所需要的参数</strong>。并且，<strong>方法调用的结果也需要通过网络编程来接收</strong>。但是，如果我们自己手动网络编程来实现这个调用过程的话工作量是非常大的，因为，我们需要考虑底层传输方式（TCP 还是 UDP）、序列化方式等等方面。</p>
<p>RPC 能帮助我们做什么呢？ 简单来说，通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。</p>
<p>RPC 的出现就是为了让你<strong>调用远程方法像调用本地方法一样简单。</strong></p>
<h3 id="RPC-VS-HTTP"><a href="#RPC-VS-HTTP" class="headerlink" title="RPC VS HTTP"></a>RPC VS HTTP</h3><p>无论是微服务还是分布式服务（都是 SOA，都是面向服务编程），都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？</p>
<p>常见的远程调用方式有以下几种：</p>
<p><strong>RPC</strong>：Remote Produce Call 远程过程调用。<strong>自定义数据格式，基于原生 TCP 通信，速度快，效率高</strong>。早期的 webservice，现在热门的 dubbo，都是 RPC 的典型</p>
<p><strong>Http</strong>：http 其实是一种网络传输协议，基于 TCP，<strong>规定了数据传输的格式。现在客户端浏览器与服务端通信基本都是采用 Http 协议。也可以用来进行远程服务调用。缺点是消息封装臃肿。</strong></p>
<p>现在热门的 Rest 风格，就可以通过 http 协议来实现。</p>
<p>相同点：<strong>底层通讯都是基于网络编程</strong>，都可以实现远程调用，都可以实现服务调用服务。</p>
<p>不同点：<br>当使用 RPC 框架实现服务间调用的时候，要求服务提供方和服务消费方 都必须使用统一的 RPC 框架，跨操作系统在同一编程语言内使用<br><strong>优势：调用快、处理快</strong></p>
<p>http：<br><strong>当使用 http 进行服务间调用的时候，无需关注服务提供方使用的编程语言，也无需关注服务消费方使用的编程语言，服务提供方只需要提供 restful 风格的接口，服务消费方，按照 restful 的原则，请求服务，即可跨系统跨编程语言的远程调用框架</strong></p>
<p><strong>优势：通用性强</strong></p>
<h4 id="restful"><a href="#restful" class="headerlink" title="restful"></a>restful</h4><p>在 REST 样式的 Web 服务中，<strong>每个资源都有一个地址</strong>。资源本身都是方法调用的目标，方法列表对所有资源都是一样的。这些方法都是标准方法，包括 HTTP GET、POST、PUT、DELETE，还可能包括 HEAD 和 OPTIONS。</p>
<p>在 RPC 样式的架构中，<strong>关注点在于方法</strong>，而在 REST 样式的架构中，关注点在于资源 —— 将使用标准方法检索并操作信息片段（使用表示的形式）。资源表示形式在表示形式中使用超链接互联。</p>
<p>RESTful 架构是对 MVC 架构改进后所形成的一种架构，<strong>通过使用事先定义好的接口与不同的服务联系起来</strong>。在 RESTful 架构中，<strong>浏览器使用 POST，DELETE，PUT 和 GET 四种请求方式分别对指定的 URL 资源进行增删改查操作</strong>。因此，<strong>RESTful 是通过 URI 实现对资源的管理及访问，具有扩展性强、结构清晰的特点。</strong></p>
<p>RESTful 架构将服务器分成前端服务器和后端服务器两部分，前端服务器为用户提供无模型的视图；后端服务器为前端服务器提供接口。浏览器向前端服务器请求视图，通过视图中包含的 AJAX 函数发起接口请求获取模型。<br>项目开发引入 RESTful 架构，利于团队并行开发。在 RESTful 架构中，将多数 HTTP 请求转移到前端服务器上，降低服务器的负荷，使视图获取后端模型失败也能呈现。但 RESTful 架构却不适用于所有的项目，当项目比较小时无需使用 RESTful 架构，项目变得更加复杂。</p>
<p>（1）每一个 URI 代表一种资源；<br>（2）客户端和服务器之间，传递这种资源的某种表现层；<br>（3）客户端通过四个 HTTP 动词，对服务器端资源进行操作，实现”表现层状态转化”。</p>
<p><img src="https://i.loli.net/2021/08/08/rG74PqAnCzLyYQ6.png" alt="image-20210808143751929"></p>
<h4 id="RPC-中网络传输协议"><a href="#RPC-中网络传输协议" class="headerlink" title="RPC 中网络传输协议"></a>RPC 中网络传输协议</h4><p>基于 TCP 协议的 RPC 调用</p>
<p>由服务的调用方与服务的提供方建立 Socket 连接，并由服务的调用方通过 Socket 将需要调用的接口名称、方法名称和参数序列化后传递给服务的提供方，服务的提供方反序列化后再利用反射调用相关的方法。</p>
<p>将结果返回给服务的调用方，整个基于 TCP 协议的 RPC 调用大致如此。</p>
<p>但是在实例应用中则会进行一系列的封装，如 RMI 便是在 TCP 协议上传递可序列化的 Java 对象。</p>
<p>基于 HTTP 协议的 RPC 调用</p>
<p>该方法更像是访问网页一样，只是它的返回结果更加单一简单。</p>
<p>其大致流程为：由服务的调用者向服务的提供者发送请求，这种请求的方式可能是 GET、POST、PUT、DELETE 等中的一种，服务的提供者可能会根据不同的请求方式做出不同的处理，或者某个方法只允许某种请求方式。</p>
<p>而调用的具体方法则是根据 URL 进行方法调用，而方法所需要的参数可能是对服务调用方传输过去的 XML 数据或者 JSON 数据解析后的结果，返回 JOSN 或者 XML 的数据结果。</p>
<p>由于前有很多开源的 Web 服务器，如 Tomcat，所以其实现起来更加容易，就像做 Web 项目一样。</p>
<p>两种方式对比</p>
<p>基于 TCP 的协议实现的 RPC 调用，由于 TCP 协议处于协议栈的下层，<strong>能够更加灵活地对协议字段进行定制，</strong>减少网络开销，提高性能，实现更大的吞吐量和并发数。</p>
<p>但是需要更多关注底层复杂的细节，实现的代价更高。同时对不同平台，如安卓，iOS 等，需要重新开发出不同的工具包来进行请求发送和相应解析，工作量大，难以快速响应和满足用户需求。</p>
<p>基于 HTTP 协议实现的 RPC 则可以使用 JSON 和 XML 格式的请求或响应数据。</p>
<p>而 JSON 和 XML 作为通用的格式标准(使用 HTTP 协议也需要序列化和反序列化，不过这不是该协议下关心的内容，成熟的 Web 程序已经做好了序列化内容)，开源的解析工具已经相当成熟，在其上进行二次开发会非常便捷和简单。</p>
<p>但是由于 HTTP 协议是上层协议，发送包含同等内容的信息，使用 HTTP 协议传输所占用的字节数会比使用 TCP 协议传输所占用的字节数更高。</p>
<p>因此在同等网络下，通过 HTTP 协议传输相同内容，效率会比基于 TCP 协议的数据效率要低，信息传输所占用的时间也会更长，当然压缩数据，能够缩小这一差距。</p>
<h5 id="简单对比-RPC-和-Restful-API"><a href="#简单对比-RPC-和-Restful-API" class="headerlink" title="简单对比 RPC 和 Restful API"></a><strong>简单对比 RPC 和 Restful API</strong></h5><p>RESTful API 架构</p>
<p>REST 的几个特点为：资源、统一接口、URI 和无状态。</p>
<p>①资源</p>
<p>所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，就是一个具体的实在。</p>
<p>②统一接口</p>
<p>RESTful 架构风格规定，数据的元操作，即 CRUD(Create，Read，Update 和 Delete，即数据的增删查改)操作，分别对应于 HTTP 方法：GET 用来获取资源，POST 用来新建资源(也可以用于更新资源)，PUT 用来更新资源，DELETE 用来删除资源，这样就统一了数据操作的接口，仅通过 HTTP 方法，就可以完成对数据的所有增删查改工作。</p>
<p>③URL</p>
<p>可以用一个 URI(统一资源定位符)指向资源，即每个 URI 都对应一个特定的资源。</p>
<p>要获取这个资源，访问它的 URI 就可以，因此 URI 就成了每一个资源的地址或识别符。</p>
<p>④无状态</p>
<p>所谓无状态的，即所有的资源，都可以通过 URI 定位，而且这个定位与其他资源无关，也不会因为其他资源的变化而改变。有状态和无状态的区别，举个简单的例子说明一下。</p>
<p>如查询员工的工资，如果查询工资是需要登录系统，进入查询工资的页面，执行相关操作后，获取工资的多少，则这种情况是有状态的。</p>
<p>因为查询工资的每一步操作都依赖于前一步操作，只要前置操作不成功，后续操作就无法执行。</p>
<p>如果输入一个 URI 即可得到指定员工的工资，则这种情况是无状态的，因为获取工资不依赖于其他资源或状态。</p>
<p>且这种情况下，员工工资是一个资源，由一个 URI 与之对应，可以通过 HTTP 中的 GET 方法得到资源，这是典型的 RESTful 风格。</p>
<h5 id="RPC-和-Restful-API-对比"><a href="#RPC-和-Restful-API-对比" class="headerlink" title="RPC 和 Restful API 对比"></a>RPC 和 Restful API 对比</h5><p>面对对象不同：</p>
<p>RPC 更侧重于动作。</p>
<p>REST 的主体是资源。</p>
<p>RESTful 是<strong>面向资源</strong>的设计架构，但在系统中有很多对象不能抽象成资源，比如登录，修改密码等而 RPC 可以通过动作去操作资源。所以在操作的全面性上 RPC 大于 RESTful。</p>
<p>传输效率：</p>
<p>RPC 效率更高。RPC，使用自定义的 TCP 协议，可以让请求报文体积更小，或者使用 HTTP2 协议，也可以很好的减少报文的体积，提高传输效率。</p>
<p>复杂度：</p>
<p>RPC 实现复杂，流程繁琐。</p>
<p>REST 调用及测试都很方便。</p>
<p>RPC 实现需要实现编码，序列化，网络传输等。而 RESTful 不要关注这些，RESTful 实现更简单。</p>
<p>灵活性：</p>
<p>HTTP 相对更规范，更标准，更通用，无论哪种语言都支持 HTTP 协议。</p>
<p>RPC 可以实现跨语言调用，但整体灵活性不如 RESTful。</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>RPC 主要用于公司内部的服务调用，性能消耗低，传输效率高，实现复杂。</p>
<p>HTTP 主要用于对外的异构环境，浏览器接口调用，App 接口调用，第三方接口调用等。</p>
<p>RPC 使用场景(大型的网站，内部子系统较多、接口非常多的情况下适合使用 RPC)：</p>
<p>长链接。不必每次通信都要像 HTTP 一样去 3 次握手，减少了网络开销。</p>
<p>注册发布机制。RPC 框架一般都有注册中心，有丰富的监控管理;发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。</p>
<p>安全性，没有暴露资源操作。</p>
<p>微服务支持。就是最近流行的服务化架构、服务化治理，RPC 框架是一个强力的支撑。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><img src="https://i.loli.net/2021/08/06/KWeIP5wtzvQ8SVU.png" alt="image-20210806114259901"></p>
<p>client 调用远程方法-&gt; request 序列化 -&gt; 协议编码 -&gt; 网络传输-&gt; 服务端 -&gt; 解码-&gt;反序列化 request -&gt; 调用本地方法得到 response -&gt; 序列化 -&gt;编码-&gt;……..</p>
<h3 id="常见的-RPC-框架"><a href="#常见的-RPC-框架" class="headerlink" title="常见的 RPC 框架"></a>常见的 RPC 框架</h3><h4 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h4><p>是一款高性能、轻量级的开源 Java RPC 框架，它提供了三大核心能力：</p>
<p>面向接口的远程方法调用<br>智能容错和负载均衡<br>服务自动注册和发现。</p>
<p>简单来说 Dubbo 是一个分布式服务框架，致力于提供高性能和透明化的 RPC 远程服务调用方案，以及 SOA 服务治理方案。</p>
<p>Dubbo 是由阿里开源，后来加入了 Apache 。正式由于 Dubbo 的出现，才使得越来越多的公司开始使用以及接受分布式架构。</p>
<h4 id="Motan"><a href="#Motan" class="headerlink" title="Motan"></a>Motan</h4><p>motan 是 2016 年新浪微博开源的一款 RPC 框架，据说在新浪微博正支撑着千亿次调用。</p>
<p>很多人喜欢拿 motan 和 Dubbo 作比较，毕竟都是国内大公司开源的。笔者在查阅了很多资料，以及简单查看了其源码之后发现：motan 更像是一个精简版的 dubbo，可能是借鉴了 Dubbo 的思想，motan 的设计更加精简，功能更加纯粹。</p>
<p>不过，我不推荐你在实际项目中使用 motan。如果你要是公司实际使用的话，还是推荐 Dubbo ，其社区活跃度以及生态都要好很多。</p>
<h4 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h4><p>gRPC 是 Google 开源的一个高性能、通用的开源 RPC 框架。其由主要面向移动应用开发并基于 HTTP&#x2F;2 协议标准而设计，基于 ProtoBuf 序列化协议开发，并且支持众多开发语言。</p>
<p>通过 ProtoBuf 定义接口和数据类型还挺繁琐的，虽然 gRPC 确实很多亮点的地方，但是我还是选择 Dubbo。</p>
<h4 id="Thrift"><a href="#Thrift" class="headerlink" title="Thrift"></a>Thrift</h4><p>Apache Thrift 是 Facebook 开源的跨语言的 RPC 通信框架，目前已经捐献给 Apache 基金会管理，由于其跨语言特性和出色的性能，在很多互联网公司得到应用，有能力的公司甚至会基于 thrift 研发一套分布式服务框架，增加诸如服务注册、服务发现等功能。</p>
<p>Thrift 支持多种不同的编程语言，包括 C++、Java、Python、PHP、Ruby 等（相比于 gRPC 支持的语言更多 ）。</p>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p><strong>gRPC 和 Thrift</strong> 虽然支持跨语言的 RPC 调用，但是因为它们只提供了最基本的 RPC 框架功能，缺乏一系列配套的服务化组件和服务治理功能的支撑。</p>
<p>Dubbo 不论是从功能完善程度、生态系统还是社区活跃度来说都是最优秀的。最重要的是其在国内有很多成功的案例比如当当网、滴滴等等。下图展示了 Dubbo 的生态系统。</p>
<p>但是，Dubbo 和 Motan 主要是给 Java 语言使用。虽然，Dubbo 和 Motan 目前也能兼容部分语言，但是不太推荐。如果需要跨语言调用的话，可以考虑一下 Thrift 和 gRPC。</p>
<h3 id="自己实现-RPC-框架的思路"><a href="#自己实现-RPC-框架的思路" class="headerlink" title="自己实现 RPC 框架的思路"></a>自己实现 RPC 框架的思路</h3><p><img src="https://i.loli.net/2021/08/06/aG7gWErNb9iymIU.png" alt="image-20210806144123153"></p>
<h4 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a><strong>注册中心</strong></h4><h5 id="zookeeper-作为注册中心的问题？"><a href="#zookeeper-作为注册中心的问题？" class="headerlink" title="zookeeper 作为注册中心的问题？"></a>zookeeper 作为注册中心的问题？</h5><p>在实践中，注册中心不能因为自身的任何原因<strong>破坏服务之间本身的可连通性</strong><br>注册中心需要的是 AP，而 Zookeeper 是 CP</p>
<p>CAP ：一致性、可用性、分区容忍性<br>一致性：是指在同一时刻，分布式系统中的所有数据备份为相同值<br>可用性：指集群中的某一个节点故障宕机后，集群还能响应客户端请求。<br>分区容忍性：当分布式系统中因为一些原因导致无法通信而分成多个分区，系统还能正常对外服务。</p>
<p>在 CAP 模型中，<strong>zookeeper 是 CP，意味着面对网络分区时，为了保持一致性，他是不可用的。</strong></p>
<p>因为 zookeeper 是一个<strong>分布式协调系统</strong>，如果使用最终一致性（AP）的话，将是一个糟糕的设计，他的核心算法是 <strong>ZAb，所有设计都是为了一致性。</strong></p>
<p>对于协调系统，这是非常正确的，<strong>但是对于服务发现，可用性是第一位的，例如发生了短暂的网络分区时，即使拿到的信息是有瑕疵的、旧的，也好过完全不可用。</strong></p>
<p>注册中心本质上的功能就是一个<strong>查询函数：</strong></p>
<p>ServiceList &#x3D; F(service-name)<br>以 service-name 为查询参数，得到对应的可用的服务端点列表 endpoints(ip:port)。</p>
<p>1，我们假设<strong>不同的客户端得到的服务列表数据是不一致的，看看有什么后果。</strong></p>
<p>现在有 2 个服务调用者 service1 和 service2，从注册中心获取 serviceB 的服务列表，但取得的数据不一致。</p>
<p>s1 &#x3D; { ip1,ip2 … ip9 }<br>s2 &#x3D; { ip2,ip3 … ip10 }<br>这个不一致带来的影响是什么？</p>
<p><strong>就是 serviceB 各个实例的流量不均衡。</strong></p>
<p>这个不均衡有什么严重影响吗？并没有，完全可以接受，而且，又不会一直这样。</p>
<p>所以，注册中心使用最终一致性模型（AP）完全可以的。</p>
<p><strong>2，现在我们看一下 CP 带来的不可用的影响。</strong></p>
<p>3 个机房部署 5 个 ZK 节点。</p>
<p>现在机房 3 出现网络分区了，形成了孤岛。</p>
<p>发生网络分区时，各个区都会开始选举 leader，那么节点数少的那个分区将会停止运行，也就是 ZK5 不可用了。</p>
<p>这时，serviceA 就访问不了机房 1 和机房 2 的 serviceB 了，而且连自己所在机房的 serviceB 也访问不了了。</p>
<p>不能访问其他机房还可以理解，不能访问自己机房的服务就理解不了了，本机房内部的网络好好的，不能因为你注册中心有问题就不能访问了吧。</p>
<p><strong>因为注册中心为了保障数据一致性而放弃了可用性，导致同机房服务之间无法调用，这个是接受不了的。</strong></p>
<p><strong>所以，注册中心的可用性比数据强一致性更加重要，所以注册中心应该是偏向 AP，而不是 CP。</strong></p>
<p><strong>zookeeper 的性能不适合注册中心</strong></p>
<p>在大规模服务集群场景中，zookeeper 的性能也是瓶颈。</p>
<p>zookeeper 所有的写操作都是 leader 处理的，在大规模服务注册写请求时，压力巨大，而且 leader 是单点，无法水平扩展。</p>
<p>还有所有服务于 zookeeper 的长连接也是很重的负担。</p>
<p>zookeeper 对每一个写请求，都会写一个事务日志，同时会定期将内存数据镜像 dump 到磁盘，保持数据一致性和持久性。这个动作会降低性能，而且对于注册中心来讲，是不需要的。</p>
<p><strong>小结</strong></p>
<p>从 CP 模型上来讲，zookeeper 并不适合注册中心高可用的需要。</p>
<p>从性能上来讲，zookeeper 也无法满足注册中心大规模且频繁注册写的场景。</p>
<p><strong>zookeeper 的特长是做分布式协调服务，</strong>例如 kafka、hbase、flink、hadoop 等大项目都在用 zookeeper。</p>
<h5 id="redis-注册中心"><a href="#redis-注册中心" class="headerlink" title="redis 注册中心"></a>redis 注册中心</h5><p>redis 作为 dubbo 的注册中心，实现的功能跟 zk 相同，但是内部的实现机制大相径庭，因为 zk 有临时节点，服务端在 zk 中创建临时节点会一直保持连接，如果服务器出现崩溃，自动断连，而 redis 则要靠主服务器 进行定时轮询</p>
<h5 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class ZkServiceDiscoveryImpl implements ServiceDiscovery &#123;<br>    private final LoadBalance loadBalance;//负载均衡<br><br>    public ZkServiceDiscoveryImpl() &#123;<br>        this.loadBalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(&quot;loadBalance&quot;);<br>    &#125;<br><br>    @Override<br>    public InetSocketAddress lookupService(RpcRequest rpcRequest) &#123;<br>    	//服务名<br>        String rpcServiceName = rpcRequest.getRpcServiceName();<br>        CuratorFramework zkClient = CuratorUtils.getZkClient();<br>        //找子节点<br>        List&lt;String&gt; serviceUrlList = CuratorUtils.getChildrenNodes(zkClient, rpcServiceName);<br>        //找不到，就抛出not found<br>        if (serviceUrlList == null || serviceUrlList.size() == 0) &#123;<br>            throw new RpcException(RpcErrorMessageEnum.SERVICE_CAN_NOT_BE_FOUND, rpcServiceName);<br>        &#125;<br>        // load balancing<br>        String targetServiceUrl = loadBalance.selectServiceAddress(serviceUrlList, rpcRequest);<br>        <br>        String[] socketAddressArray = targetServiceUrl.split(&quot;:&quot;);<br>        String host = socketAddressArray[0];<br>        int port = Integer.parseInt(socketAddressArray[1]);<br>        return new InetSocketAddress(host, port);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure>

<h5 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class ZkServiceRegistryImpl implements ServiceRegistry &#123;<br>    @Override<br>    public void registerService(String rpcServiceName, InetSocketAddress inetSocketAddress) &#123;<br>        String servicePath = CuratorUtils.ZK_REGISTER_ROOT_PATH + &quot;/&quot; + rpcServiceName + inetSocketAddress.toString();<br>        CuratorFramework zkClient = CuratorUtils.getZkClient();<br>        //创建一个持久节点<br>        CuratorUtils.createPersistentNode(zkClient, servicePath);<br>    &#125;<br><br></code></pre></td></tr></table></figure>

<p>推荐使用 Zookeeper 作为注册中心。当然了，你也可以使用 Nacos ，甚至是 Redis。</p>
<p>ZooKeeper 为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如数据发布&#x2F;订阅、负载均衡、命名服务、分布式协调&#x2F;通知、集群管理、Master 选举、分布式锁和分布式队列等功能。并且<strong>，ZooKeeper 将数据保存在内存中，性能是非常棒的</strong>。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景）。</p>
<p>当然了，如果你想通过文件来存储服务地址的话也是没问题的，不过性能会比较差。</p>
<p>注册中心负责<strong>服务地址的注册与查找，相当于目录服务</strong>。 <strong>服务端启动的时候将服务名称及其对应的地址(ip+port)注册到注册中心</strong>，服务消费端根据服务名称找到对应的服务地址。有了服务地址之后，服务消费端就可以通过网络请求服务端了。</p>
<h5 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h5><p><strong>查看常用命令(help 命令)</strong></p>
<p>通过 help 命令查看 ZooKeeper 常用命令</p>
<p><strong>创建节点(create 命令)</strong></p>
<p>通过 create 命令在根目录创建了 node1 节点，与它关联的字符串是”node1”</p>
<p>create &#x2F;node1 “node1”</p>
<p><strong>更新节点数据内容(set 命令)</strong></p>
<p> set &#x2F;node1 “set node1”</p>
<p><strong>获取节点的数据(get 命令)</strong></p>
<p>get 命令可以获取指定节点的数据内容和节点的状态</p>
<p><strong>查看某个目录下的子节点(ls 命令)</strong></p>
<p>通过 ls 命令查看根目录下的节点</p>
<p>ls &#x2F;</p>
<p>通过 ls 命令查看 node1 目录下的节点</p>
<p>ls &#x2F;node1</p>
<p><strong>查看节点状态(stat 命令)</strong></p>
<p>通过 stat 命令查看节点状态</p>
<p>stat &#x2F;node1<br>比如 cversion、aclVersion、numChildren 等等</p>
<p><strong>查看节点信息和状态(ls2 命令)</strong></p>
<p>ls2 命令更像是  ls 命令和 stat 命令的结合。 ls2 命令返回的信息包括 2 部分：</p>
<p>子节点列表<br>当前节点的 stat 信息。</p>
<p><strong>删除节点(delete 命令)</strong></p>
<p>这个命令很简单，但是需要注意的一点是如果你要删除某一个节点，那么这个节点必须无子节点才行。</p>
<h5 id="连接-zookeeper"><a href="#连接-zookeeper" class="headerlink" title="连接 zookeeper"></a>连接 zookeeper</h5><p>通过 CuratorFrameworkFactory 创建 CuratorFramework 对象，然后再调用  CuratorFramework 对象的 start() 方法即可</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">CuratorFramework zkClient = CuratorFrameworkFactory.builder()<br>    // the server to connect to (can be a server list)<br>    .connectString(&quot;127.0.0.1:2181&quot;)<br>    .retryPolicy(retryPolicy)<br>    .build();<br>zkClient.start();<br></code></pre></td></tr></table></figure>

<p>baseSleepTimeMs：重试之间等待的初始时间<br>maxRetries ：最大重试次数<br>connectString ：要连接的服务器列表<br>retryPolicy ：重试策略</p>
<h5 id="zookeeper-常见概念"><a href="#zookeeper-常见概念" class="headerlink" title="zookeeper 常见概念"></a>zookeeper 常见概念</h5><h6 id="ZooKeeper-典型应用场景"><a href="#ZooKeeper-典型应用场景" class="headerlink" title="ZooKeeper 典型应用场景"></a><strong>ZooKeeper 典型应用场景</strong></h6><p>分布式锁 ： 通过创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。<br>命名服务 ：可以通过 ZooKeeper 的顺序节点生成全局唯一 ID<br>数据发布&#x2F;订阅 ：通过 Watcher 机制 可以很方便地实现数据发布&#x2F;订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。</p>
<h6 id="Data-model（数据模型）"><a href="#Data-model（数据模型）" class="headerlink" title="Data model（数据模型）"></a>Data model（数据模型）</h6><p>ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，这些数据可以是数字、字符串或者是二级制序列。并且。每个节点还可以拥有 N 个子节点，最上层是根节点以“&#x2F;”来代表。每个数据节点在 ZooKeeper 中被称为 znode，它是 ZooKeeper 中数据的最小单元。并且，每个 znode 都一个唯一的路径标识。</p>
<p>ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以不要放比较大的数据在 znode 上，ZooKeeper 给出的上限是每个结点的数据大小最大是 1M。</p>
<p><img src="https://i.loli.net/2021/08/06/U4PZ357vfcK2QDT.png" alt="image-20210806184839468"></p>
<h6 id="znode-4-种类型"><a href="#znode-4-种类型" class="headerlink" title="znode 4 种类型"></a>znode 4 种类型</h6><p><strong>持久（PERSISTENT）节点</strong> ：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。<br><strong>临时（EPHEMERAL）节点</strong> ：临时节点的生命周期是与 客户端会话（session） 绑定的，会话消失则节点消失 。并且，临时节点只能做叶子节点 ，不能创建子节点。<br><strong>持久顺序（PERSISTENT_SEQUENTIAL）节点</strong> ：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 &#x2F;node1&#x2F;app0000000001 、&#x2F;node1&#x2F;app0000000002 。<br><strong>临时顺序（EPHEMERAL_SEQUENTIAL）节点</strong> ：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。</p>
<p>每个 znode 由 2 部分组成:</p>
<p>stat ：状态信息<br>data ： 节点存放的数据的具体内容</p>
<p><img src="https://i.loli.net/2021/08/06/CAHXpy2Qitw8M1h.png" alt="image-20210806184946339"></p>
<h6 id="ACL（权限控制）"><a href="#ACL（权限控制）" class="headerlink" title="ACL（权限控制）"></a>ACL（权限控制）</h6><p>ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。</p>
<p>对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：</p>
<p>CREATE : 能创建子节点<br>READ ：能获取节点数据和列出其子节点<br>WRITE : 能设置&#x2F;更新节点数据<br>DELETE : 能删除子节点<br>ADMIN : 能设置节点 ACL 的权限</p>
<h6 id="Watcher（事件监听器）"><a href="#Watcher（事件监听器）" class="headerlink" title="Watcher（事件监听器）"></a>Watcher（事件监听器）</h6><p>Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper 允许用户在<strong>指定节点上注册一些 Watcher</strong>，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。</p>
<p><img src="https://i.loli.net/2021/08/06/cYBTq4IkzRsagZF.png" alt="image-20210806185101550"></p>
<h6 id="ZooKeeper-集群"><a href="#ZooKeeper-集群" class="headerlink" title="ZooKeeper 集群"></a>ZooKeeper 集群</h6><p>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。ZooKeeper 官方提供的架构图就是一个 ZooKeeper 集群整体对外提供服务。</p>
<p>集群间通过 <strong>ZAB 协议（ZooKeeper Atomic Broadcast）</strong>来保持数据的一致性。</p>
<p>ZooKeeper 中没有选择传统的 Master&#x2F;Slave 概念，而是引入了 <strong>Leader、Follower 和 Observer</strong> 三种角色。</p>
<p><img src="https://i.loli.net/2021/08/06/xSmqUpYf78lrvHk.png" alt="image-20210806185249694"></p>
<p>ZooKeeper 集群中的所有机器通过一个 Leader 选举过程 来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，<strong>Follower 和 Observer 都只能提供读服务</strong>。Follower 和 Observer 唯一的区别在于 <strong>Observer 机器不参与 Leader 的选举过程</strong>，<strong>也不参与写操作的“过半写成功”策略，</strong>因此 <strong>Observer 机器可以在不影响写性能的情况下提升集群的读性能。</strong></p>
<p>当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器。</p>
<p><strong>Leader election（选举阶段）</strong>：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。<br><strong>Discovery（发现阶段）</strong> ：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。<br><strong>Synchronization（同步阶段）</strong> :同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。<br><strong>Broadcast（广播阶段）</strong> :到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</p>
<h6 id="ZooKeeper-集群为啥最好奇数台？"><a href="#ZooKeeper-集群为啥最好奇数台？" class="headerlink" title="ZooKeeper 集群为啥最好奇数台？"></a>ZooKeeper 集群为啥最好奇数台？</h6><p>ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。假如我们的集群中有 n 台 ZooKeeper 服务器，那么也就是剩下的服务数必须大于 n&#x2F;2。先说一下结论，2n 和 2n-1 的容忍度是一样的，都是 n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。</p>
<p>比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。 假如我们有 5 台，那么最大允许宕掉 2 台 ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。</p>
<h6 id="何为集群脑裂？"><a href="#何为集群脑裂？" class="headerlink" title="何为集群脑裂？"></a>何为集群脑裂？</h6><p>对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候子集群各自选主导致“脑裂”的情况。</p>
<p>举例说明：比如现在有一个由 6 台服务器所组成的一个集群，部署在了 2 个机房，每个机房 3 台。正常情况下只有 1 个 leader，但是当两个机房中间网络断开的时候，每个机房的 3 台服务器都会认为另一个机房的 3 台服务器下线，而选出自己的 leader 并对外提供服务。若没有过半机制，当网络恢复的时候会发现有 2 个 leader。仿佛是 1 个大脑（leader）分散成了 2 个大脑，这就发生了脑裂现象。脑裂期间 2 个大脑都可能对外提供了服务，这将会带来数据一致性等问题。</p>
<h6 id="ZAB-协议介绍"><a href="#ZAB-协议介绍" class="headerlink" title="ZAB 协议介绍"></a>ZAB 协议介绍</h6><p>ZAB（<strong>ZooKeeper Atomic Broadcast 原子广播</strong>） 协议是为分布式协调服务 ZooKeeper 专门设计的一种<strong>支持崩溃恢复的原子广播协议</strong>。 在 ZooKeeper 中，主要依赖 <strong>ZAB 协议来实现分布式数据一致性</strong>，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</p>
<p>ZAB 协议包括<strong>两种基本的模式</strong>，分别是</p>
<p><strong>崩溃恢复 ：</strong>当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中<strong>已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。</strong>其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致。</p>
<p><strong>消息广播 ：</strong>当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入<strong>消息广播模式</strong>了。 当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。</p>
<h5 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h5><p>分布式系统的最大难点，就是各个节点的状态如何保持一致。CAP 理论是在设计分布式系统的过程中，处理数据一致性问题时必须考虑的理论。</p>
<p>CAP 即：</p>
<p>Consistency（一致性）<br>Availability（可用性）<br>Partition tolerance（分区容忍性）</p>
<p>①一致性：对于客户端的每次读操作，要么读到的是最新的数据，要么读取失败。换句话说，一致性是站在分布式系统的角度，对访问本系统的客户端的一种承诺：要么我给您返回一个错误，要么我给你返回绝对一致的最新数据，不难看出，其强调的是<strong>数据正确</strong>。</p>
<p>②可用性：任何客户端的请求都<strong>能得到响应数据，不会出现响应错误</strong>。换句话说，可用性是站在分布式系统的角度，对访问本系统的客户的另一种承诺：我一定会给您返回数据，不会给你返回错误，但不保证数据最新，强调的是不出错。</p>
<p>③分区容忍性：由于分布式系统通过网络进行通信，网络是不可靠的。当任意数量的消息丢失或延迟到达时，系统仍会继续提供服务，不会挂掉。换句话说，分区容忍性是站在分布式系统的角度，对访问本系统的客户端的再一种承诺：<strong>我会一直运行，不管我的内部出现何种数据同步问题，强调的是不挂掉。</strong></p>
<p>假设 N1 和 N2 之间通信的时候网络突然出现故障，有用户向 N1 发送数据更新请求，那 N1 中的数据 DB0 将被更新为 DB1，由于网络是断开的，N2 中的数据库仍旧是 DB0；</p>
<p>如果这个时候，有用户向 N2 发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据 DB1，怎么办呢？有二种选择，第一，牺牲数据一致性，响应旧的数据 DB0 给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作完成之后，再给用户响应最新的数据 DB1。</p>
<h5 id="raft-协议"><a href="#raft-协议" class="headerlink" title="raft 协议"></a>raft 协议</h5><p>有三个节点：a，b，c。客户端对这个由 3 个节点组成的数据库集群进行操作时的值一致性如何保证，就是分布式一致性问题。Raft 就是一种实现了<strong>分布式一致性的协议</strong>（还有其他一些一致性算法，例如：ZAB、PAXOS 等）</p>
<h5 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h5><p>为了<strong>保证一个方法或属性在高并发情况下的同一时间只能被同一个线程执行</strong>，在传统单体应用单机部署的情况下，可以使用并发处理相关的功能进行互斥控制。但是，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的应用并不能提供分布式锁的能力。为了解决这个问题就需要一种跨机器的互斥机制来控制共享资源的访问。</p>
<h6 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h6><p>基于数据库的实现方式的核心思想是：在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。</p>
<p><strong>问题：</strong></p>
<p>1、这把锁强<strong>依赖数据库的可用性</strong>，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</p>
<p>2、这把<strong>锁没有失效时间，一旦解锁操作失败</strong>，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</p>
<p>3、这把锁<strong>只能是非阻塞的</strong>，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</p>
<p>4、这把锁是<strong>非重入的</strong>，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</p>
<p>解决：</p>
<p>数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。<br>没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。<br>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。<br>非重入的？在数据库表中加个字段，<strong>记录当前获得锁的机器的主机信息和线程信息</strong>，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</p>
<p><strong>基于数据库排它锁</strong></p>
<p>在查询语句后面增加 for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB 引擎在加锁的时候，<strong>只有通过索引进行检索的时候才会使用行级锁</strong>，否则会使用表级锁。这里我们希望使用行级锁，就要给<strong>method_name 添加索引</strong>，值得注意的是，这个索引一定要创建成<strong>唯一索引</strong>，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。</p>
<p>当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。</p>
<p>我们可以认为<strong>获得排它锁的线程即可获得分布式锁</strong>，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过**connection.commit()**操作来释放锁。</p>
<p>这种方法可以有效的解决上面提到的<strong>无法释放锁和阻塞锁</strong>的问题。</p>
<p>阻塞锁？ for update 语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。<br>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。</p>
<p><strong>问题？</strong></p>
<p>MySql 会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。</p>
<p>还有一个问题，就是我们要使用排他锁来进行分布式锁的 lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆。</p>
<h6 id="基于-redis"><a href="#基于-redis" class="headerlink" title="基于 redis"></a>基于 redis</h6><p>可以使用缓存来代替数据库来实现分布式锁，这个可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，redis 的 setnx 方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。</p>
<p>（1）SETNX<br>SETNX key val：当且仅当 key 不存在时，set 一个 key 为 val 的字符串，返回 1；若 key 存在，则什么都不做，返回 0。<br>（2）expire<br>expire key timeout：为 key 设置一个超时时间，单位为 second，超过这个时间锁会自动释放，避免死锁。<br>（3）delete<br>delete key：删除 key</p>
<p>实现思想：<br>（1）获取锁的时候，使用 setnx 加锁，并使用 expire 命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的<strong>value 值为一个随机生成的 UUID，通过此在释放锁的时候进行判断。</strong><br>（2）获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。<br>（3）释放锁的时候，通过 UUID 判断是不是该锁，若是该锁，<strong>则执行 delete 进行锁释放。</strong></p>
<p>设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。</p>
<h6 id="基于-zookeeper"><a href="#基于-zookeeper" class="headerlink" title="基于 zookeeper"></a>基于 zookeeper</h6><p>基于 zookeeper 临时有序节点可以实现的分布式锁。</p>
<p>大致思想即为：每个客户端对某个方法加锁时，在 zookeeper 上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。</p>
<p><strong>锁无法释放？</strong>使用 Zookeeper 可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在 ZK 中创建一个临时节点，<strong>一旦客户端获取到锁之后突然挂掉（Session 连接断开）</strong>，<strong>那么这个临时节点就会自动删除掉。</strong>其他客户端就可以再次获得锁。</p>
<p><strong>非阻塞锁？</strong>使用 Zookeeper 可以实现阻塞的锁，客户端可以通过在 ZK 中创建顺序节点，<strong>并且在节点上绑定监听器，一旦节点有变化</strong>，Zookeeper 会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。</p>
<p><strong>不可重入？</strong>使用 Zookeeper 也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。</p>
<p><strong>单点问题？</strong>使用 Zookeeper 可以有效的解决单点问题，ZK 是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。</p>
<p>其实，使用 Zookeeper 也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端和 ZK 集群的 session 连接断了，那么 ZK 以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。</p>
<p>这个问题不常见是因为 zk 有重试机制，<strong>一旦 zk 集群检测不到客户端的心跳，就会重试</strong>，Curator 客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。</p>
<p><strong>从性能角度（从高到低）</strong><br><strong>缓存 &gt; Zookeeper &gt;&#x3D; 数据库</strong></p>
<p><strong>从可靠性角度（从高到低）</strong><br><strong>Zookeeper &gt; 缓存 &gt; 数据库</strong></p>
<h4 id="网络传输"><a href="#网络传输" class="headerlink" title="网络传输"></a>网络传输</h4><h5 id="网络传输实体类"><a href="#网络传输实体类" class="headerlink" title="网络传输实体类"></a>网络传输实体类</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class RpcRequest implements Serializable &#123;<br>    private static final long serialVersionUID = 1905122041950251207L;//序列化版本控制<br>    private String requestId;<br>    private String interfaceName;<br>    private String methodName;<br>    private Object[] parameters;<br>    private Class&lt;?&gt;[] paramTypes;<br>    private String version;<br>    private String group;//处理一个接口有多个实现类的情况<br>    //服务名称：接口名加对应的实现方法。<br>    public String getRpcServiceName() &#123;<br>        return this.getInterfaceName() + this.getGroup() + this.getVersion();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class RpcResponse&lt;T&gt; implements Serializable &#123;<br>    private static final long serialVersionUID = 715745410605631233L;<br>    private String requestId;//唯一标识每一个请求<br>    private Integer code;//返回数字<br>    private String message;//返回的string<br>    private T data;<br><br>    public static &lt;T&gt; RpcResponse&lt;T&gt; success(T data, String requestId) &#123;<br>        RpcResponse&lt;T&gt; response = new RpcResponse&lt;&gt;();<br>        response.setCode(RpcResponseCodeEnum.SUCCESS.getCode());<br>        response.setMessage(RpcResponseCodeEnum.SUCCESS.getMessage());<br>        response.setRequestId(requestId);<br>        if (null != data) &#123;<br>            response.setData(data);<br>        &#125;<br>        return response;<br>    &#125;<br><br>    public static &lt;T&gt; RpcResponse&lt;T&gt; fail(RpcResponseCodeEnum rpcResponseCodeEnum) &#123;<br>        RpcResponse&lt;T&gt; response = new RpcResponse&lt;&gt;();<br>        response.setCode(rpcResponseCodeEnum.getCode());<br>        response.setMessage(rpcResponseCodeEnum.getMessage());<br>        return response;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure>

<h5 id="netty-网络客户传输"><a href="#netty-网络客户传输" class="headerlink" title="netty 网络客户传输"></a>netty 网络客户传输</h5><p><strong>NettyClient.java</strong></p>
<p>doConnect() :用于连接服务端（目标方法所在的服务器）并返回对应的 Channel。当我们知道了服务端的地址之后，我们就可以通过 NettyClient 成功连接服务端了。（有了 Channel 之后就能发送数据到服务端了）</p>
<p>sendRpcRequest() : 用于传输 rpc 请求(RpcRequest) 到服务端。</p>
<p><strong>UnprocessedRequests.java</strong></p>
<p>用于存放未被服务端处理的请求（建议限制 map 容器大小，避免未处理请求过多 OOM)。</p>
<p><strong>NettyClientHandler</strong></p>
<p>自定义客户端 ChannelHandler 用于处理服务器发送的数据。</p>
<p>从代码中，可以看出当 rpc 请求被成功处理（客户端收到服务端的执行结果）之后，我们调用了 <strong>unprocessedRequests.complete(rpcResponse) 方法</strong>，这样的话，你只需要通过下面的方式就能成功接收到客户端返回的结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">CompletableFuture&lt;RpcResponse&gt; completableFuture = (CompletableFuture&lt;RpcResponse&gt;) clientTransport.sendRpcRequest(rpcRequest);<br>rpcResponse = completableFuture.get();<br></code></pre></td></tr></table></figure>

<p><strong>ChannelProvider.java</strong></p>
<p>用于存放 Channel（Channel 用于在服务端和客户端之间传输数据）。</p>
<p><strong>NettyRpcServer.java</strong></p>
<p>Netty 服务端。并监听客户端的连接。</p>
<p><strong>NettyServerHandler.java</strong></p>
<p>自定义服务端 ChannelHandler 用于处理客户端发送的数据。</p>
<p>当客端发的 rpc 请求(RpcRequest) 来了之后，服务端就会处理 rpc 请求(RpcRequest) ，处理完之后就把得到 rpc 相应(RpcResponse)传输给客户端。</p>
<p>既然我们要调用远程的方法，就要发送网络请求来传递目标类和方法的信息以及方法的参数等数据到服务提供端。</p>
<p>网络传输具体实现你可以使用 Socket （ Java 中最原始、最基础的网络通信方式。但是，Socket 是阻塞 IO、性能低并且功能单一）。</p>
<p>你也可以使用同步非阻塞的 I&#x2F;O 模型 NIO ，但是用它来进行网络编程真的太麻烦了。不过没关系，你可以使用基于 NIO 的网络编程框架 Netty ，它将是你最好的选择。</p>
<p>Netty 是一个基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。<br>它极大地简化并简化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。<br>支持多种协议如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。</p>
<h5 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h5><p><strong>服务器端：</strong></p>
<p>创建 <strong>ServerSocket 对象</strong>并且绑定地址（ip）和端口号(port)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">server.bind(new InetSocketAddress(host, port))<br></code></pre></td></tr></table></figure>

<p>通过 <strong>accept()方法监听</strong>客户端请求<br>连接建立后，通过输入流读取客户端发送的请求信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">Message message = (Message) objectInputStream.readObject();<br></code></pre></td></tr></table></figure>

<p>通过输出流向客户端发送响应信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">objectOutputStream.writeObject(message);<br></code></pre></td></tr></table></figure>

<p>关闭相关资源</p>
<h6 id="管理多个客户端"><a href="#管理多个客户端" class="headerlink" title="管理多个客户端"></a>管理多个客户端</h6><p><img src="https://i.loli.net/2021/08/06/1bNwXIjGmecq7K9.png" alt="image-20210806153434387"></p>
<p> 比较简单并且实际的改进方法就是使用<strong>线程池</strong>。线程池还可以让线程的创建和回收成本相对较低，并且我们可以指定线程池的可创建线程的最大数量，这样就不会导致线程创建过多，机器资源被不合理消耗。</p>
<p><strong>客户端：</strong></p>
<p>创建 Socket 对象并且连接指定的服务器的地址（ip）和端口号(port)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">socket.connect(inetSocketAddress)<br></code></pre></td></tr></table></figure>

<p>连接建立后，通过输出流向服务器端发送请求信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">objectOutputStream.writeObject(message)<br></code></pre></td></tr></table></figure>

<p>通过输入流获取服务器响应的信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">return objectInputStream.readObject();<br></code></pre></td></tr></table></figure>

<p>关闭相关资源</p>
<h5 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h5><p>Netty 是一个基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。</p>
<p>它极大地简化并简化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。</p>
<p>支持多种协议如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。</p>
<p>Netty 成功地找到了一种在不妥协可维护性和性能的情况下实现易于开发，性能，稳定性和灵活性的方法。</p>
<p>这个应该是老铁们最关心的一个问题了，凭借自己的了解，简单说一下，理论上 NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做网络通信 :</p>
<h6 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h6><p>作为 RPC 框架的网络通信工具 </p>
<p>实现一个自己的 HTTP 服务器 </p>
<p>实现一个即时通讯系统</p>
<p>消息推送系统<br>……</p>
<p>Dubbo、RocketMQ、Elasticsearch、gRPC 等等都用到了 Netty。</p>
<h6 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h6><p>客户端中主要有一个用于向服务端发送消息的 **sendMessage()**方法，通过这个方法你可以将消息也就是 RpcRequest 对象发送到服务端，并且你可以同步获取到服务端返回的结果也就是 RpcResponse 对象。 </p>
<p><strong>sendMessage()方法分析：</strong></p>
<p>首先初始化了一个 Bootstrap</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain"> @Override<br>protected void initChannel(SocketChannel ch) &#123;<br>/*<br>自定义序列化编解码器<br>*/<br>// RpcResponse -&gt; ByteBuf<br>ch.pipeline().addLast(new NettyKryoDecoder(kryoSerializer, RpcResponse.class));<br>// ByteBuf -&gt; RpcRequest<br>ch.pipeline().addLast(new NettyKryoEncoder(kryoSerializer, RpcRequest.class));<br>ch.pipeline().addLast(new NettyClientHandler());<br>&#125;<br><br></code></pre></td></tr></table></figure>

<p>通过 Bootstrap 对象连接服务端</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">ChannelFuture f = b.connect(host, port).sync();<br>Channel futureChannel = f.channel();<br></code></pre></td></tr></table></figure>

<p>通过 Channel 向服务端发送消息 RpcRequest</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">futureChannel.writeAndFlush(rpcRequest)<br></code></pre></td></tr></table></figure>

<p>发送成功后，阻塞等待 ，直到 Channel 关闭</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">futureChannel.closeFuture().sync();<br></code></pre></td></tr></table></figure>

<p>拿到服务端返回的结果 RpcResponse</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">NettyClientHandler<br><br>// 声明一个 AttributeKey 对象<br>AttributeKey&lt;RpcResponse&gt; key = AttributeKey.valueOf(&quot;rpcResponse&quot;);<br>// 将服务端的返回结果保存到 AttributeMap 上，AttributeMap 可以看作是一个Channel的共享数据源<br>// AttributeMap的key是AttributeKey，value是Attribute<br>ctx.channel().attr(key).set(rpcResponse);<br></code></pre></td></tr></table></figure>

<p>（<strong>NettyClientHandler</strong>用于读取服务端发送过来的 RpcResponse 消息对象，并将 RpcResponse 消息对象保存到 AttributeMap 上。</p>
<p>AttributeMap 可以看作是一个 Channel 的共享数据源。这样的话，我们就能通过 channel 和 key 将数据读取出来。</p>
<p>AttributeMap ,AttributeMap 是一个接口，但是类似于 Map 数据结构 。</p>
<p>Channel 实现了 <strong>AttributeMap 接口</strong>，这样也就表明它存在了 AttributeMap 相关的属性。 <strong>每个 Channel 上的 AttributeMap 属于共享数据</strong>。AttributeMap 的结构，和 Map 很像，我们可以把 key 看作是 AttributeKey，value 看作是 Attribute，我们可以根据 AttributeKey 找到对应的 Attribute。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">AttributeKey&lt;RpcResponse&gt; key = AttributeKey.valueOf(&quot;rpcResponse&quot;);<br>return futureChannel.attr(key).get();<br></code></pre></td></tr></table></figure>



<h6 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">ServerBootstrap b = new ServerBootstrap();<br>b.group(bossGroup, workerGroup)<br>                    .channel(NioServerSocketChannel.class)<br>                    // TCP默认开启了 Nagle 算法，该算法的作用是尽可能的发送大数据快，减少网络传输。TCP_NODELAY 参数的作用就是控制是否启用 Nagle 算法。<br>                    .childOption(ChannelOption.TCP_NODELAY, true)<br>                    // 是否开启 TCP 底层心跳机制<br>                    .childOption(ChannelOption.SO_KEEPALIVE, true)<br>                    //表示系统用于临时存放已完成三次握手的请求的队列的最大长度,如果连接建立频繁，服务器处理创建新连接较慢，可以适当调大这个参数<br>                    .option(ChannelOption.SO_BACKLOG, 128)<br>                    .handler(new LoggingHandler(LogLevel.INFO))<br>                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;<br>                        @Override<br>                        protected void initChannel(SocketChannel ch) &#123;<br>     ch.pipeline().addLast(new NettyKryoDecoder(kryoSerializer, RpcRequest.class));<br>     ch.pipeline().addLast(new NettyKryoEncoder(kryoSerializer, RpcResponse.class));<br>     ch.pipeline().addLast(new NettyServerHandler());<br>                        &#125;<br>                    &#125;);<br><br>            // 绑定端口，同步等待绑定成功<br>            ChannelFuture f = b.bind(port).sync();<br>            // 等待服务端监听端口关闭<br>            f.channel().closeFuture().sync();<br></code></pre></td></tr></table></figure>

<h6 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h6><p>NettyKryoEncoder 是我们自定义的编码器。它负责处理”出站”消息，将消息格式转换为字节数组然后写入到字节数据的容器 ByteBuf 对象中。</p>
<p>4B  magic code（魔法数）  </p>
<p>1B version（版本）   </p>
<p>4B full length（消息长度）   </p>
<p>1B messageType（消息类型）</p>
<p>1B compress（压缩类型） </p>
<p>1B codec（序列化类型）    </p>
<p>4B  requestId（请求的 Id）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain"> @Override<br>protected void encode(ChannelHandlerContext ctx, RpcMessage rpcMessage, ByteBuf out) &#123;<br>        try &#123;<br>            out.writeBytes(RpcConstants.MAGIC_NUMBER);//魔数4<br>            out.writeByte(RpcConstants.VERSION);//版本1<br>            out.writerIndex(out.writerIndex() + 4);//跳过4字节，留着写长度<br>            byte messageType = rpcMessage.getMessageType();<br>            out.writeByte(messageType);//消息类型1<br>            out.writeByte(rpcMessage.getCodec());//序列化类型1<br>            out.writeByte(CompressTypeEnum.GZIP.getCode());//压缩类型1<br>            out.writeInt(ATOMIC_INTEGER.getAndIncrement());//请求ID4<br>            <br>            byte[] bodyBytes = null;<br>            int fullLength = RpcConstants.HEAD_LENGTH;//头部长度<br>            <br>            if (messageType != RpcConstants.HEARTBEAT_REQUEST_TYPE<br>                    &amp;&amp; messageType != RpcConstants.HEARTBEAT_RESPONSE_TYPE) &#123;<br>                // 序列化<br>         String codecName = SerializationTypeEnum.getName(rpcMessage.getCodec());<br>         Serializer serializer = ExtensionLoader.getExtensionLoader(Serializer.class)<br>                        .getExtension(codecName);<br>          bodyBytes = serializer.serialize(rpcMessage.getData());//序列化<br>                // 压缩<br>        String compressName = CompressTypeEnum.getName(rpcMessage.getCompress());<br>        Compress compress = ExtensionLoader.getExtensionLoader(Compress.class)<br>                        .getExtension(compressName);<br>         bodyBytes = compress.compress(bodyBytes);//压缩后的长度<br>          <br>         fullLength += bodyBytes.length;<br>            &#125;<br>            <br>            if (bodyBytes != null) &#123;<br>                out.writeBytes(bodyBytes);<br>            &#125;<br>            int writeIndex = out.writerIndex();<br>            //跳过魔术加版本<br>            out.writerIndex(writeIndex - fullLength + RpcConstants.MAGIC_NUMBER.length + 1);<br>            //写全长<br>            out.writeInt(fullLength);<br>            out.writerIndex(writeIndex);<br>        &#125; catch (Exception e) &#123;<br>            log.error(&quot;Encode request error!&quot;, e);<br>        &#125;<br>    &#125;<br><br></code></pre></td></tr></table></figure>

<h6 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">private Object decodeFrame(ByteBuf in) &#123;<br>        // 有序的bytebuf<br>        checkMagicNumber(in);//魔术<br>        checkVersion(in);//版本<br>        int fullLength = in.readInt();<br>        // 构建返回对象<br>        byte messageType = in.readByte();<br>        byte codecType = in.readByte();<br>        byte compressType = in.readByte();<br>        int requestId = in.readInt();<br>        RpcMessage rpcMessage = RpcMessage.builder()<br>                .codec(codecType)<br>                .requestId(requestId)<br>                .messageType(messageType).build();<br>        //心跳请求？<br>        if (messageType == RpcConstants.HEARTBEAT_REQUEST_TYPE) &#123;<br>            rpcMessage.setData(RpcConstants.PING);<br>            return rpcMessage;<br>        &#125;<br>        //心跳返回？<br>        if (messageType == RpcConstants.HEARTBEAT_RESPONSE_TYPE) &#123;<br>            rpcMessage.setData(RpcConstants.PONG);<br>            return rpcMessage;<br>        &#125;<br>        //正文长度<br>        int bodyLength = fullLength - RpcConstants.HEAD_LENGTH;<br>        if (bodyLength &gt; 0) &#123;<br>            byte[] bs = new byte[bodyLength];<br>            in.readBytes(bs);<br>            // 解压缩<br>            String compressName = CompressTypeEnum.getName(compressType);<br>            Compress compress = ExtensionLoader.getExtensionLoader(Compress.class)<br>                    .getExtension(compressName);<br>            bs = compress.decompress(bs);<br>            // 反序列化<br>            String codecName = SerializationTypeEnum.getName(rpcMessage.getCodec());<br>            Serializer serializer = ExtensionLoader.getExtensionLoader(Serializer.class)<br>                    .getExtension(codecName);<br>            //rqcreauest？<br>            if (messageType == RpcConstants.REQUEST_TYPE) &#123;<br>                RpcRequest tmpValue = serializer.deserialize(bs, RpcRequest.class);<br>                rpcMessage.setData(tmpValue);<br>            &#125; else &#123;<br>                RpcResponse tmpValue = serializer.deserialize(bs, RpcResponse.class);<br>                rpcMessage.setData(tmpValue);<br>            &#125;<br>        &#125;<br>        return rpcMessage;<br>    &#125;<br></code></pre></td></tr></table></figure>



<h4 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h4><p>要在网络传输数据就要涉及到序列化。为什么需要序列化和反序列化呢？ </p>
<p>因为<strong>网络传输的数据必须是二进制</strong>的。因此，我们的 Java 对象没办法直接在网络中传输。为了能够让 Java 对象在网络中传输我们需要将其序列化为二进制的数据。我们最终需要的还是目标 Java 对象，因此我们还要将二进制的数据“解析”为目标 Java 对象，也就是对二进制数据再进行一次反序列化。</p>
<p>另外，<strong>不仅网络传输的时候需要用到序列化和反序列化，将对象存储到文件、数据库等场景都需要用到序列化和反序列化。</strong></p>
<p>JDK 自带的序列化，只需实现 java.io.Serializable 接口即可，不过这种方式不推荐，因为不支持跨语言调用并且性能比较差。</p>
<p>现在比较常用序列化的有 hessian、kyro、protostuff ……</p>
<h5 id="属于哪一层？"><a href="#属于哪一层？" class="headerlink" title="属于哪一层？"></a>属于哪一层？</h5><p><img src="https://i.loli.net/2021/08/06/G4DzcJvQf2Z9mku.png" alt="image-20210806150427787"></p>
<p>OSI 七层协议模型中，<strong>表示层</strong>做的事情主要就是对应用层的用户数据进行处理转换为二进制流。反过来的话，就是将二进制流转换成应用层的用户数据。</p>
<p>因为，OSI 七层协议模型中的应用层、表示层和会话层对应的都是 TCP&#x2F;IP 四层模型中的应用层，所以序列化协议属于 TCP&#x2F;IP 协议应用层的一部分。</p>
<h5 id="常见序列化协议对比"><a href="#常见序列化协议对比" class="headerlink" title="常见序列化协议对比"></a>常见序列化协议对比</h5><p>JDK 自带的序列化方式一般不会用 ，因为序列化效率低并且部分版本有安全漏洞。比较常用的序列化协议有 <strong>hessian、kyro、protostuff。</strong></p>
<p>下面提到的都是基于二进制的序列化协议，像 <strong>JSON 和 XML</strong>这种属于文本类序列化方式。虽然 JSON 和 XML 可读性比较好，但是性能较差。</p>
<p><strong>JDK 自带的序列化方式</strong></p>
<p>JDK 自带的序列化，只需实现 <strong>java.io.Serializable</strong>接口即可。</p>
<p>序列化号 serialVersionUID 属于<strong>版本控制</strong>的作用。序列化的时候 serialVersionUID 也会被写入二级制序列，当反序列化时会<strong>检查 serialVersionUID 是否和当前类的 serialVersionUID 一致</strong>。如果 serialVersionUID 不一致则会抛出 InvalidClassException 异常。强烈推荐每个序列化类都手动指定其 serialVersionUID，如果不手动指定，那么编译器会动态生成默认的序列化号。</p>
<p><strong>kyro</strong></p>
<p>Kryo 是一个高性能的序列化&#x2F;反序列化工具，由于其变长存储特性并使用了字节码生成机制，拥有较高的运行速度和较小的字节码体积。</p>
<p>另外，Kryo 已经是一种非常成熟的序列化实现了，已经在 Twitter、Groupon、Yahoo 以及多个著名开源项目（如 Hive、Storm）中广泛的使用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class KryoSerializer implements Serializer &#123;<br>    //Lambda方式传入实现了 Supplier 函数接口的参数。<br>    private final ThreadLocal&lt;Kryo&gt; kryoThreadLocal = ThreadLocal.withInitial(new Supplier&lt;Kryo&gt;() &#123;<br>        @Override<br>        public Kryo get() &#123;<br>            //先注册<br>            Kryo kryo = new Kryo();<br>            kryo.register(RpcResponse.class);<br>            kryo.register(RpcRequest.class);<br>            return kryo;<br>        &#125;<br>    &#125;);<br><br>    @Override<br>    public byte[] serialize(Object obj) &#123;<br>        try (ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();<br>             Output output = new Output(byteArrayOutputStream)) &#123;<br>            Kryo kryo = kryoThreadLocal.get();<br>            // Object-&gt;byte:将对象序列化为byte数组<br>            kryo.writeObject(output, obj);<br>            kryoThreadLocal.remove();<br>            return output.toBytes();<br>        &#125; catch (Exception e) &#123;<br>            throw new SerializeException(&quot;Serialization failed&quot;);<br>        &#125;<br>    &#125;<br><br>    @Override<br>    public &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; clazz) &#123;<br>        try (ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);<br>             Input input = new Input(byteArrayInputStream)) &#123;<br>            Kryo kryo = kryoThreadLocal.get();<br>            // byte-&gt;Object:从byte数组中反序列化出对对象<br>            Object o = kryo.readObject(input, clazz);<br>            kryoThreadLocal.remove();<br>            return clazz.cast(o);<br>        &#125; catch (Exception e) &#123;<br>            throw new SerializeException(&quot;Deserialization failed&quot;);<br>        &#125;<br>    &#125;<br><br></code></pre></td></tr></table></figure>

<p><strong>hession</strong></p>
<p>hessian 是一个轻量级的,自定义描述的二进制 RPC 协议。hessian 是一个比较老的序列化实现了，并且同样也是跨语言的。</p>
<p><strong>Protobuf</strong></p>
<p>Protobuf 出自于 Google，性能还比较优秀，也支持多种语言，同时还是跨平台的。就是在使用中过于繁琐，因为你需要自己定义 IDL 文件和生成对应的序列化代码。这样虽然不然灵活，但是，另一方面导致 protobuf 没有序列化漏洞的风险。</p>
<h4 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h4><p>我们知道代理模式就是： 我们给某一个对象提供一个代理对象，并由代理对象来代替真实对象做一些事情。你可以把代理对象理解为一个幕后的工具人。 举个例子：我们真实对象调用方法的时候，我们可以通过代理对象去做一些事情比如安全校验、日志打印等等。但是，这个过程是完全对真实对象屏蔽的。</p>
<p>RPC 的主要目的就是让我们调用远程方法像调用本地方法一样简单，我们不需要关心远程方法调用的细节比如网络传输。</p>
<p>当你调用远程方法的时候，<strong>实际会通过代理对象来传输网络请求</strong>，不然的话，怎么可能直接就调用到远程方法。</p>
<h5 id="JDK-动态代理"><a href="#JDK-动态代理" class="headerlink" title="JDK 动态代理"></a>JDK 动态代理</h5><p>在 Java 动态代理机制中 <strong>InvocationHandler 接口和 Proxy 类是核心。</strong></p>
<p>Proxy 类中使用频率最高的方法是：newProxyInstance() ，这个方法主要用来生成一个代理对象。</p>
<p>   plain public static Object newProxyInstance(ClassLoader loader,<br>                                          Class&lt;?&gt;[] interfaces,<br>                                          InvocationHandler h)</p>
<p>这个方法一共有 3 个参数：</p>
<p>loader :类加载器，用于加载代理对象。<br>interfaces : 被代理类实现的一些接口；<br>h : 实现了 InvocationHandler 接口的对象；</p>
<p>要实现动态代理的话，还必须需要实现 InvocationHandler 来自定义处理逻辑。 当我们的动态代理对象调用一个方法时候，这个方法的调用就会被转发到实现 InvocationHandler 接口类的 invoke 方法来调用。</p>
<p>invoke() 方法有下面三个参数：</p>
<p>proxy :动态生成的代理类<br>method : <strong>与代理类对象调用的方法相对应</strong><br>args : <strong>当前 method 方法的参数</strong></p>
<p>也就是说：你通过 Proxy 类的 newProxyInstance() 创建的代理对象在调用方法的时候，<strong>实际会调用到实现 InvocationHandler 接口的类的 invoke()方法。 你可以在 invoke() 方法中自定义处理逻辑</strong>，比如在方法执行前后做什么事情。</p>
<p><strong>步骤</strong>：</p>
<p>定义一个接口及其实现类；<br>自定义 InvocationHandler 并重写 invoke 方法，在 invoke 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；<br>通过 Proxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 方法创建代理对象；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public Object invoke(Object proxy, Method method, Object[] args) &#123;<br>      //生成RPCrequest<br>       RpcRequest rpcRequest = RpcRequest.builder().methodName(method.getName())<br>               .parameters(args)<br>               .interfaceName(method.getDeclaringClass().getName())<br>               .paramTypes(method.getParameterTypes())<br>               .requestId(UUID.randomUUID().toString())<br>               .group(rpcServiceConfig.getGroup())<br>               .version(rpcServiceConfig.getVersion())<br>               .build();<br>       RpcResponse&lt;Object&gt; rpcResponse = null;<br>       <br>       if (rpcRequestTransport instanceof NettyRpcClient) &#123;<br>           CompletableFuture&lt;RpcResponse&lt;Object&gt;&gt; completableFuture = (CompletableFuture&lt;RpcResponse&lt;Object&gt;&gt;) <br>           //发送rpcrequest<br>           rpcRequestTransport.sendRpcRequest(rpcRequest);<br>           rpcResponse = completableFuture.get();<br>       &#125;<br>       if (rpcRequestTransport instanceof SocketRpcClient) &#123;<br>           rpcResponse = (RpcResponse&lt;Object&gt;) <br>           rpcRequestTransport.sendRpcRequest(rpcRequest);<br>       &#125;<br>       this.check(rpcResponse, rpcRequest);<br>       return rpcResponse.getData();<br>   &#125;<br></code></pre></td></tr></table></figure>



<h5 id="CGLIB-动态代理"><a href="#CGLIB-动态代理" class="headerlink" title="CGLIB 动态代理"></a>CGLIB 动态代理</h5><p>JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。</p>
<p>为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。</p>
<p>CGLIB(Code Generation Library)是一个基于 ASM 的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。CGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了 CGLIB， 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。</p>
<p>在 CGLIB 动态代理机制中 MethodInterceptor 接口和 Enhancer 类是核心。</p>
<p>你需要自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法。</p>
<p><strong>CGLIB 动态代理类使用步骤</strong></p>
<p>定义一个类；<br>自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；<br>通过 Enhancer 类的 create()创建代理类；</p>
<h5 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h5><p><strong>JDK 动态代理和 CGLIB 动态代理对比</strong></p>
<p>JDK 动态代理只能<strong>只能代理实现了接口的类</strong>，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过<strong>生成一个被代理类的子类</strong>来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。<br>就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。</p>
<p><strong>静态代理和动态代理的对比</strong></p>
<p>灵活性 ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，<strong>静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改</strong>。</p>
<p>JVM 层面 ：静态代理在<strong>编译时</strong>就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在<strong>运行时动态生成类字节码</strong>，并加载到 JVM 中的。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><p>RpcClientProxy.java</p>
<p>当我们去调用一个远程的方法的时候，实际上是通过代理对象调用的。</p>
<p>网络传输细节都被封装在了  <code>invoke()</code>  方法中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public Object invoke(Object proxy, Method method, Object[] args) &#123;<br>      //构造rpcrequset<br>       RpcRequest rpcRequest = RpcRequest.builder().methodName(method.getName())<br>               .parameters(args)<br>               .interfaceName(method.getDeclaringClass().getName())<br>               .paramTypes(method.getParameterTypes())<br>               .requestId(UUID.randomUUID().toString())<br>               .group(rpcServiceProperties.getGroup())<br>               .version(rpcServiceProperties.getVersion())<br>               .build();<br>       RpcResponse&lt;Object&gt; rpcResponse = null;<br>       if (rpcRequestTransport instanceof NettyRpcClient) &#123;<br>           CompletableFuture&lt;RpcResponse&lt;Object&gt;&gt; completableFuture = (CompletableFuture&lt;RpcResponse&lt;Object&gt;&gt;) rpcRequestTransport.sendRpcRequest(rpcRequest);<br>           rpcResponse = completableFuture.get();<br>       &#125;<br>       if (rpcRequestTransport instanceof SocketRpcClient) &#123;<br>           rpcResponse = (RpcResponse&lt;Object&gt;) rpcRequestTransport.sendRpcRequest(rpcRequest);<br>       &#125;<br>       this.check(rpcResponse, rpcRequest);<br>       return rpcResponse.getData();<br>   &#125;<br></code></pre></td></tr></table></figure>



<h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>系统中的某个服务的访问量特别大，我们将这个服务部署在了多台服务器上，当客户端发起请求的时候，多台服务器都可以处理这个请求。那么，如何正确选择处理该请求的服务器就很关键。假如，你就要一台服务器来处理该服务的请求，那该服务部署在多台服务器的意义就不复存在了。负载均衡就是为了避免单个服务器响应同一请求，容易造成服务器宕机、崩溃等问题。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><p>我们定义了两个接口 ServiceDiscovery.java 和 ServiceRegistry.java，这两个接口分别定义了服务发现和服务注册行为。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class ZkServiceRegistryImpl implements ServiceRegistry &#123;<br>@Override<br>public void registerService(String rpcServiceName, InetSocketAddress inetSocketAddress) &#123;<br> String servicePath = CuratorUtils.ZK_REGISTER_ROOT_PATH + &quot;/&quot; + rpcServiceName + inetSocketAddress.toString();<br>CuratorFramework zkClient = CuratorUtils.getZkClient();<br>CuratorUtils.createPersistentNode(zkClient, servicePath);//创建一个用永久节点<br> &#125;<br></code></pre></td></tr></table></figure>

<p>当我们的服务被注册进 zookeeper 的时候，我们将完整的服务名称 <strong>rpcServiceName</strong> （class name+group+version）作为根节点 ，子节点是对应的服务地址（ip+端口号）。</p>
<p>class name : <strong>服务接口名</strong>也就是类名比如：github.javaguide.HelloService。<br>version :（服务版本）主要是为后续不兼容升级提供可能<br>group :主要用于处理一个接口有多个类实现的情况。</p>
<p>一个根节点（rpcServiceName）<strong>可能会对应多个服务地址</strong>（相同服务被部署多份的情况）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class ZkServiceDiscoveryImpl implements ServiceDiscovery &#123;<br>    private final LoadBalance loadBalance;<br><br>public ZkServiceDiscoveryImpl() &#123;<br>this.loadBalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(&quot;loadBalance&quot;);<br>    &#125;<br><br>    @Override<br>    public InetSocketAddress lookupService(RpcRequest rpcRequest) &#123;<br>        String rpcServiceName = rpcRequest.getRpcServiceName();<br>        CuratorFramework zkClient = CuratorUtils.getZkClient();<br>        List&lt;String&gt; serviceUrlList = CuratorUtils.getChildrenNodes(zkClient, rpcServiceName);<br>        if (serviceUrlList == null || serviceUrlList.size() == 0) &#123;<br>            throw new RpcException(RpcErrorMessageEnum.SERVICE_CAN_NOT_BE_FOUND, rpcServiceName);<br>        &#125;<br>        // load balancing<br>        String targetServiceUrl = loadBalance.selectServiceAddress(serviceUrlList, rpcRequest);<br>        <br>        String[] socketAddressArray = targetServiceUrl.split(&quot;:&quot;);<br>        String host = socketAddressArray[0];<br>        int port = Integer.parseInt(socketAddressArray[1]);<br>        return new InetSocketAddress(host, port);<br>    &#125;<br></code></pre></td></tr></table></figure>



<h4 id="具体算法"><a href="#具体算法" class="headerlink" title="具体算法"></a>具体算法</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public interface LoadBalance &#123;<br>    String selectServiceAddress(List&lt;String&gt; serviceAddresses, RpcRequest rpcRequest);<br>&#125;<br></code></pre></td></tr></table></figure>



<h5 id="随机"><a href="#随机" class="headerlink" title="随机"></a>随机</h5><h5 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a>轮询</h5><h5 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h5><p>简单的路由算法可以使用余数哈希算法：<code>HashCode = key % number of server</code>。由于 HashCode 具有随机性，因此使用余数哈希路由算法可保证缓存数据在整个 Memcached 服务器集群中比较均衡地分布。</p>
<p>假设由于业务发展，网站需要将 3 台缓存服务器扩容至 4 台。更改服务器列表，仍旧使用余数 Hash，很容易就可以计算出，3 台服务器扩容至 4 台服务器，大约有 75％（3&#x2F;4）被缓存了的数据不能正确命中，随着服务器集群规模的增大，这个比例线性上升。当 100 台服务器的集群中加入一台新服务器，不能命中的概率是 99％(N&#x2F;(N＋1))。</p>
<blockquote>
<p>假设扩容前有 N 台服务器，扩容一台服务器<br>也就是说每(N+1)*N 个数里面有 N 个 key 经过余数 Hash 映射后是一样的，所以命中率为 1&#x2F;(N+1)，所以未命中率为(N&#x2F;(N＋1))</p>
</blockquote>
<p>当大部分被缓存了的数据因为服务器扩容而不能正确读取时，这些数据访问的压力就落到了数据库的身上，这将大大超过数据库的负载能力，严重的可能会导致数据库宕机。</p>
<p>一致性 Hash 算法通过一个叫作一致性 Hash 环的数据结构实现 key 到缓存服务器的 Hash 映射。</p>
<p>具体算法过程为：先构造一个长度为<code>0~2^32</code>的整数环（这个环被称作一致性 Hash 环），根据节点名称(通常是 IP）的 Hash 值（其分布范围同样为<code>0~x^32</code>）将缓存服务器节点放置在这个 Hash 环上。然后根据需要缓存的数据的 key 值计算得到其 Hash 值（其分布范围也同样为<code>0~x^32</code>），然后在 Hash 环上顺时针查找距离这个 key 的 Hash 值最近的缓存服务器节点，完成 key 到服务器的 Hash 映射查找。</p>
<p>当缓存服务器集群需要扩容的时候，只需要将新加入的节点名称<code>(NODE3)</code>的 Hash 值放入一致性 Hash 环中，由于 key 是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一小段。</p>
<p>上图中，加入新节点<code>NODE3</code>后，原来的 key 大部分还能继续计算到原来的节点，只有<code>key3</code>、<code>key0</code>从原来的<code>NODE1</code>重新计算到<code>NODE3</code>。这样就能保证大部分被缓存的数据还可以继续命中。3 台服务器扩容至 4 台服务器，可以继续命中原有缓存数据的概率是 75％，远高于余数 Hash 的 25％，而且随着集群规模越大，继续命中原有缓存数据的概率也逐渐增大，100 台服务器扩容增加 1 台服务器，继续命中的概率是 99％。虽然仍有小部分数据缓存在服务器中不能被读到，但是这个比例足够小，通过访问数据库获取也不会对数据库造成致命的负载压力。</p>
<h6 id="虚拟节点"><a href="#虚拟节点" class="headerlink" title="虚拟节点"></a>虚拟节点</h6><p>新加入的节点<code>NODE3</code>只影响了原来的节点<code>NODE1</code>，也就是说一部分一部分原来需要访问<code>NODE1</code>的缓存数据现在需要访问<code>NODE3</code>。但是原来的节点<code>NODE0</code>和<code>NODE2</code>不受影响，这就意味着<code>NODE0</code>和<code>NODE2</code>缓存数据量和负载压力是<code>NODE1</code>与<code>NODE3</code>的两倍。如果 4 台机器的性能是一样的，那么这种结果显然不是我们需要的。</p>
<p>怎么办？计算机领域有句话：计算机的任何问题都可以通过增加一个虚拟层来解决。计算机硬件、计算机网络、计算机软件都莫不如此。计算机网络的 7 层协议，每一层都可以看作是下一层的虚拟层；计算机操作系统可以看作是计算机硬件的虚拟层；Java 虚拟机可以看作是操作系统的虚拟层；分层的计算机软件架构事实上也是利用虚拟层的概念。</p>
<p>解决上述一致性 Hash 算法带来的负载不均衡问题，也可以通过使用虚拟层的手段：将每台物理缓存服务器虚拟为一组虚拟缓存服务器，将虚拟服务器的 Hash 值放置在 Hash 环上，key 在环上先找到虚拟服务器节点，再得到物理服务器的信息。</p>
<p>这样新加入物理服务器节点时，<strong>是将一组虚拟节点加入环中，如果虚拟节点的数目足够多，这组虚拟节点将会影响同样多数目的目的已经在环上存在的虚拟节点，</strong>这些已经存在的虚拟节点又对应不同的物理节点。</p>
<p>最终的结果是：新加入一台缓存服务器，<strong>将会较为均匀地影响原来集群中已经存在的所有服务器，也就是说分摊原有缓存服务器集群中所有服务器的一小部分负载，其总的影响范围和上面讨论过的相同</strong>。</p>
<p>新加入节点<code>NODE3</code>对应的一组虚拟节点为<code>V30</code>，<code>V31</code>，<code>V32</code>，加入到一致性 Hash 环上后，影响<code>V01</code>，<code>V12</code>，<code>V22</code>三个虚拟节点，而这三个虚拟节点分别对应<code>NODE0</code>，<code>NODE1</code>，<code>NODE2</code>三个物理节点。最终 Memcached 集群中加入一个节点，但是同时影响到集群中已存在的三个物理节点，在理想情况下，每个物理节点受影响的数据量（还在缓存中，但是不能被访问到数据）为其节点缓存数据量的 1&#x2F;4（X&#x2F;（N＋X），N 为原有物理节点数，X 为新加入物理节点数），也就是集群中已经被缓存的数据有 75％可以被继续命中，和未使用虚拟节点的一致性 Hash 算法结果相同。显然每个物理节点对应的虚拟节点越多，各个物理节点之间的负载越均衡，新加入物理服务器对原有的物理服务器的影响越保持一致（这就是一致性 Hash 这个名称的由来）。</p>
<h4 id="版本一"><a href="#版本一" class="headerlink" title="版本一"></a>版本一</h4><p>考虑最简单的 RPC 功能。<br>客户端调用服务端方法，服务端返回。</p>
<p>1，有一个 User 对象，是客户端与服务端都已知的<br>2，定义客户端需要调用，服务端需要提供的服务接口 UserService<br>3，服务端需要实现 UserService 接口的功能 UserServiceImpl<br>4，客户端建立 Socket 连接，传输 Id 给服务端，得到返回的 User 对象<br>5，服务端以 BIO 的方式监听 Socket，如有数据，调用对应服务的实现类执行任务，将结果返回给客户端</p>
<p>问题<br>只能调用服务端唯一的方法<br>返回值也只只支持一种</p>
<h4 id="版本-2"><a href="#版本-2" class="headerlink" title="版本 2"></a>版本 2</h4><p>定义了一个通用的 Request 的对象（消息格式）<br>（在上个版本中，Request 仅仅只发送了一个 id 参数过去，这显然是不合理的，<br>因为服务端不会只有一个服务一个方法，因此只传递参数不会知道调用那个方法。<br>因此一个 RPC 请求中，client 发送应该是需要调用的 Service 接口名，方法名，参数，参数类型<br>这样服务端就能根据这些信息根据反射调用相应的方法。<br>还是使用 java 自带的序列化方式。）</p>
<p> 定义了一个通用的 Response 的对象（消息格式）</p>
<p>（上个版本中 response 传输的是 User 对象，显然在一个应用中我们不可能只传输一种类型的数据<br>由此我们将传输对象抽象成为 Object<br>。Rpc 需要经过网络传输，有可能失败，引入状态码和状态信息表示服务调用成功还是失败）</p>
<p>通过 jdk 动态代理封装传输细节， 每一次代理对象调用方法，会经过 invoke 方法增强（反射获取 request 对象，socket 发送至客户端，得到返回的 rpcresponce）</p>
<p>客户端反射得到结果<br>&#x2F;&#x2F; 读取客户端传过来的 request<br>RPCRequest request &#x3D; (RPCRequest) ois.readObject();<br>&#x2F;&#x2F; 反射调用对应方法<br>Method method &#x3D; userService.getClass().getMethod(request.getMethodName(), request.getParamsTypes());<br>Object invoke &#x3D; method.invoke(userService, request.getParams());<br>&#x2F;&#x2F; 封装，写入 response 对象<br>oos.writeObject(RPCResponse.success(invoke));<br>问题<br>服务端直接绑定的是 UserService 服务，如果还有其它服务接口暴露呢（多个服务的注册）<br>服务端以 BIO 的方式性能太低<br>解决<br>用一个 Map 来保存，&lt;interfaceName, xxxServiceImpl&gt;<br>此时来了一个 request，就能从 map 中取出对应的服务<br>Object service &#x3D; map.get(request.getInterfaceName())<br>服务端用线程池<br>threadPool &#x3D; new ThreadPoolExecutor(Runtime.getRuntime().availableProcessors(),<br>1000, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(100));</p>
<h4 id="版本-3"><a href="#版本-3" class="headerlink" title="版本 3"></a>版本 3</h4><p>netty 改善<br>客户端<br>&#x2F;&#x2F;超时设定：5 秒没连接就断开<br>.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000)<br>.handler(new ChannelInitializer<SocketChannel>() {<br>@Override<br>protected void initChannel(SocketChannel ch) {<br>ChannelPipeline p &#x3D; ch.pipeline();<br>&#x2F;&#x2F;5 秒没有数据发送，就发送心跳包。<br>p.addLast(new IdleStateHandler(0, 5, 0, TimeUnit.SECONDS));<br>p.addLast(new RpcMessageEncoder());&#x2F;&#x2F;编码<br>p.addLast(new RpcMessageDecoder());&#x2F;&#x2F;解码<br>p.addLast(new NettyRpcClientHandler());<br>}<br>});<br>4B  magic code（魔法数）   1B version（版本）   4B full length（消息长度）    1B messageType（消息类型-request，reaponse，心跳）<br>1B compress（压缩类型） 1B codec（序列化类型）    4B  requestId（请求的 Id） </p>
<p>服务端<br>&#x2F;&#x2F; TCP 默认开启了 Nagle 算法，该算法的作用是尽可能的发送大数据快，减少网络传输。TCP_NODELAY 参数的作用就是控制是否启用 Nagle 算法。<br>.childOption(ChannelOption.TCP_NODELAY, true)<br>&#x2F;&#x2F; 是否开启 TCP 底层心跳机制<br>.childOption(ChannelOption.SO_KEEPALIVE, true)<br>&#x2F;&#x2F;表示系统用于临时存放已完成三次握手的请求的队列的最大长度,如果连接建立频繁，服务器处理创建新连接较慢，可以适当调大这个参数<br>.option(ChannelOption.SO_BACKLOG, 128)<br>.handler(new LoggingHandler(LogLevel.INFO))<br>&#x2F;&#x2F; 当客户端第一次进行请求的时候才会进行初始化<br>.childHandler(new ChannelInitializer<SocketChannel>() {<br>    @Override<br>    protected void initChannel(SocketChannel ch) {<br>        &#x2F;&#x2F; 30 秒之内没有收到客户端请求的话就关闭连接<br>        ChannelPipeline p &#x3D; ch.pipeline();<br>        p.addLast(new IdleStateHandler(30, 0, 0, TimeUnit.SECONDS));<br>        p.addLast(new RpcMessageEncoder());<br>        p.addLast(new RpcMessageDecoder());<br>        p.addLast(serviceHandlerGroup, new NettyRpcServerHandler());</p>
<p>问题：服务端与客户端通信的 host 与 port 预先就必须知道的，每一个客户端都必须知道对应服务的 ip 与端口号， 并且如果服务挂了或者换地址了，就很麻烦。扩展性也不强。</p>
<h4 id="版本-4"><a href="#版本-4" class="headerlink" title="版本 4"></a>版本 4</h4><p>zookeeper 注册中心<br>public void registerService(String rpcServiceName, InetSocketAddress inetSocketAddress) {<br>String servicePath &#x3D; CuratorUtils.ZK_REGISTER_ROOT_PATH + “&#x2F;“ + rpcServiceName + inetSocketAddress.toString();<br>CuratorFramework zkClient &#x3D; CuratorUtils.getZkClient();<br>CuratorUtils.createPersistentNode(zkClient, servicePath);<br>}</p>
<p>public InetSocketAddress lookupService(RpcRequest rpcRequest) {<br>    String rpcServiceName &#x3D; rpcRequest.getRpcServiceName();<br>    CuratorFramework zkClient &#x3D; CuratorUtils.getZkClient();<br>    List<String> serviceUrlList &#x3D; CuratorUtils.getChildrenNodes(zkClient, rpcServiceName);<br>    if (serviceUrlList &#x3D;&#x3D; null || serviceUrlList.size() &#x3D;&#x3D; 0) {<br>        throw new RpcException(RpcErrorMessageEnum.SERVICE_CAN_NOT_BE_FOUND, rpcServiceName);<br>    }<br>    &#x2F;&#x2F; load balancing<br>    String targetServiceUrl &#x3D; loadBalance.selectServiceAddress(serviceUrlList, rpcRequest);</p>
<p>   plain String[] socketAddressArray &#x3D; targetServiceUrl.split(“:”);<br>    String host &#x3D; socketAddressArray[0];<br>    int port &#x3D; Integer.parseInt(socketAddressArray[1]);<br>    return new InetSocketAddress(host, port);<br>}<br>简单的负载均衡<br>随机<br>轮询<br>一致性哈希</p>
<p>容错</p>
<p>在 RPC 中可选的网络传输方式有多种，可以选择 TCP 协议、UDP 协议、HTTP 协议。</p>
<p>基于 TCP 协议的 RPC 调用</p>
<p>由服务的调用方与服务的提供方建立 Socket 连接，并由服务的调用方通过 Socket 将需要调用的接口名称、方法名称和参数序列化后传递给服务的提供方，服务的提供方反序列化后再利用反射调用相关的方法。</p>
<p>将结果返回给服务的调用方，整个基于 TCP 协议的 RPC 调用大致如此。</p>
<p>但是在实例应用中则会进行一系列的封装，如 RMI 便是在 TCP 协议上传递可序列化的 Java 对象。</p>
<p>基于 HTTP 协议的 RPC 调用</p>
<p>该方法更像是访问网页一样，只是它的返回结果更加单一简单。</p>
<p>其大致流程为：由服务的调用者向服务的提供者发送请求，这种请求的方式可能是 GET、POST、PUT、DELETE 等中的一种，服务的提供者可能会根据不同的请求方式做出不同的处理，或者某个方法只允许某种请求方式。</p>
<p>而调用的具体方法则是根据 URL 进行方法调用，而方法所需要的参数可能是对服务调用方传输过去的 XML 数据或者 JSON 数据解析后的结果，返回 JOSN 或者 XML 的数据结果。</p>
<p>由于目前有很多开源的 Web 服务器，如 Tomcat，所以其实现起来更加容易，就像做 Web 项目一样。</p>
<p>两种方式对比</p>
<p>基于 TCP 的协议实现的 RPC 调用，由于 TCP 协议处于协议栈的下层，能够更加灵活地对协议字段进行定制，减少网络开销，提高性能，实现更大的吞吐量和并发数。</p>
<p>但是需要更多关注底层复杂的细节，实现的代价更高。同时对不同平台，如安卓，iOS 等，需要重新开发出不同的工具包来进行请求发送和相应解析，工作量大，难以快速响应和满足用户需求。</p>
<p>基于 HTTP 协议实现的 RPC 则可以使用 JSON 和 XML 格式的请求或响应数据。</p>
<p>而 JSON 和 XML 作为通用的格式标准(使用 HTTP 协议也需要序列化和反序列化，不过这不是该协议下关心的内容，成熟的 Web 程序已经做好了序列化内容)，开源的解析工具已经相当成熟，在其上进行二次开发会非常便捷和简单。</p>
<p>但是由于 HTTP 协议是上层协议，发送包含同等内容的信息，使用 HTTP 协议传输所占用的字节数会比使用 TCP 协议传输所占用的字节数更高。</p>
<p>因此在同等网络下，通过 HTTP 协议传输相同内容，效率会比基于 TCP 协议的数据效率要低，信息传输所占用的时间也会更长，当然压缩数据，能够缩小这一差距。</p>
<p>简单对比 RPC 和 Restful API</p>
<p>RESTful API 架构</p>
<p>REST 的几个特点为：资源、统一接口、URI 和无状态。</p>
<p>①资源</p>
<p>所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，就是一个具体的实在。</p>
<p>②统一接口</p>
<p>RESTful 架构风格规定，数据的元操作，即 CRUD(Create，Read，Update 和 Delete，即数据的增删查改)操作，分别对应于 HTTP 方法：GET 用来获取资源，POST 用来新建资源(也可以用于更新资源)，PUT 用来更新资源，DELETE 用来删除资源，这样就统一了数据操作的接口，仅通过 HTTP 方法，就可以完成对数据的所有增删查改工作。</p>
<p>③URL</p>
<p>可以用一个 URI(统一资源定位符)指向资源，即每个 URI 都对应一个特定的资源。</p>
<p>要获取这个资源，访问它的 URI 就可以，因此 URI 就成了每一个资源的地址或识别符。</p>
<p>④无状态</p>
<p>所谓无状态的，即所有的资源，都可以通过 URI 定位，而且这个定位与其他资源无关，也不会因为其他资源的变化而改变。有状态和无状态的区别，举个简单的例子说明一下。</p>
<p>如查询员工的工资，如果查询工资是需要登录系统，进入查询工资的页面，执行相关操作后，获取工资的多少，则这种情况是有状态的。</p>
<p>因为查询工资的每一步操作都依赖于前一步操作，只要前置操作不成功，后续操作就无法执行。</p>
<p>如果输入一个 URI 即可得到指定员工的工资，则这种情况是无状态的，因为获取工资不依赖于其他资源或状态。</p>
<p>且这种情况下，员工工资是一个资源，由一个 URI 与之对应，可以通过 HTTP 中的 GET 方法得到资源，这是典型的 RESTful 风格。</p>
<p>RPC 和 Restful API 对比</p>
<p>面对对象不同：</p>
<p>RPC 更侧重于动作。<br>REST 的主体是资源。<br>RESTful 是面向资源的设计架构，但在系统中有很多对象不能抽象成资源，比如登录，修改密码等而 RPC 可以通过动作去操作资源。所以在操作的全面性上 RPC 大于 RESTful。</p>
<p>传输效率：</p>
<p>RPC 效率更高。RPC，使用自定义的 TCP 协议，可以让请求报文体积更小，或者使用 HTTP2 协议，也可以很好的减少报文的体积，提高传输效率。</p>
<p>复杂度：</p>
<p>RPC 实现复杂，流程繁琐。<br>REST 调用及测试都很方便。<br>RPC 实现需要实现编码，序列化，网络传输等。而 RESTful 不要关注这些，RESTful 实现更简单。</p>
<p>灵活性：</p>
<p>HTTP 相对更规范，更标准，更通用，无论哪种语言都支持 HTTP 协议。<br>RPC 可以实现跨语言调用，但整体灵活性不如 RESTful。</p>
<p>总结</p>
<p>RPC 主要用于公司内部的服务调用，性能消耗低，传输效率高，实现复杂。</p>
<p>HTTP 主要用于对外的异构环境，浏览器接口调用，App 接口调用，第三方接口调用等。</p>
<p>RPC 使用场景(大型的网站，内部子系统较多、接口非常多的情况下适合使用 RPC)：</p>
<p>长链接。不必每次通信都要像 HTTP 一样去 3 次握手，减少了网络开销。<br>注册发布机制。RPC 框架一般都有注册中心，有丰富的监控管理;发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。<br>安全性，没有暴露资源操作。<br>微服务支持。就是最近流行的服务化架构、服务化治理，RPC 框架是一个强力的支撑。</p>
]]></content>
      <categories>
        <category>开发框架</category>
      </categories>
      <tags>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title>常见数据结构和算法</title>
    <url>/2021/08/05/a-%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="常见数据结构"><a href="#常见数据结构" class="headerlink" title="常见数据结构"></a>常见数据结构</h2><p>根据数据访问的特点，可分为线性数据结构和非线性数据结构。</p>
<p>线性结构：数组、链表、栈、队列等。</p>
<p>非线性结构：散列表、树、堆、图等。</p>
<p><img src="https://i.loli.net/2021/08/20/sPgipbEXy4NtQZj.png" alt="image-20210820104323459"></p>
<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。</p>
<p>数组中元素的存储是按照先后顺序进行的，<strong>同时在内存中也是按照这个顺序进行连续存放。</strong></p>
<p>数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。</p>
<h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><p>链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。</p>
<p>链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。</p>
<p>每个结点包括两个部分：一个是存储数据元素的数据域，另一个是存储下一个结点地址的指针域。 相比与线性数据表结构，操作复杂。</p>
<p>由于不必须按顺序存储，链表在插入的时候可以达到 O(1)的复杂度，比另一种线性表顺序表快得多，但是<strong>查找一个节点或者访问特定编号的节点则需要 O(n)的时间</strong>，而线性表和顺序表相应的时间复杂度分别是 O(logn)和 O(1)。</p>
<p>链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。</p>
<p>这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。</p>
<p>一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。</p>
<p><img src="https://i.loli.net/2021/08/20/MHYs3ytOh1wdNif.png" alt="image-20210820104600004"></p>
<h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>跳表也叫跳跃表，是一种动态的数据结构。如果我们需要在有序链表中进行查找某个值，需要遍历整个链表，二分查找对链表不支持，二分查找的底层要求为数组，遍历整个链表的时间复杂度为 O(n)。</p>
<p>我们可以<strong>把链表改造成 B 树、红黑树、AVL 树等数据结构来提升查询效率</strong>，但是 B 树、红黑树、AVL 树这些数据结构实现起来非常复杂，里面的细节也比较多。</p>
<p>跳表就是为了提升有序链表的查询速度产生的一种动态数据结构，跳表相对 B 树、红黑树、AVL 树这些数据结构实现起来比较简单，但时间复杂度与 B 树、红黑树、AVL 树这些数据结构不相上下，时间复杂度能够达到 O(logn)。</p>
<p>跳表一般使用<strong>单链表来实现，这样比较节约空间</strong>。我使用双向链表来实现跳表，因为双向链表相对单向链表来说比较容易理解跳表的实现。</p>
<p>跳表的性质：</p>
<p>由很多层结构组成<br>每一层都是一个有序的链表<br>最底层(Level 1)的链表包含所有元素<br>如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。<br>从上面的对比中可以看出，链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从 O(n)提升至 O(logn)。</p>
<p><img src="https://i.loli.net/2021/08/20/3XwCZTpGfWFVg2d.png" alt="image-20210820104806454"></p>
<h3 id="栈和队列"><a href="#栈和队列" class="headerlink" title="栈和队列"></a>栈和队列</h3><h3 id="树"><a href="#树" class="headerlink" title="树"></a>树</h3><p>在二叉树的概念下又衍生出<strong>满二叉树和完全二叉树</strong>的概念</p>
<p><img src="https://i.loli.net/2021/08/20/WiLGwKbvPEm1StC.png" alt="image-20210820105029787"></p>
<p><strong>完全二叉树：</strong>除最后一层无任何子节点外，每一层上的所有结点都有两个子结点。也可以这样理解，除叶子结点外的所有结点均有两个子结点。节点数达到最大值，所有叶子结点必须在同一层上（除了最后一层结点，其它层的结点数都达到了最大值；同时最后一层的结点都是按照从左到右依次排布。</p>
<p><strong>满二叉树：</strong>若设二叉树的深度为 h，除第 h 层外，其它各层 (1～(h-1)层) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边（除了最后一层，其它层的结点都有两个子结点）。</p>
<h4 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h4><p>平衡二叉树又被称为 AVL 树，<strong>它是一棵二叉排序树</strong>，且具有以下性质：</p>
<p><strong>它是一棵空树或它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树</strong></p>
<p><strong>二叉排序树：</strong>是一棵空树，或者：</p>
<p><strong>若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</strong></p>
<p><strong>若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</strong></p>
<p>它的左、右子树也分别为二叉排序树。</p>
<p>树的高度：结点层次的最大值。</p>
<p><strong>二叉排序树意味着二叉树中的数据是排好序的，顺序为左结点&lt;根节点&lt;右结点，这表明二叉排序树的中序遍历结果是有序的。</strong></p>
<p> 平衡二叉树的产生是为了<strong>解决二叉排序树在插入时发生线性排列的现象</strong>。由于二叉排序树本身为有序，当插入一个有序程度十分高的序列时，生成的二叉排序树会持续在某个方向的字数上插入数据，导致最终的二叉排序树会退化为链表，从而使得二叉树的查询和插入效率恶化。</p>
<h4 id="二叉树的遍历方式"><a href="#二叉树的遍历方式" class="headerlink" title="二叉树的遍历方式"></a>二叉树的遍历方式</h4><p>先序遍历：先根节点-&gt;遍历左子树-&gt;遍历右子树</p>
<p>中序遍历：遍历左子树-&gt;根节点-&gt;遍历右子树</p>
<p>后序遍历：遍历左子树-&gt;遍历右子树-&gt;根节点</p>
<h4 id="深度优先搜索（DFS）与广度优先搜索（BFS）"><a href="#深度优先搜索（DFS）与广度优先搜索（BFS）" class="headerlink" title="深度优先搜索（DFS）与广度优先搜索（BFS）"></a>深度优先搜索（DFS）与广度优先搜索（BFS）</h4><p>实现：</p>
<p><strong>bfs</strong>＝队列，入队列，出队列 一次访问一条路径；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">queue.add(root);<br>   while (!queue.isEmpty())&#123;<br>       int size=queue.size();<br>       List&lt;Integer&gt; temp=new ArrayList&lt;&gt;();<br>       for (int i = 0; i &lt; size; i++) &#123;<br>           TreeNode poll = queue.poll();<br>           temp.add(poll.val);<br>           if (poll.left!=null)queue.offer(poll.left);<br>           if (poll.right!=null)queue.offer(poll.right);<br>       &#125;<br>       res.add(temp);<br>   &#125;<br></code></pre></td></tr></table></figure>

<p><strong>dfs</strong>&#x3D;栈，压栈，出栈 一次访问多条路径；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">//递归<br>public static void helper(TreeNode root,List&lt;Integer&gt;res) &#123;<br>    if (root == null) return;<br>    res.add(root.val);<br>    helper(root.left,res);<br>    helper(root.right,res);<br>&#125;<br></code></pre></td></tr></table></figure>

<p>前序遍历是中左右，每次先处理的是中间节点，那么先将跟节点放入栈中，然后将右孩子加入栈，再加入左孩子。这样出栈的时候才是中左右的顺序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">st.push(root);<br>   while (!st.isEmpty()) &#123;<br>       TreeNode node = st.pop();                       // 中 <br>       result.add(node-&gt;val);<br>       if (node.right) st.push(node.right);           // 右（空节点不入栈）<br>       if (node.left) st.push(node.left);             // 左（空节点不入栈）<br>   &#125;<br></code></pre></td></tr></table></figure>

<p>因为前序遍历的顺序是<strong>中左右</strong>，先访问的元素是中间节点，要处理的元素也是中间节点，所以才能写出相对简洁的代码，<strong>因为要访问的元素和要处理的元素顺序是一致的，都是中间节点。</strong></p>
<p>那么再看看中序遍历，中序遍历是<strong>左中右</strong>，先访问的是二叉树顶部的节点，然后一层一层向下访问，直到到达树左面的最底部，再开始处理节点（也就是在把节点的数值放进 result 数组中），这就造成了<strong>处理顺序和访问顺序是不一致的。</strong></p>
<p>那么在使用迭代法写中序遍历，就需要借用指针的遍历来帮助访问节点，栈则用来处理节点上的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">TreeNode cur = root;<br>     while (cur != NULL || !st.isEmpty()) &#123;<br>         if (cur != NULL) &#123; // 指针来访问节点，访问到最底层<br>             st.push(cur); // 将访问的节点放进栈<br>             cur = cur.left;                // 左<br>         &#125; else &#123;<br>             cur = st.pop(); // 从栈里弹出的数据，就是要处理的数据（放进result数组里的数据）<br>             result.add(cur.val);     // 中<br>             cur = cur.right;               // 右<br>         &#125;<br>     &#125;<br>     return result;<br></code></pre></td></tr></table></figure>

<p>​		1</p>
<p>​	2 	3</p>
<p>4	 5  6   7</p>
<p>1-2-4</p>
<p>再来看后序遍历，先序遍历是<strong>中左右</strong>，后续遍历是<strong>左右中</strong>，那么我们只需要调整一下先序遍历的代码顺序，就变成<strong>中右左</strong>的遍历顺序，然后在反转 result 数组，输出的结果顺序就是左右中了。</p>
<p>关系：</p>
<p>用 DFS 解决的问题都可以用 BFS 解决。<strong>DFS 易于编写（递归）</strong>，时间消耗较少但是容易发生爆栈，而 BFS 可以控制队列的长度。</p>
<h3 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h3><p>平衡二叉树（AVL）为了追求高度平衡，需要通过平衡处理使得左右子树的高度差必须小于等于 1。高度平衡带来的好处是能够提供更高的搜索效率，<strong>其最坏的查找时间复杂度都是 O(logN)<strong>。但是由于需要维持这份高度平衡，所付出的代价就是当对树种结点进行插入和删除时，</strong>需要经过多次旋转实现复衡</strong>。这导致 AVL 的<strong>插入和删除</strong>效率并不高。</p>
<p>为了解决这样的问题，能不能找一种结构能够兼顾搜索和插入删除的效率呢？红黑树可以解决。</p>
<p>红黑树具有五个特性：   </p>
<p>每个结点要么是红的要么是黑的。<br>根结点是黑的。<br>每个叶结点（叶结点即指树尾端 NIL 指针或 NULL 结点）都是黑的。<br>如果一个结点是红的，那么它的两个儿子都是黑的。<br>对于任意结点而言，其到叶结点树尾端 NIL 指针的每条路径都包含相同数目的黑结点。</p>
<p><img src="https://i.loli.net/2021/08/20/7TJMQVSFXtUiNBd.png" alt="image-20210820112252998"></p>
<p>红黑树通过将结点进行红黑着色，使得原本高度平衡的树结构被稍微打乱，平衡程度降低。红黑树不追求完全平衡，只要求达到部分平衡。这是一种折中的方案，大大提高了结点删除和插入的效率。</p>
<p><img src="https://i.loli.net/2021/08/20/X5xm7lJnV92RusH.png" alt="image-20210820112333170"></p>
<h3 id="散列表（hash-表）"><a href="#散列表（hash-表）" class="headerlink" title="散列表（hash 表）"></a>散列表（hash 表）</h3><p>散列表也叫哈希表，是一种通过键值对直接访问数据的机构。</p>
<p>散列表的实现原理正是映射的原理，通过设定的一个关键字和一个映射函数，就可以直接获得访问数据的地址，<strong>实现 O(1)的数据访问效率</strong>。在映射的过程中，事先设定的函数就是一个映射表，也可以称作散列函数或者哈希函数。</p>
<p>确定好散列函数之后，通过某个 key 值的确会得到一个唯一的 value 地址。但是却会出现一些特殊情况。即通过不同的 key 值可能会访问到同一个地址，这个现象称之为冲突。</p>
<p>冲突在发生之后，当在对不同的 key 值进行操作时会使得造成相同地址的数据发生覆盖或者丢失，是非常危险的。所以在设计散列表往往还需要采用冲突解决的办法。</p>
<p><strong>hash 冲突：</strong></p>
<p><strong>开放地址法（也叫开放寻址法）</strong>：实际上就是当需要存储值时，对 Key 哈希之后，发现这个地址已经有值了，这时该怎么办？不能放在这个地址，不然之前的映射会被覆盖。这时对计算出来的地址进行一个探测再哈希，比如往后移动一个地址，如果没人占用，就用这个地址。如果超过最大长度，则可以对总长度取余。这里移动的地址是产生冲突时的<strong>增列序量。</strong></p>
<p><strong>再哈希法：</strong>在产生冲突之后，使用关键字的其他部分继续计算地址，如果还是有冲突，则继续使用其他部分再计算地址。这种方式的缺点是时间增加了。</p>
<p><strong>链地址法：</strong>链地址法其实就是对 Key 通过哈希之后落在同一个地址上的值，做一个链表。其实在很多高级语言的实现当中，也是使用这种方式处理冲突的。</p>
<p><strong>公共溢出区：</strong>这种方式是建立一个公共溢出区，当地址存在冲突时，把新的地址放在公共溢出区里。目前比较<strong>常用的冲突解决方法是链地址法，一般可以通过数组和链表的结合达到冲突数据缓存的目的。</strong></p>
<p>考虑到链表过长造成的问题，<strong>还可以使用红黑树替换链表进行冲突数据的处理操作</strong>，来提高散列表的查询稳定性。</p>
<h3 id="B-树"><a href="#B-树" class="headerlink" title="B 树"></a>B 树</h3><p>B 树是一种多路搜索树，它的每个节点可以拥有多于两个孩子节点。M 路的 B 树最多拥有 M 个孩子节点。</p>
<p><img src="https://i.loli.net/2021/08/20/k3M98f5eJFWzZjH.png" alt="image-20210820113238166"></p>
<p>文件系统和数据库的索引都是<strong>存在硬盘上的</strong>，并且如果数据量大的话，不一定能一次性加载到内存中</p>
<p>如果一棵树都无法一次性加载进内存，该怎么查找呢？</p>
<p>B 树的多路存储的威力就在于此，<strong>可以每次加载 B 树的一个节点</strong>，然后，一步步往下找。</p>
<p>查找时候，每次载入一个节点进内存就行，<strong>如果在内存中，红黑树比 B 树效率更高，但是涉及到磁盘操作，B 树就更优了。</strong></p>
<p>B+树是在 B 树基础上进行改造的，<strong>它的数据都在叶子节点</strong>，同时叶子节点之间还加了指针形成链表。</p>
<p>B+树在数据库的索引中用的比较多，如果数据库 select 数据，不一定只选一条，很多时候选多条，比如按照 id 排序后选 10 条。</p>
<p><strong>这样如果是多条的话，B 树需要做局部的中序遍历，可能需要跨层访问，</strong>而 B+树由于所有数据都在叶子节点，不用跨层，同时由于有链表结构，只需要找到首尾，通过链表就能把所有数据取出来了。</p>
<p><strong>存储密度：顺序存储结构是一个一个挨着，基本上是一个空间对应一个数据；而链式存储由于每个结点都含有指针区域，故存储空间占用比较大，存储密度也就相对来说比较少。</strong></p>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><p>堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最坏，最好，平均时间复杂度均为 O(nlogn)，它是不稳定排序。</p>
<p>堆的性质<br>① 是一棵完全二叉树<br>② 每个节点的值都大于或等于其子节点的值，为最大堆；反之为最小堆。</p>
<p><img src="https://i.loli.net/2021/08/17/zhuLKPnZQDM6VIx.png" alt="image-20210817155031261"></p>
<p>一般用数组来表示堆，下标为 i 的结点的父结点下标为(i-1)&#x2F;2；其左右子结点分别为 (2i + 1)、(2i + 2)</p>
<p><img src="https://i.loli.net/2021/08/16/FBkb4rJcL5S9IGy.png" alt="image-20210816150908734"></p>
<p>堆排序的基本思想是：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余 n-1 个元素重新构造成一个堆，这样会得到 n 个元素的次小值。如此反复执行，便能得到一个有序序列了</p>
<p>a.将<strong>无序序列</strong>构建成一个堆，根据升序降序需求选择大顶堆或小顶堆;</p>
<p>b.将堆顶元素与末尾元素交换，<strong>将最大元素”沉”到数组末端;</strong></p>
<p>c.重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static void main(String[] args) &#123;<br>       int[] nums = &#123;4, 10, 3, 6, 1, 2&#125;;<br>       heapsort(nums, nums.length);<br>       System.out.println(Arrays.toString(nums));<br>   &#125;<br><br>   public static void heapsort(int[] tree, int n) &#123;<br>       build_heap(tree, n);<br>       for (int i = n - 1; i &gt;= 0; i--) &#123;<br>           swap(tree, i, 0);<br>           heapify(tree, i, 0);<br>       &#125;<br>   &#125;<br><br>   public static void build_heap(int[] nums, int n) &#123;<br>       int last = n - 1;<br>       int par = (last - 1) / 2;<br>       for (int j = par; j &gt;= 0; j--) &#123;<br>           heapify(nums, n, j);<br>       &#125;<br>   &#125;<br><br>   public static void heapify(int[] nums, int n, int i) &#123;<br>       if (i &gt;= n) return;<br>       int c1 = 2 * i + 1;<br>       int c2 = 2 * i + 2;<br>       int max = i;<br>       if (c1 &lt; n &amp;&amp; nums[c1] &gt; nums[max]) &#123;<br>           max = c1;<br>       &#125;<br>       if (c2 &lt; n &amp;&amp; nums[c2] &gt; nums[max]) &#123;<br>           max = c2;<br>       &#125;<br>       if (max != i) &#123;<br>           swap(nums, i, max);<br>           heapify(nums, n, max);<br>       &#125;<br>   &#125;<br></code></pre></td></tr></table></figure>

<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>一.初始化建堆<br>　　初始化建堆只需要对二叉树的非叶子节点调用 build_heap()函数，由下至上，由右至左选取非叶子节点来调用函数。那么倒数第二层的最右边的非叶子节点就是最后一个非叶子结点。<br>　　假设高度为 k，则从倒数第二层右边的节点开始，这一层的节点都要执行子节点比较然后交换（如果顺序是对的就不用交换）；倒数第三层呢，则会选择其子节点进行比较和交换，如果没交换就可以不用再执行下去了。如果交换了，那么又要选择一支子树进行比较和交换；高层也是这样逐渐递归。<br>　　那么总的时间计算为：s &#x3D; 2^( i - 1 ) * ( k - i )；其中 i 表示第几层，2^( i - 1) 表示该层上有多少个元素，( k - i) 表示子树上要下调比较的次数。<br>　　S &#x3D; 2^(k-2) * 1 + 2^(k-3)2……..+2(k-2)+2^(0)*(k-1) &#x3D;&#x3D;&#x3D;&gt; 因为叶子层不用交换，所以 i 从 k-1 开始到 1；<br>　　S &#x3D; 2^k -k -1；又因为 k 为完全二叉树的深度，而 log(n) &#x3D;k，把此式带入；<br>　　得到：S &#x3D; n - log(n) -1，所以时间复杂度为：O(n)</p>
<p>二.排序重建堆<br>　　在取出堆顶点放到对应位置并把原堆的最后一个节点填充到堆顶点之后，需要对堆进行重建，只需要对堆的顶点调用 heapify()函数。<br>　　每次重建意味着有一个节点出堆，所以需要将堆的容量减一。重建堆一共需要 n-1 次循环，每次循环的比较次数为 log(i)，则相加为：log2+log3+……+log(n-1)+log(n)≈log(n!)。可以证明 log(n!)和 nlog(n)是同阶函数：<br>∵(n&#x2F;2)^n&#x2F;2≤n!≤n^n,∵(n&#x2F;2)^n&#x2F;2≤n!≤n^n,<br>∴n&#x2F;4log(n)&#x3D;n&#x2F;2log(n1&#x2F;2)≤n&#x2F;2log(n&#x2F;2)≤log(n!)≤nlog(n)∴n&#x2F;4log⁡(n)&#x3D;n&#x2F;2log⁡(n1&#x2F;2)≤n&#x2F;2log⁡(n&#x2F;2)≤log⁡(n!)≤nlog⁡(n)<br>　　所以时间复杂度为 O(nlogn)</p>
<p>　　初始化建堆的时间复杂度为 O(n)，排序重建堆的时间复杂度为 nlog(n)，所以总的时间复杂度为**O(n+nlogn)&#x3D;O(nlogn)**。另外堆排序的比较次数和序列的初始状态有关，但只是在序列初始状态为堆的情况下比较次数显著减少，在序列有序或逆序的情况下比较次数不会发生明显变化。</p>
<h3 id="快排"><a href="#快排" class="headerlink" title="快排"></a>快排</h3><p>选取基准值，左边小于其，右边大于其。左右子序列重复此过程。<br>大量数据时表现良好。<br>数据越乱表现越好。数据接近有序是退化成冒泡排序。<br>一种不稳定的排序方式。<br>也是一种交换排序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int[] sort(int[] nums) &#123;<br>    quicksort(nums, 0, nums.length - 1);<br>    return nums;<br>&#125;<br><br>private static void quicksort(int[] nums, int left, int right) &#123;<br>    if (left &gt;= right) return;<br>    int pindex = partition(nums, left, right);<br>    quicksort(nums, left, pindex - 1);<br>    quicksort(nums, pindex + 1, right);<br>&#125;<br><br>private static int partition(int[] nums, int left, int right) &#123;<br>    Random r = new Random();<br>    int rindex = left + r.nextInt(right - left + 1);<br>    swap(nums, rindex, left);<br><br>    int pivot = nums[left];<br>    int l = left;<br>    for (int i = left + 1; i &lt;= right; i++) &#123;<br>        if (nums[i] &lt; pivot) &#123;<br>            l++;<br>            swap(nums, i, l);<br>        &#125;<br>    &#125;<br>    swap(nums, left, l);<br>    return l;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><p>每次都选择最大（最小）的元素放在最前面，依次往后。<br>堆排序亦是选择排序：利用堆来选择数据。时间复杂度降低。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">for (int i = 0; i &lt; len; i++) &#123;<br>    int min = i;<br>    for (int j = i + 1; j &lt; len; j++) &#123;<br>        if (nums[j] &lt; nums[min]) &#123;<br>            min = j;<br>        &#125;<br>    &#125;<br>    swap(nums, min, i);<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><p>始终维持一个有序的队列。</p>
<p>元素越接近于稳定时，效率越高。<br>稳定的排序方式。<br>希尔排序是对直接插入排序的优化。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">for (int i = 1; i &lt; len; i++) &#123;//第一个数有序<br>    int temp=nums[i];<br>    int j=i;<br>    while (j&gt;0&amp;&amp;nums[j-1]&gt;temp)&#123;<br>        nums[j]=nums[j-1];<br>        j--;<br>    &#125;<br>    nums[j]=temp;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><p>比较相邻两个值的大小，出现逆序就交换。<br>稳定的排序。<br>慢：每次只能移动相邻的两个数据。<br>一种交换排序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">for (int i = 0; i &lt; len; i++) &#123;//扫苗多少趟<br>    for (int j = 0; j &lt; len-1; j++) &#123;<br>        if (nums[j] &gt; nums[j + 1]) &#123;<br>            swap(nums, j, j + 1);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>分治法的应用。<br>合并有序的子序列。<br>o(n)的空间复杂度。更多考虑解决磁盘外部排序的问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int[] sort(int[] nums)&#123;<br>    int[] temp=new int[nums.length];<br>    mergesort(nums,0,nums.length-1,temp);<br>    return nums;<br>&#125;<br><br>private static void mergesort(int[] nums, int left, int right, int[] temp) &#123;<br>    if (left&gt;=right)return;<br>    int mid=left+(right-left)&gt;&gt;1;<br>    mergesort(nums, left,mid,temp);<br>    mergesort(nums,mid+1,right,temp);<br>    //数组有序，不用merge<br>    if (nums[mid]&lt;=nums[mid+1])&#123;<br>        return;<br>    &#125;<br>    merge(nums,left,mid,right,temp);<br>&#125;<br><br>private static void merge(int[] nums, int left, int mid, int right, int[] temp) &#123;<br>    //System.arraycopy(nums,left,temp,left,right-left+1);<br>    for (int i = left; i &lt;= right; i++) &#123;<br>        temp[i]=nums[i];<br>    &#125;<br>    //左右两半的起点<br>    int i=left;<br>    int j=mid+1;<br>    for (int k = left; k &lt;= right; k++) &#123;<br>        if (i==mid+1)nums[k]=temp[j++];<br>        else if (j==right+1)nums[k]=temp[i++];<br>        else if (temp[i]&lt;=temp[j])nums[k]=temp[i++];<br>        else nums[k]=temp[j++];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><ul>
<li>稳定性：相同数值的元素经过排序以后，相对的位置保持不变。</li>
<li>内部排序：数据全部放在内存中。</li>
<li>外部排序：内存装不下</li>
</ul>
<p><img src="https://i.loli.net/2021/08/05/ojG8w5gRxvYDzrB.png" alt="image-20210805144637116"></p>
<h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2><h3 id="二叉树遍历"><a href="#二叉树遍历" class="headerlink" title="二叉树遍历"></a>二叉树遍历</h3><blockquote>
<p>深度优先便利–广度优先遍历</p>
</blockquote>
<blockquote>
<p>前序：preorder 根-左-右</p>
</blockquote>
<blockquote>
<p>中序：inorder 左-根-右</p>
</blockquote>
<blockquote>
<p>后序：postorder 左-右-根</p>
</blockquote>
<blockquote>
<p>层序：levelorder</p>
</blockquote>
<ul>
<li>前序遍历</li>
<li>递归</li>
<li>迭代</li>
<li>中序遍历</li>
<li>递归</li>
<li>迭代</li>
<li>后序遍历</li>
<li>递归</li>
<li>迭代</li>
</ul>
<h4 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">//递归版本<br>public static List&lt;Integer&gt; preorder2(TreeNode root)&#123;<br>    List&lt;Integer&gt; res = new ArrayList&lt;&gt;();<br>    helper(root,res);<br>    return res;<br>&#125;<br>public static void helper(TreeNode root,List&lt;Integer&gt;res) &#123;<br>    if (root == null) return;<br>    res.add(root.val);<br>    helper(root.left,res);<br>    helper(root.right,res);<br>&#125;<br><br>public static void preorder(TreeNode root)&#123;<br>    if (root==null)return;<br>    System.out.print(root.val+&quot; &quot;);<br>    preorder(root.left);<br>    preorder(root.right);<br>&#125;<br>//迭代统一写法<br>public static List&lt;Integer&gt; preorder3(TreeNode root)&#123;<br>    List&lt;Integer&gt; res=new ArrayList&lt;&gt;();<br>    if (root==null)return res;<br>    Stack&lt;TreeNode&gt; stack=new Stack&lt;&gt;();<br>    stack.push(root);<br>    while (!stack.isEmpty())&#123;<br>        TreeNode top = stack.peek();<br>        if (top!=null)&#123;<br>            stack.pop();<br>            if (top.right!=null)stack.push(top.right);<br>            if (top.left!=null)stack.push(top.left);<br>            stack.push(top);<br>            stack.push(null);<br>        &#125;else&#123;<br>            stack.pop();<br>            TreeNode pop = stack.pop();<br>            res.add(pop.val);<br>        &#125;<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="层序遍历"><a href="#层序遍历" class="headerlink" title="层序遍历"></a>层序遍历</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static List&lt;List&lt;Integer&gt;&gt; levelorder(TreeNode root)&#123;<br>    if (root==null)return null;<br>    List&lt;List&lt;Integer&gt;&gt;res=new ArrayList&lt;&gt;();<br>    LinkedList&lt;TreeNode&gt; queue=new LinkedList&lt;&gt;();<br>    queue.add(root);<br>    while (!queue.isEmpty())&#123;<br>        int size=queue.size();<br>        List&lt;Integer&gt; temp=new ArrayList&lt;&gt;();<br>        for (int i = 0; i &lt; size; i++) &#123;<br>            TreeNode poll = queue.poll();<br>            temp.add(poll.val);<br>            if (poll.left!=null)queue.offer(poll.left);<br>            if (poll.right!=null)queue.offer(poll.right);<br>        &#125;<br>        res.add(temp);<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>右视图-只需要判断一下是否是最后一个。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain"> for (int i = 0; i &lt; size; i++) &#123;<br>    TreeNode node = queue.poll();<br>    if (node.left != null) queue.offer(node.left);<br>    if (node.right != null) queue.offer(node.right);<br>    if (i == size - 1)  //将当前层的最后一个节点放入结果列表<br>        res.add(node.val);<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li><h5 id="n-叉数层序遍历"><a href="#n-叉数层序遍历" class="headerlink" title="n 叉数层序遍历"></a>n 叉数层序遍历</h5></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) &#123;<br>    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();<br>    Deque&lt;Node&gt; que = new LinkedList&lt;&gt;();<br>    if (root == null) return res;<br>    que.offer(root);<br>    while (!que.isEmpty()) &#123;<br>        int size = que.size();<br>        List&lt;Integer&gt; temp = new ArrayList&lt;&gt;();<br>        for (int i = 0; i &lt; size; i++) &#123;<br>            Node poll = que.poll();<br>            temp.add(poll.val);<br><br>            List&lt;Node&gt; children = poll.children;<br>            if (children == null || children.size() == 0) &#123;<br>                continue;<br>            &#125;<br>            for (Node child : children) &#123;<br>                if (child != null) que.offer(child);<br>            &#125;<br>        &#125;<br>        res.add(temp);<br>    &#125;<br>    return res;<br>&#125;<br><br>class Node &#123;<br>    public int val;<br>    public List&lt;Node&gt; children;<br>    public Node() &#123;<br>    &#125;<br>    public Node(int _val) &#123;<br>        val = _val;<br>    &#125;<br>    public Node(int _val, List&lt;Node&gt; _children) &#123;<br>        val = _val;<br>        children = _children;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li><h5 id="锯齿形层序遍历"><a href="#锯齿形层序遍历" class="headerlink" title="锯齿形层序遍历"></a>锯齿形层序遍历</h5></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">/**<br> * z字形遍历-偶数层倒序遍历<br> * @param root<br> * @return<br> */<br>public static List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) &#123;<br>    List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();<br>    if (root == null) &#123;<br>        return result;<br>    &#125;<br>    LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();<br>    queue.add(root);<br>    while (!queue.isEmpty()) &#123;<br>        // 该层的节点数量<br>        int size = queue.size();<br>        List&lt;Integer&gt; temp = new ArrayList&lt;&gt;();<br>        for (int i = 0; i &lt; size; i++) &#123;<br>            TreeNode node = queue.poll();<br>            // 根据层次来判断顺序<br>            if (result.size() % 2 == 0) &#123;<br>                temp.add(node.val);<br>            &#125; else &#123;<br>                temp.add(0, node.val);//插到最前面<br>            &#125;<br>            if (node.left != null) queue.add(node.left);<br>            if (node.right != null)queue.add(node.right);<br>        &#125;<br>        result.add(temp);<br>    &#125;<br>    return result;<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>理解使用队列进行层序遍历的本质。</li>
<li>z 字形遍历时，result.size 一开始是 0，第二层时为 1，所以奇数时插到前面。</li>
</ul>
<h4 id="最近公共祖先"><a href="#最近公共祖先" class="headerlink" title="最近公共祖先"></a>最近公共祖先</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static TreeNode lowestCommonAncestor2(TreeNode root, TreeNode p, TreeNode q) &#123;<br>    return helper(root,p,q);<br>&#125;<br>private static TreeNode helper(TreeNode root, TreeNode p, TreeNode q) &#123;<br>    if (root==null||root==p||root==q)return root;<br>    TreeNode left=helper(root.left,p,q);<br>    TreeNode right=helper(root.right,p,q);<br>    if (left!=null&amp;&amp;right!=null)return root;<br>    if (left==null)return right;<br>    return left;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="两节点最近路径"><a href="#两节点最近路径" class="headerlink" title="两节点最近路径"></a>两节点最近路径</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static List&lt;Integer&gt; findDistance(TreeNode root, TreeNode p, TreeNode q) &#123;<br>    if (p == q) &#123;<br>        return new ArrayList&lt;&gt;(p.val);<br>    &#125;<br>    List&lt;Integer&gt; res = new ArrayList&lt;&gt;();<br>    List&lt;TreeNode&gt; list1 = findPath(root, p);<br>    List&lt;TreeNode&gt; list2 = findPath(root, q);<br><br>    //单独考虑在同一条路径的情况<br>    if (list1.containsAll(list2) || list2.containsAll(list1)) &#123;<br>        int max = Math.max(list1.size(), list2.size());<br>        List&lt;TreeNode&gt; llist = list1.size() == max ? list1 : list2;<br>        List&lt;TreeNode&gt; slist = list1.size() == max ? list2 : list1;<br>        for (int i = 0; i &lt; slist.size(); i++) &#123;<br>            System.out.print(slist.get(i).val+&quot; &quot;);<br>        &#125;<br>        System.out.println();<br>        for (int i = 0; i &lt; llist.size(); i++) &#123;<br>            System.out.print(llist.get(i).val+&quot; &quot;);<br>        &#125;<br>        for (int i = slist.size()-1; i &lt; llist.size(); i++) &#123;<br>            res.add(llist.get(i).val);<br>        &#125;<br>    &#125; else &#123;<br>        //去重<br>        int lastSame = 0;<br>        for (int i = 0; i &lt; list1.size(); i++) &#123;<br>            if (list1.get(i) == list2.get(i)) &#123;<br>                lastSame = i;<br>            &#125; else &#123;<br>                break;<br>            &#125;<br>        &#125;<br>        for (int i = list1.size() - 1; i &gt; lastSame; i--) &#123;<br>            res.add(list1.get(i).val);<br>        &#125;<br>        for (int i = lastSame; i &lt; list2.size(); i++) &#123;<br>            res.add(list2.get(i).val);<br>        &#125;<br>    &#125;<br>    return res;<br>&#125;<br><br>private static List&lt;TreeNode&gt; findPath(TreeNode root, TreeNode node) &#123;<br>    List&lt;TreeNode&gt; res = new ArrayList&lt;&gt;();<br>    getPathFromRoot(root, node, res);<br>    return res;<br>&#125;<br><br>public static boolean getPathFromRoot(TreeNode root, TreeNode node, List&lt;TreeNode&gt; pathArray) &#123;<br>    if (root == null || node == null) return false;<br>    pathArray.add(root);<br>    if (root == node) return true;<br>    if (root.left != null &amp;&amp; getPathFromRoot(root.left, node, pathArray) == true)<br>        return true;<br>    if (root.right != null &amp;&amp; getPathFromRoot(root.right, node, pathArray) == true)<br>        return true;<br>    //回溯<br>    pathArray.remove(pathArray.size() - 1);<br>    return false;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="是平衡二叉树吗？"><a href="#是平衡二叉树吗？" class="headerlink" title="是平衡二叉树吗？"></a>是平衡二叉树吗？</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static boolean isBalanced(TreeNode root) &#123;<br>    return getHeight(root) != -1;<br>&#125;<br>//返回以该节点为根节点二叉树的深度<br>private static int getHeight(TreeNode root) &#123;<br>    if (root==null)return 0;<br>    int left=getHeight(root.left);<br>    if (left==-1)return -1;<br>    int right=getHeight(root.right);<br>    if (right==-1)return -1;<br>    if (Math.abs(left-right)&gt;1)return -1;<br>    return Math.max(left,right)+1;<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li><p>最大路径和？（任意节点出发）</p>
</li>
<li><p>最大深度</p>
</li>
<li><p>前序遍历中序（中序和后序）遍历构造二叉树</p>
</li>
<li><p>路径和等于 target 的路径（根节点出发）</p>
</li>
<li><p>翻转二叉树</p>
</li>
<li><p>根节点到叶子结点的数字之和</p>
</li>
<li><p>对称二叉树？</p>
</li>
<li><p>二叉搜索树？</p>
</li>
<li><p>二叉搜索树第 k 大节点？</p>
</li>
</ul>
<h4 id="第二小的节点（根节点-x3D-左右节点较小的值）"><a href="#第二小的节点（根节点-x3D-左右节点较小的值）" class="headerlink" title="第二小的节点（根节点&#x3D;左右节点较小的值）"></a>第二小的节点（根节点&#x3D;左右节点较小的值）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public int findSecondMinimumValue(TreeNode root) &#123;<br>    if (root == null || (root.left == null &amp;&amp; root.right == null)) return -1;//没有最小节点<br>    //找出候选数，默认就是子节点值，如果子节点值和root值相同，递归，在子树中寻找候选数<br>    int left = root.left.val;<br>    int right = root.right.val;<br>    if (root.left.val == root.val) left = findSecondMinimumValue(root.left);<br>    if (root.right.val == root.val) right = findSecondMinimumValue(root.right);<br>    //如果左右候选数都正常，返回较小值就可<br>    if (left != -1 &amp;&amp; right != -1) &#123;<br>        return Math.min(left, right);<br>    &#125;<br>    //如果候选数有-1，说明整个子树中没有可供候选的数<br>    if (left != -1) &#123;<br>        //左子树正常，答案就是左边的候选数<br>        return left;<br>    &#125; else &#123;<br>        //右子树正常，返回答案<br>        //或者右子树也没有候选数，返回-1，即right<br>        return right;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="路径总和"><a href="#路径总和" class="headerlink" title="路径总和"></a>路径总和</h4><h5 id="路径总和-3-不限起点"><a href="#路径总和-3-不限起点" class="headerlink" title="路径总和 3-不限起点"></a>路径总和 3-不限起点</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">int pathnumber;<br>public int pathSum(TreeNode root, int sum) &#123;<br>    if (root == null) return 0;<br>    Sum(root, sum);<br>    pathSum(root.left, sum);<br>    pathSum(root.right, sum);<br>    return pathnumber;<br>&#125;<br><br><br>public void Sum(TreeNode root, int sum) &#123;<br>    if (root == null) return;<br>    sum -= root.val;<br>    if (sum == 0) &#123;<br>        pathnumber++;<br>    &#125;<br>    Sum(root.left, sum);<br>    Sum(root.right, sum);<br>&#125;<br></code></pre></td></tr></table></figure>

<h5 id="路径总和-2（根节点到叶子节点有无）"><a href="#路径总和-2（根节点到叶子节点有无）" class="headerlink" title="路径总和 2（根节点到叶子节点有无）"></a>路径总和 2（根节点到叶子节点有无）</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static boolean hasPathSum2(TreeNode root, int sum) &#123;<br>    if (root == null) return false;<br>    return traversal(root, sum - root.val);<br>&#125;<br><br>private static boolean traversal(TreeNode cur, int count) &#123;<br>    if (cur.left == null &amp;&amp; cur.right == null &amp;&amp; count == 0)return true;<br>    if (cur.left == null &amp;&amp; cur.right == null) return false;<br>    if (cur.left != null) &#123;<br>        count = count - cur.left.val;<br>        if (traversal(cur.left, count)) return true;<br>        count = count + cur.left.val;<br>    &#125;<br>    if (cur.right != null) &#123;<br>        count = count - cur.right.val;<br>        if (traversal(cur.right, count)) return true;<br>        count = count + cur.right.val;//回溯<br>    &#125;<br>    return false;<br>&#125;<br><br>public static boolean hasPathSum(TreeNode root, int sum) &#123;<br>    if (root == null) return false;<br>    if (root.left == null &amp;&amp; root.right == null &amp;&amp; sum == root.val) &#123;<br>        return true;<br>    &#125;<br>    boolean l = hasPathSum(root.left, sum - root.val);<br>    boolean r = hasPathSum(root.right, sum - root.val);<br>    return l || r;<br>&#125;<br></code></pre></td></tr></table></figure>

<h5 id="路径总和（打印上一题的路径）"><a href="#路径总和（打印上一题的路径）" class="headerlink" title="路径总和（打印上一题的路径）"></a>路径总和（打印上一题的路径）</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123;<br>    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();<br>    dfs(root, sum, 0, new ArrayList&lt;&gt;(), res);<br>    return res;<br>&#125;<br><br>private static void dfs(TreeNode root, int sum, int total,<br>                        List&lt;Integer&gt; list, List&lt;List&lt;Integer&gt;&gt; res) &#123;<br>    if (root == null) return;<br>    list.add(root.val);<br>    total = total + root.val;<br>    if (root.left == null &amp;&amp; root.right == null) &#123;<br>        if (sum == total) &#123;<br>            res.add(new ArrayList&lt;&gt;(list));<br>        &#125;<br>        list.remove(list.size() - 1);<br>        return;<br>    &#125;<br>    dfs(root.left, sum, total, list, res);<br>    dfs(root.right, sum, total, list, res);<br>    list.remove(list.size() - 1);<br>&#125;<br></code></pre></td></tr></table></figure>

<h5 id="路径总和（打印所有路径）"><a href="#路径总和（打印所有路径）" class="headerlink" title="路径总和（打印所有路径）"></a>路径总和（打印所有路径）</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public List&lt;String&gt; binaryTreePaths(TreeNode root) &#123;<br>    List&lt;String&gt; res = new ArrayList&lt;&gt;();<br>    if (root == null)return res;<br>    List&lt;Integer&gt; paths = new ArrayList&lt;&gt;();<br>    traversal(root, paths, res);<br>    return res;<br>&#125;<br><br>private void traversal(TreeNode root, List&lt;Integer&gt; paths, List&lt;String&gt; res) &#123;<br>    paths.add(root.val);<br>    // 叶子结点<br>    if (root.left == null &amp;&amp; root.right == null) &#123;<br>        StringBuilder sb = new StringBuilder();<br>        for (int i = 0; i &lt; paths.size() - 1; i++) &#123;<br>            sb.append(paths.get(i)).append(&quot;-&gt;&quot;);<br>        &#125;<br>        sb.append(paths.get(paths.size() - 1));<br>        res.add(sb.toString());<br>        return;<br>    &#125;<br>    if (root.left != null) &#123;<br>        traversal(root.left, paths, res);<br>        paths.remove(paths.size() - 1);// 回溯<br>    &#125;<br>    if (root.right != null) &#123;<br>        traversal(root.right, paths, res);<br>        paths.remove(paths.size() - 1);// 回溯<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h2 id="红黑树-1"><a href="#红黑树-1" class="headerlink" title="红黑树"></a>红黑树</h2><p>红黑树的本质其实也是对概念模型：<strong>2-3-4 树</strong>的一种实现。</p>
<p><strong>2-3-4 树是阶数为 4 的 B 树</strong>，B 树，全名 BalanceTree，平衡树。这种结构主要用来做查找。</p>
<p>红黑树也是<strong>二叉查找树</strong>，它是<strong>自平衡</strong>的二叉查找树，在进行插入和删除等可能会破坏树的平衡的操作时，需要重新自处理达到平衡状态。</p>
<p>红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：</p>
<p>性质 1：每个节点要么是黑色，要么是红色。<br>性质 2：根节点是黑色。<br>性质 3：每个叶子节点（NIL）是黑色。<br>性质 4：每个红色结点的两个子结点一定都是黑色。<br>性质 5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。</p>
<h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>双堆找中位数：</p>
<p>如果一个数字要添加到小根堆，就先添加到大根堆，再将大根堆堆顶的元素转移至小根堆；反之亦然，以此能够保证小根堆中的元素永远大于大根堆中的元素。</p>
<h2 id="链表-1"><a href="#链表-1" class="headerlink" title="链表"></a>链表</h2><h3 id="单链表-1"><a href="#单链表-1" class="headerlink" title="单链表+1"></a>单链表+1</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode plusOne(ListNode head) &#123;<br>      //翻转链表<br>      ListNode newHead = null;<br>      while (head != null) &#123;<br>          ListNode temp = head.next;<br>          head.next = newHead;<br>          newHead = head;<br>          head = temp;<br>      &#125;<br><br>      int count = 1;<br>      ListNode temp = newHead;<br>      while (count &gt; 0) &#123;<br>          temp.val += count;<br>          count = 0;<br>          if (temp.val &gt;= 10) &#123;<br>              temp.val -= 10;<br>              count = 1;<br>          &#125;<br>          if (count &gt; 0 &amp;&amp; temp.next == null) &#123;<br>              temp.next = new ListNode(count);<br>              count = 0;<br>          &#125;<br>          temp = temp.next;<br>      &#125;<br>      //再次反转<br>      head = null;<br>      while (newHead != null) &#123;<br>          temp = newHead.next;<br>          newHead.next = head;<br>          head = newHead;<br>          newHead = temp;<br>      &#125;<br>      return head;<br>  &#125;<br></code></pre></td></tr></table></figure>

<h3 id="反转链表"><a href="#反转链表" class="headerlink" title="反转链表"></a>反转链表</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode reverseList(ListNode head) &#123;<br>    ListNode cur = head;<br>    ListNode pre = null;<br>    ListNode temp = null;<br>    while (cur != null) &#123;<br>        temp = cur.next;<br>        cur.next = pre;<br>        pre = cur;<br>        cur = temp;<br>    &#125;<br>    return pre;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="k-个一组反转链表"><a href="#k-个一组反转链表" class="headerlink" title="k 个一组反转链表"></a>k 个一组反转链表</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode reverseKGroup(ListNode head, int k) &#123;<br>    ListNode dummy = new ListNode(0);<br>    dummy.next = head;<br>    ListNode pre = dummy;<br>    ListNode end = dummy;<br>    while (end.next != null) &#123;<br>        for (int i = 0; i &lt; k &amp;&amp; end != null; i++) &#123;<br>            end = end.next;//分组，end指向小组最后一个节点<br>        &#125;<br>        if (end == null) &#123;<br>            break;//链表长度小于k，不翻转<br>        &#125;<br>        ListNode next = end.next;//下一组起点<br>        end.next = null;//断开<br>        ListNode start = pre.next;//要翻转的头结点<br><br>        pre.next = reverse(start);<br>        start.next = next;<br>        pre = start;//要翻转节点的上一个节点<br>        end = start;<br>    &#125;<br>    return dummy.next;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="环形链表"><a href="#环形链表" class="headerlink" title="环形链表"></a>环形链表</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode detectCycle(ListNode head) &#123;<br>       ListNode fast = head;<br>       ListNode slow = head;<br>       while (true) &#123;<br>           if (fast == null || fast.next == null) return null;//无环<br>           fast = fast.next.next;<br>           slow = slow.next;<br>           if (fast == slow) break;<br>       &#125;<br>       //到这里一定有环<br>       fast = head;<br>       while (slow != fast) &#123;<br>           slow = slow.next;<br>           fast = fast.next;<br>       &#125;<br>       return slow;<br>   &#125;<br></code></pre></td></tr></table></figure>

<h3 id="链表相交"><a href="#链表相交" class="headerlink" title="链表相交"></a>链表相交</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123;<br>       if (headA == null || headB == null) return null;<br>       ListNode a = headA;<br>       ListNode b = headB;<br>       while (a != b) &#123;<br>           a = a == null ? headB : a.next;<br>           b = b == null ? headA : b.next;<br>       &#125;<br>       return a;<br>   &#125;<br></code></pre></td></tr></table></figure>



<h3 id="合并链表"><a href="#合并链表" class="headerlink" title="合并链表"></a>合并链表</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode mergeTwoLists(ListNode n1, ListNode n2) &#123;<br>    ListNode dummy = new ListNode(-1);<br>    ListNode head = dummy;<br>    while (n1 != null &amp;&amp; n2 != null) &#123;<br>        if (n1.val &gt;= n2.val) &#123;<br>            head.next = n2;<br>            n2 = n2.next;<br>        &#125; else &#123;<br>            head.next = n1;<br>            n1 = n1.next;<br>        &#125;<br>        head = head.next;<br>    &#125;<br>    if (n1 == null) &#123;<br>        head.next = n2;<br>    &#125; else &#123;<br>        head.next = n1;<br>    &#125;<br>    return dummy.next;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="合并-k-个有序链表"><a href="#合并-k-个有序链表" class="headerlink" title="合并 k 个有序链表"></a>合并 k 个有序链表</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static ListNode mergeKLists(ListNode[] lists) &#123;<br>    if (lists.length == 0) return null;<br>    ListNode dummyHead = new ListNode(0);<br>    ListNode curr = dummyHead;<br>    PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;(new Comparator&lt;ListNode&gt;() &#123;<br>        @Override<br>        public int compare(ListNode o1, ListNode o2) &#123;<br>            return o1.val - o2.val;<br>        &#125;<br>    &#125;);<br>    for (ListNode list : lists) &#123;<br>        if (list == null) continue;<br>        pq.add(list);<br>    &#125;<br><br>    while (!pq.isEmpty()) &#123;<br>        ListNode nextNode = pq.poll();<br>        curr.next = nextNode;<br>        curr = curr.next;<br>        if (nextNode.next != null) &#123;<br>            pq.add(nextNode.next);<br>        &#125;<br>    &#125;<br>    return dummyHead.next;<br>&#125;<br></code></pre></td></tr></table></figure>



<h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><h3 id="大数加法"><a href="#大数加法" class="headerlink" title="大数加法"></a>大数加法</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static String addStrings(String num1, String num2) &#123;<br>    StringBuilder sb = new StringBuilder();<br>    int c = 0;<br>    int i = num1.length() - 1;<br>    int j = num2.length() - 1;<br><br>    while (i &gt;= 0 || j &gt;= 0 || c != 0) &#123;<br>        int n1 = i &gt;= 0 ? num1.charAt(i--) - &#x27;0&#x27; : 0;<br>        int n2 = j &gt;= 0 ? num2.charAt(j--) - &#x27;0&#x27; : 0;<br>        int temp = n1 + n2 + c;<br>        sb.append(temp % 10);<br>        c = temp / 10;<br>    &#125;<br>    return sb.reverse().toString();<br>&#125;<br></code></pre></td></tr></table></figure>



<h2 id="数组-1"><a href="#数组-1" class="headerlink" title="数组"></a>数组</h2><h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><h4 id="两数之和"><a href="#两数之和" class="headerlink" title="两数之和"></a>两数之和</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int[] twoSum(int[] nums, int target) &#123;<br>    int[] res = new int[2];<br>    if (nums.length == 0) return null;<br>    Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();<br>    int temp=0;<br>    for (int i = 0; i &lt; nums.length; i++) &#123;<br>        temp=target-nums[i];<br>        if (map.containsKey(temp)) &#123;<br>            res[1] = i;<br>            res[0] = map.get(temp);<br>        &#125;<br>        map.put(nums[i], i);<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="无重复字符最大子串"><a href="#无重复字符最大子串" class="headerlink" title="无重复字符最大子串"></a>无重复字符最大子串</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int lengthOfLongestSubstring(String s) &#123;<br>    int res = 0;<br>    Set&lt;Character&gt; set = new HashSet&lt;&gt;();<br>    for (int r = 0, l = 0; r &lt; s.length(); r++) &#123;<br>        char c = s.charAt(r);<br>        while (set.contains(c)) &#123;<br>            set.remove(s.charAt(l));<br>            l++;<br>        &#125;<br>        set.add(c);<br>        res = Math.max(res, r - l + 1);<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="旋转数组"><a href="#旋转数组" class="headerlink" title="旋转数组"></a>旋转数组</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int[] reverse(int[] nums, int i) &#123;<br>       rev(nums, 0, nums.length - 1);<br>       rev(nums, 0, i - 1);<br>       rev(nums, i, nums.length - 1);<br>       return nums;<br>   &#125;<br><br>   public static int[] rev(int[] nums, int start, int end) &#123;<br>       int l = start;<br>       int r = end;<br>       while (r &gt; l) &#123;<br>           int temp = nums[l];<br>           nums[l] = nums[r];<br>           nums[r] = temp;<br>           r--;<br>           l++;<br>       &#125;<br>       return nums;<br>   &#125;<br></code></pre></td></tr></table></figure>

<h3 id="二分法"><a href="#二分法" class="headerlink" title="二分法"></a>二分法</h3><blockquote>
<p>顺序集合的查找</p>
</blockquote>
<blockquote>
<p>循环不变量</p>
</blockquote>
<p>1，[left,right]</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">while (l&lt;=r)&#123;<br>    int mid=l+(r-l)/2;<br>    if (nums[mid]&gt;target)&#123;<br>        r=mid-1;<br>    &#125;else if (nums[mid]&lt;target)&#123;<br>        l=mid+1;<br>    &#125;else &#123;<br>        return mid;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>2，[left,right)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">while (l&lt;r)&#123;<br>    int mid=l+(r-l)/2;<br>    if (nums[mid]&gt;target)&#123;<br>        r=mid;<br>    &#125;else if (nums[mid]&lt;target)&#123;<br>        l=mid+1;<br>    &#125;else &#123;<br>        return mid;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int[] maxSlidingWindow(int[] nums, int k) &#123;<br>       if (nums.length == 0) return new int[0];<br>       int[] res = new int[nums.length - k + 1];<br>       LinkedList&lt;Integer&gt; queue = new LinkedList&lt;&gt;();<br>       for (int i = 0, j = 0; i &lt; nums.length; i++) &#123;<br>           if (!queue.isEmpty() &amp;&amp; i - queue.peekFirst() &gt;= k) &#123;<br>               queue.pollFirst();<br>           &#125;<br>           while (!queue.isEmpty() &amp;&amp; nums[i] &gt; nums[queue.peekLast()]) &#123;<br>               queue.pollLast();<br>           &#125;<br>           queue.addLast(i);<br>           if (i &gt;= k - 1) &#123;<br>               res[j] = nums[queue.peek()];<br>               j++;<br>           &#125;<br>       &#125;<br>       return res;<br>   &#125;<br></code></pre></td></tr></table></figure>

<h3 id="最长不重复子串"><a href="#最长不重复子串" class="headerlink" title="最长不重复子串"></a>最长不重复子串</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int lengthOfLongestSubstring(String s) &#123;<br>    int res = 0;<br>    int l = 0;<br>    Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;();<br>    for (int r = 0; r &lt; s.length(); r++) &#123;<br>        if (map.containsKey(s.charAt(r))) &#123;<br>            l = Math.max(l, map.get(s.charAt(r)));<br>        &#125;<br>        res = Math.max(res, r - l + 1);<br>        map.put(s.charAt(r), r + 1);<br>    &#125;<br>    return res;<br>&#125;<br><br> public int lengthOfLongestSubstring(String s) &#123;<br>        // 记录字符上一次出现的位置<br>        int[] last = new int[128];<br>        for(int i = 0; i &lt; 128; i++) &#123;<br>            last[i] = -1;<br>        &#125;<br>        int n = s.length();<br><br>        int res = 0;<br>        int start = 0; // 窗口开始位置<br>        for(int i = 0; i &lt; n; i++) &#123;<br>            int index = s.charAt(i);<br>            start = Math.max(start, last[index] + 1);<br>            res   = Math.max(res, i - start + 1);<br>            last[index] = i;<br>        &#125;<br>        return res;<br>    &#125;<br></code></pre></td></tr></table></figure>

<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><h3 id="简单"><a href="#简单" class="headerlink" title="简单"></a>简单</h3><ul>
<li>斐波拉切数列</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int fib(int n) &#123;<br>    if (n==0)return 0;<br>    if (n==1)return 1;<br>    int[] dp=new int[n+1];<br>    dp[0]=0;<br>    dp[1]=1;<br>    for (int i = 2; i &lt;= n; i++) &#123;<br>        dp[i]=dp[i-1]+dp[i-2];<br>    &#125;<br>    return dp[n];<br>&#125;<br><br>public static int fib2(int n)&#123;<br>    if (n==0)return 0;<br>    if (n==1)return 1;<br>    int dp0=0;<br>    int dp1=1;<br>    for (int i = 2; i &lt;= n; i++) &#123;<br>        int sum=dp0+dp1;<br>        dp0=dp1;<br>        dp1=sum;<br>    &#125;<br>    return dp1;<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>爬楼梯</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int climb(int n) &#123;<br>    if (n &lt;= 1) return n;<br>    int[] dp = new int[n + 1];<br>    dp[1] = 1;<br>    dp[2] = 2;<br>    for (int i = 3; i &lt; n; i++) &#123;<br>        dp[i] = dp[i - 1] + dp[i - 2];<br>    &#125;<br>    return dp[n];<br>&#125;<br>//dp[0]在此没有意义。<br>//拓展：最少花费爬楼梯<br>public static int minCostClimbingStairs(int[] cost) &#123;<br>    if (cost == null || cost.length == 0) return 0;<br>    if (cost.length == 1) return cost[0];<br><br>    int[] dp = new int[cost.length];<br>    dp[0] = cost[0];<br>    dp[1] = cost[1];<br>    for (int i = 2; i &lt; cost.length; i++) &#123;<br>        dp[i] = Math.min(dp[i - 1], dp[i - 2]) + cost[i];<br>    &#125;<br>    //最后一步，如果是由倒数第二步爬，则最后一步的体力花费可以不用算<br>    return Math.min(dp[cost.length - 1], dp[cost.length - 2]);<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>不同路径</li>
</ul>
<p><img src="https://i.loli.net/2021/08/13/6AaWL3Hr7gosuOK.png" alt="image-20210813160649637"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int uniquepaths2(int m, int n) &#123;<br>    int[][] dp = new int[m][n];<br>    for (int i = 0; i &lt; m; i++) &#123;<br>        dp[i][0] = 1;<br>    &#125;<br>    for (int i = 0; i &lt; n; i++) &#123;<br>        dp[0][i] = 1;<br>    &#125;<br>    for (int i = 1; i &lt; m; i++) &#123;<br>        for (int j = 1; j &lt; n; j++) &#123;<br>            dp[i][j] = dp[i - 1][j] + dp[i][j - 1];<br>        &#125;<br>    &#125;<br>    return dp[m - 1][n - 1];<br>&#125;<br><br>//考虑某些位置有障碍<br>int m=grid.length();<br>int n=grud[0].length();<br>//初始化<br>for (int i = 0; i &lt; m&amp;&amp;grid[i][0]==0; i++) &#123;<br>        dp[i][0] = 1;<br>   &#125;<br>for (int i = 0; i &lt; n&amp;&amp;grid[0][j]==0; i++) &#123;<br>        dp[0][i] = 1;<br>   &#125;<br>//遍历-加上判断条件即可<br>if(grid[i][j]==1)continue;<br></code></pre></td></tr></table></figure>

<ul>
<li>整数拆分</li>
</ul>
<p>1，贪心算法-拆成 3<em>3</em>3*3……</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">if(n==2)return 1;<br>if(n==3)return 2;<br>if(n==4)return 4;<br>int res=1;<br>while(n&gt;4)&#123;<br>    res=res*3;<br>    n=n-3;<br>&#125;<br>res=res*n;<br>return res;<br>//数学证明？<br></code></pre></td></tr></table></figure>

<ul>
<li>2，动态规划</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">int[] dp=new int[n+1];<br>dp[2]=1;<br>for(int i=3;i&lt;=n;i++)&#123;<br>    for(int j=1;j&lt;i-1;j++)&#123;<br>        dp[i]=max(dp[i],max(j*(i-j),j*dp[i-j]));<br>    &#125;<br>&#125; <br>return dp[n];<br></code></pre></td></tr></table></figure>



<h3 id="背包问题"><a href="#背包问题" class="headerlink" title="背包问题"></a>背包问题</h3><ul>
<li>01 背包</li>
</ul>
<p>问题描述：物品 N 件，背包重量 W，物品的价值与重量为 value[i]，weight[i]。</p>
<p>dp[i][j]表示在下标[0,i-1]的物品中任意取，存放到容量为 j 的背包的最大价值。</p>
<p>1，递推公式。</p>
<p>dp[i][j]&#x3D;max(dp[i-1][j],dp[i-1][j-weight[i]]+value[i])。</p>
<p>第 i 个物品不取。</p>
<p>第 i 个物品取。dp[i-1][j-weight[i]]+value[i]为背包放 i 物品的最大价值。</p>
<p>2，初始化。</p>
<p>dp[i][0]&#x3D;0,背包容量为 0，一定是 0。</p>
<p>dp[0][j]&#x3D;?存放 0 号物品时，最大价值？</p>
<p>dp[0][j]&#x3D;dp[0][j-weight[0]]+value[0]</p>
<p>倒序遍历！</p>
<p>3，遍历顺序。</p>
<p>先遍历物品好理解。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int bag(int bagweight, int[] weight, int[] value) &#123;<br>    int[][] dp = new int[weight.length][bagweight + 1];<br>    for (int i = bagweight; i &gt;= weight[0]; i--) &#123;<br>        dp[0][i] = dp[0][i - weight[0]] + value[0];<br>    &#125;<br>    for (int i = 1; i &lt; weight.length; i++) &#123;<br>        for (int j = 0; j &lt;= bagweight; j++) &#123;<br>            if (j &gt;= weight[i]) &#123;<br>                dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    return dp[weight.length-1][bagweight];<br>&#125;<br><br>public static void main(String[] args) &#123;<br>    int[] w = &#123;1, 3, 4&#125;;<br>    int[] v = &#123;15, 20, 30&#125;;<br>    System.out.println(bag(4, w, v));<br>&#125;<br></code></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/13/A5q8CkLMDeo1B6F.png" alt="image-20210813160820472"></p>
<blockquote>
<p>一维 dp[ ]数组。</p>
</blockquote>
<blockquote>
<p>遍历背包大小时倒序遍历-为了保证每个物品只用一次。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int bag1(int bagweight, int[] weight, int[] value)&#123;<br>    int[] dp=new int[bagweight+1];<br>    for (int i = 0; i &lt; weight.length; i++) &#123;<br>        for (int j = bagweight; j &gt;= weight[i]; j--) &#123;<br>            dp[j]= Math.max(dp[j],dp[j-weight[i]]+value[i]);<br>        &#125;<br>    &#125;<br>    return dp[bagweight];<br>&#125;<br></code></pre></td></tr></table></figure>

<p><img src="https://cr1c7chgh5.feishu.cn/space/api/box/stream/download/asynccode/?code=YmQ3OTM2ZWM4NmQ4ODc5MjNkN2FjOTcwMjdkNTRhZmNfNzhkTThMUHltY09UY0VUN1RVcFpPNTNNVG1NenRwYzZfVG9rZW46Ym94Y25JVDhmT0ZuTWFGMDExY3g4S0h4OURkXzE2Mjg4NDE5NjE6MTYyODg0NTU2MV9WNA" alt="img"></p>
<ul>
<li>完全背包-每个物品都可以被放入无数次。</li>
<li>只需要改变遍历背包时的遍历顺序。</li>
</ul>
<h4 id="完全背包"><a href="#完全背包" class="headerlink" title="完全背包"></a>完全背包</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int bag2(int bagweight, int[] weight, int[] value) &#123;<br>    int[] dp = new int[bagweight + 1];<br>    for (int i = 0; i &lt; weight.length; i++) &#123;<br>        for (int j = weight[i]; j &lt;= bagweight; j++) &#123;<br>            dp[j] = Math.max(dp[j], dp[j - weight[i]] + value[i]);<br>        &#125;<br>    &#125;<br>    return dp[bagweight];<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>零钱兑换（1,2,5）</li>
<li>可以先遍历总金额吗？不能。</li>
<li>如果求<strong>组合数</strong>就是外层 for 循环遍历物品，内层 for 遍历背包。</li>
<li>如果求<strong>排列数</strong>就是外层 for 遍历背包，内层 for 循环遍历物品</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int coinnum(int[] coins,int money)&#123;<br>    int[] dp=new int[money+1];<br>    dp[0]=1;<br>    for (int i = 0; i &lt; coins.length; i++) &#123;//遍历物品<br>        for (int j = coins[i]; j &lt;= money; j++) &#123;//遍历容量<br>            dp[j]=dp[j-coins[i]]+dp[j];<br>        &#125;<br>    &#125;<br>    return dp[money];<br>&#125;<br></code></pre></td></tr></table></figure>



<ul>
<li>爬楼梯进阶</li>
<li>每次都可以爬 1,2,3,4，，，，n 步？</li>
<li>等价于完全背包问题。</li>
<li>物品就是一步两步三步。</li>
<li>总量就是总的台阶步数。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int climb3(int n, int m) &#123;<br>    int[] dp = new int[n + 1];<br>    dp[0] = 1;<br>    //排列问题-先遍历背包<br>    for (int i = 1; i &lt;= n; i++) &#123;<br>        for (int j = 1; j &lt;= m; j++) &#123;//遍历物品<br>            if (i - j &gt;= 0) &#123;<br>                dp[i] = dp[i] + dp[i - j];<br>            &#125;<br>        &#125;<br>    &#125;<br>    return dp[n];<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>零钱兑换最少的硬币数</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int coinmin(int[] coins, int sum) &#123;<br>    int[] dp = new int[sum + 1];<br>    Arrays.fill(dp, Integer.MAX_VALUE);<br>    dp[0] = 0;<br>    for (int i = 0; i &lt; coins.length; i++) &#123;<br>        for (int j = coins[i]; j &lt;= sum; j++) &#123;<br>            if (dp[j - coins[i]] != Integer.MAX_VALUE) &#123;<br>                dp[j] = Math.min(dp[j - coins[i]] + 1, dp[j]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    if (dp[sum] == Integer.MAX_VALUE) return -1;<br>    return dp[sum];<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>构成完全平方数的最小个数</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int sqmin(int n) &#123;<br>    int[] dp = new int[n + 1];<br>    Arrays.fill(dp, Integer.MAX_VALUE);<br>    dp[0] = 0;<br>    for (int i = 0; i &lt;= n; i++) &#123;//遍历背包<br>        for (int j = 1; j * j &lt;= i; j++) &#123;//遍历物品<br>            dp[j] = Math.min(dp[i - j * j] + 1, dp[i]);<br>        &#125;<br>    &#125;<br>    return dp[n];<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="打家劫舍"><a href="#打家劫舍" class="headerlink" title="打家劫舍"></a>打家劫舍</h3><h4 id="初级打家劫舍"><a href="#初级打家劫舍" class="headerlink" title="初级打家劫舍"></a>初级打家劫舍</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int rob(int[] nums) &#123;<br>    if (nums.length == 0) return 0;<br>    if (nums.length == 1) return nums[0];<br>    int[] dp = new int[nums.length];<br>    dp[0] = nums[0];<br>    dp[1] = Math.max(nums[0], nums[1]);<br>    for (int i = 2; i &lt; nums.length; i++) &#123;<br>        dp[i] = Math.max(dp[i - 2] + nums[i], dp[i - 1]);<br>    &#125;<br>    return dp[nums.length - 1];<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="环形打家劫舍"><a href="#环形打家劫舍" class="headerlink" title="环形打家劫舍"></a>环形打家劫舍</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int rob(int[] nums) &#123;<br>    int len=nums.length;<br>    if (len==0)return 0;<br>    if (len==1)return nums[0];<br>    int res1=helper(nums,0,nums.length-2);<br>    int res2=helper(nums,1,nums.length-1);<br>    return Math.max(res1,res2);<br>&#125;<br><br>private static int helper(int[] nums, int start, int end) &#123;<br>    if (start==end)return nums[start];<br>    int[] dp=new int[nums.length];<br>    dp[start]=nums[start];<br>    dp[start+1]=Math.max(nums[start],nums[start+1]);<br>    for (int i = start+2; i &lt;= end; i++) &#123;<br>        dp[i]= Math.max(dp[i-2]+nums[i],dp[i-1]);<br>    &#125;<br>    return dp[end];<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="树形打家劫舍"><a href="#树形打家劫舍" class="headerlink" title="树形打家劫舍"></a>树形打家劫舍</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int rob(TreeNode root)&#123;<br>   //表示偷某个节点和不偷某个节点的最大值<br>    int[] res=robtree(root);<br>    return Math.max(res[0],res[1]);<br>&#125;<br><br>private static int[] robtree(TreeNode cur) &#123;<br>    if (cur==null)return new int[2];<br>    int[] left = robtree(cur.left);<br>    int[] right = robtree(cur.right);<br>    <br>    int val1=cur.val+left[0]+right[0];<br>    int val2=Math.max(left[0],left[1])+Math.max(right[0],right[1]);<br>    return new int[]&#123;val2,val1&#125;;<br>&#125;<br></code></pre></td></tr></table></figure>





<h3 id="股票问题"><a href="#股票问题" class="headerlink" title="股票问题"></a>股票问题</h3><h4 id="买股票最佳时机（只能买卖一次）"><a href="#买股票最佳时机（只能买卖一次）" class="headerlink" title="买股票最佳时机（只能买卖一次）"></a>买股票最佳时机（只能买卖一次）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int maxProfit(int[] prices) &#123;<br>    int low=prices[0];<br>    int res=0;<br>    for(int i=1;i&lt;prices.length;i++)&#123;<br>        low=Math.min(prices[i],low);<br>        res=Math.max(res,prices[i]-low);<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="买股票最佳时机（可以买卖多次）"><a href="#买股票最佳时机（可以买卖多次）" class="headerlink" title="买股票最佳时机（可以买卖多次）"></a>买股票最佳时机（可以买卖多次）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public int maxProfit(int[] prices) &#123;<br>    int res=0;<br>    for (int i = 1; i &lt; prices.length; i++) &#123;<br>        if (prices[i]&gt;prices[i-1])&#123;<br>            res=res+(prices[i]-prices[i-1]);<br>        &#125;<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="买股票最佳时机（最多买卖-2-次，同时只能有一支）"><a href="#买股票最佳时机（最多买卖-2-次，同时只能有一支）" class="headerlink" title="买股票最佳时机（最多买卖 2 次，同时只能有一支）"></a>买股票最佳时机（最多买卖 2 次，同时只能有一支）</h4><blockquote>
<p>动态规划：每天有 5 个状态，第一&#x2F;二天买入&#x2F;出，无操作</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public int maxProfit(int[] prices) &#123;<br>    if (prices.length == 0) return 0;<br>    int[][] dp = new int[prices.length][5];<br>    dp[0][1] = -prices[0];<br>    dp[0][3] = -prices[0];<br>    for (int i = 1; i &lt; prices.length; i++) &#123;<br>        dp[i][0] = dp[i - 1][0];<br>        dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][0] - prices[i]);<br>        dp[i][2] = Math.max(dp[i - 1][2], dp[i - 1][1] + prices[i]);<br>        dp[i][3] = Math.max(dp[i - 1][3], dp[i - 1][2] - prices[i]);<br>        dp[i][4] = Math.max(dp[i - 1][4], dp[i - 1][3] + prices[i]);<br>    &#125;<br>    return dp[prices.length - 1][4];<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="买股票最佳时机（最多买卖-k-次，同时只能有一支）"><a href="#买股票最佳时机（最多买卖-k-次，同时只能有一支）" class="headerlink" title="买股票最佳时机（最多买卖 k 次，同时只能有一支）"></a>买股票最佳时机（最多买卖 k 次，同时只能有一支）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public int maxProfit(int k, int[] prices) &#123;<br>    if (prices.length == 0) return 0;<br>    int[][] dp = new int[prices.length][2 * k + 1];<br>    //奇数代表卖入，偶数代表买<br>    for (int i = 1; i &lt; 2 * k; i += 2) &#123;<br>        dp[0][i] = -prices[0];<br>    &#125;<br>    for (int i = 1; i &lt; prices.length; i++) &#123;<br>        for (int j = 0; j &lt; 2 * k - 1; j += 2) &#123;<br>            dp[i][j + 1] = Math.max(dp[i - 1][j + 1], dp[i - 1][j] - prices[i]);<br>            dp[i][j + 2] = Math.max(dp[i - 1][j + 2], dp[i - 1][j + 1] + prices[i]);<br>        &#125;<br>    &#125;<br>    return dp[prices.length - 1][2 * k];<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="买股票最佳时机（买卖多次，冷冻期一天）"><a href="#买股票最佳时机（买卖多次，冷冻期一天）" class="headerlink" title="买股票最佳时机（买卖多次，冷冻期一天）"></a>买股票最佳时机（买卖多次，冷冻期一天）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public int maxProfit(int[] prices) &#123;<br>    if (prices.length == 0) return 0;<br>    //状态：买入，卖出（两天前就卖出，今天卖出），冷冻期<br>    int[][] dp = new int[prices.length][4];<br>    dp[0][0] = -prices[0];<br>    for (int i = 1; i &lt; prices.length; i++) &#123;<br>        dp[i][0] = Math.max(dp[i - 1][0], Math.max(dp[i - 1][3], dp[i - 1][1]) - prices[i]);<br>        dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][3]);<br>        dp[i][2] = dp[i - 1][0] + prices[i];<br>        dp[i][3] = dp[i - 1][2];<br>    &#125;<br>    return Math.max(dp[prices.length - 1][3],<br>            Math.max(dp[prices.length - 1][1], dp[prices.length - 1][2]));<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="子序列问题"><a href="#子序列问题" class="headerlink" title="子序列问题"></a>子序列问题</h3><h4 id="最长递增子序列"><a href="#最长递增子序列" class="headerlink" title="最长递增子序列"></a>最长递增子序列</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int maxlts(int[] nums) &#123;<br>    if (nums.length &lt;= 1) return nums.length;<br>    int[] dp = new int[nums.length];<br>    Arrays.fill(dp, 1);<br>    int res = 0;<br>    for (int i = 1; i &lt; nums.length; i++) &#123;<br>        for (int j = 0; j &lt; i; j++) &#123;<br>            if (nums[i] &gt; nums[j]) &#123;<br>                dp[i] = Math.max(dp[i], dp[j] + 1);<br>            &#125;<br>            res = Math.max(res, dp[i]);<br>        &#125;<br>    &#125;<br>    System.out.println(Arrays.toString(dp));<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="最长连续递增子序列"><a href="#最长连续递增子序列" class="headerlink" title="最长连续递增子序列"></a>最长连续递增子序列</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int maxlts(int[] nums) &#123;<br>    if (nums.length == 0) return 0;<br>    int[] dp = new int[nums.length];<br>    Arrays.fill(dp, 1);<br>    int res = 1;<br>    for (int i = 0; i &lt; nums.length - 1; i++) &#123;<br>        if (nums[i + 1] &gt; nums[i]) &#123;<br>            dp[i + 1] = dp[i] + 1;<br>        &#125;<br>        res = Math.max(res, dp[i]);<br>    &#125;<br>    System.out.println(Arrays.toString(dp));<br>    return res;<br>&#125;<br><br>//贪心算法<br>public static int maxlts2(int[] nums) &#123;<br>    if (nums.length == 0) return 0;<br>    int res = 1;<br>    int count = 1;<br>    for (int i = 0; i &lt; nums.length - 1; i++) &#123;<br>        if (nums[i + 1] &gt; nums[i]) &#123;<br>            count++;<br>        &#125; else &#123;<br>            count = 1;<br>        &#125;<br>        res = Math.max(res, count);<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="最长重复子数组"><a href="#最长重复子数组" class="headerlink" title="最长重复子数组"></a>最长重复子数组</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int maxarray(int[] nums1,int[] nums2)&#123;<br>    int[][] dp=new int[nums1.length+1][nums2.length+1];<br>    int res=0;<br>    for (int i = 1; i &lt;= nums1.length; i++) &#123;<br>        for (int j = 1; j &lt;= nums2.length; j++) &#123;<br>            if (nums1[i-1]==nums2[j-1])&#123;<br>                dp[i][j]=dp[i-1][j-1]+1;<br>            &#125;<br>            res= Math.max(res,dp[i][j]);<br>        &#125;<br>    &#125;<br>    for (int i = 0; i &lt; dp.length; i++) &#123;<br>        for (int j = 0; j &lt; dp[0].length; j++) &#123;<br>            System.out.print(dp[i][j]+&quot;   &quot;);<br>        &#125;<br>        System.out.println();<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="最长公共子序列"><a href="#最长公共子序列" class="headerlink" title="最长公共子序列"></a>最长公共子序列</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int maxarray(int[] nums1,int[] nums2)&#123;<br>    int[][] dp=new int[nums1.length+1][nums2.length+1];<br>    int res=0;<br>    for (int i = 1; i &lt;= nums1.length; i++) &#123;<br>        for (int j = 1; j &lt;= nums2.length; j++) &#123;<br>            if (nums1[i-1]==nums2[j-1])&#123;<br>                dp[i][j]=dp[i-1][j-1]+1;<br>            &#125;else&#123;<br>                dp[i][j]=Math.max(dp[i-1][j],dp[i][j-1]);<br>            &#125;<br>            res= Math.max(res,dp[i][j]);<br>        &#125;<br>    &#125;<br>    for (int i = 0; i &lt; dp.length; i++) &#123;<br>        for (int j = 0; j &lt; dp[0].length; j++) &#123;<br>            System.out.print(dp[i][j]+&quot;   &quot;);<br>        &#125;<br>        System.out.println();<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="最大子序和"><a href="#最大子序和" class="headerlink" title="最大子序和"></a>最大子序和</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int maxsubarray(int[] nums)&#123;<br>    int res=Integer.MIN_VALUE;<br>    int count=0;<br>    for (int i = 0; i &lt; nums.length; i++) &#123;<br>        count=count+nums[i];<br>        if (count&gt;res)&#123;<br>            res=count;<br>        &#125;<br>        if (count&lt;=0)count=0;<br>    &#125;<br>    return res;<br>&#125;<br><br>public static int maxsubarray2(int[] nums)&#123;<br>    if (nums.length==0)return 0;<br>    int[] dp=new int[nums.length];<br>    dp[0]=nums[0];<br>    int res=nums[0];<br>    for (int i = 1; i &lt; nums.length; i++) &#123;<br>        dp[i]= Math.max(dp[i-1]+nums[i],nums[i]);<br>        res= Math.max(res,dp[i]);<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="回文子串"><a href="#回文子串" class="headerlink" title="回文子串"></a>回文子串</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int countSubstrings(String s)&#123;<br>    int res=0;<br>    for (int i = 0; i &lt; s.length(); i++) &#123;<br>        res=res+extend(s,i,i,s.length());<br>        res=res+extend(s,i,i+1,s.length());<br>    &#125;<br>    return res;<br>&#125;<br><br>private static int extend(String s, int i, int j, int length) &#123;<br>     int re=0;<br>     while (i&gt;=0&amp;&amp;j&lt;length&amp;&amp;s.charAt(i)==s.charAt(j))&#123;<br>         i++;<br>         j--;<br>         re++;<br>     &#125;<br>     return re;<br>&#125;<br>public static int huiwen(String s)&#123;<br>    boolean[][] dp=new boolean[s.length()][s.length()];<br>    int res=0;<br>    for (int i = s.length()-1; i &gt;=0; i--) &#123;<br>        for (int j = i; j &lt; s.length(); j++) &#123;<br>            if (s.charAt(i)==s.charAt(j))&#123;<br>                if (j-i&lt;=1)&#123;<br>                    res++;<br>                    dp[i][j]=true;<br>                &#125;else if(dp[i+1][j-1])&#123;<br>                    res++;<br>                    dp[i][j]=true;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>    return res;<br>&#125;<br>//最长回文子串<br>public static String maxhuiwen(String s)&#123;<br>    if (s.length()&lt;2)return s;<br>    int start=0;<br>    int max=1;<br>    int len=s.length();<br>    for (int i = 0; i &lt; len; ) &#123;<br>        //剩下的已经不可能更长了。<br>        if (len-i&lt;=max/2)break;<br>        int l=i;<br>        int r=i;<br>        while (r&lt;len-1&amp;&amp;s.charAt(r)==s.charAt(r+1))&#123;<br>            r++;<br>        &#125;<br>        i=r+1;<br>        while (r&lt;len-1&amp;&amp;l&gt;0&amp;&amp;s.charAt(r+1)==s.charAt(l-1))&#123;<br>            r++;<br>            l--;<br>        &#125;<br>        if (r-l+1&gt;max)&#123;<br>            max=r-l+1;<br>            start=l;<br>        &#125;<br>    &#125;<br>    return s.substring(start,start+max);<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="最长回文子序列"><a href="#最长回文子序列" class="headerlink" title="最长回文子序列"></a>最长回文子序列</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int longestPalindromeSubseq(String s) &#123;<br>    int[][] dp = new int[s.length()][s.length()];<br>    for (int i = s.length() - 1; i &gt;= 0; i--) &#123;<br>        dp[i][i] = 1;<br>        for (int j = i + 1; j &lt; s.length(); j++) &#123;<br>            if (s.charAt(i) == s.charAt(j)) &#123;<br>                dp[i][j] = dp[i + 1][j - 1] + 2;<br>            &#125; else &#123;<br>                dp[i][j] = Math.max(dp[i + 1][j], dp[i][j - 1]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    return dp[0][s.length() - 1];<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="判断子序列"><a href="#判断子序列" class="headerlink" title="判断子序列"></a>判断子序列</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static boolean isSubsequence(String s, String t) &#123;<br>       if (s.length() == 0) return true;<br>       int ss = 0;<br>       for (int i = 0; i &lt; t.length(); i++) &#123;<br>           if (s.charAt(ss) == t.charAt(i)) &#123;<br>               ss++;<br>               if (ss == s.length()) return true;<br>           &#125;<br>       &#125;<br>       return false;<br>   &#125;<br></code></pre></td></tr></table></figure>

<h4 id="编辑距离"><a href="#编辑距离" class="headerlink" title="编辑距离"></a>编辑距离</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int minDistance(String s1,String s2)&#123;<br>    int[][] dp=new int[s1.length()+1][s2.length()+1];<br>    for (int i = 0; i &lt;= s1.length(); i++) &#123;<br>        dp[i][0]=i;<br>    &#125;<br>    for (int i = 0; i &lt;= s2.length(); i++) &#123;<br>        dp[0][i]=i;<br>    &#125;<br>    for (int i = 1; i &lt;= s1.length(); i++) &#123;<br>        for (int j = 1; j &lt;= s2.length(); j++) &#123;<br>            if (s1.charAt(i-1)==s2.charAt(j-1))&#123;<br>                dp[i][j]=dp[i-1][j-1];<br>            &#125;else &#123;<br>                //s1增加一个元素dp[i-1][j]+1==as asd<br>                //s2添加一个元素dp[i][j-1]+1==asd as<br>                //替换元素dp[i-1][j-1]+1==asd ase<br>                dp[i][j]= Math.min(Math.min(dp[i - 1][j - 1] + 1, dp[i - 1][j] + 1), dp[i][j - 1] + 1);<br>            &#125;<br>        &#125;<br>    &#125;<br>    return dp[s1.length()][s2.length()];<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="hotcode"><a href="#hotcode" class="headerlink" title="hotcode"></a>hotcode</h3><h4 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class LRUCache &#123;<br>    private class node &#123;<br>        //双向链表类<br>        int val;<br>        int key;<br>        node pre;<br>        node next;<br>        public node(int key, int val) &#123;<br>            this.val = val;<br>            this.key = key;<br>        &#125;<br>    &#125;<br><br>    private HashMap&lt;Integer, node&gt; map;<br>    private int capacity;<br>    private node dummyfirst;<br>    private node dummylast;<br><br>    public LRUCache(int capacity) &#123;<br>        map = new HashMap&lt;&gt;(capacity);<br>        this.capacity = capacity;<br>        dummyfirst = new node(-1, -1);<br>        dummylast = new node(-1, -1);<br><br>        dummyfirst.next = dummylast;<br>        dummylast.pre = dummyfirst;<br>    &#125;<br><br>    public int get(int key) &#123;<br>        if (!map.containsKey(key)) &#123;<br>            return -1;<br>        &#125;<br>        //缓存中有<br>        node n = map.get(key);<br>        //删除该节点<br>        n.pre.next = n.next;<br>        n.next.pre = n.pre;<br>        //移到最后面<br>        movetolast(n);<br>        return n.val;<br>    &#125;<br><br>    public void put(int key, int value) &#123;<br>        if (get(key) != -1) &#123;//已经有了<br>            map.get(key).val = value;//更新值就可以<br>            return;<br>        &#125;<br>        //之前没有<br>        node add = new node(key, value);<br>        map.put(key, add);<br>        //移到最后面<br>        movetolast(add);<br>        //满了就移除<br>        if (map.size() &gt; capacity) &#123;<br>            //删除最前面的（最久未用）<br>            map.remove(dummyfirst.next.key);<br>            dummyfirst.next = dummyfirst.next.next;<br>            dummyfirst.next.pre = dummyfirst;<br>        &#125;<br>    &#125;<br><br>    private void movetolast(node n) &#123;<br>        n.next = dummylast;<br>        n.pre = dummylast.pre;<br>        dummylast.pre = n;<br>        n.pre.next = n;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="接雨水"><a href="#接雨水" class="headerlink" title="接雨水"></a>接雨水</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int trap(int[] height) &#123;<br>    int len = height.length;<br>    int[] maxl = new int[len];<br>    int[] maxr = new int[len];<br>    int res = 0;<br>    for (int i = 1; i &lt; len; i++) &#123;<br>        maxl[i] = Math.max(maxl[i - 1], height[i - 1]);<br>    &#125;<br>    for (int i = len - 2; i &gt;= 0; i--) &#123;<br>        maxr[i] = Math.max(maxr[i + 1], height[i + 1]);<br>    &#125;<br><br>    for (int i = 0; i &lt; len; i++) &#123;<br>        int h = Math.min(maxl[i], maxr[i]);<br>        if (h &gt; height[i]) &#123;<br>            res = res + h - height[i];<br>        &#125;<br>    &#125;<br>    return res;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class Singleton &#123;<br>    private volatile static Singleton uniqueInstance;<br>    private Singleton()&#123;<br>        <br>    &#125;<br>    public static Singleton getUniqueInstance()&#123;<br>        if (uniqueInstance==null)&#123;<br>            synchronized (Singleton.class)&#123;<br>                if (uniqueInstance==null)&#123;<br>                    uniqueInstance=new Singleton();<br>                &#125;<br>            &#125;<br>        &#125;<br>        return uniqueInstance;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="TOPK-问题"><a href="#TOPK-问题" class="headerlink" title="TOPK 问题"></a>TOPK 问题</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int findKthLargest(int[] nums, int k) &#123;<br>    int len = nums.length;<br>    PriorityQueue&lt;Integer&gt; minheap = new PriorityQueue&lt;&gt;(len, (a, b) -&gt; a - b);//默认最小堆<br>    for (int i = 0; i &lt; len; i++) &#123;<br>        minheap.add(nums[i]);<br>    &#125;<br>    for (int i = 0; i &lt; len - k; i++) &#123;<br>        minheap.poll();<br>    &#125;<br>    return minheap.peek();<br>&#125;<br><br>public int findKthLargest2(int[] nums, int k) &#123;<br>    int len = nums.length;<br>    // 最小堆<br>    PriorityQueue&lt;Integer&gt; priorityQueue = new PriorityQueue&lt;&gt;(k + 1, (a, b) -&gt; (a - b));<br>    for (int num : nums) &#123;<br>        priorityQueue.add(num);<br>        if (priorityQueue.size() == k + 1) &#123;<br>            priorityQueue.poll();<br>        &#125;<br>    &#125;<br>    return priorityQueue.peek();<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="杨辉三角"><a href="#杨辉三角" class="headerlink" title="杨辉三角"></a>杨辉三角</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public List&lt;Integer&gt; getRow(int rowIndex) &#123;<br>    List&lt;Integer&gt; list = new ArrayList&lt;&gt;();<br>    while (rowIndex &gt;= 0) &#123;<br>        rowIndex--;<br>        list.add(1);<br>        for (int i = list.size() - 2; i &gt; 0; i--) &#123;<br>            list.set(i, list.get(i) + list.get(i - 1));<br>        &#125;<br>    &#125;<br>    return list;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第一个缺失的正数"><a href="#第一个缺失的正数" class="headerlink" title="第一个缺失的正数"></a>第一个缺失的正数</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int firstMissingPositive(int[] nums) &#123;<br>   Set&lt;Integer&gt; set=new HashSet&lt;&gt;();<br>    for (int i = 0; i &lt; nums.length; i++) &#123;<br>        set.add(nums[i]);<br>    &#125;<br>    for (int i = 1; i &lt;= nums.length; i++) &#123;<br>        if (!set.contains(i))&#123;<br>            return i;<br>        &#125;<br>    &#125;<br>    return nums.length+1;<br>&#125;<br>public static int firstMissingPositive2(int[] nums) &#123;<br>    int len=nums.length;<br>    for (int i = 0; i &lt; len; i++) &#123;<br>        if (nums[i]&lt;=0)nums[i]=len+1;<br>    &#125;<br>    for (int i = 0; i &lt; len; i++) &#123;<br>        int num= Math.abs(nums[i]);<br>        if (num&lt;=len)&#123;<br>            nums[num-1]=-Math.abs(nums[num-1]);<br>        &#125;<br>    &#125;<br>    for (int i = 0; i &lt; len; i++) &#123;<br>        if (nums[i]&gt;0)&#123;<br>            return i+1;<br>        &#125;<br>    &#125;<br>    return len+1;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="多数元素"><a href="#多数元素" class="headerlink" title="多数元素"></a>多数元素</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public int majorityElement(int[] nums) &#123;<br>       int major=nums[0];<br>       int count=0;<br>       for(int i=0;i&lt;nums.length;i++)&#123;<br>           if(count==0)&#123;<br>               major=nums[i];<br>               count=1;<br>           &#125;else if(major==nums[i])&#123;<br>               count++;<br>           &#125;else &#123;<br>               count--;<br>           &#125;<br>       &#125;<br>       count=0;<br>        for(int i=0;i&lt;nums.length;i++)&#123;<br>            if(nums[i]==major)&#123;<br>                count++;<br>            &#125;<br>        &#125;<br>        return count&gt;nums.length/2?major:-1;<br>   &#125;<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>top</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式</title>
    <url>/2021/08/05/a%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="设计模式类型"><a href="#设计模式类型" class="headerlink" title="设计模式类型"></a>设计模式类型</h2><h3 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a>创建型模式</h3><p>这些设计模式提供了一种在<strong>创建对象的同时隐藏创建逻辑的方式</strong>，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。</p>
<p><strong>工厂模式（Factory Pattern）</strong><br><strong>抽象工厂模式（Abstract Factory Pattern）</strong><br><strong>单例模式（Singleton Pattern）</strong><br>建造者模式（Builder Pattern）<br>原型模式（Prototype Pattern）</p>
<h3 id="结构型模式"><a href="#结构型模式" class="headerlink" title="结构型模式"></a>结构型模式</h3><p>这些设计模式关注<strong>类和对象的组合</strong>。继承的概念被用来组合接口和定义组合对象获得新功能的方式。</p>
<p><strong>适配器模式（Adapter Pattern）</strong><br>桥接模式（Bridge Pattern）<br>过滤器模式（Filter、Criteria Pattern）<br>组合模式（Composite Pattern）<br><strong>装饰器模式（Decorator Pattern）</strong><br>外观模式（Facade Pattern）<br>享元模式（Flyweight Pattern）<br><strong>代理模式（Proxy Pattern）</strong></p>
<h3 id="行为型模式"><a href="#行为型模式" class="headerlink" title="行为型模式"></a>行为型模式</h3><p>这些设计模式特别关注<strong>对象之间的通信。</strong>	</p>
<p>责任链模式（Chain of Responsibility Pattern）<br>命令模式（Command Pattern）<br>解释器模式（Interpreter Pattern）<br>迭代器模式（Iterator Pattern）<br>中介者模式（Mediator Pattern）<br>备忘录模式（Memento Pattern）<br>观察者模式（Observer Pattern）<br>状态模式（State Pattern）<br>空对象模式（Null Object Pattern）<br>策略模式（Strategy Pattern）<br>模板模式（Template Pattern）<br>访问者模式（Visitor Pattern）</p>
<h3 id="J2EE-模式"><a href="#J2EE-模式" class="headerlink" title="J2EE 模式"></a>J2EE 模式</h3><p>这些设计模式特别关注<strong>表示层</strong>。这些模式是由 Sun Java Center 鉴定的。	</p>
<p>MVC 模式（MVC Pattern）<br>业务代表模式（Business Delegate Pattern）<br>组合实体模式（Composite Entity Pattern）<br>数据访问对象模式（Data Access Object Pattern）<br>前端控制器模式（Front Controller Pattern）<br>拦截过滤器模式（Intercepting Filter Pattern）<br>服务定位器模式（Service Locator Pattern）<br>传输对象模式（Transfer Object Pattern）</p>
<h2 id="设计模式的六大原则"><a href="#设计模式的六大原则" class="headerlink" title="设计模式的六大原则"></a>设计模式的六大原则</h2><p>0、<strong>单一职责原则</strong>(Single Responsibility Principle)</p>
<p>单一职责原则表示一个模块的组成元素之间的功能相关性。从软件变化的角度来看，就一个类而言，应该仅有一个让它变化的原因；通俗地说，<strong>即一个类只负责一项职责。</strong></p>
<p>假设某个类 P 负责两个不同的职责，职责 P1 和 职责 P2，那么当职责 P1 需求发生改变而需要修改类 P，有可能会导致原来运行正常的职责 P2 功能发生故障。</p>
<p>1、<strong>开闭原则</strong>（Open Close Principle）</p>
<p>开闭原则的意思是：<strong>对扩展开放，对修改关闭</strong>。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，<strong>是为了使程序的扩展性好，易于维护和升级</strong>。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。</p>
<p>2、<strong>里氏代换原则</strong>（Liskov Substitution Principle）</p>
<p>里氏代换原则是<strong>面向对象设计</strong>的基本原则之一。 里氏代换原则中说，<strong>任何基类可以出现的地方，子类一定可以出现</strong>。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。</p>
<p>里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是<strong>抽象化</strong>，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。</p>
<p>3、<strong>依赖倒转原则</strong>（Dependence Inversion Principle）</p>
<p>这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。</p>
<p>4、<strong>接口隔离原则</strong>（Interface Segregation Principle）</p>
<p>这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：<strong>降低类之间的耦合度。</strong></p>
<p>5、<strong>迪米特法则，又称最少知道原则</strong>（Demeter Principle）</p>
<p>最少知道原则是指：一个<strong>实体应当尽量少地与其他实体之间发生相互作用</strong>，使得系统功能模块相对独立。</p>
<p>6、<strong>合成复用原则（</strong>Composite Reuse Principle）</p>
<p>合成复用原则是指：<strong>尽量使用合成&#x2F;聚合的方式，而不是使用继承</strong>。</p>
<h2 id="常见设计模式"><a href="#常见设计模式" class="headerlink" title="常见设计模式"></a>常见设计模式</h2><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><p>单例模式（Singleton）的目的是为了保证在一个进程中，某个类有且仅有一个实例。</p>
<p>因为这个类只有一个实例，因此，自然不能让调用方使用 new Xyz()来创建实例了。所以，单例的构造方法必须是 private，这样就防止了调用方自己创建实例。</p>
<p>只有 private 构造方法，确保外部无法实例化；</p>
<p>通过 private static 变量持有唯一实例，<strong>保证全局唯一性；</strong></p>
<p>通过 public static 方法返回此唯一实例，<strong>使外部调用方能获取到实例。</strong></p>
<h4 id="懒汉式，线程不安全"><a href="#懒汉式，线程不安全" class="headerlink" title="懒汉式，线程不安全"></a>懒汉式，线程不安全</h4><p>是否 Lazy 初始化：是</p>
<p>是否多线程安全：否</p>
<p>这种写法起到了 Lazy Loading 的效果，但是只能在单线程下使用。</p>
<p>如果在多线程下，一个线程进入了 if (singleton &#x3D;&#x3D; null)判断语句块，还未来得及往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。所以在多线程环境下不可使用这种方式。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class Singleton &#123;  <br>    private static Singleton instance;  <br>    private Singleton ()&#123;&#125;  <br><br>	public static Singleton getInstance() &#123;  <br>	if (instance == null) &#123;  <br>    instance = new Singleton();  <br>	&#125;  <br>	return instance;  <br>	&#125;  <br>	&#125;<br></code></pre></td></tr></table></figure>

<h4 id="懒汉式，线程安全"><a href="#懒汉式，线程安全" class="headerlink" title="懒汉式，线程安全"></a>懒汉式，线程安全</h4><p>是否 Lazy 初始化：是</p>
<p>是否多线程安全：是</p>
<p>描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。<br>优点：<strong>第一次调用才初始化，避免内存浪费。</strong><br>缺点：<strong>必须加锁 synchronized 才能保证单例，但加锁会影响效率</strong>。<br>getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class Singleton &#123;  <br>    private static Singleton instance;  <br>    private Singleton ()&#123;&#125;  <br>    public static synchronized Singleton getInstance() &#123;  <br>    if (instance == null) &#123;  <br>        instance = new Singleton();  <br>    &#125;  <br>    return instance;  <br>    &#125;  <br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h4><p>是否 Lazy 初始化：否</p>
<p>是否多线程安全：是</p>
<p>优点：这种写法比较简单，<strong>就是在类装载的时候就完成实例化</strong>。避免了线程同步问题。</p>
<p>缺点：在类装载的时候就完成实例化，<strong>没有达到 Lazy Loading 的效果</strong>。<strong>如果从始至终从未使用过这个实例，则会造成内存的浪费。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class Singleton &#123;  <br>    private static Singleton instance = new Singleton();  <br>    private Singleton ()&#123;&#125;  <br>    public static Singleton getInstance() &#123;  <br>    return instance;  <br>    &#125;  <br>&#125;<br></code></pre></td></tr></table></figure>



<h4 id="双检锁-x2F-双重校验锁（DCL，即-double-checked-locking）"><a href="#双检锁-x2F-双重校验锁（DCL，即-double-checked-locking）" class="headerlink" title="双检锁&#x2F;双重校验锁（DCL，即 double-checked locking）"></a>双检锁&#x2F;双重校验锁（DCL，即 double-checked locking）</h4><p><strong>是否 Lazy 初始化：</strong>是</p>
<p><strong>是否多线程安全：</strong>是</p>
<p><strong>描述：</strong>我们进行了两次 if (singleton &#x3D;&#x3D; null)检查，这样就可以保证线程安全了。这样，实例化代码只用执行一次，后面再次访问时，判断 if (singleton &#x3D;&#x3D; null)，直接 return 实例化对象。</p>
<p>优点：线程安全；延迟加载；效率较高。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class Singleton &#123;<br>    private volatile static Singleton uniqueInstance;<br>    private Singleton()&#123;<br>        <br>    &#125;<br>    public static Singleton getUniqueInstance()&#123;<br>        if (uniqueInstance==null)&#123;<br>            synchronized (Singleton.class)&#123;<br>                if (uniqueInstance==null)&#123;<br>                    uniqueInstance=new Singleton();<br>                &#125;<br>            &#125;<br>        &#125;<br>        return uniqueInstance;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>volatile 修饰 uniqueinstance 的必要性：</p>
<p>uniqueinstance&#x3D;new singleton()；实际上分为 3 步。</p>
<ul>
<li>1，为 uniqueinstance 分配内存。</li>
<li>2，初始化 uniqueinstance。</li>
<li>3，将 uniqueinstance 指向分配的内存地址。</li>
</ul>
<p>因此：</p>
<ul>
<li>代码读取到 instance 不为 null 时，instance 引用的对象可能还没有完成初始化。</li>
<li><strong>防止指令重排。</strong></li>
</ul>
<h4 id="静态内部类"><a href="#静态内部类" class="headerlink" title="静态内部类"></a>静态内部类</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public class Singleton &#123;<br><br>private Singleton() &#123;&#125;<br><br>private static class SingletonInstance &#123;<br>    private static final Singleton INSTANCE = new Singleton();<br>&#125;<br><br>public static Singleton getInstance() &#123;<br>    return SingletonInstance.INSTANCE;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>这种方式跟饿汉式方式采用的机制类似，但又有不同。两者都是采用了<strong>类装载的机制</strong>来保证初始化实例时只有一个线程。不同的地方在饿汉式方式是只要 Singleton 类被装载就会实例化，没有 Lazy-Loading 的作用，而静态内部类方式<strong>在 Singleton 类被装载时并不会立即实例化，而是在需要实例化时，调用 getInstance 方法，才会装载 SingletonInstance 类，从而完成 Singleton 的实例化。</strong></p>
<p>复制代码<br>这种方式跟饿汉式方式采用的机制类似，但又有不同。两者都是采用了类装载的机制来保证初始化实例时只有一个线程。不同的地方在饿汉式方式是只要 Singleton 类被装载就会实例化，没有 Lazy-Loading 的作用，而静态内部类方式在 Singleton 类被装载时并不会立即实例化，而是在需要实例化时，调用 getInstance 方法，才会装载 SingletonInstance 类，从而完成 Singleton 的实例化。</p>
<p><strong>类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM 帮助我们保证了线程的安全性</strong>，在类进行初始化时，别的线程是无法进入的。</p>
<p>优点：避免了线程不安全，延迟加载，效率高。</p>
<h4 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public enum Singleton &#123;<br>    INSTANCE;<br>    public void whateverMethod() &#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>借助 JDK1.5 中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。可能是因为枚举在 JDK1.5 中才添加，所以在实际项目开发中，很少见人这么写过。</p>
<p>优点<br>系统内存中该类只存在一个对象，节省了系统资源，对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能。</p>
<p>缺点<br>当想实例化一个单例类的时候，必须要记住使用相应的获取对象的方法，而不是使用 new，可能会给其他开发人员造成困扰，特别是看不到源码的时候。</p>
<p>适用场合<br>需要频繁的进行创建和销毁的对象；<br>创建对象时耗时过多或耗费资源过多，但又经常用到的对象；<br>工具类对象；<br>频繁访问数据库或文件的对象。</p>
<h3 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h3><p>工厂方法是指定义<strong>工厂接口和产品接口</strong>，但如何创建实际工厂和实际产品被推迟到子类实现，从而使调用方只和抽象工厂与抽象产品打交道。</p>
<p>实际更常用的是更简单的<strong>静态工厂方法</strong>，它允许工厂内部对创建产品进行优化。</p>
<p>调用方尽量持有接口或抽象类，避免持有具体类型的子类，以便工厂方法能随时切换不同的子类返回，却不影响调用方代码。</p>
<p><strong>Integer n &#x3D; Integer.valueOf(100);</strong></p>
<p>Integer 既是产品又是静态工厂。它提供了静态方法 valueOf()来创建 Integer。那么这种方式和直接写 new Integer(100)有何区别呢？我们观察 valueOf()方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public final class Integer &#123;<br>    public static Integer valueOf(int i) &#123;<br>        if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)<br>            return IntegerCache.cache[i + (-IntegerCache.low)];<br>        return new Integer(i);<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure>


<p>它的好处在于，valueOf()内部可能会使用 new 创建一个新的 Integer 实例，<strong>但也可能直接返回一个缓存的 Integer 实例。对于调用方来说，没必要知道 Integer 创建的细节。</strong></p>
<h3 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h3><p>策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，<strong>可以灵活的使用其中的一个算法。</strong></p>
<p>策略模式在 Java 标准库中应用非常广泛，Arrays.sort()：</p>
<p>我们观察 Arrays.sort(T[] a, Comparator&lt;? super T&gt; c)，这个排序方法，它在内部实现了 TimSort 排序，但是，排序算法在比较两个元素大小的时候，需要借助我们<strong>传入的 Comparator 对象</strong>，才能完成比较。因此，这里的策略是指比较两个元素大小的策略，可以是忽略大小写比较，可以是倒序比较，也可以根据字符串长度比较。</p>
<p>因此，上述排序使用到了策略模式，它实际上指，在一个方法中，流程是确定的，但是，<strong>某些关键步骤的算法依赖调用方传入的策略，这样，传入不同的策略，即可获得不同的结果，大大增强了系统的灵活性。</strong></p>
<h3 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h3><p>将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。</p>
<p>适配器模式在 Java 标准库中有广泛应用。比如我们持有数据类型是 String[]，但是需要 List 接口时，可以用一个 Adapter：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">String[] exist = new String[] &#123;&quot;Good&quot;, &quot;morning&quot;, &quot;Bob&quot;, &quot;and&quot;, &quot;Alice&quot;&#125;;<br>Set&lt;String&gt; set = new HashSet&lt;&gt;(Arrays.asList(exist));<br></code></pre></td></tr></table></figure>


<p>注意到 List<T> Arrays.asList(T[])就相当于一个转换器，它可以把数组转换为 List。</p>
<h3 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h3><p>动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。</p>
<p><img src="https://i.loli.net/2021/08/05/MAzhEK9sGqicf3T.png" alt="image-20210805184859592"></p>
<p>最顶层的 Component 是接口，对应到 IO 的就是 InputStream 这个抽象类。ComponentA、ComponentB 是实际的子类，对应到 IO 的就是 FileInputStream、ServletInputStream 这些数据源。Decorator 是用于实现各个附加功能的抽象装饰器，对应到 IO 的就是 FilterInputStream。而从 Decorator 派生的就是一个一个的装饰器，它们每个都有独立的功能，对应到 IO 的就是 BufferedInputStream、GZIPInputStream 等。</p>
<p>Decorator 模式有什么好处？它实际上把核心功能和附加功能给分开了。核心功能指 FileInputStream 这些真正读数据的源头，附加功能指加缓冲、压缩、解密这些功能。如果我们要新增核心功能，就增加 Component 的子类，例如 ByteInputStream。如果我们要增加附加功能，就增加 Decorator 的子类，例如 CipherInputStream。两部分都可以独立地扩展，而具体如何附加功能，由调用方自由组合，从而极大地增强了灵活性。</p>
]]></content>
      <categories>
        <category>top</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>先想想写啥、咋写</title>
    <url>/2021/07/11/a%E7%AC%AC%E4%B8%80%E7%AF%87/</url>
    <content><![CDATA[<h1 id="为什么要写博客"><a href="#为什么要写博客" class="headerlink" title="为什么要写博客"></a>为什么要写博客</h1><p>工作一年来总感觉忙于工作业务，忽略了自我的成长与沉淀，偶尔动动笔记录点想法，感觉异常平静，受益匪浅，很利于修身养性。为什么不养成习惯了？</p>
<h2 id="平静内心"><a href="#平静内心" class="headerlink" title="平静内心"></a>平静内心</h2><p>在忙碌的生活里创造一个自我的空间，随意流浪。</p>
<h2 id="沉淀知识"><a href="#沉淀知识" class="headerlink" title="沉淀知识"></a>沉淀知识</h2><p>做业务、学技术…还是要多总结、多思考，防止猴子掰玉米行为。</p>
<h2 id="记录生活"><a href="#记录生活" class="headerlink" title="记录生活"></a>记录生活</h2><p>写写日记吧，回看起来，挺有意思的。</p>
<h2 id="思考人生"><a href="#思考人生" class="headerlink" title="思考人生"></a>思考人生</h2><p>时刻清醒，时刻思考，我是谁？要去哪？该做啥？</p>
<h1 id="写哪些内容"><a href="#写哪些内容" class="headerlink" title="写哪些内容"></a>写哪些内容</h1><p>一般的博客都会有分类、标签这两种方式来区分不同的博文，我想在这里先想好有哪些方方面面，来大致想象出可能会有的内容。</p>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><ul>
<li>生活随笔-随意记录生活感悟</li>
<li>吃喝玩乐-记录美好生活</li>
<li>宝藏分享-喜欢的音乐、电影、游戏…</li>
<li>Golang</li>
<li>Java</li>
<li>计算机基础-三大件</li>
<li>数据库</li>
<li>中间件-消息队列-es …</li>
<li>开发框架-spring…</li>
<li>开发工具-git、ide、linux …</li>
</ul>
<h2 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h2><p>不拘一格，随便加。</p>
<p><strong>最后，祝愿自己可以偶尔总结。</strong></p>
<blockquote>
<p>sticky: 100 排序置顶 tag</p>
</blockquote>
]]></content>
      <categories>
        <category>生活随笔</category>
      </categories>
      <tags>
        <tag>思考</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>下划线转驼峰</title>
    <url>/2021/08/09/%E4%B8%8B%E5%88%92%E7%BA%BF%E8%BD%AC%E9%A9%BC%E5%B3%B0/</url>
    <content><![CDATA[<p>举例：Hello_woRLD&#x3D;&#x3D;helloWorld</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static String camelName(String name) &#123;<br>       StringBuilder result = new StringBuilder();<br>       if (name == null || name.isEmpty()) &#123;<br>           return &quot;&quot;;<br>       &#125; else if (!name.contains(&quot;_&quot;)) &#123;<br>           // 不含下划线，仅将首字母小写<br>           return name.substring(0, 1).toLowerCase() + name.substring(1);<br>       &#125;<br>       // 用下划线将原始字符串分割<br>       String camels[] = name.split(&quot;_&quot;);<br>       for (String camel : camels) &#123;<br>           // 跳过原始字符串中开头、结尾的下换线或双重下划线<br>           if (camel.isEmpty()) &#123;<br>               continue;<br>           &#125;<br>           // 处理真正的驼峰片段<br>           if (result.length() == 0) &#123;<br>               // 第一个驼峰片段，全部字母都小写<br>               result.append(camel.toLowerCase());<br>           &#125; else &#123;<br>               // 其他的驼峰片段，首字母大写<br>               result.append(camel.substring(0, 1).toUpperCase());<br>               result.append(camel.substring(1).toLowerCase());<br>           &#125;<br>       &#125;<br>       return result.toString();<br>   &#125;<br></code></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>操作系统-fork</title>
    <url>/2021/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-fork/</url>
    <content><![CDATA[<h3 id="简单概念介绍"><a href="#简单概念介绍" class="headerlink" title="简单概念介绍"></a>简单概念介绍</h3><h4 id="逻辑地址"><a href="#逻辑地址" class="headerlink" title="逻辑地址"></a>逻辑地址</h4><p>CPU 所生成的地址。CPU 产生的<strong>逻辑地址</strong>被分为 :p （页号） 它包含每个页在物理内存中的基址，用来作为页表的索引；d （页偏移），同基址相结合，用来确定送入内存设备的物理内存地址。</p>
<h4 id="物理地址"><a href="#物理地址" class="headerlink" title="物理地址"></a>物理地址</h4><p>内存单元所看到的地址。用户程序看不见真正的物理地址。<strong>用户只生成逻辑地址，且认为进程的地址空间为 0 到 max。</strong>物理地址范围从 R+0 到 R+max，R 为基地址,地址映射－将程序地址空间中使用的逻辑地址变换成内存中的物理地址的过程。由<strong>内存管理单元（MMU）</strong>来完成。</p>
<p>可执行程序在存储（没有调入内存）时分为<strong>代码区，数据区，未初始化数据区</strong>三部分。</p>
<p>（1）代码区存放 CPU 执行的<strong>机器指令</strong>。通常代码区是共享的，即其它执行程序可调用它。代码段（code segment&#x2F;text segment）通常是只读的，有些构架也允许自行修改。<br>（2）数据区存放<strong>已初始化的全局变量，静态变量（包括全局和局部的），常量</strong>。static 全局变量和 static 函数只能在当前文件中被调用。<br>（3）未初始化数据区（Block Started by Symbol,BSS)<strong>存放全局未初始化的变量</strong>。BSS 的数据在程序开始执行之前被初始化为 0 或 NULL。</p>
<p> 可执行程序在运行时又多出了两个区域：<strong>栈区和堆区。</strong><br>    （4）<strong>栈区</strong>。由编译器自动释放，存放函数的<strong>参数值，局部变量</strong>等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈中。然后这个被调用的函数再为它的自动变量和临时变量在栈上分配空间。<strong>每调用一个函数一个新的栈就会被使用</strong>。栈区是从高地址位向低地址位增长的，<strong>是一块连续的内在区域</strong>，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。<br>    （5）<strong>堆区</strong>。用于<strong>动态内存分配</strong>，位于 BSS 和栈中间的地址位。由程序员<strong>申请分配（malloc)和释放（free）</strong>。堆是从低地址位向高地址位增长，<strong>采用链式存储结构</strong>。频繁地 malloc&#x2F;free 造成内存空间的不连续，<strong>产生碎片。</strong>当申请堆空间时库函数按照一定的算法搜索可用的足够大的空间。<strong>因此堆的效率比栈要低的多。</strong></p>
<h3 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h3><p>fork（）会<strong>产生一个和父进程完全相同的子进程</strong>，但子进程在此后多会 exec<strong>系统调用</strong>，出于效率考虑，linux 中引入了“<strong>写时复制</strong>“技术，也就是<strong>只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程</strong>。在 fork 之后 exec 之前两个进程用的是<strong>相同的物理空间（内存区）</strong>，子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</p>
<p><strong>当父子进程中有更改相应段的行为发生时</strong>，再为子进程相应的段分配物理空间。</p>
<p>如果<strong>不是因为 exec</strong>，内核会给子进程的数据段、堆栈段分配相应的物理空间（至此两者有各自的进程空间，互不影响），而<strong>代码段继续共享父进程的物理空间</strong>（两者的代码完全相同）。</p>
<p>如果<strong>是因为 exec</strong>，由于两者<strong>执行的代码不同</strong>，子进程的代码段也会分配单独的物理空间。</p>
<p>fork 时子进程获得父进程<strong>数据空间、堆和栈的复制，所以变量的地址是一样的。</strong></p>
<p>fork 子进程完全复制父进程的栈空间，也复制了页表，<strong>但没有复制物理页面</strong>，所以这时<strong>虚拟地址相同，物理地址也相同</strong>，但是会把父子共享的页面标记为“<strong>只读</strong>”（类似 mmap 的 private 的方式），如果父子进程一直对这个页面是同一个页面，知道其中<strong>任何一个进程要对共享的页面“写操作”</strong>，这时<strong>内核会复制一个物理页面给这个进程使用，同时修改页表。而把原来的只读页面标记为“可写”，留给另外一个进程使用</strong>。</p>
<p>这就是所谓的“<strong>写时复制</strong>”。正因为 fork 采用了这种写时复制的机制，所以 fork 出来子进程之后，父子进程哪个先调度呢？内核一般会先调度子进程，因为很多情况下子进程是要马上执行 exec，会清空栈、堆。这些和父进程共享的空间，加载新的代码段，这就避免了“写时复制”拷贝共享页面的机会。<strong>如果父进程先调度很可能写共享页面，会产生“写时复制”的无用功。</strong></p>
<p>在理解时，你可以认为 fork 后，这两个相同的虚拟地址指向的是不同的物理地址，这样方便理解父子进程之间的独立性</p>
<h4 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h4><p>但实际上，linux 为了提高 fork 的效率，采用了 <strong>copy-on-write</strong> 技术，fork 后，这两个虚拟地址实际上指向相同的物理地址（内存页），只有任何一个进程试图修改这个虚拟地址里的内容前，两个虚拟地址才会指向不同的物理地址（新的物理地址的内容从原物理地址中复制得到）。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-常见概念</title>
    <url>/2021/07/30/Spring-%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h3 id="什么是-Spring-框架"><a href="#什么是-Spring-框架" class="headerlink" title="什么是 Spring 框架?"></a>什么是 Spring 框架?</h3><p>Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。</p>
<p>我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。</p>
<p>比如说 Spring 自带 **IoC（Inverse of Control:控制反转） 和 AOP(Aspect-Oriented Programming:面向切面编程)**、可以很方便地对数据库进行访问、可以很方便地集成第三方组件（电子邮件，任务，调度，缓存等等）、对单元测试支持比较好、支持 RESTful Java 应用程序的开发。</p>
<h3 id="列举一些重要的-Spring-模块？"><a href="#列举一些重要的-Spring-模块？" class="headerlink" title="列举一些重要的 Spring 模块？"></a>列举一些重要的 Spring 模块？</h3><p>Spring Core</p>
<p>核心模块， Spring 其他所有的功能基本都需要依赖于该类库，主要提供 <strong>IoC 依赖注入</strong>功能的支持。</p>
<p>Spring Aspects</p>
<p>该模块为与 AspectJ 的集成提供支持。</p>
<p>Spring AOP</p>
<p>提供了<strong>面向切面的编程</strong>实现。</p>
<p>Spring Data Access&#x2F;Integration ：</p>
<p>Spring Data Access&#x2F;Integration 由 5 个模块组成：</p>
<p>spring-jdbc : 提供了对数据库访问的抽象 JDBC。不同的数据库都有自己独立的 API 用于操作数据库，而 Java 程序只需要和 JDBC API 交互，这样就屏蔽了数据库的影响。<br>spring-tx : 提供对事务的支持。<br>spring-orm : 提供对 Hibernate 等 ORM 框架的支持。<br>spring-oxm ： 提供对 Castor 等 OXM 框架的支持。<br>spring-jms : Java 消息服务。<br>Spring Web</p>
<p><strong>Spring Web 由 4 个模块组成：</strong></p>
<p>spring-web ：对 Web 功能的实现提供一些最基础的支持。<br>spring-webmvc ： 提供对 Spring MVC 的实现。<br>spring-websocket ： 提供了对 WebSocket 的支持，WebSocket 可以让客户端和服务端进行双向通信。<br>spring-webflux ：提供对 WebFlux 的支持。WebFlux 是 Spring Framework 5.0 中引入的新的响应式框架。与 Spring MVC 不同，它不需要 Servlet API，是完全异步.<br>Spring Test</p>
<p><strong>Spring 团队提倡测试驱动开发（TDD）</strong>。有了控制反转 (IoC)的帮助，单元测试和集成测试变得更简单。</p>
<p>Spring 的测试模块对 JUnit（单元测试框架）、TestNG（类似 JUnit）、Mockito（主要用来 Mock 对象）、PowerMock（解决 Mockito 的问题比如无法模拟 final, static， private 方法）等等常用的测试框架支持的都比较好。</p>
<h3 id="Spring-IOC-amp-AOP"><a href="#Spring-IOC-amp-AOP" class="headerlink" title="Spring IOC &amp; AOP"></a>Spring IOC &amp; AOP</h3><p>IoC（Inverse of Control:控制反转） 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将<strong>原本在程序中手动创建对象的控制权，交由 Spring 框架来管理</strong>。</p>
<h4 id="为什么叫控制反转？"><a href="#为什么叫控制反转？" class="headerlink" title="为什么叫控制反转？"></a>为什么叫控制反转？</h4><p>控制 ：指的是<strong>对象创建（实例化、管理）的权力</strong><br>反转 ：控制权交给外部环境（Spring 框架、IoC 容器）</p>
<p>将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件&#x2F;注解即可，完全不用考虑对象是如何被创建出来的。</p>
<p>在实际项目中一个 Service 类可能依赖了很多其他的类，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。</p>
<p>在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。</p>
<h4 id="谈谈自己对于-AOP-的了解"><a href="#谈谈自己对于-AOP-的了解" class="headerlink" title="谈谈自己对于 AOP 的了解"></a>谈谈自己对于 AOP 的了解</h4><p>AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如<strong>事务处理、日志管理、权限控制</strong>等）封装起来，便于减少系统的重复代码<strong>，</strong>降低模块间的耦合度，并有利于未来的可拓展性和可维护性。</p>
<p>Spring AOP 就是<strong>基于动态代理的</strong>，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib ，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理。</p>
<h3 id="Spring-bean"><a href="#Spring-bean" class="headerlink" title="Spring bean"></a>Spring bean</h3><p>简单来说，bean 代指的就是那些被 IoC 容器所管理的对象。</p>
<p>我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据的定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。</p>
<p>bean 的作用域有哪些?</p>
<p>singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的，对单例设计模式的应用。<br>prototype : 每次请求都会创建一个新的 bean 实例。<br>request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。<br>session : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。<br>global-session ： 全局 session 作用域，仅仅在基于 portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码(例如：HTML)片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话。</p>
<p><strong>如何配置 bean 的作用域呢？</strong></p>
<p>xml 方式：</p>
<p><bean id="..." class="..." scope="singleton"></bean><br>注解方式：</p>
<p>@Bean<br>@Scope(value &#x3D; ConfigurableBeanFactory.SCOPE_PROTOTYPE)<br>public Person personPrototype() {<br>    return new Person();<br>}</p>
<p><strong>单例 bean 的线程安全问题？</strong></p>
<p>大部分时候我们并没有在项目中使用多线程，所以很少有人会关注这个问题。单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。</p>
<p>常见的有两种解决办法：</p>
<p>在 bean 中尽量避免定义可变的成员变量。<br>在类中定义一个 <strong>ThreadLocal 成员变量</strong>，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。<br>不过，大部分 bean 实际都是无状态（没有实例变量）的（比如 Dao、Service），这种情况下， bean 是线程安全的。</p>
<p><strong>@Component 和 @Bean 的区别是什么？</strong><br>@Component 注解作用于类，而@Bean 注解作用于方法。<br>@Component 通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean 告诉了 Spring 这是某个类的示例，当我需要用它的时候还给我。<br>@Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring 容器时，则只能通过 @Bean 来实现。</p>
<p><strong>将一个类声明为 bean 的注解有哪些?</strong><br>我们一般使用 @Autowired 注解自动装配 bean，要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,采用以下注解可实现：</p>
<p>@Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。<br>@Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。<br>@Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。<br>@Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。</p>
<h4 id="bean-的生命周期"><a href="#bean-的生命周期" class="headerlink" title="bean 的生命周期?"></a>bean 的生命周期?</h4><p>Bean 容器找到配置文件中 Spring Bean 的定义。<br>Bean 容器利用 Java Reflection API 创建一个 Bean 的实例。<br>如果涉及到一些属性值 利用 set()方法设置一些属性值。<br>如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入 Bean 的名字。<br>如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader 对象的实例。<br>如果 Bean 实现了 BeanFactoryAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoade r 对象的实例。<br>与上面的类似，如果实现了其他 *.Aware 接口，就调用相应的方法。<br>如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行 postProcessBeforeInitialization() 方法<br>如果 Bean 实现了 InitializingBean 接口，执行 afterPropertiesSet()方法。<br>如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。<br>如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行 postProcessAfterInitialization() 方法<br>当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。<br>当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。</p>
<p><img src="https://i.loli.net/2021/08/11/W41nvyI2YuNFclL.png" alt="image-20210811145215723"></p>
<h3 id="Spring-MVC-原理"><a href="#Spring-MVC-原理" class="headerlink" title="Spring MVC 原理"></a>Spring MVC 原理</h3><p><img src="https://i.loli.net/2021/08/11/vCYGHg4qM1sbp5J.png" alt="image-20210811145259316"></p>
<p>客户端（浏览器）发送请求，直接请求到 DispatcherServlet。<br>DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。<br>解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。<br>HandlerAdapter 会根据 Handler 来调用真正的处理器开处理请求，并处理相应的业务逻辑。<br>处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。<br>ViewResolver 会根据逻辑 View 查找实际的 View。<br>DispaterServlet 把返回的 Model 传给 View（视图渲染）。<br>把 View 返回给请求者（浏览器）</p>
<h4 id="Spring-框架中用到了哪些设计模式？"><a href="#Spring-框架中用到了哪些设计模式？" class="headerlink" title="Spring 框架中用到了哪些设计模式？"></a>Spring 框架中用到了哪些设计模式？</h4><p><strong>工厂设计模式 :</strong> Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。<br><strong>代理设计模式</strong> : Spring AOP 功能的实现。<br><strong>单例设计模式</strong> : Spring 中的 Bean 默认都是单例的。<br><strong>模板方法模式</strong> : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。<br>包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。<br>观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。<br>适配器模式 : Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配 Controller。</p>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统-简单概念</title>
    <url>/2021/08/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h3 id="软中断硬中断"><a href="#软中断硬中断" class="headerlink" title="软中断硬中断"></a>软中断硬中断</h3><p>Linux 系统为了解决<strong>中断处理程序执⾏过⻓和中断丢失</strong>的问题，将中断过程分成了两个阶段，分别是</p>
<ul>
<li>上半部⽤来<strong>快速处理中断</strong>，⼀般会暂时关闭中断请求，主要负责处理跟<strong>硬件紧密相关或者时间敏感</strong>的事情。</li>
<li>下半部⽤来延迟处理上半部未完成的⼯作，⼀般以<strong>「内核线程」</strong>的⽅式运⾏。</li>
</ul>
<p><strong>⽹卡收到⽹络包后</strong>，会通过硬件中断通知内核有新的数据到了，于是内核就会调⽤对应的中断处理程序来响应该事件，这个事件的处理也是会分成上半部和下半部。</p>
<ul>
<li>上部分要做到快速处理，所以只要把<strong>⽹卡的数据读到内存中，然后更新⼀下硬件寄存器的状态</strong>，⽐如把状态更新为表示数据已经读到内存中的状态值。</li>
<li>接着，内核会触发⼀个软中断，把⼀些处理⽐较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部，其<strong>主要是需要从内存中找到⽹络数据，再按照⽹络协议栈，对⽹络数据进⾏逐层解析和处理，最后把数据送给应⽤程序</strong>。</li>
</ul>
<p>所以，中断处理程序的上部分和下半部可以理解为：</p>
<p>上半部直接处理硬件请求，也就是硬中断，主要是负责<strong>耗时短</strong>的⼯作，特点是<strong>快速执⾏</strong>；</p>
<p>下半部是由内核触发，也就说软中断，主要是负责上半部未完成的⼯作，通常都是<strong>耗时⽐较⻓</strong>的事情，特点是<strong>延迟执⾏</strong>；</p>
<h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><p>计算机是由各种外部硬件设备组成的，⽐如<strong>内存、cpu、硬盘</strong>等，如果每个应⽤都要和这些硬件设备对接通信协议，那这样太累了，所以由内核来负责，让<strong>内核作为应⽤连接硬件设备的桥梁</strong>，应⽤程序只需关⼼与内核交互，不⽤关⼼硬件的细节。<br>现代操作系统，内核⼀般会提供 4 个基本能⼒：</p>
<ul>
<li><strong>管理进程、线程</strong>，决定哪个进程、线程使⽤ CPU，也就是进程调度的能⼒；</li>
<li><strong>管理内存</strong>，决定内存的分配和回收，也就是内存管理的能⼒；</li>
<li><strong>管理硬件设备</strong>，为进程与硬件设备之间提供通信能⼒，也就是硬件通信能⼒；</li>
<li><strong>提供系统调⽤</strong>，如果应⽤程序要运⾏<strong>更⾼权限</strong>运⾏的服务，那么就需要有系统调⽤，它是⽤户程序与操作系统之间的接⼝。</li>
</ul>
<p><img src="https://i.loli.net/2021/08/04/qb4CBd1XiT2AHrv.png" alt="image-20210804214134653"></p>
<h3 id="堆栈"><a href="#堆栈" class="headerlink" title="堆栈"></a>堆栈</h3><p>由编译器自动释放，存放函数的<strong>参数值，局部变量</strong>等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈中。然后这个被调用的函数再为它的自动变量和临时变量在栈上分配空间。<strong>每调用一个函数一个新的栈就会被使用</strong>。栈区是从高地址位向低地址位增长的，<strong>是一块连续的内在区域</strong>，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。</p>
<h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p>堆是是<strong>不连续的内存区域</strong>，这是由于系统使用<strong>链表存储空闲内存地址的</strong>，自然是不连续的。而链表的遍历方式是由低地址向高地址，堆的大小受限于计算机系统中有效的内存，由此可见，堆获得的空间比较灵活，也比较大。<br>操作系统有一个<strong>记录空闲内存地址的链表</strong>，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，</p>
<h3 id="32-位-64-位"><a href="#32-位-64-位" class="headerlink" title="32 位 64 位"></a>32 位 64 位</h3><p>从程序上说：32 位与 64 位程序，是指经过语言编译后的可执行文件，比如 C 语言编写的程序就需要区分是 32 位的还是 64 位</p>
<p>从系统和硬件上讲：<strong>CPU 一次处理数据的能力是 32 位还是 64 位</strong>，关系着系统需要安装 32 位还是 64 位的系统</p>
<p>32 位和 64 位中的“位”，也叫字长，是 CPU 通用寄存器的数据宽度，是数据传递和处理的基本单位。字长是 CPU 的主要技术指标之一，指的是 CPU 一次能并行处理的二进制位数，字长总是 8 的整数倍</p>
<p><img src="https://i.loli.net/2021/08/05/5TA1EkOFcBIMp8Q.png" alt="image-20210805161650063"></p>
<h3 id="用户态内核态"><a href="#用户态内核态" class="headerlink" title="用户态内核态"></a>用户态内核态</h3><p><img src="https://i.loli.net/2021/08/06/G6DNz3QckpS4dMO.png" alt="image-20210806101858699"></p>
<p>内核态：控制计算机的硬件资源，并提供上层应用程序运行的环境。</p>
<p>用户态：上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源。</p>
<p>系统调用：为了使上层应用能够访问到这些资源，内核为上层应用提供访问的接口。</p>
<p>在 CPU 的所有指令中，<strong>有一些指令是非常危险的</strong>，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。如果所有的程序都能使用这些指令，那么十分危险。所以，CPU 将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统-线程与进程</title>
    <url>/2021/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h3><h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><p>更好的描述和控制程序的并发执行。<br>PCB 进程控制块-进程存在的唯一标志。<br>程序的一次执行过程。<br>拥有资源的基本单位。<br>状态：运行，就绪，阻塞，创建，结束</p>
<h4 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h4><p>一个基本的 CPU 执行单元。<br>是系统独立调度派的基本单位。<br>一个进程中可以有多个线程。<br>线程切换只需要保存设置程序计数器，虚拟机栈少量内容，开销小。轻量级进程。</p>
<h3 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h3><ul>
<li>⼀旦操作系统把进程切换到运⾏状态，也就意味着该进程占⽤着 CPU 在执⾏，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执⾏了，于是操作系统会选择下⼀个要运⾏的进程。</li>
<li><strong>选择⼀个进程运⾏这⼀功能是在操作系统中完成的，通常称为调度程序（scheduler）</strong></li>
<li>在进程的⽣命周期中，当<strong>进程从⼀个运⾏状态到另外⼀状态变化的时候</strong>，其实会触发⼀次调度。 </li>
<li>⾮抢占式调度算法挑选⼀个进程，然后让<strong>该进程运⾏直到被阻塞，或者直到该进程退出</strong>，才会调⽤另外⼀个进程，也就是说不会理时钟中断这个事情。 </li>
<li>抢占式调度算法挑选⼀个进程，然后让该进程只运⾏某段时间，如果在该时段结束时，该进程仍然在运⾏时，则会<strong>把它挂起</strong>，接着调度程序从就绪队列挑选另外⼀个进程。</li>
<li>这种抢占式调度处理，需要在时间间隔的末端发⽣时钟中断，以便把 CPU 控制返回给调度程序进⾏调度，也就是常说的<strong>时间⽚机制 。</strong></li>
</ul>
<p><strong>调度的算法评价：</strong></p>
<ol>
<li><strong>CPU 利⽤率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提⾼ CPU 的利⽤率；</li>
<li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，⻓作业的进程会占⽤较⻓的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li><strong>周转时间</strong>：周转时间是进程运⾏和阻塞时间总和，⼀个进程的周转时间越⼩越好；</li>
<li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，⽽是进程处于就绪队列的时间，等待的时间越⻓，⽤户越不满意；</li>
<li><strong>响应时间</strong>：⽤户提交请求到系统第⼀次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ol>
<h3 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h3><h4 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h4><ul>
<li>连接两个进程实现通信的一个共享文件。pipe</li>
<li><strong>字符流</strong>的形式写入接收。</li>
<li>固定大小的缓冲区，4kb。</li>
<li>同一时刻只能<strong>单向通信。</strong></li>
<li>不管是匿名管道还是命名管道，进程写⼊的数据都是<strong>缓存在内核中</strong>，另⼀个进程读取数据时候⾃然也是从内核中获取，同时通信数据都遵循<strong>先进先出原则</strong>。</li>
<li>缓冲区中有数据才能读，写数据会先写满，才会允许读。还有数据时，不允许写。</li>
</ul>
<h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><ul>
<li><p>管道的通信⽅式是效率低的，因此<strong>管道不适合进程间频繁地交换数据</strong>。</p>
</li>
<li><p>消息队列的通信模式就可以解决。⽐如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。</p>
</li>
<li><p>消息队列是<strong>保存在内核中的消息链表</strong>，在发送数据时，会分成⼀个⼀个<strong>独⽴的数据单元，也就是消息体</strong>（数据块），消息体是<strong>⽤户⾃定义的数据类型</strong>，消息的发送⽅和接收⽅要约定好消息体的数据类型，所以每个消息体都是<strong>固定⼤⼩的存储块，</strong>不像管道是⽆格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</p>
</li>
<li><p>消息队列⽣命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在，⽽前⾯提到的匿名管道的⽣命周期，是随进程的创建⽽建⽴，随进程的结束⽽销毁。</p>
</li>
<li><p>消息队列<strong>不适合⽐较⼤数据的传输，</strong>因为在内核中每个消息体都有⼀个最⼤⻓度的限制，同时所有队列所包含的全部消息体的总⻓度也是有上限。</p>
</li>
<li><p>消息队列通信过程中，<strong>存在⽤户态与内核态之间的数据拷⻉开销。</strong></p>
</li>
</ul>
<h4 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h4><ul>
<li>拿出⼀块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写⼊的东⻄，另外⼀个进程⻢上就能看到了，<strong>不需要拷⻉来拷⻉去，⼤⼤提⾼了进程间通信的速度。</strong></li>
</ul>
<h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><ul>
<li><p>多个进程同时修改同⼀个共享内存，很有可能就冲突。<strong>信号量就实现了这⼀保护机制。</strong></p>
</li>
<li><p>信号量其实是⼀个<strong>整型的计数器</strong>，主要⽤于实现进程间的<strong>互斥与同步</strong>，⽽不是⽤于缓存进程间通信的数据。</p>
</li>
<li><p><strong>信号量表示资源的数量</strong>，控制信号量的⽅式有两种原⼦操作：</p>
</li>
<li><p><strong>⼀个是 P 操作，这个操作会把信号量减去 1，</strong>相减后如果信号量 **&lt; 0，**则表明资源已被占⽤，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使⽤，进程可正常继续执⾏。</p>
</li>
<li><p><strong>另⼀个是 V 操作，这个操作会把信号量加上 1，</strong>相加后如果信号量 **&lt;&#x3D; 0**，则表明当前有阻塞中的进程，于是会将该进程唤醒运⾏；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</p>
</li>
<li><p>P 操作是⽤在进⼊共享资源之前，V 操作是⽤在离开共享资源之后，这两个操作是必须<strong>成对出现的。</strong></p>
</li>
<li><p><strong>信号量初始化为 1</strong> ，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有⼀个进程在访问，这就很好的保护了共享内存。</p>
</li>
<li><p>信号量来实现多进程<strong>同步的⽅式</strong>，我们可以<strong>初始化信号量为 0</strong> 。</p>
</li>
</ul>
<p><img src="https://i.loli.net/2021/08/06/puJzalWFGyTfjmt.png" alt="image-20210801220932770"></p>
<h4 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h4><ul>
<li>对于<strong>异常情况下的⼯作模式</strong>，就需要⽤「信号」的⽅式来通知进程。</li>
<li>信号事件的来源主要有<strong>硬件来源</strong>（如键盘 Cltr+C ）和<strong>软件来源</strong>（如 kill 命令）。</li>
<li>信号是进程间通信机制中<strong>唯⼀的异步通信机制</strong>，因为可以在任何时候发送信号给某⼀进程，⼀旦有信号产⽣，我们就有下⾯这⼏种，⽤户进程对信号的处理⽅式。</li>
<li><strong>默认操作，捕捉信号，忽略信号。</strong></li>
</ul>
<h4 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h4><p>  Socket 通信不仅可以<strong>跨⽹络与不同主机的进程间通信，还可以在同主机上进程间通信。</strong><br>  根据创建 socket 类型的不同，通信的⽅式也就不同：</p>
<ul>
<li><strong>实现 TCP 字节流通信</strong>： socket 类型是 AF_INET 和 SOCK_STREAM；</li>
<li><strong>实现 UDP 数据报通信</strong>： socket 类型是 AF_INET 和 SOCK_DGRAM；</li>
<li><strong>实现本地进程间通信：</strong> 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket。</li>
</ul>
<h5 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h5><ul>
<li>服务端和客户端初始化 socket ，得到⽂件描述符；</li>
<li><strong>服务端调⽤ bind</strong> ，将绑定在 IP 地址和端⼝;</li>
<li><strong>服务端调⽤ listen</strong> ，进⾏监听；</li>
<li><strong>服务端调⽤ accept</strong> ，等待客户端连接；</li>
<li><strong>客户端调⽤ connect</strong> ，向服务器端的地址和端⼝发起连接请求；</li>
<li>服务端 accept 返回<strong>⽤于传输的 socket 的⽂件描述符；</strong></li>
<li>客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；</li>
<li>客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完数据后，服务端调⽤ close ，表示连接关闭。</li>
</ul>
<h5 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h5><ul>
<li>每⼀个 UDP 的 socket 都需要 bind 。</li>
</ul>
<h3 id="进程同步"><a href="#进程同步" class="headerlink" title="进程同步"></a>进程同步</h3><h4 id="哲学家就餐"><a href="#哲学家就餐" class="headerlink" title="哲学家就餐"></a>哲学家就餐</h4><p>⽤⼀个数组 state 来记录每⼀位哲学家在<strong>进程、思考还是饥饿状态</strong>（正在试图拿叉⼦）。那么，⼀个哲学家只有在两个邻居都没有进餐时，才可以进⼊进餐状态。</p>
<h4 id="生产者消费者"><a href="#生产者消费者" class="headerlink" title="生产者消费者"></a>生产者消费者</h4><p><strong>互斥信号量 mutex ：</strong>⽤于互斥访问缓冲区，初始化值为 1；<br><strong>资源信号量 fullBuffers</strong> ：⽤于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0<br>（表明缓冲区⼀开始为空）；<br><strong>资源信号量 emptyBuffers</strong> ：⽤于⽣产者询问缓冲区是否有空位，有空位则⽣成数据，初始化值为 n<br>（缓冲区⼤⼩）；</p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>多个进程因为竞争资源造成僵局，互相等待。</p>
<p><strong>条件</strong></p>
<ul>
<li>互斥-资源仅为一个线程占有</li>
<li>不剥夺</li>
<li>请求与保持-保持了至少一个资源又在请求其他的资源</li>
<li>循环等待-进程资源的循环等待链</li>
</ul>
<h3 id="其他的锁"><a href="#其他的锁" class="headerlink" title="其他的锁"></a>其他的锁</h3><p><strong>互斥锁</strong>加锁失败后，线程会释放 CPU ，给其他线程；（两次线程上下文切换）<br><strong>⾃旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁<br>⾃旋锁是通过 CPU 提供的 <strong>CAS</strong> 函数（Compare And Swap），在「⽤户态」完成加锁和解锁操作，<strong>不会主动产⽣线程上下⽂切换，所以相⽐互斥锁来说，会快⼀些，开销也⼩⼀些。</strong></p>
<p><strong>互斥锁、⾃旋锁、读写锁，都是属于悲观锁</strong>。<br>悲观锁做事⽐较悲观，它认为多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁。<br>那相反的，如果<strong>多线程同时修改共享资源的概率⽐较低，就可以采⽤乐观锁。</strong></p>
<p>乐观锁做事⽐较乐观，它假定冲突的概率很低，它的⼯作⽅式是：<strong>先修改完共享资源，再验证这段时间内有没有发⽣冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。</strong></p>
<p>放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很⾼，但是冲突的概率⾜够低的话，还是可以接受的。</p>
<p><strong>场景例⼦：在线⽂档。</strong><br>我们都知道在线⽂档可以同时多⼈编辑的，如果使⽤了悲观锁，那么只要有⼀个⽤户正在编辑⽂档，此时其他⽤户就⽆法打开相同的⽂档了，这⽤户体验当然不好了。<br>那实现多⼈同时编辑，实际上是⽤了乐观锁，它允许多个⽤户打开同⼀个⽂档进⾏编辑，编辑完提交之后才验证修改的内容是否有冲突。<br>怎么样才算发⽣冲突？这⾥举个例⼦，⽐如⽤户 A 先在浏览器编辑⽂档，之后⽤户 B 在浏览器也打开了相同的⽂档进⾏编辑，但是⽤户 B ⽐⽤户 A 提交改动，这⼀过程⽤户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并⾏修改的地⽅就会发⽣冲突。</p>
<p>服务端要怎么验证是否冲突了呢？<br>当⽤户提交修改时，发给服务端的请求<strong>会带上原始⽂档版本号</strong>，服务器收到后将它与当前版本号进⾏⽐较，<strong>如果版本号⼀致则修改成功，否则提交失败</strong></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>消息队列 基础</title>
    <url>/2023/07/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>基础</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统-调度算法</title>
    <url>/2021/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h3><h4 id="先来先服务"><a href="#先来先服务" class="headerlink" title="先来先服务"></a>先来先服务</h4><p>不利于短作业</p>
<h4 id="短作业优先"><a href="#短作业优先" class="headerlink" title="短作业优先"></a>短作业优先</h4><p>不利于长作业</p>
<h4 id="高响应比优先"><a href="#高响应比优先" class="headerlink" title="高响应比优先"></a>高响应比优先</h4><p>权衡：优先权&#x3D;（等待时间+要求服务时间）&#x2F;要求服务时间</p>
<h4 id="时间片轮转"><a href="#时间片轮转" class="headerlink" title="时间片轮转"></a>时间片轮转</h4><ul>
<li><p>如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率；</p>
</li>
<li><p>如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。</p>
</li>
<li><p>⼀般来说，时间⽚设为 <strong>20ms~50ms</strong> 通常是⼀个⽐较合理的折中值。</p>
</li>
</ul>
<h4 id="最高优先级"><a href="#最高优先级" class="headerlink" title="最高优先级"></a>最高优先级</h4><ul>
<li><p>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化；</p>
</li>
<li><p>动态优先级：根据进程的动态变化调整优先级，⽐如如果进程运⾏时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升⾼其优先级，也就是随着时间的推移增加等待进程的优先级。<br>该算法也有两种处理优先级⾼的⽅法，⾮抢占式和抢占式：</p>
</li>
<li><p>⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程。</p>
</li>
<li><p>抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏。</p>
</li>
<li><p>但是依然有缺点，可能会导致低优先级的进程永远不会运⾏。</p>
</li>
</ul>
<h4 id="多级反馈队列"><a href="#多级反馈队列" class="headerlink" title="多级反馈队列"></a>多级反馈队列</h4><p>  是「时间⽚轮转算法」和「最⾼优先级算法」的综合和发展。</p>
<p><img src="https://i.loli.net/2021/08/06/6ziUqckShIRCQFN.png" alt="image-20210801222105298"></p>
<ul>
<li>设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短；</li>
<li>新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成；</li>
<li>当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏；</li>
<li>可以发现，对于短作业可能可以在第⼀级队列很快被处理完。对于⻓作业，如果在第⼀级队列处理不完，可以移⼊下次队列等待被执⾏，虽然等待的时间变⻓了，但是运⾏时间也变更⻓了，所以该算法很好的兼顾了⻓短作业，同时有较好的响应时间。</li>
</ul>
<h3 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h3><h4 id="最佳页面（OPT）"><a href="#最佳页面（OPT）" class="headerlink" title="最佳页面（OPT）"></a>最佳页面（OPT）</h4><p>淘汰以后最长时间不用的。<br>无法实现，不能预知未来，可以用来评价其他算法。</p>
<h4 id="先进先出（FIFO）"><a href="#先进先出（FIFO）" class="headerlink" title="先进先出（FIFO）"></a>先进先出（FIFO）</h4><p>淘汰最早进入的。</p>
<h4 id="最久未使用（LRU）"><a href="#最久未使用（LRU）" class="headerlink" title="最久未使用（LRU）"></a>最久未使用（LRU）</h4><h4 id="时钟页面置换（CLOCK）"><a href="#时钟页面置换（CLOCK）" class="headerlink" title="时钟页面置换（CLOCK）"></a>时钟页面置换（CLOCK）</h4><ul>
<li>LRU 开销比较大。难以实现。</li>
<li>该算法的思路是，把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最⽼的⻚⾯。</li>
<li>当发⽣缺⻚中断时，算法⾸先检查表针指向的⻚⾯：</li>
<li>如果它的访问位位是 0 就淘汰该⻚⾯，并把新的⻚⾯插⼊这个位置，然后把表针前移⼀个位置；</li>
<li>如果访问位是 1 就清除访问位，并把表针前移⼀个位置，重复这个过程直到找到了⼀个访问位为 0 的⻚⾯为⽌。</li>
</ul>
<h4 id="最不常用"><a href="#最不常用" class="headerlink" title="最不常用"></a>最不常用</h4><p>设置访问计数器。</p>
<h3 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h3><h4 id="先来先服务-1"><a href="#先来先服务-1" class="headerlink" title="先来先服务"></a>先来先服务</h4><h4 id="最短寻道时间"><a href="#最短寻道时间" class="headerlink" title="最短寻道时间"></a>最短寻道时间</h4><p>找最近的。<br><strong>会产生饥饿现象。</strong></p>
<h4 id="扫描算法（Scan）"><a href="#扫描算法（Scan）" class="headerlink" title="扫描算法（Scan）"></a>扫描算法（Scan）</h4><p>磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的<strong>最后的磁道</strong>，才调换⽅向，这就是扫描（Scan）算法。</p>
<p><strong>问题：中间磁道比较优先级高。</strong></p>
<h4 id="循环扫描（CSCAN）"><a href="#循环扫描（CSCAN）" class="headerlink" title="循环扫描（CSCAN）"></a>循环扫描（CSCAN）</h4><p>只有磁头朝某个特定⽅向移动时，才处理磁道访问请求，⽽返回时<strong>直接快速移动⾄最靠边缘的磁道</strong>，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应⼀个⽅向上的请求。</p>
<h4 id="LOOK-与-CLOOK"><a href="#LOOK-与-CLOOK" class="headerlink" title="LOOK 与 CLOOK"></a>LOOK 与 CLOOK</h4><p>扫描算法和循环扫描算法，都是磁头移动到磁盘「<strong>最始端或最末端</strong>」才开始调换⽅向。<br>优化的思路就是磁头在移动到「<strong>最远的请求</strong>」位置，然后⽴即反向移动。</p>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>调度算法</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统-内存管理</title>
    <url>/2021/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h3 id="分段管理"><a href="#分段管理" class="headerlink" title="分段管理"></a>分段管理</h3><p><img src="https://i.loli.net/2021/08/06/gY7BE1UoqzbDnLO.png" alt="image-20210801212559233"></p>
<p><img src="https://i.loli.net/2021/08/06/EevMmVO14PZa8gF.png" alt="image-20210801214351270"></p>
<p>进程的地址空间：按照程序自身的<strong>逻辑关系划分</strong>（代码段，数据段……）为若干个段，每个段都有一个段名（在低级语言中，程序员使用段名来编程），每段从 0 开始编址。<br>内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。</p>
<p>由于是按逻辑功能模块划分，用户编程更方便，程序可读性更高。</p>
<p><strong>逻辑地址</strong>：段号：段内地址</p>
<p><strong>段表</strong>：段号&#x3D;段基地址&#x3D;段长。<br>缺点：</p>
<ul>
<li><strong>内存碎片。</strong></li>
<li><strong>内存交换效率低。</strong></li>
</ul>
<h3 id="分页管理"><a href="#分页管理" class="headerlink" title="分页管理"></a>分页管理</h3><h4 id="分页式"><a href="#分页式" class="headerlink" title="分页式"></a>分页式</h4><ul>
<li><p><strong>固定分区会产生碎片</strong>。把内存划分为很多块，作为进程内存分配的最小单位。</p>
</li>
<li><p>页面大小要权衡，应该是 2 的幂次。太大会产生页内碎片，太小，页表会占用大量内存，降低换入换出效率。<br><strong>分页管理的地址结构：页号：页内偏移量</strong></p>
<p>为 32 位，<strong>0-11 为页内偏移，12-31 为页号。</strong></p>
<p>每页大小 2^12&#x3D;<strong>4kb。</strong></p>
</li>
<li><p>为了方便每个进程<strong>在内存中找到每个页面对应的物理块</strong>，会为每个进程创建一张<strong>页表</strong>（存储在内存中&#x3D;&#x3D;&#x3D;访问一次数据需要<strong>访问两次内存</strong>）。<br>页表由<strong>页表项</strong>组成<strong>第一部分是，页号，第二部分是物理块号。</strong></p>
</li>
</ul>
<p><img src="https://i.loli.net/2021/08/06/CjPalYZUGqMAsEn.png" alt="image-20210801213808642"></p>
<h4 id="分页管理问题"><a href="#分页管理问题" class="headerlink" title="分页管理问题"></a>分页管理问题</h4><ul>
<li>每次访问内存<strong>都需要进行地址的转换</strong>。速度受限制。</li>
<li><strong>页表不能太大</strong>，否则内存利用率会降低。</li>
</ul>
<h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><ul>
<li><p>具有并行查找能力的高速缓冲存储器&#x3D;&#x3D;<strong>快表（联想存储器 TLB）</strong>–把最常访问的⼏个⻚表项存储到访问速度更快的硬件。</p>
</li>
<li><p>这时先查快表，没有再查慢表。（局部性原理）</p>
</li>
</ul>
<h4 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h4><ul>
<li><p>虚拟内存地址空间 4Gb，页表大小是 4kb，需要 100 万个页，假设每个页表项大小为 4b。那么需要 4Mb 来存储页表。</p>
</li>
<li><p>每个进程都有自己的页表，假设有 200 个进程，就需要 800Mb 来存储页表，很大了。</p>
</li>
<li><p>建立上一级页表存储页表间的映射关系。</p>
</li>
<li><p><strong>顶级页表一般只有一个页面。</strong></p>
</li>
</ul>
<p>建立多级页表：建立索引，不用去存储无用页表项，也不用去盲目的查找页表项。</p>
<p><img src="https://i.loli.net/2021/08/06/ZQH2XSo81gRuCa7.png" alt="image-20210801213945467"></p>
<h3 id="段页式管理"><a href="#段页式管理" class="headerlink" title="段页式管理"></a>段页式管理</h3><ul>
<li>分段<strong>利于反应程序的逻辑结构以及段的共享</strong>。</li>
<li>先将程序划分为<strong>多个有逻辑意义的段</strong>，接着再把<strong>每个段划分为多个⻚</strong>，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚；</li>
<li>地址结构就由<strong>段号、段内⻚号和⻚内位移</strong>三部分组成。</li>
<li>⽤于段⻚式地址变换的数据结构是每⼀个程序⼀张段表，每个段⼜建⽴⼀张⻚表，段表中的地址是⻚表的起始地址，⽽⻚表中的地址则为某⻚的物理⻚号。</li>
</ul>
<p><img src="https://i.loli.net/2021/08/06/knoWqyRxGDMKC1P.png" alt="image-20210801214844351"></p>
<ul>
<li>第⼀次访问段表，得到<strong>⻚表起始地址；</strong></li>
<li>第⼆次访问⻚表，得到<strong>物理⻚号；</strong></li>
<li>第三次将物理⻚号与⻚内位移组合，得到物理地址。</li>
</ul>
<h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>基于局部性原理：程序装入时，先装入一部分，其他的驻留在外存，当访问的信息不在内存时，再换入。<br>这好像给用户提供了一个比实际内存大的内存空间。</p>
<p><strong>使用外存的空间来扩展内存的空间。</strong><br><strong>实现：</strong><br>    分页<br>    分段<br>    段页式<br>需要：<br>    内外存<br>    页表机制<br>    中断机构（缺页中断）<br>    地址变换（先检索快表）</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>为了在多进程环境下，使得<strong>进程之间的内存地址不受影响</strong>，相互隔离，于是操作系统就为每个进程独⽴分<br>配⼀套<strong>虚拟地址空间</strong>，每个程序只关⼼⾃⼰的虚拟地址就可以，实际上⼤家的虚拟地址都是⼀样的，但分<br>布到物理地址内存是不⼀样的。作为程序，也不⽤关⼼物理地址的事情。</p>
<p>每个进程都有⾃⼰的虚拟空间，⽽物理内存只有⼀个，所以当启⽤了⼤量的进程，物理内存必然会很紧<br>张，于是操作系统会通过<strong>内存交换</strong>技术，把不常使⽤的内存暂时存放到硬盘（换出），在需要的时候再装<br>载回物理内存（换⼊）。</p>
<p>那既然有了虚拟地址空间，那必然要把<strong>虚拟地址「映射」到物理地址</strong>，这个事情通常由操作系统来维护。<br>那么对于虚拟地址与物理地址的映射关系，可以有<strong>分段和分⻚</strong>的⽅式，同时两者结合都是可以的。</p>
<p>内存分段是根据<strong>程序的逻辑⻆度</strong>，分成了<strong>栈段、堆段、数据段、代码段</strong>等，这样可以分离出不同属性的<br>段，同时是⼀块连续的空间。但是每个段的⼤⼩都不是统⼀的，这就会导致<strong>内存碎⽚和内存交换效率低</strong>的<br>问题。</p>
<p>于是，就出现了内存分⻚，把虚拟空间和物理空间分成⼤⼩固定的⻚，如在 Linux 系统中，每⼀⻚的⼤⼩<br>为 <strong>4KB</strong> 。由于分了⻚后，就不会产⽣细⼩的内存碎⽚。同时在内存交换的时候，写⼊硬盘也就⼀个⻚或<br>⼏个⻚，这就⼤⼤提⾼了内存交换的效率。</p>
<p>再来，为了解决简单分⻚产⽣的<strong>⻚表过⼤的问题</strong>，就有了<strong>多级⻚表</strong>，它解决了空间上的问题，但这就会导<br>致 CPU 在寻址的过程中，需要有很多层表参与，加⼤了时间上的开销。于是根据程序的局部性原理，在<br>CPU 芯⽚中加⼊了 <strong>TLB，负责缓存最近常被访问的⻚表项，⼤⼤提⾼了地址的转换速度。</strong></p>
<p><strong>Linux 系统主要采⽤了分⻚管理</strong>，但是由于 Intel 处理器的发展史，Linux 系统⽆法避免分段管理。于是<br>Linux 就把<strong>所有段的基地址设为 0</strong> ，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相<br>当于屏蔽了 CPU 逻辑地址的概念，所以段只被⽤于访问控制和内存保护。</p>
<p>另外，Linxu 系统中虚拟空间分布可分为<strong>⽤户态和内核态</strong>两部分，其中⽤户态的分布：<strong>代码段、全局变量、</strong><br><strong>BSS、函数栈、堆内存、映射区</strong></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title>最长回文子串（子序列）</title>
    <url>/2021/07/30/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2%EF%BC%88%E5%AD%90%E5%BA%8F%E5%88%97%EF%BC%89/</url>
    <content><![CDATA[<h4 id="1，最长回文子串"><a href="#1，最长回文子串" class="headerlink" title="1，最长回文子串"></a>1，最长回文子串</h4><h5 id="动态规划：o（n-2）空间复杂度"><a href="#动态规划：o（n-2）空间复杂度" class="headerlink" title="动态规划：o（n^2）空间复杂度"></a>动态规划：o（n^2）空间复杂度</h5><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> String <span class="hljs-title function_">longestPalindrome</span><span class="hljs-params">(String s)</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> s.length();<br>    <span class="hljs-keyword">if</span> (len &lt; <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> s;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">maxLen</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">begin</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>    <span class="hljs-comment">// dp[i][j] 表示 s[i, j] 是否是回文串</span><br>    <span class="hljs-type">boolean</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">boolean</span>[len][len];<br>    <span class="hljs-type">char</span>[] charArray = s.toCharArray();<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; len; i++) &#123;<br>        dp[i][i] = <span class="hljs-literal">true</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt; len; j++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; j; i++) &#123;<br>            <span class="hljs-keyword">if</span> (charArray[i] != charArray[j]) &#123;<br>                dp[i][j] = <span class="hljs-literal">false</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">if</span> (j - i &lt;= <span class="hljs-number">2</span>) &#123;<br>                    dp[i][j] = <span class="hljs-literal">true</span>;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    dp[i][j] = dp[i + <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>];<br>                &#125;<br>            &#125;<br>            <span class="hljs-comment">// 只要 dp[i][j] == true 成立，就表示子串 s[i..j] 是回文，此时记录回文长度和起始位置</span><br>            <span class="hljs-keyword">if</span> (dp[i][j] &amp;&amp; j - i + <span class="hljs-number">1</span> &gt; maxLen) &#123;<br>                maxLen = j - i + <span class="hljs-number">1</span>;<br>                begin = i;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> s.substring(begin, begin + maxLen);<br>&#125;<br><br></code></pre></td></tr></table></figure>

<h5 id="最优解：中心扩散法。o（1）空间复杂度"><a href="#最优解：中心扩散法。o（1）空间复杂度" class="headerlink" title="最优解：中心扩散法。o（1）空间复杂度"></a>最优解：中心扩散法。o（1）空间复杂度</h5><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">longestPalindrome</span><span class="hljs-params">(String s)</span> &#123;<br>       <span class="hljs-keyword">if</span> (s.length() &lt; <span class="hljs-number">2</span>) &#123;<br>           <span class="hljs-keyword">return</span> s;<br>       &#125;<br>       <span class="hljs-type">int</span> <span class="hljs-variable">start</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, max = <span class="hljs-number">1</span>;<br>       <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> s.length();<br>       <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; len; ) &#123;<br>           <span class="hljs-keyword">if</span> (len - i &lt;= max / <span class="hljs-number">2</span>) <span class="hljs-keyword">break</span>;<br>           <span class="hljs-type">int</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> i, right = i;<br>           <span class="hljs-keyword">while</span> (right &lt; len - <span class="hljs-number">1</span> &amp;&amp; s.charAt(right + <span class="hljs-number">1</span>) == s.charAt(right))<br>               ++right; <span class="hljs-comment">//过滤掉重复的</span><br>           <span class="hljs-comment">//下次在判断的时候从重复的下一个字符开始判断</span><br>           i = right + <span class="hljs-number">1</span>;<br>           <span class="hljs-comment">//然后往两边判断，找出回文子串的长度</span><br>           <span class="hljs-keyword">while</span> (right &lt; len - <span class="hljs-number">1</span> &amp;&amp; left &gt; <span class="hljs-number">0</span> &amp;&amp; s.charAt(right + <span class="hljs-number">1</span>) == s.charAt(left - <span class="hljs-number">1</span>)) &#123;<br>               ++right;<br>               --left;<br>           &#125;<br>           <span class="hljs-keyword">if</span> (right - left + <span class="hljs-number">1</span> &gt; max) &#123;<br>               max = right - left + <span class="hljs-number">1</span>;<br>               start = left;<br>           &#125;<br>       &#125;<br>       <span class="hljs-keyword">return</span> s.substring(start, start + max);<br>   &#125;<br></code></pre></td></tr></table></figure>

<h4 id="2，最长回文子序列"><a href="#2，最长回文子序列" class="headerlink" title="2，最长回文子序列"></a>2，最长回文子序列</h4><h5 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h5><p>dp[i][j]表示 i,j 范围的最长回文子序列。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">longestPalindromeSubseq</span><span class="hljs-params">(String s)</span> &#123;<br>    <span class="hljs-type">int</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[s.length()][s.length()];<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> s.length() - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;<br>        dp[i][i] = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> i + <span class="hljs-number">1</span>; j &lt; s.length(); j++) &#123;<br>            <span class="hljs-keyword">if</span> (s.charAt(i) == s.charAt(j)) &#123;<br>                dp[i][j] = dp[i + <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] + <span class="hljs-number">2</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                dp[i][j] = Math.max(dp[i + <span class="hljs-number">1</span>][j], dp[i][j - <span class="hljs-number">1</span>]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][s.length() - <span class="hljs-number">1</span>];<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="3，无重复最长子串"><a href="#3，无重复最长子串" class="headerlink" title="3，无重复最长子串"></a>3，无重复最长子串</h4><p>高频</p>
<p>思路：滑动窗口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">lengthOfLongestSubstring</span><span class="hljs-params">(String s)</span>&#123;<br>        <span class="hljs-type">int</span> len=s.length();<br>        HashMap&lt;Character,Integer&gt; map=<span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>        <span class="hljs-type">int</span> ans=<span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; len; j++) &#123;<br>            <span class="hljs-keyword">if</span> (map.containsKey(s.charAt(j)))&#123;<br>                i=Math.max(i,map.get(s.charAt(j)));<br>            &#125;<br>            ans=Math.max(ans,j-i+<span class="hljs-number">1</span>);<br>            map.put(s.charAt(j),j+<span class="hljs-number">1</span>);<span class="hljs-comment">//</span><br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br><br>核心：发现了重复的字符，左边窗口就要向右一位。<br>    如下写法亦可。<br>     <span class="hljs-keyword">if</span> (map.containsKey(s.charAt(j)))&#123;<br>                i=Math.max(i,map.get(s.charAt(j)+<span class="hljs-number">1</span>));<br>            &#125;<br>            ans=Math.max(ans,j-i+<span class="hljs-number">1</span>);<br>            map.put(s.charAt(j),j);<span class="hljs-comment">//</span><br>	&#125;<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>子串子序列</tag>
      </tags>
  </entry>
  <entry>
    <title>笔试随意记录</title>
    <url>/2021/07/31/%E7%AC%94%E8%AF%95%E6%80%BB%E7%BB%931/</url>
    <content><![CDATA[<h3 id="有序数组，交换两数，找出这两个数的下标"><a href="#有序数组，交换两数，找出这两个数的下标" class="headerlink" title="有序数组，交换两数，找出这两个数的下标"></a>有序数组，交换两数，找出这两个数的下标</h3><h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>用两个标志位去找乱序的那两个数字。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plain">public static int[] change(int[] nums) &#123;<br>        int first = -1;<br>        int second = -1;<br>        int[] res = new int[2];<br>        for (int i = 1; i &lt; nums.length; i++) &#123;<br>            if (first == -1 &amp;&amp; nums[i - 1] &gt; nums[i]) first = i - 1;<br>            if (first != -1 &amp;&amp; nums[i - 1] &gt; nums[i]) second = i;<br>        &#125;<br>        res[0] = first + 1;<br>        res[1] = second + 1;<br>        return res;<br>    &#125;<br></code></pre></td></tr></table></figure>

<h3 id="括号的个数"><a href="#括号的个数" class="headerlink" title="括号的个数"></a>括号的个数</h3><p>【】【】【【】3】2</p>
<p>表示 1+1+2（3）&#x3D;8 个括号</p>
<h4 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h4><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getBox</span><span class="hljs-params">(String s)</span> &#123;<br>       Stack&lt;Integer&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Stack</span>&lt;&gt;();<br>       <span class="hljs-type">int</span> <span class="hljs-variable">res</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>       <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; s.length(); i++) &#123;<br>           <span class="hljs-keyword">if</span> (s.charAt(i) == <span class="hljs-string">&#x27;[&#x27;</span>) &#123;<br>               stack.push(<span class="hljs-number">1</span>);<span class="hljs-comment">//保底一个</span><br>           &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (s.charAt(i) == <span class="hljs-string">&#x27;]&#x27;</span>) &#123;<br>               <span class="hljs-type">int</span> <span class="hljs-variable">temp</span> <span class="hljs-operator">=</span> stack.pop();<br>               <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span> &lt; s.length() &amp;&amp; s.charAt(i + <span class="hljs-number">1</span>) &lt;= <span class="hljs-string">&#x27;9&#x27;</span> &amp;&amp; s.charAt(i + <span class="hljs-number">1</span>) &gt; <span class="hljs-string">&#x27;0&#x27;</span>) &#123;<span class="hljs-comment">//后面为数字，要结算</span><br>                   temp *= (s.charAt(i + <span class="hljs-number">1</span>) - <span class="hljs-string">&#x27;0&#x27;</span>);<br>                   i++;<span class="hljs-comment">//结算完跳过这个数字</span><br>               &#125;<br>               <span class="hljs-keyword">if</span> (stack.isEmpty()) &#123;<span class="hljs-comment">//空的，表示一个分段算完了</span><br>                   res += temp;<br>               &#125; <span class="hljs-keyword">else</span> &#123;<br>                   <span class="hljs-type">int</span> <span class="hljs-variable">top</span> <span class="hljs-operator">=</span> stack.pop() + temp;<br>                   stack.push(top);<br>               &#125;<br>           &#125;<br>       &#125;<br>       <span class="hljs-keyword">return</span> res;<br>   &#125;<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>算法题</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络-http</title>
    <url>/2021/07/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-http/</url>
    <content><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>HTTP 是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和 规范」。</p>
<h2 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h2><h3 id="报文"><a href="#报文" class="headerlink" title="报文"></a>报文</h3><table>
<thead>
<tr>
<th align="left">方法 get：获取资源。 post：传输内容实体。 put：传输文件。 head：与 get 类似，不返回内容主体。</th>
<th>URI</th>
<th>协议版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">可选的首部字段</td>
<td></td>
<td></td>
</tr>
<tr>
<td align="left">内容实体</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>协议版本</th>
<th>状态码</th>
<th>状态码原因短语</th>
</tr>
</thead>
<tbody><tr>
<td>可选的响应首部字段</td>
<td></td>
<td></td>
</tr>
<tr>
<td>主体</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h3><p>1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际⽤到的⽐较少。 </p>
<p>2xx 类状态码表示<strong>服务器成功处理了客户端的请求</strong>，也是我们最愿意看到的状态。 </p>
<ul>
<li>「200 OK」是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body 数据。 </li>
<li>「204 No Content」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li>
<li>「206 Partial Content」是应⽤于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽ 是其中的⼀部分，也是服务器处理成功的状态。</li>
</ul>
<p>3xx 类状态码表示客户端请求的资源发送了变动，需要客户端⽤新的 URL 重新发送请求获取资源，也就是重定向。 </p>
<ul>
<li>「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。 </li>
<li>「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。 301 和 302 都会在响应头⾥使⽤字段 Location ，指明后续要跳转的 URL，浏览器会⾃动重定向新的 URL。</li>
</ul>
<p>4xx 类状态码表示客户端发送的报⽂有误，服务器⽆法处理，也就是错误码的含义。 </p>
<ul>
<li>「400 Bad Request」表示客户端请求的报⽂有错误，但只是个笼统的错误。 </li>
<li>「403 Forbidden」表示服务器禁⽌访问资源，并不是客户端的请求出错。 </li>
<li>「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以⽆法提供给客户端。</li>
</ul>
<p>5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错误码。 </p>
<ul>
<li>「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道。</li>
<li>「501 Not Implemented」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。</li>
<li>「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器 发⽣了错误。 </li>
<li>「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应服务器。</li>
</ul>
<h3 id="字段"><a href="#字段" class="headerlink" title="字段"></a>字段</h3><p>Host 字段 客户端发送请求时，⽤来指定服务器的域名。</p>
<p>服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。</p>
<p>Connection 字段最常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。</p>
<p>Content-Type 字段⽤于服务器回应时，告诉客户端，本次数据是什么格式。</p>
<p>Content-Encoding 字段说明数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式</p>
<h3 id="get-post"><a href="#get-post" class="headerlink" title="get post"></a>get post</h3><h4 id="区别？"><a href="#区别？" class="headerlink" title="区别？"></a>区别？</h4><p>Get ⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。</p>
<p>POST ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥。⽐如，留⾔后点击「提交」，浏览器就会执⾏⼀次 POST 请求，把你的留⾔⽂字放进了报⽂ body ⾥，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。</p>
<h4 id="安全幂等？"><a href="#安全幂等？" class="headerlink" title="安全幂等？"></a>安全幂等？</h4><p>在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。</p>
<p>所谓的「幂等」，意思是<strong>多次执⾏相同的操作</strong>，结果都是「相同」的。</p>
<p>那么很明显 <strong>GET ⽅法就是安全且幂等</strong>的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。<strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等的</strong>。</p>
<h3 id="HTTP-是不保存状态的协议-如何保存用户状态"><a href="#HTTP-是不保存状态的协议-如何保存用户状态" class="headerlink" title="HTTP 是不保存状态的协议,如何保存用户状态?"></a>HTTP 是不保存状态的协议,如何保存用户状态?</h3><p><img src="https://i.loli.net/2021/08/06/PvL5K2BYp18URHu.png" alt="image-20210806103941528"></p>
<p>HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。</p>
<p><strong>Session 机制</strong>的存在就是为了解决这个问题，Session 的主要作用就是<strong>通过服务端记录用户的状态</strong>。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。</p>
<p>服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个 Session）。</p>
<p>在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库 redis 保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，<strong>我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。</strong></p>
<p>Cookie 被禁用怎么办?</p>
<p><strong>最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。</strong></p>
<h3 id="Cookie-的作用是什么-和-Session-有什么区别？"><a href="#Cookie-的作用是什么-和-Session-有什么区别？" class="headerlink" title="Cookie 的作用是什么?和 Session 有什么区别？"></a>Cookie 的作用是什么?和 Session 有什么区别？</h3><p>Cookie 和 Session 都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。</p>
<p>Cookie 一般用来保存用户信息 比如 ① 我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；② 一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③ 登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。</p>
<p>Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。</p>
<p>Cookie 存储在客户端中，而 Session 存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。</p>
<p>单个 cookie 保存的数据不能超过 4K，很多浏览器都限制一个站点最多保存 20 个 cookie。</p>
<h2 id="https"><a href="#https" class="headerlink" title="https"></a>https</h2><table>
<thead>
<tr>
<th>http</th>
<th>不安全</th>
<th>三次握手</th>
<th>80 端口</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>https</td>
<td>安全（SSL&#x2F;TSL）</td>
<td>三次握手+SSL 握手</td>
<td>443 端口</td>
<td>需要向 CA 申请数字证书</td>
</tr>
</tbody></table>
<h3 id="解决了啥？"><a href="#解决了啥？" class="headerlink" title="解决了啥？"></a>解决了啥？</h3><blockquote>
<p>窃听-信息加密</p>
<p>篡改-校验</p>
<p>冒充-身份证书</p>
</blockquote>
<h3 id="如何解决不安全的问题？"><a href="#如何解决不安全的问题？" class="headerlink" title="如何解决不安全的问题？"></a>如何解决不安全的问题？</h3><p>混合加密</p>
<p>对称加密（只有一个密钥，速度快）（通信过程中）+非对称加密（两个密钥）（通信建立前）</p>
<p>摘要算法实现完整性：每份数据都生成独一无二的指纹。</p>
<p>服务器公钥放到数字证书中</p>
<p><img src="https://i.loli.net/2021/08/08/YsWAFXOp5Mbx1vy.png" alt="image-20210808135009407"></p>
<h2 id="http-演变"><a href="#http-演变" class="headerlink" title="http 演变"></a>http 演变</h2><h3 id="什么是-HTTP-2-0"><a href="#什么是-HTTP-2-0" class="headerlink" title="什么是 HTTP 2.0"></a>什么是 HTTP 2.0</h3><p>HTTP&#x2F;2（超文本传输协议第 2 版，最初命名为 HTTP 2.0），是 HTTP 协议的的第二个主要版本，使用于万维网。HTTP&#x2F;2 是 HTTP 协议自 1999 年 HTTP 1.1 发布后的首个更新，主要基于 SPDY 协议（是 Google 开发的基于 TCP 的应用层协议，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验）。</p>
<h3 id="与-HTTP-1-1-相比，主要区别包括"><a href="#与-HTTP-1-1-相比，主要区别包括" class="headerlink" title="与 HTTP 1.1 相比，主要区别包括"></a>与 HTTP 1.1 相比，主要区别包括</h3><p>HTTP&#x2F;2<strong>采用二进制格式而非文本格式</strong><br>HTTP&#x2F;2 是<strong>完全多路复用的</strong>，而非有序并阻塞的——只需一个连接即可实现并行<br>使用<strong>报头压缩</strong>，HTTP&#x2F;2 降低了开销<br>HTTP&#x2F;2 让服务器可以将响应主动“推送”到客户端缓存中</p>
<h3 id="HTTP-x2F-2-为什么是二进制？"><a href="#HTTP-x2F-2-为什么是二进制？" class="headerlink" title="HTTP&#x2F;2 为什么是二进制？"></a>HTTP&#x2F;2 为什么是二进制？</h3><p>比起像 HTTP&#x2F;1.x 这样的文本协议，二进制协议解析起来更高效、“线上”更紧凑，更重要的是错误更少。</p>
<h3 id="为什么-HTTP-x2F-2-需要多路传输"><a href="#为什么-HTTP-x2F-2-需要多路传输" class="headerlink" title="为什么 HTTP&#x2F;2 需要多路传输?"></a>为什么 HTTP&#x2F;2 需要多路传输?</h3><p>HTTP&#x2F;1.x 有个问题叫<strong>线端阻塞</strong>(head-of-line blocking), 它是指一个连接(connection)一次只提交一个请求的效率比较高, 多了就会变慢。 HTTP&#x2F;1.1 试过用流水线(pipelining)来解决这个问题, 但是效果并不理想(数据量较大或者速度较慢的响应, 会阻碍排在他后面的请求). 此外, 由于网络媒介(intermediary )和服务器不能很好的支持流水线, 导致部署起来困难重重。</p>
<p>而多路传输(Multiplexing)能很好的解决这些问题, 因为它能同时处理多个消息的请求和响应; 甚至可以在传输过程中将一个消息跟另外一个掺杂在一起。所以客户端只需要一个连接就能加载一个页面。</p>
<h3 id="消息头为什么需要压缩"><a href="#消息头为什么需要压缩" class="headerlink" title="消息头为什么需要压缩?"></a>消息头为什么需要压缩?</h3><p>假定一个页面有 80 个资源需要加载（这个数量对于今天的 Web 而言还是挺保守的）, 而每一次请求都有 1400 字节的消息头（着同样也并不少见，因为 Cookie 和引用等东西的存在）, 至少要 7 到 8 个来回去“在线”获得这些消息头。这还不包括响应时间——那只是从客户端那里获取到它们所花的时间而已。这全都由于 TCP 的慢启动机制，它会基于对已知有多少个包，来确定还要来回去获取哪些包 – 这很明显的限制了最初的几个来回可以发送的数据包的数量。相比之下，即使是头部轻微的压缩也可以是让那些请求只需一个来回就能搞定——有时候甚至一个包就可以了。这种开销是可以被节省下来的，特别是当你考虑移动客户端应用的时候，即使是良好条件下，一般也会看到几百毫秒的来回延迟。</p>
<h3 id="服务器推送的好处是什么？"><a href="#服务器推送的好处是什么？" class="headerlink" title="服务器推送的好处是什么？"></a>服务器推送的好处是什么？</h3><p>当浏览器请求一个网页时，服务器将会发回 HTML，在服务器开始发送 JavaScript、图片和 CSS 前，服务器需要等待浏览器解析 HTML 和发送所有内嵌资源的请求。<strong>服务器推送服务通过“推送”那些它认为客户端将会需要的内容到客户端的缓存中，以此来避免往返的延迟。</strong></p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络-IO多路复用</title>
    <url>/2021/07/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</url>
    <content><![CDATA[<h3 id="解释名词"><a href="#解释名词" class="headerlink" title="解释名词"></a>解释名词</h3><h4 id="用户空间内核空间"><a href="#用户空间内核空间" class="headerlink" title="用户空间内核空间"></a>用户空间内核空间</h4><p>现在操作系统都是采用虚拟存储技术，那么对 32 位操作系统而言，它的寻址空间（虚拟存储空间）为 4G（2 的 32 次方）。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对 linux 操作系统而言，将最高的 1G 字节，供内核使用，称为内核空间，而将较低的 3G 字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个进程使用，称为用户空间。</p>
<p>每个进程可以通过<strong>系统调用</strong>进入内核，因此，Linux 内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有 4G 字节的虚拟空间。</p>
<h4 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h4><ul>
<li>设备管理</li>
<li>文件管理</li>
<li>进程控制</li>
<li>进程通信</li>
<li>内存管理</li>
</ul>
<h4 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a>进程上下文切换</h4><p>为控制进程的执行，操作系统内核挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行，这种行为称为上下文切换（context switch）。通过上下文切换技术，即使在单处理器系统上也能够并发执行多个任务。</p>
<p>进程切换的原因：</p>
<ol>
<li>在 CPU 上运行进程的<strong>时间片耗尽</strong>，便会被操作系统挂起，调度器选择其他进程执行。</li>
<li>在 CPU 上运行进程被<strong>更高优先级的进程抢占</strong>。</li>
<li>在 CPU 上运行进程需要<strong>等待某种设备资源时</strong>，进程会被挂起，从运行状态（TASK_RUNNING）改为就绪状态（TASK_INTERRUPTIBLE）。</li>
<li>在 CPU 上运行进程的时间片尚未耗尽时，<strong>发生硬件中断</strong>，CPU 中断当前执行的进程，转而去调用对应的中断处理程序处理中断。</li>
</ol>
<p>进程切换细节：</p>
<ul>
<li>保存处理机上下文，包括程序计数器和其他寄存器。</li>
<li>更新 PCB 信息。</li>
<li>把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列。</li>
<li>选择另一个进程执行，并更新其 PCB。</li>
<li>更新内存管理的数据结构。</li>
<li>恢复处理机上下文。</li>
</ul>
<p>进程的阻塞是进程自身的一种<strong>主动行为</strong>，也因此只有处于运行态的进程（获得 CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是<strong>不占用 CPU 资源的</strong>。</p>
<h4 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h4><p>文件描述符形式上是一个非负整数。它是一个<strong>索引值</strong>，指向内核为每一个进程所维护的该进程打开文件的记录表。</p>
<p>当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于 UNIX、Linux 这样的操作系统。</p>
<h4 id="缓存-IO"><a href="#缓存-IO" class="headerlink" title="缓存 IO"></a>缓存 IO</h4><p>缓存 I&#x2F;O 又被称作标准 I&#x2F;O，大多数文件系统的默认 I&#x2F;O 操作都是缓存 I&#x2F;O。在 Linux 的缓存 I&#x2F;O 机制中，操作系统会将 I&#x2F;O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，<strong>数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</strong></p>
<p>缺点：<br>数据在传输过程中需要<strong>在应用程序地址空间和内核进行多次数据拷贝操作</strong>，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p>
<h4 id="阻塞-IO"><a href="#阻塞-IO" class="headerlink" title="阻塞 IO"></a>阻塞 IO</h4><p>当用户进程调用了 recvfrom 这个系统调用，内核就开始了 IO 的第一个阶段：<strong>准备数据</strong>（对于网络 IO 来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的 UDP 包。这个时候内核就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当内核一直等到数据准备好了，它就会<strong>将数据从 kernel 中拷贝到用户内存</strong>，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来。</p>
<p><strong>两个阶段都被阻塞。</strong></p>
<h4 id="非阻塞-IO"><a href="#非阻塞-IO" class="headerlink" title="非阻塞 IO"></a>非阻塞 IO</h4><p>当用户进程发出 read 操作时，如果内核中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦内核中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回。</p>
<p>所以，nonblocking IO 的特点是<strong>用户进程需要不断的主动询问内核</strong></p>
<p>NIO 在一些<strong>短业务线，访问量高</strong>的程序中使用，会提高系统的吞吐量，但是对于业务线长，且访问量低的程序来说，就未必是件好事，使用 BIO 可能会更好一些，<strong>不然线程就会空转，浪费 CPU。</strong></p>
<h4 id="IO-多路复用"><a href="#IO-多路复用" class="headerlink" title="IO 多路复用"></a>IO 多路复用</h4><p>优点：<strong>一个进程可以同时处理多个连接。</strong></p>
<p>I&#x2F;O 多路复用的特点是通过一种机制<strong>一个进程能同时等待多个文件描述符</strong>，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。</p>
<h4 id="异步-IO"><a href="#异步-IO" class="headerlink" title="异步 IO"></a>异步 IO</h4><p>异步（线程自己不去获得结果，而是由其他的线程送来结果）</p>
<p><img src="https://i.loli.net/2021/08/06/UxFNmyufwlKnLhE.png" alt="image-20210731094812802">异步情况下一定是非阻塞的。</p>
<p>异步意味着：在进行读写操作时，线程不必等待结果，而是通过回调的方式由另外的线程来获取。linux 在 2.6 底层通过多路复用模拟了异步 IO。windows 通过 IOCP 真正实现了异步 IO。</p>
<p>select，poll，epoll 本质上都是<strong>同步 I&#x2F;O</strong>，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I&#x2F;O 则无需自己负责进行读写，异步 I&#x2F;O 的实现会由其他线程负责把数据从内核拷贝到用户空间。</p>
<h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>select 实现多路复⽤的⽅式：</p>
<p>将已连接的 Socket 都放到⼀个<strong>⽂件描述符集合</strong>，然后调⽤ select 函数<strong>将⽂件描述符集合拷⻉到内核</strong>⾥，让内核来检查是否有⽹络事件产⽣，检查的⽅式很粗暴，就是通过遍历⽂件描述符集合的⽅式，当检查到有事件产⽣后，将此 Socket 标记为可读或可写。</p>
<p>接着<strong>再把整个⽂件描述符集合拷⻉回⽤户态</strong>⾥，然后⽤户态还需要再通过遍历的⽅法找到可读或可写的 Socket，然后再对其处理。</p>
<p>对于 select 这种⽅式，需要进⾏ 2 次「遍历」⽂件描述符集合，⼀次是在内核态⾥，⼀个次是在⽤户态⾥ ，⽽且还会发⽣ 2 次「拷⻉」⽂件描述符集合，先从⽤户空间传⼊内核空间，由内核修改后，再传出到⽤户空间中。</p>
<p>select 使⽤3 个固定⻓度的 BitsMap（表示可读，可写，except），表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最⼤值为 <strong>1024</strong> ，只能监听 0~1023 的⽂件描述符。</p>
<p>select<strong>目前几乎在所有的平台上支持，</strong>其良好跨平台支持也是它的一个优点。select 的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，<strong>在 Linux 上一般为 1024，</strong>可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。</p>
<h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>poll 不再⽤ BitsMap 来存储所关注的⽂件描述符，取⽽代之⽤<strong>动态数组，以链表形式来组织</strong>，（pollfd 的指针）突破了 select 的⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。</p>
<p><img src="https://i.loli.net/2021/08/06/2kPGI6thcdoiLUe.png" alt="image-20210731095816033"></p>
<p>但是 poll 和 select 并没有太⼤的本质区别，都是使⽤「线性结构」存储进程关注的 Socket 集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。</p>
<h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>第⼀点，epoll 在内核⾥使⽤<strong>红⿊树</strong>来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加⼊内核中的红⿊树⾥，红⿊树是个⾼效的数据结构，增删查⼀般时间复杂度是 O(logn) ，通过对这棵⿊红树进⾏操作，这样就不需要像 select&#x2F;poll 每次操作时都传⼊整个 socket 集合，只需要传⼊⼀个待检测的 socket，减少了内核和⽤户空间⼤量的数据拷⻉和内存分配。</p>
<p>第⼆点， epoll 使⽤<strong>事件驱动的机制</strong>，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，<strong>当⽤户调⽤ epoll_wait() 函数时</strong>，只会返回有事件发⽣的⽂件描述符，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率。</p>
<p><img src="https://i.loli.net/2021/08/11/fHIJbCpiOan5ymZ.png" alt="image-20210811133207962"></p>
<p>epoll 对文件描述符的操作有两种模式<strong>：LT（level trigger）和 ET（edge trigger）</strong>。LT 模式是默认模式，LT 模式与 ET 模式的区别如下：</p>
<p><strong>LT 模式</strong>：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。<strong>下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。</strong></p>
<p><strong>ET 模式</strong>：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，<strong>下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。</strong></p>
<p>LT(level triggered)是缺省的工作方式，并且同时支持 block 和 no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的 fd 进行 IO 操作。如果你不作任何操作，内核还是会继续通知你的。</p>
<p>ET(edge-triggered)是<strong>高速工作方式，</strong>只支持<strong>no-block socket</strong>。在这种模式下，当描述符从未就绪变为就绪时，内核通过 epoll 告诉你。然后<strong>它会假设你知道文件描述符已经就绪，</strong>并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个 fd 作 IO 操作(从而导致它再次变成未就绪)，<strong>内核不会发送更多的通知(only once)</strong></p>
<p>ET 模式在很大程度上<strong>减少了 epoll 事件被重复触发的次数</strong>，因此效率要比 LT 模式高。</p>
<p>（会循环从⽂件描述符读写数据，那么<strong>如果⽂件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那⾥</strong>，程序就没办法继续往下执⾏。所以，<strong>边缘触发模式⼀般和⾮阻塞 I&#x2F;O 搭配使⽤</strong>，程序会⼀直执⾏ I&#x2F;O 操作，直到系统调⽤（如 read 和 write ）返回错误。）</p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络-tcp</title>
    <url>/2021/07/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-tcp/</url>
    <content><![CDATA[<h3 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h3><ul>
<li>TCP 是<strong>⾯向连接的、可靠的、基于字节流</strong>的传输层通信协议 。</li>
<li>TCP 四元组可以唯⼀的确定⼀个连接，四元组包括如下： <strong>源地址 源端⼝ ⽬的地址 ⽬的端⼝</strong> 。</li>
<li><strong>源地址和⽬的地址的字段（32 位）是在 IP 头部中</strong>，作⽤是通过 IP 协议发送报⽂给对⽅主机。</li>
<li><strong>源端⼝和⽬的端⼝的字段（16 位）是在 TCP 头部中</strong>，作⽤是告诉 TCP 协议应该把报⽂发给哪个进程。</li>
</ul>
<p>服务端最⼤并发 TCP 连接数远不能达到理论上限。</p>
<p>主要是⽂件描述符限制，Socket 都是⽂件，所以⾸先要通过 ulimit 配置⽂件描述符的数⽬。<br>另⼀个是内存限制，每个 TCP 连接都要占⽤⼀定内存，操作系统的内存是有限的。</p>
<h4 id="头部格式"><a href="#头部格式" class="headerlink" title="头部格式"></a>头部格式</h4><p><img src="https://i.loli.net/2021/08/05/LJjRVuwsymNHSn3.png" alt="image-20210731112848824"></p>
<p>序列号：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的⼤⼩。⽤来解决⽹络包乱序问题。</p>
<p>确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。⽤来解决不丢包的问题。</p>
<p>控制位：</p>
<ul>
<li>ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。</li>
<li>RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。</li>
<li>SYN：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。</li>
<li>FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。</li>
</ul>
<h4 id="TCP-vs-UDP"><a href="#TCP-vs-UDP" class="headerlink" title="TCP vs UDP"></a>TCP vs UDP</h4><p><img src="https://i.loli.net/2021/08/05/dJwpgNLSEkFMq84.png" alt="image-20210731113120885"></p>
<p>TCP 和 UDP 区别：</p>
<ol>
<li><p>连接<br> TCP 是⾯向连接的传输层协议，传输数据前先要建⽴连接。<br> UDP 是不需要连接，即刻传输数据。</p>
</li>
<li><p>服务对象<br> TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。<br> UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信</p>
</li>
<li><p>可靠性<br> TCP 是可靠交付数据的，数据可以⽆差错、不丢失、不᯿复、按需到达。<br> UDP 是尽最⼤努⼒交付，不保证可靠交付数据。</p>
</li>
<li><p>拥塞控制、流量控制<br> TCP 有拥塞控制和流ᰁ控制机制，保证数据传输的安全性。UDP 则没有，即使⽹络⾮常拥堵了，也不会影响 UDP 的发送速率。</p>
</li>
<li><p>⾸部开销<br> TCP ⾸部⻓度较⻓，会有⼀定的开销，⾸部在没有使⽤「选项」字段时是 20 个字节，如果使⽤了「选项」字段则会变⻓的。<br> UDP ⾸部只有 8 个字节，并且是固定不变的，开销较⼩。</p>
</li>
<li><p>传输⽅式<br> TCP 是流式传输，没有边界，但保证顺序和可靠。<br> UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。</p>
</li>
<li><p>分⽚不同<br>TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。</p>
</li>
</ol>
<p> UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。</p>
<ol start="8">
<li><p>TCP 和 UDP 应⽤场景：<br> 由于 TCP 是⾯向连接，能保证数据的可靠性交付，因此经常⽤于：<br> FTP ⽂件传输<br> HTTP &#x2F; HTTPS</p>
<p> 由于 UDP ⾯向⽆连接，它可以随时发送数据，再加上 UDP 本身的处理既简单⼜⾼效，因此经常⽤于：</p>
</li>
</ol>
<p>包总数较少的通信，如 DNS 、 SNMP 等<br>视频、⾳频等多媒体通信<br>⼴播通信</p>
<h4 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h4><p>UDP 是⼀个简单、不可靠的传输协议，⽽且是 UDP 包之间是⽆序的，也没有依赖关系。⽽且，UDP 是不需要连接的，也就不需要握⼿和挥⼿的过程，所以天然的就⽐ TCP 快。</p>
<p>当然，HTTP&#x2F;3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应⽤层」实现了 QUIC 协议，它具有类似 TCP 的连接管理、拥塞窗⼝、流ᰁ控制的⽹络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不⽤担⼼数据包丢失的问题。</p>
<h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><p><img src="https://i.loli.net/2021/08/05/tFSzZdBAvgEK27o.png" alt="image-20210731113603327"></p>
<p>注意序列号和确认应答号的变化。<br>第三次握手可以携带数据。</p>
<p>注意序列号和确认应答号的变化。</p>
<p>第三次握手可以携带数据。</p>
<h4 id="为什么是三次？"><a href="#为什么是三次？" class="headerlink" title="为什么是三次？"></a>为什么是三次？</h4><ol>
<li>避免历史连接！！！。</li>
<li>同步双方序列号（去重，按序接收）。</li>
<li>避免资源浪费。（只有两次，客户端的 syn 阻塞，就会重新发送 syn，那么服务端每收到一个 syn 就要建立连接。）</li>
</ol>
<ul>
<li>在⽹络拥堵情况下，⼀个「旧 SYN 报⽂」⽐「最新的 SYN 」 报⽂早到达了服务端；</li>
<li>那么此时服务端就会回⼀个 SYN + ACK 报⽂给客户端；</li>
<li>客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送 RST 报⽂给服务端，表示中⽌这⼀次连接。</li>
<li>如果是两次握⼿连接，就不能判断当前连接是否是历史连接，三次握⼿则可以在客户端（发送⽅）准备发送第三次报⽂时，客户端因有⾜够的上下⽂来判断当前连接是否是历史连接。</li>
</ul>
<h4 id="既然-IP-层会分⽚，为什么-TCP-层还需要-MSS-呢？"><a href="#既然-IP-层会分⽚，为什么-TCP-层还需要-MSS-呢？" class="headerlink" title="既然 IP 层会分⽚，为什么 TCP 层还需要 MSS 呢？"></a>既然 IP 层会分⽚，为什么 TCP 层还需要 MSS 呢？</h4><p>MTU ：⼀个⽹络包的最⼤⻓度，以太⽹中⼀般为 1500 字节；<br>MSS ：除去 IP 和 TCP 头部之后，⼀个⽹络包所能容纳的 TCP 数据的最⼤⻓度；</p>
<ul>
<li>当 IP 层有⼀个超过 MTU ⼤⼩的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分⽚，把数据分⽚成若⼲⽚，保证每⼀个分⽚都⼩于 MTU。把⼀份 IP 数据报进⾏分⽚以后，由⽬标主机的 IP 层来进⾏组装后，再交给上⼀层 TCP 传输层。</li>
<li>那么当如果⼀个 IP 分⽚丢失，整个 IP 报⽂的所有分⽚都得重传。</li>
<li>因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</li>
<li>当接收⽅发现 TCP 报⽂（头部 + 数据）的某⼀⽚丢失后，则不会响应 ACK 给对⽅，那么发送⽅的 TCP 在超时后，就会重发「整个 TCP 报⽂（头部 + 数据）」。</li>
</ul>
<h4 id="什么是-SYN-攻击？如何避免-SYN-攻击？"><a href="#什么是-SYN-攻击？如何避免-SYN-攻击？" class="headerlink" title="什么是 SYN 攻击？如何避免 SYN 攻击？"></a>什么是 SYN 攻击？如何避免 SYN 攻击？</h4><p>攻击者短时间伪造不同 IP 地址的 SYN 报⽂，服务端每接收到⼀个 SYN 报⽂，就进⼊ SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报⽂，⽆法得到未知 IP 主机的 ACK 应答，久⽽久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常⽤户服务。</p>
<p><img src="https://i.loli.net/2021/08/05/CE9ZOqDpnFK4joB.png" alt="image-20210731145537881"></p>
<p><img src="https://i.loli.net/2021/08/05/QZeGdAhMkUXjLYt.png" alt="image-20210731145610582"></p>
<p><strong>解决办法：</strong></p>
<p>控制该队列的最⼤值：SYN_RCVD 状态连接的最⼤个数：net.core.netdev_max_backlog</p>
<ul>
<li>tcp_syncookies 的⽅式可以应对 SYN 攻击的⽅法：<br>net.ipv4.tcp_syncookies &#x3D; 1<br>当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」；<br>计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，<br>服务端接收到客户端的应答报⽂时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「Accept 队列」。</li>
</ul>
<h3 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h3><p><img src="https://i.loli.net/2021/08/05/FsewJVSbrgqBzUp.png" alt="image-20210731145722373"></p>
<p>关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了<strong>但是还能接收数据</strong>。服务器收到客户端的 FIN 报⽂时，先回⼀个 ACK 应答报⽂，⽽<strong>服务端可能还有数据需要处理和发送</strong>，等服务端不再发送数据时，才发送 <strong>FIN 报⽂给客户端来表示同意现在关闭连接</strong>。</p>
<h4 id="为什么-TIME-WAIT-等待的时间是-2MSL"><a href="#为什么-TIME-WAIT-等待的时间是-2MSL" class="headerlink" title="为什么 TIME_WAIT 等待的时间是 2MSL"></a>为什么 TIME_WAIT 等待的时间是 2MSL</h4><p>MSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。<br>⽹络中可能存在来⾃发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响应，所以⼀来⼀回需要等待 2 倍的时间。<br>⽐如如果被动关闭⽅没有收到断开连接的最后的 ACK 报⽂，就会触发超时重发 Fin 报⽂，另⼀⽅接收到 FIN 后，会重发 ACK 给被动关闭⽅， ⼀来⼀去正好 2 个 MSL。<br>在 Linux 系统⾥ 2MSL 默认是 60 秒，那么⼀个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。</p>
<h4 id="需要-TIME-WAIT-状态"><a href="#需要-TIME-WAIT-状态" class="headerlink" title="需要 TIME-WAIT 状态"></a>需要 TIME-WAIT 状态</h4><ul>
<li>防⽌具有相同「四元组」的「旧」数据包被收到；<br>经过 2MSL 这个时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的。</li>
<li>保证「被动关闭连接」的⼀⽅能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收。</li>
</ul>
<h4 id="如果已经建⽴了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建⽴了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建⽴了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建⽴了连接，但是客户端突然出现故障了怎么办？</h4><p>TCP 有⼀个机制是<strong>保活机制</strong>。这个机制的原理是这样的：ping-pong<br>定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作⽤，每隔⼀个时间间隔，发送⼀个探测报⽂，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。</p>
<h3 id="socket-编程？"><a href="#socket-编程？" class="headerlink" title="socket 编程？"></a>socket 编程？</h3><h4 id="连接过程"><a href="#连接过程" class="headerlink" title="连接过程"></a>连接过程</h4><p><img src="https://i.loli.net/2021/08/05/cXSudR6i82maxOI.png" alt="image-20210731150237375"></p>
<h4 id="listen-时候参数-backlog-的意义？"><a href="#listen-时候参数-backlog-的意义？" class="headerlink" title="listen 时候参数 backlog 的意义？"></a>listen 时候参数 backlog 的意义？</h4><p>参数⼀ socketfd 为 socketfd ⽂件描述符<br>参数⼆ <strong>backlog</strong>，这参数在历史版本有⼀定的变化<br>在早期 Linux 内核 backlog 是 <strong>SYN 队列⼤⼩</strong>，也就是未完成的队列⼤⼩。<br>在 Linux 内核 2.2 之后，backlog 变成 <strong>accept 队列</strong>，也就是已完成连接建⽴的队列⻓度，所以现在通常认为 backlog 是 accept 队列长度</p>
<p>客户端 connect 成功返回是在第⼆次握⼿，服务端 accept 成功返回是在三次握⼿成功之后。</p>
<h3 id="可靠传输"><a href="#可靠传输" class="headerlink" title="可靠传输"></a>可靠传输</h3><p><strong>序列号、确认应答、重发控制、连接管理以及窗⼝控制等。</strong></p>
<h4 id="自动重传请求（Automatic-Repeat-reQuest，ARQ）"><a href="#自动重传请求（Automatic-Repeat-reQuest，ARQ）" class="headerlink" title="自动重传请求（Automatic Repeat-reQuest，ARQ）"></a>自动重传请求（Automatic Repeat-reQuest，ARQ）</h4><p>OSI 模型中数据链路层的错误纠正协议之一。它通过使用<strong>确认和超时</strong>这两个机制，在不可靠服务的基础上实现可靠的信息传输。<strong>如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。</strong><br>当发送窗口和接收窗口的大小都等于 1 时，就是停止等待协议。<br>当发送窗口大于 1，接收窗口等于 1 时，就是回退 N 步协议。<br>当发送窗口和接收窗口的大小均大于 1 时，就是选择重发协议</p>
<h4 id="重传机制"><a href="#重传机制" class="headerlink" title="重传机制"></a>重传机制</h4><p>序列号与确认应答！</p>
<p><strong>超时重传</strong>-数据包丢失，确认应答丢失。</p>
<p><img src="https://i.loli.net/2021/08/05/OFfCLUwdjGsRPZI.png" alt="image-20210731150635851"></p>
<p>当超时时间 RTO 较⼤时，重发就慢，没有效率，性能差；<br>当超时时间 RTO 较⼩时，会导致可能并没有丢就重发。<br>超时重传时间 RTO 的值应该略⼤于报⽂往返 RTT 的值。<br>如果超时重发的数据，再次超时的时候，TCP 的策略是超时间隔加倍。<br>也就是每当遇到⼀次超时重传的时候，都会将下⼀次超时时间间隔设为先前值的两倍。两次超时，就说明⽹络环境差，不宜频繁反复发送。</p>
<p><strong>快速重传</strong><br>三次同样的 ACK。</p>
<p><strong>SACK</strong><br> SACK （ Selective Acknowledgment 选择性确认）。<br>这种⽅式需要在 <strong>TCP 头部「选项」字段⾥加⼀个 SACK</strong> 的东⻄，它可以将缓存的地图发送给发送⽅，这样<strong>发送⽅就可以知道哪些数据收到了，哪些数据没收到，</strong>知道了这些信息，就可以只重传丢失的数据。<br>D-SACK</p>
<h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>窗⼝⼤⼩就是指⽆需等待确认应答，⽽可以继续发送数据的最⼤值。</p>
<p>如果每次传输数据都只能发送一个 MSS，就需要等待接收方的 ACK，这显然会极大的影响传输的速率。在发送数据的时候，最好的方式是一下将所有的数据全部发送出去，然后一起确认。</p>
<p>首先 TCP 在进行数据传输的时候都是<strong>先将数据放在数据缓冲区中的</strong>，TCP 维护了两个缓冲区，<strong>发送方缓冲区和接收方缓冲区。</strong></p>
<p>发送方缓冲区：发送方缓冲区用于存储<strong>已经准备就绪数据和发送了但是没有被确认的数据</strong>。<br>接收方缓冲区：接收方缓冲区用于存储<strong>已经被接收但是还没有被用户进程消费的数据。</strong></p>
<p>滑动窗口机制是<strong>TCP 的一种流量控制方法</strong>，该机制允许发送方在停止并等待确认前连续发送多个分组，而不必每发送一个分组就停下来等待确认，从而增加数据传输的速率<strong>提高应用的吞吐量。</strong></p>
<p>TCP 的包可以分为四种状态</p>
<p>已发送并且已经确认的包。<br>已发送但是没有确认的包。<br>未发送但是可以发送的包。<br>不允许被发送的包。</p>
<p>滑动窗口协议的基本工作流程就是由<strong>接收方通告窗口的大小</strong>，这个窗口称为提出窗口，也就是接收方窗口。接收方提出的窗口则是被接收缓冲区所影响的，如果数据没有被用户进程使用那么接收方通告的窗口就会相应得到减小，发送窗口取决于接收方窗口的大小。可用窗口的大小等于<strong>接收方窗口减去发送但是没有被确认的数据包大小。</strong></p>
<p>最基本的传输可靠性来源于<strong>“确认重传”</strong>机制。</p>
<p>TCP 的滑动窗口的可靠性也是建立在“确认重传”基础上的。</p>
<p><strong>发送窗口</strong>只有收到对端对于本段发送窗口内字节的 ACK 确认，才会<strong>移动发送窗口的左边界。</strong></p>
<p><strong>接收窗口</strong>只有在<strong>前面所有的段都确认的情况下才会移动左边界。</strong>当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。</p>
<p><strong>累计确认：</strong></p>
<p><img src="https://i.loli.net/2021/08/05/To93btGQDuPNFpl.png" alt="image-20210731150833402"></p>
<h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>怎么让发送⽅<strong>避免发送⼩数据呢？</strong><br>发送⽅通常的策略:<br>使⽤ <strong>Nagle 算法</strong>，该算法的思路是延时处理，它满⾜以下两个条件中的⼀条才可以发送数据：<br>窗⼝⼤⼩ &gt;&#x3D; MSS 或是 数据⼤⼩ &gt;&#x3D; MSS<br>收到之前发送数据的 ack 回包<br>只要没满⾜上⾯条件中的⼀条，发送⽅⼀直在囤积数据，直到满⾜上⾯的发送条件。<br>另外，Nagle 算法默认是打开的，可以在 <strong>Socket 设置 TCP_NODELAY</strong> 选项来关闭这个算法。</p>
<h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><p><strong>什么是拥塞窗⼝？和发送窗⼝有什么关系呢？</strong><br>拥塞窗⼝ cwnd 是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。<br>我们在前⾯提到过发送窗⼝ swnd 和接收窗⼝ rwnd 是约等于的关系，那么由于加⼊了拥塞窗⼝的概念后，此时发送窗⼝的值是 swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。<br><strong>只要⽹络中没有出现拥塞， cwnd 就会增⼤；</strong><br><strong>但⽹络中出现了拥塞， cwnd 就减少</strong>；</p>
<p><strong>那么怎么知道当前⽹络是否出现了拥塞呢？</strong><br>其实只要「发送⽅」没有在规定时间内接收到 ACK 应答报⽂，也就是<strong>发⽣了超时重传</strong>，就会认为⽹络出现了⽤拥塞。</p>
<h5 id="拥塞控制有哪些控制算法？"><a href="#拥塞控制有哪些控制算法？" class="headerlink" title="拥塞控制有哪些控制算法？"></a><strong>拥塞控制有哪些控制算法？</strong></h5><p><strong>慢启动开始</strong></p>
<p>1.开始时发送方 cwnd&#x3D;1，发送报文段 M1，如果收到确认 M1，那么此时增大 cwnd&#x3D;2，并发送 M2，M3</p>
<p>2.要注意，发送方每收到一个确认报文段，cwnd+1（不包括缺失重传的确认）</p>
<p>也就是说，<strong>每经过一个传输伦次（RTT 时间）</strong>，cwnd 加倍。</p>
<p>但是，为了防止拥塞窗口 cwnd 增长过大而引起网络拥塞，<strong>设置一个慢开始门限 ssthresh</strong>。</p>
<p>1.当 cwnd&lt;ssthresh，使用上述的慢开始算法</p>
<p>2.当 cwnd&gt;ssthresh，停止使用慢开始，使用拥塞避免算法</p>
<p>3.当 cwnd&#x3D;&#x3D;ssthresh，两者都可以使用</p>
<p><strong>拥塞避免</strong></p>
<p>拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口<strong>cwnd+1，</strong>而不是加倍，这样 cwnd 就按线性增大。</p>
<p><strong>快重传</strong></p>
<p>快重传规定，发送方只要连续收到 3 个重复确认，立即重传对方发来的 M3。</p>
<p><img src="https://i.loli.net/2021/08/05/zJP16DFvGAOWirM.png" alt="image-20210805160153353"></p>
<p><strong>快恢复</strong></p>
<p>当发送方连续收到三个重复确认，执行乘法减小，ssthresh 减半</p>
<p>1，由于发送方可能认为网络现在没有拥塞，因此与慢开始不同，把 cwnd 值设置为 ssthresh 减半之后的值，然后执行拥塞避免算法，线性增大 cwnd。</p>
<p>2，既然发送方收到<strong>三个重复的确认</strong>，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中并不是堆积了分组而是减少了三个分组。因此可以适当把拥塞窗口扩大了些。</p>
<p><img src="https://i.loli.net/2021/08/05/pvt5AOQLyq2WUa8.png" alt="image-20210731151028278"></p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络-网络模型</title>
    <url>/2021/07/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h3 id="七层网络模型"><a href="#七层网络模型" class="headerlink" title="七层网络模型"></a>七层网络模型</h3><p><strong>应用层</strong></p>
<p>服务与用户应用。</p>
<p><strong>表示层</strong></p>
<p>解决信息的语法表示问题，比如加密解密。</p>
<p><strong>会话层</strong></p>
<p>实现不同主机上用户进程之间的通信。</p>
<p><strong>传输层</strong></p>
<p><strong>网络层</strong></p>
<p><strong>链路层</strong></p>
<p><strong>物理层</strong></p>
<h3 id="五层标准模型"><a href="#五层标准模型" class="headerlink" title="五层标准模型"></a>五层标准模型</h3><p><strong>应用层</strong></p>
<p>专注于为用户提供应用功能，不关心如何传输。工作于用户态。<br>决定了向用户提供应用服务时的通信活动。</p>
<p>DNS（域名系统）&#x3D;域名和 IP 的映射,HTTP（生成针对目标服务器的 HTTP 请求报文）,FTP（文件传输协议）</p>
<p>HTTP 报文</p>
<p><strong>传输层</strong></p>
<p>两台计算机之间的数据传输。为应用层提供网络支持。</p>
<p>TCP(传输控制协议)&#x2F;UDP（用户数据报协议）</p>
<p>TCP 报文段</p>
<p><strong>网络层</strong></p>
<p>规定了通过怎样的路径到达对方计算机。（选择一条传输路线）将数据从一个设备传输到另一个设备。</p>
<p>IP（寻址，路由）一边中转一边传送</p>
<p>IP 数据包</p>
<p><strong>链路层</strong></p>
<p>（处理连接网络的硬件部分）标识网络中的设备，为网络层提供链路级别的服务。</p>
<p>ARP&#x3D;&#x3D;<strong>ip 地址到硬件地址的动态映射</strong>-ARP 高速缓存。</p>
<p><strong>物理层</strong></p>
<p>为链路层提供二进制传输服务。</p>
<h3 id="打开百度到显示具体过程？"><a href="#打开百度到显示具体过程？" class="headerlink" title="打开百度到显示具体过程？"></a>打开百度到显示具体过程？</h3><p><strong>解析 URL</strong></p>
<p><strong>DNS 解析</strong></p>
<p><strong>TCP 连接</strong></p>
<p><strong>发送 HTTP 请求</strong></p>
<p><strong>服务器处理请求并返回 HTTP 报文</strong></p>
<p><strong>浏览器解析渲染页面</strong></p>
<p><strong>连接结束</strong></p>
<p><img src="https://i.loli.net/2021/08/06/pIaiW62BMZtPrmS.png" alt="image-20210806103355600"></p>
<p><strong>解析 url</strong></p>
<p><strong>生成 http 消息</strong></p>
<p><strong>真实地址查询 dns</strong></p>
<p><img src="https://i.loli.net/2021/08/05/imGRJ3j4PqUerE7.png" alt="image-20210731105736261"></p>
<p><strong>应⽤程序（浏览器）通过调⽤ Socket 库，来委托协议栈⼯作。</strong></p>
<p>协议栈的上半部分有两块，是负责收发数据的 TCP 和 UDP 协议，它们两会接受应⽤层的委托执⾏收发数据的操作。</p>
<p>协议栈的下⾯⼀半是⽤ IP 协议控制⽹络包收发操作，在互联⽹上传数据时，数据会被切分成⼀块块的⽹络包，⽽<br>将⽹络包发送给对⽅的操作就是由 IP 负责的。</p>
<p>此外 IP 中还包括 ICMP 协议和 ARP 协议。<br>ICMP ⽤于<strong>告知⽹络包传送过程中产⽣的错误以及各种控制信息。</strong><br>ARP ⽤于<strong>根据 IP 地址查询相应的以太⽹ MAC 地址。</strong></p>
<p><strong>可靠传输 TCP</strong></p>
<p><strong>远程定位 IP</strong></p>
<p><strong>两点传输 MAC</strong></p>
<p>在 MAC 包头⾥需要发送⽅ MAC 地址和接收⽅⽬标 MAC 地址，⽤于两点之间的传输。<br>⼀般在 TCP&#x2F;IP 通信⾥，MAC 包头的协议类型只使⽤：<br>0800 ： IP 协议<br>0806 ： ARP 协议</p>
<p><strong>先查询 ARP 缓存</strong>，如果其中已经保存了对⽅的 MAC 地址，就不需要发送 ARP 查询，直接使⽤ ARP 缓存中 的地址。 ⽽当 ARP 缓存中不存在对⽅ MAC 地址时，则发送 ARP <strong>⼴播查询。</strong></p>
<p><strong>出⼝ ⽹卡</strong></p>
<p>⽹卡驱动从 IP 模块获取到包之后，会将其复制到⽹卡内的缓存区中，接着会在其开头加上报头和起始帧分界符， 在末尾加上⽤于检测错误的帧校验序列</p>
<p><img src="https://i.loli.net/2021/08/05/gpoRLKxYM84Xcwn.png" alt="image-20210731104901289"></p>
<p><img src="https://i.loli.net/2021/08/05/74mbiBgpHStlhnx.png" alt="image-20210731104830860"></p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>模型</tag>
      </tags>
  </entry>
</search>
