<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"xieyi123456.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"livere","storage":true,"lazyload":true,"nav":null,"activeClass":"livere"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="think and do">
<meta property="og:type" content="website">
<meta property="og:title" content="XieYi&#39;s Blog">
<meta property="og:url" content="https://xieyi123456.github.io/page/3/index.html">
<meta property="og:site_name" content="XieYi&#39;s Blog">
<meta property="og:description" content="think and do">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="XieYi">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://xieyi123456.github.io/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>XieYi's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="XieYi's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">XieYi's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">log something</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="XieYi"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">XieYi</p>
  <div class="site-description" itemprop="description">think and do</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:2643100268@qq.com" title="E-Mail → mailto:2643100268@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Netty-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Netty-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/" class="post-title-link" itemprop="url">Netty-核心组件</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:14:18" itemprop="dateCreated datePublished" datetime="2021-07-30T15:14:18+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Netty/" itemprop="url" rel="index"><span itemprop="name">Netty</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="观念理解"><a href="#观念理解" class="headerlink" title="观念理解"></a>观念理解</h2><ul>
<li>channel：数据的传输通道。</li>
<li>msg：流动的数据。</li>
<li>pipeline：流水线，上面有多道工序。</li>
<li>handler：数据处理的工序。分为inbound，outbound。</li>
<li>eventloop：处理数据的工人。<ul>
<li>工人可以管理多个channel的io操作（一个工人内部有selector和thread）。一旦工人负责了某个channel，就要负责到底。（线程安全）。</li>
<li>工人既可以执行io操作，还可以进行任务处理，工人都有自己的任务队列。</li>
<li>工人按照pipeline的顺序，依次按照对应的handler进行。</li>
</ul>
</li>
</ul>
<h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="Eventloop（事件循环对象）："><a href="#Eventloop（事件循环对象）：" class="headerlink" title="Eventloop（事件循环对象）："></a>Eventloop（事件循环对象）：</h3><ul>
<li>本质上是一个<strong>单线程执行器</strong>（同时维护了一个selector）。</li>
<li>用来处理channel上源源不断的io事件。（监听网络事件并调用事件处理器进行相关的IO操作）</li>
<li>eventloop负责处理注册到其上的channel的io操作。</li>
<li>继承了juc下的scheduledExecutorService（包含了线程池的方法）</li>
<li>继承了netty自己的oedereventexecutor（判断一个线程是否属于此eventloop，判断一个eventloop属于哪个eventloopgroup）</li>
</ul>
<h3 id="EventloopGroup（事件循环组）："><a href="#EventloopGroup（事件循环组）：" class="headerlink" title="EventloopGroup（事件循环组）："></a>EventloopGroup（事件循环组）：</h3><ul>
<li><strong>一组eventloop。</strong></li>
<li>channel会调用他的register方<strong>法绑定一个eventloop</strong>，后续io操作由他负责到底。</li>
<li>EventLoop 处理的 I&#x2F;O 事件都将在它专有的 Thread 上被处理，即 Thread 和 EventLoop属于 1 : 1 的关系，从⽽保证线程安全</li>
<li>NioEventLoopGroup 默认的构造函数实际会起的<strong>线程数为 CPU核心*2 。</strong><br>每个 NioEventLoopGroup 对象内部都会分配⼀组 NioEventLoop ，其⼤⼩是 nThreads , 这样就构成了⼀个线程池， <strong>⼀个 NIOEventLoop 和⼀个线程相对应。</strong></li>
</ul>
<h3 id="channel："><a href="#channel：" class="headerlink" title="channel："></a>channel：</h3><p>传送数据的传输通道，或者说对网络操作的抽象。<br>包括bind（），connect（），read（），write（）等方法。<br>常用nioserversocketchannel与niosocketchannel。<br>close（）；<br>closefuture（）；<br>pipeline（）；<br>write（）；<br>writeandflush（）；数据写入并刷出。</p>
<p>Netty 是异步⾮阻塞的，我们不能⽴刻得到操作是否执⾏成功，但是，<strong>你可以通过 ChannelFuture 接⼝addListener() ⽅法注册⼀个 ChannelFutureListener ，当操作执⾏成功或者失败时，监听就会⾃动触发返回结果。并且，你还可以通过 ChannelFuture 的 channel() ⽅法获取关联的 Channel。</strong></p>
<ul>
<li><strong>channlefuture 异步非阻塞</strong>的解决：<br>1，<strong>sync（）；</strong><br>2，<strong>addlistener（回调对象）异步处理结果。（等待结果的也不是主线程）</strong></li>
</ul>
<p><strong>为什么要异步？</strong></p>
<p>必须多线程，多核cpu。<br>并没有缩短响应时间，而是吞吐量。<br><strong>必须合理的任务拆分</strong>。</p>
<h3 id="future-amp-promise："><a href="#future-amp-promise：" class="headerlink" title="future&amp;promise："></a>future&amp;promise：</h3><p>future继承jdk的future。<br>promise继承自future。<br>jdk：只能同步等待任务结束。</p>
<p>netty future：可以异步等待方法结束。也要等待任务结束。</p>
<p>promise：只作为两个线程传递结果的容器。</p>
<h3 id="handler-amp-pipeline："><a href="#handler-amp-pipeline：" class="headerlink" title="handler&amp;pipeline："></a>handler&amp;pipeline：</h3><ul>
<li>handler：用来处理channel上各种事件，分为入站和出站。</li>
<li>注意：只有向channel中写数据才会触发出站handler。</li>
<li><strong>出站顺序是从后往前。</strong></li>
<li>ctx.writeansflush()，<strong>会从那个入站向前找。后面的出站处理器就不会执行了。</strong></li>
<li>1-2-3-6-5-4。</li>
</ul>
<h3 id="Bootstrap-和-ServerBootstrap"><a href="#Bootstrap-和-ServerBootstrap" class="headerlink" title="Bootstrap 和 ServerBootstrap"></a>Bootstrap 和 ServerBootstrap</h3><p><img src="https://i.loli.net/2021/08/04/1PX7lzRvHGAZ3qp.png" alt="image-20210804201619460"></p>
<p><img src="https://i.loli.net/2021/08/04/UMuZ4JIyYnO7fQL.png" alt="image-20210804201633173"></p>
<p>Bootstrap 通常使⽤ <strong>connet()</strong> ⽅法连接到远程的主机和端⼝，作为⼀个 Netty TCP 协议通<br>信中的客户端。另外， Bootstrap 也可以通过 bind() ⽅法绑定本地的⼀个端⼝，作为 UDP<br>协议通信中的⼀端。</p>
<ol>
<li>ServerBootstrap 通常使⽤ bind() ⽅法绑定本地的端⼝上，然后等待客户端的连接。</li>
<li>Bootstrap 只需要配置⼀个线程组— EventLoopGroup 。⽽ ServerBootstrap 需要配置两个线<br> 程组— EventLoopGroup ，⼀个⽤于处理连接，⼀个⽤于具体的处理。</li>
</ol>
<h3 id="bytebuf："><a href="#bytebuf：" class="headerlink" title="bytebuf："></a>bytebuf：</h3><p>对nio中的增强。</p>
<p>支持：<br>1，直接内存。创建销毁比较昂贵。读写性能高。（默认）<br>     堆内存。受到GC影响。<br>2，<strong>池化的最大意义在于可以重用 ByteBuf。</strong></p>
<ul>
<li>没有池化，则每次都得创建新的 ByteBuf 实例，这个操作对直接内存代价昂贵，就算是堆内存，也会增加 GC 压力</li>
<li>有了池化，则可以重用池中 ByteBuf 实例，并且采用了与 jemalloc 类似的内存分配算法提升分配效率</li>
<li>高并发时，池化功能更节约内存，减少内存溢出的可能<br>4.1之后非安卓默认池化。<br>参数设定：netty.allocator.type&#x3D;{polled|unpolled}</li>
</ul>
<p><strong>组成：</strong></p>
<p><img src="https://i.loli.net/2021/08/04/uVCU9FcGnJsHeDm.png" alt="image-20210804201545205"></p>
<p>可以指定最大容量。</p>
<p><strong>内存回收</strong><br>由于 Netty 中有堆外内存的 ByteBuf 实现，堆外内存最好是手动来释放，而不是等 GC 垃圾回收。</p>
<ul>
<li>UnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收内存即可</li>
<li>UnpooledDirectByteBuf 使用的就是直接内存了，需要特殊的方法来回收内存</li>
<li>PooledByteBuf 和它的子类使用了池化机制，需要更复杂的规则来回收内存</li>
</ul>
<p><strong>Netty 这里采用了引用计数法来控制回收内存，每个 ByteBuf 都实现了 ReferenceCounted 接口</strong></p>
<ul>
<li>每个 ByteBuf 对象的初始计数为 1</li>
<li>调用 release 方法计数减 1，如果计数为 0，ByteBuf 内存被回收</li>
<li>调用 retain 方法计数加 1，表示调用者没用完之前，其它 handler 即使调用了 release 也不会造成回收</li>
<li>当计数为 0 时，底层内存会被回收，这时即使 ByteBuf 对象还在，其各个方法均无法正常使用<br>扩容</li>
<li>如何写入后数据大小未超过 512，则选择下一个 16 的整数倍，例如写入后大小为 12 ，则扩容后 capacity 是 16</li>
<li>如果写入后数据大小超过 512，则选择下一个 2^n，例如写入后大小为 513，则扩容后 capacity 是 2^10&#x3D;1024（2^9&#x3D;512 已经不够了）</li>
<li>扩容不能超过 max capacity 会报错</li>
</ul>
<h4 id="ByteBuf-优势"><a href="#ByteBuf-优势" class="headerlink" title="ByteBuf 优势"></a>ByteBuf 优势</h4><ul>
<li>池化 - 可以重用池中 ByteBuf 实例，更节约内存，减少内存溢出的可能</li>
<li>读写指针分离，不需要像 ByteBuffer 一样切换读写模式</li>
<li>可以自动扩容</li>
<li>支持链式调用，使用更流畅</li>
<li>很多地方体现零拷贝，例如 slice、duplicate、CompositeByteBuf</li>
</ul>
<h2 id="netty服务端与客户端启动过程"><a href="#netty服务端与客户端启动过程" class="headerlink" title="netty服务端与客户端启动过程"></a>netty服务端与客户端启动过程</h2><h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">new ServerBootstrap()</span><br><span class="line">    .group(new NioEventLoopGroup()) </span><br><span class="line">    .channel(NioServerSocketChannel.class) </span><br><span class="line">    .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; </span><br><span class="line">        protected void initChannel(NioSocketChannel ch) &#123;</span><br><span class="line">            ch.pipeline().addLast(new StringDecoder()); </span><br><span class="line">            ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;String&gt;() &#123; </span><br><span class="line">                @Override</span><br><span class="line">                protected void channelRead0(ChannelHandlerContext ctx, String msg) &#123;</span><br><span class="line">                    System.out.println(msg);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    .bind(8080); // 4</span><br></pre></td></tr></table></figure>

<p>1，创建两个 NioEventLoopGroup 对象实例： bossGroup 和 workerGroup 。<br>bossGroup : ⽤于处理客户端的 TCP 连接请求。<br>workerGroup ： 负责每⼀条连接的具体读写数据的处理逻辑，真正负责 I&#x2F;O 读写操作，交<br>由对应的 Handler 处理。<br>2，创建了⼀个服务端启动引导&#x2F;辅助类： ServerBootstrap ，这个类将引导我们进⾏服<br>务端的启动⼯作。<br>3，通过 .group() ⽅法给引导类 ServerBootstrap 配置两⼤线程组，确定了线程模型。<br>4，通过 channel() ⽅法给引导类 ServerBootstrap 指定了 IO 模型为 NIO<br>5，通过 .childHandler() 给引导类创建⼀个 ChannelInitializer ，然后指定了服务端消息的业务<br>处理逻辑 HelloServerHandler 对象<br>6，调⽤ ServerBootstrap 类的 bind() ⽅法绑定端⼝</p>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">new Bootstrap()</span><br><span class="line">    .group(new NioEventLoopGroup()) // 1</span><br><span class="line">    .channel(NioSocketChannel.class) // 2</span><br><span class="line">    .handler(new ChannelInitializer&lt;Channel&gt;() &#123; // 3</span><br><span class="line">        @Override</span><br><span class="line">        protected void initChannel(Channel ch) &#123;</span><br><span class="line">            ch.pipeline().addLast(new StringEncoder()); // 8</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    .connect(&quot;127.0.0.1&quot;, 8080) // 4</span><br><span class="line">    .sync() // 5</span><br><span class="line">    .channel() // 6</span><br><span class="line">    .writeAndFlush(new Date() + &quot;: hello world!&quot;); // 7</span><br></pre></td></tr></table></figure>

<p>1.创建⼀个 NioEventLoopGroup 对象实例<br>2.创建客户端启动的引导类是 Bootstrap<br>3.通过 .group() ⽅法给引导类 Bootstrap 配置⼀个线程组<br>4.通过 channel() ⽅法给引导类 Bootstrap 指定了 IO 模型为 NIO<br>5.通过 .childHandler() 给引导类创建⼀个 ChannelInitializer ，然后指定了客户端消息的业务处理<br>逻辑 HelloClientHandler 对象<br>6.调⽤ Bootstrap 类的 connect() ⽅法进⾏连接，这个⽅法需要指定两个参数：<br>inetHost : ip 地址<br>inetPort : 端⼝号</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Netty-%E4%BC%98%E7%82%B9%EF%BC%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Netty-%E4%BC%98%E7%82%B9%EF%BC%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" class="post-title-link" itemprop="url">Netty-优点，应用场景</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:14:02" itemprop="dateCreated datePublished" datetime="2021-07-30T15:14:02+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Netty/" itemprop="url" rel="index"><span itemprop="name">Netty</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>207</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="netty优点"><a href="#netty优点" class="headerlink" title="netty优点"></a>netty优点</h3><p><strong>异步的</strong>（采用多线程实现了调用方法与返回结果的分离）<br><strong>基于事件驱动（本质上基于IO多路复用）</strong></p>
<p><strong>优势：</strong></p>
<p>基于NIO，但是改善了NIO<br>1，需要自己构建协议<br>2，需要解决TCP传输问题，粘包半包。<br>3，NIO中有epoll空轮询bug。<br>4，对API增强了。bytebuff。</p>
<p>现在是4.0<br>5.0已经废弃，引入AIO，性能未提升。</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>涉及到网络通信就会用到netty<br>rpc框架-dubbo，grpc<br>聊天室？<br>spring</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Netty-NIO%E4%B8%89%E5%A4%A7%E7%BB%84%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Netty-NIO%E4%B8%89%E5%A4%A7%E7%BB%84%E4%BB%B6/" class="post-title-link" itemprop="url">Netty-NIO三大组件</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:13:44" itemprop="dateCreated datePublished" datetime="2021-07-30T15:13:44+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Netty/" itemprop="url" rel="index"><span itemprop="name">Netty</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="channel：双向数据传输通道"><a href="#channel：双向数据传输通道" class="headerlink" title="channel：双向数据传输通道"></a>channel：双向数据传输通道</h3><p>filechannel：文件</p>
<p>datagramchannel：</p>
<p>socketchannel：</p>
<p>serversocketchannel：</p>
<h3 id="buffer：内存缓冲区"><a href="#buffer：内存缓冲区" class="headerlink" title="buffer：内存缓冲区"></a>buffer：内存缓冲区</h3><p>bytebuffer：</p>
<h3 id="selector："><a href="#selector：" class="headerlink" title="selector："></a>selector：</h3><p>选择器？</p>
<p>服务器端早期–多个客户端连接&#x3D;&#x3D;多线程：</p>
<p><strong>缺点：</strong></p>
<p>内存占用高。</p>
<p>线程上下文切换成本高。</p>
<p>只适合连接数较少。</p>
<p><strong>线程池版本设计：</strong></p>
<p>缺点：</p>
<p>线程同一时间只能处理一个socket。</p>
<p>仅适合短连接（长连接–一直保持连接）场景。</p>
<p><strong>selector设计：</strong></p>
<p>一个线程管理多个channel。</p>
<p><img src="https://i.loli.net/2021/08/04/SveWTQN1dHVsoRh.png" alt="image-20210804200403644"></p>
<p>调用selector 的 select() 会阻塞直到 channel 发生了读写就绪事件，这些事件发生，select 方法就会返回这些事件交给 thread 来处理。</p>
<p><strong>基本使用</strong></p>
<ol>
<li><p>向 buffer <strong>写入数据</strong>，例如调用 channel.read(buffer)</p>
</li>
<li><p>调用 <strong>flip()</strong> 切换至读模式</p>
</li>
<li><p>从 buffer 读取数据，例如调用 <strong>buffer.get()</strong></p>
</li>
<li><p>调用 <strong>clear() 或 compact()</strong> 切换至写模式</p>
</li>
<li><p>重复 1~4 步骤</p>
</li>
</ol>
<p><img src="https://i.loli.net/2021/08/04/SPu5WniEZm8Ncv1.png" alt="image-20210804200504999"></p>
<p>分配空间：</p>
<p><strong>bytebuffer.allocate().</strong>&#x3D;&#x3D;堆内存&#x3D;读写效率低&#x3D;受到GC影响</p>
<p><strong>Bytebuffer.allocatedirect()&#x3D;</strong>&#x3D;直接内存&#x3D;读写效率高&#x3D;分配内存的效率低</p>
<p>写入：write（）</p>
<p>读取：get（）</p>
<p>get 方法会让 position 读指针向后走，如果想<strong>重复读取数据</strong></p>
<p>可以调用 <strong>rewind</strong> 方法将 position 重新置为 0</p>
<p>调用 <strong>get(int i) 方法</strong>获取索引 i 的内容，它不会移动读指针</p>
<p><strong>mark 和 reset</strong></p>
<p>mark 是在读取时，做一个标记，即使 position 改变，只要<strong>调用 reset 就能回到 mark 的位置</strong></p>
<p> <strong>rewind 和 flip 都会清除 mark 位置</strong></p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>阻塞IO（同步）：</p>
<p>非阻塞IO（同步）：read为例，在等待数据阶段用户线程不阻塞（多次内存空间的切换）。复制数据阶段阻塞。</p>
<p>多路复用（同步）：select（）为例，两个阶段都是阻塞的。好处在于：可以一次性的处理多个channel上的事件。</p>
<p>信号驱动：不常用</p>
<p>异步IO：<br>异步（线程自己不去获得结果，而是由其他的线程送来结果）</p>
<p><strong>异步情况下一定是非阻塞的。</strong></p>
<p>异步意味着：在进行读写操作时，线程不必等待结果，而是通过回调的方式由另外的线程来获取。</p>
<p>linux在2.6底层通过多路复用模拟了异步IO。</p>
<p>windows通过IOCP真正实现了异步IO。</p>
<p>netty废弃了异步IO。</p>
<h4 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h4><p><img src="https://i.loli.net/2021/08/04/NocGmtUjEZikle8.png" alt="image-20210804200720036"></p>
<p>4次数据拷贝<br>用户态内核态切换三次</p>
<h4 id="NIO优化"><a href="#NIO优化" class="headerlink" title="NIO优化"></a>NIO优化</h4><p>通过 <strong>DirectByteBuf</strong> </p>
<p><img src="https://i.loli.net/2021/08/04/PKkHasXvjMlozdy.png" alt="image-20210804200821683"></p>
<ul>
<li><p>ByteBuffer.allocate(10) HeapByteBuffer 使用的还是 <strong>java 内存</strong></p>
</li>
<li><p>ByteBuffer.allocateDirect(10) DirectByteBuffer 使用的是<strong>操作系统内存</strong><br>java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用</p>
</li>
<li><p>这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写</p>
</li>
<li><p>java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步</p>
<ul>
<li>DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列</li>
<li>通过专门线程访问引用队列，根据虚引用释放堆外内存</li>
</ul>
</li>
<li><p>减少了一次数据拷贝，用户态与内核态的切换次数没有减少</p>
</li>
</ul>
<p><strong>进一步（linux2.1之后的sendfile方法）</strong></p>
<p><img src="https://i.loli.net/2021/08/04/dXP4Fosj5ZmeiuD.png" alt="image-20210804200844338"></p>
<p>java 中对应着两个 channel 调用 transferTo&#x2F;transferFrom 方法拷贝数据</p>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 <strong>DMA</strong>将数据读入内核缓冲区，不会使用 cpu</li>
<li>数据从内核缓冲区传输到 socket 缓冲区，cpu 会参与拷贝</li>
<li>最后使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 cpu</li>
</ol>
<ul>
<li><p>只发生了一次用户态与内核态的切换</p>
</li>
<li><p>数据拷贝了 3 次</p>
</li>
</ul>
<p>进一步（linux2.4之后的sendfile方法）</p>
<p><img src="https://i.loli.net/2021/08/04/Hn7ASzdyuaqgOjW.png" alt="image-20210804200932305"></p>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 cpu</li>
<li>只会将一些 offset 和 length 信息拷入 socket 缓冲区，几乎无消耗</li>
<li>使用 DMA 将内核缓冲区的数据写入网卡，不会使用 cpu<br>整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。<br>所谓的【零拷贝】&#x3D;linux&#x3D;sendfile方法，并不是真正无拷贝，而是在<strong>不会拷贝重复数据到 jvm 内存中。</strong></li>
</ol>
<h4 id="零拷贝的优点有："><a href="#零拷贝的优点有：" class="headerlink" title="零拷贝的优点有："></a>零拷贝的优点有：</h4><ul>
<li>更少的用户态与内核态的切换</li>
<li>不利用 cpu 计算，减少 cpu 缓存伪共享（使用DMA硬件）</li>
<li>零拷贝适合<strong>小文件传输&#x3D;大文件没有缓冲的作用</strong>。（缓冲区比较小）</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Redis-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%EF%BC%8C%E9%9B%AA%E5%B4%A9%EF%BC%8C%E7%A9%BF%E9%80%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Redis-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%EF%BC%8C%E9%9B%AA%E5%B4%A9%EF%BC%8C%E7%A9%BF%E9%80%8F/" class="post-title-link" itemprop="url">Redis-缓存击穿，雪崩，穿透</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:13:09" itemprop="dateCreated datePublished" datetime="2021-07-30T15:13:09+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下<br>一次同样会打到数据库上。此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一样，起不到任何作用。</p>
<h3 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h3><p>1）接口校验。在正常业务流程中可能会存在少量访问不存在 key 的情况，但是一般不会出现大量的情况，所以这种场景最大的可能性是遭受了非法攻击。可以在最外层先做一层校验：用户鉴权、数据合法性校验等，例如商品查询中，商品的 ID 是正整数，则可以直接对非正整数直接过滤等等。</p>
<p>2）缓存空值。当访问缓存和 DB 都没有查询到值时，可以将空值写进缓存，但是设置较短的过期时间，该时间需要根据产品业务特性来设置。</p>
<p>3）布隆过滤器。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库</p>
<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><p>布隆过滤器的特点是<strong>判断不存在的，则一定不存在</strong>；<strong>判断存在的，大概率存在</strong>，但也有小概率不存在。并且这个概率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。</p>
<p>布隆过滤器<strong>由一个 bitSet 和 一组 Hash 函数（算法）组成</strong>，是一种空间效率极高的概率型算法和数据结构，主要用来判断<strong>一个元素是否在海量数据集合中存在</strong>。</p>
<p>在初始化时，bitSet 的每一位被初始化为 0，同时会定义 Hash 函数，例如有 3 组 Hash 函数：hash1、hash2、hash3。</p>
<h3 id="写入流程"><a href="#写入流程" class="headerlink" title="写入流程"></a>写入流程</h3><p>当我们要写入一个值时，过程如下，以“x”为例：<br>1）首先将“x”跟 3 组 Hash 函数分别计算，得到 bitSet 的下标为：1、7、10。<br>2）将 bitSet 的这 3 个下标标记为 1。</p>
<p>假设我们还有另外两个值：java 和 q，按上面的流程跟 3 组 Hash 函数分别计算，结果如下：<br>java：Hash 函数计算 bitSet 下标为：1、7、11<br>q函数计算 bitSet 下标为：4、10、11</p>
<h3 id="查询流程"><a href="#查询流程" class="headerlink" title="查询流程"></a>查询流程</h3><p>当我们要查询一个值时，过程如下，同样以“x”为例：：<br>1）首先将“x”跟 3 组 Hash 函数分别计算，得到 bitSet 的下标为：1、7、10。<br>2）查看 bitSet 的这 3 个下标是否都为 1，如果这 3 个下标不都为 1，则说明该值必然不存在，如果这 3 个下标都为 1，则只能说明可能存在，并不能说明一定存在。</p>
<p><img src="https://i.loli.net/2021/08/04/nZqz2gG4hsDHpwm.png" alt="image-20210804194430890"></p>
<p>其根本原因是，<strong>不同的值在跟 Hash 函数计算后，可能会得到相同的下标</strong>，所以某个值的标记位，可能会被其他值给标上了。<br>这也是为啥布隆过滤器只能判断某个值可能存在，无法判断必然存在的原因。但是反过来，如果该值根据 Hash 函数计算的标记位没有全部都为 1，那么则说明必然不存在，这个是肯定的。</p>
<p>降低这种误判率的思路也比较简单：<br>一个是<strong>加大 bitSet 的长度</strong>，这样不同的值出现“冲突”的概率就降低了，从而误判率也降低。<br><strong>提升 Hash 函数的个数</strong>，Hash 函数越多，每个值对应的 bit 越多，从而误判率也降低。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>某一个<strong>热点 key，在缓存过期的一瞬间，同时有大量的请求打进来</strong>，由于此时缓存过期了，所以请求最终都<br>会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。</p>
<h3 id="解决方案：-1"><a href="#解决方案：-1" class="headerlink" title="解决方案："></a>解决方案：</h3><p><strong>预先准备</strong>，以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长。</p>
<p><strong>现场调整</strong><br>监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key</p>
<p><strong>后台刷新数据</strong><br>启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</p>
<p><strong>二级缓存</strong><br><strong>设置不同的失效时间，保障不会被同时淘汰就行</strong></p>
<p><strong>加锁</strong><br>分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</p>
<p><strong>总结</strong><br>缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中redis后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过期监控难度较高，配合雪崩处理策略即可。</p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力<br>骤增，引起雪崩，甚至导致数据库被打挂。<br>缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。</p>
<h3 id="解决方案：-2"><a href="#解决方案：-2" class="headerlink" title="解决方案："></a>解决方案：</h3><p><strong>过期时间打散</strong>。既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过期时间时加上一个<strong>随机值时间</strong>，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。</p>
<p><strong>热点数据不过期</strong>。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。</p>
<p><strong>加互斥锁</strong>。该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算，其他线程原<br>地阻塞等待第一个线程的计算结果，然后直接走缓存即可</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Redis-%E9%9B%86%E7%BE%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Redis-%E9%9B%86%E7%BE%A4/" class="post-title-link" itemprop="url">Redis-集群</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:12:48" itemprop="dateCreated datePublished" datetime="2021-07-30T15:12:48+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:56" itemprop="dateModified" datetime="2023-07-11T23:32:56+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。</p>
<p>slaveof命令</p>
<p>部分复制：偏移量，积压缓冲区，服务器运行id</p>
<h3 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h3><ul>
<li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li>
<li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li>
<li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li>
<li>高可用基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li>
</ul>
<h3 id="主从复制实现原理"><a href="#主从复制实现原理" class="headerlink" title="主从复制实现原理"></a>主从复制实现原理</h3><p>Redis 的复制分为全量同步和增量同步。</p>
<p>如果主库发现从库传来的复制 id 和自己的 replid、replid2 都不同，或者复制偏移不在复制积压缓冲中，则判定需要进行全量复制。</p>
<p>master 发送 fullresync 响应，附带 replid 及复制偏移。然后， master 根据需要构建 rdb，并将 rdb 及复制缓冲发送给 slave。</p>
<p><img src="https://i.loli.net/2021/08/05/HeojUDSBxl2mPvg.png" alt="image-20210805212150709"></p>
<h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><p>Redis 的主从复制模式下，一旦主节点由于故障不能提供服务，需要手动将从节点晋升为主节点，同时还要通知客户端更新主节点地址，这种故障处理方式从一定程度上是无法接受的。</p>
<p>Redis Sentinel 是 Redis 高可用的实现方案。Sentinel 是一个管理多个 Redis 实例的工具，它可以实现对 Redis 的监控、通知、自动故障转移。</p>
<h3 id="哨兵模式的原理"><a href="#哨兵模式的原理" class="headerlink" title="哨兵模式的原理"></a>哨兵模式的原理</h3><p>哨兵模式的主要作用在于它能够自动完成故障发现和故障转移，并通知客户端，从而实现高可用。哨兵模式通常由一组 Sentinel 节点和一组（或多组）主从复制节点组成。</p>
<h4 id="心跳机制"><a href="#心跳机制" class="headerlink" title="心跳机制"></a>心跳机制</h4><p>（1）Sentinel与Redis Node</p>
<p>Redis Sentinel 是一个特殊的 Redis 节点。在哨兵模式创建时，需要通过配置指定 Sentinel 与 Redis Master Node 之间的关系，然后 Sentinel 会从主节点上获取所有从节点的信息，之后 Sentinel 会定时向主节点和从节点发送 info 命令获取其拓扑结构和状态信息。<br>（2）Sentinel与Sentinel</p>
<p>基于 Redis 的订阅发布功能， 每个 Sentinel 节点会向主节点的 sentinel：hello 频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息 ，同时每个 Sentinel 节点也会订阅该频道， 来获取其他 Sentinel 节点的信息以及它们对主节点的判断。<br>通过以上两步所有的 Sentinel 节点以及它们与所有的 Redis 节点之间都已经彼此感知到，之后每个 Sentinel 节点会向主节点、从节点、以及其余 Sentinel 节点定时发送 ping 命令作为心跳检测， 来确认这些节点是否可达。</p>
<h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>每个 Sentinel 都会定时进行心跳检查，当发现主节点出现心跳检测超时的情况时，此时认为该主节点已经不可用，这种判定称为主观下线。</p>
<p>之后该 Sentinel 节点会通过 sentinel ismaster-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断， 当 quorum（法定人数） 个 Sentinel 节点都认为该节点故障时，则执行客观下线，即认为该节点已经不可用。这也同时解释了为什么必须需要一组 Sentinel 节点，因为单个 Sentinel 节点很容易对故障状态做出误判。</p>
<p>这里 quorum 的值是我们在哨兵模式搭建时指定的，后文会有说明，通常为 Sentinel节点总数&#x2F;2+1，即半数以上节点做出主观下线判断就可以执行客观下线。</p>
<p>因为故障转移的工作只需要一个 Sentinel 节点来完成，所以 Sentinel 节点之间会再做一次选举工作， 基于 Raft 算法选出一个 Sentinel 领导者来进行故障转移的工作。</p>
<h4 id="被选举出的-Sentinel-领导者进行故障转移的具体步骤如下"><a href="#被选举出的-Sentinel-领导者进行故障转移的具体步骤如下" class="headerlink" title="被选举出的 Sentinel 领导者进行故障转移的具体步骤如下"></a>被选举出的 Sentinel 领导者进行故障转移的具体步骤如下</h4><p>（1）在从节点列表中选出一个节点作为新的主节点<br>        过滤不健康或者不满足要求的节点；<br>        选择 slave-priority（优先级）最高的从节点， 如果存在则返回， 不存在则继续；<br>        选择复制偏移量最大的从节点 （主从复制的多的）， 如果存在则返回， 不存在则继续；<br>        选择 runid 最小的从节点。<br>（2）Sentinel 领导者节点会对选出来的从节点执行 slaveof no one 命令让其成为主节点。<br>（3）Sentinel 领导者节点会向剩余的从节点发送命令，让他们从新的主节点上复制数据。<br>（4）Sentinel 领导者会将原来的主节点更新为从节点， 并对其进行监控， 当其恢复后命令它去复制新的主节点。</p>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>哨兵模式最大的缺点就是<strong>所有的数据都放在一台服务器</strong>上，无法较好的进行水平扩展。</p>
<p>为了解决哨兵模式存在的问题，集群模式应运而生。在高可用上，集群基本是直接复用的哨兵模式的逻辑，并且针对水平扩展进行了优化。</p>
<p><img src="https://i.loli.net/2021/08/04/GfF65HaBPXZeYUD.png" alt="image-20210804171645855"></p>
<h4 id="集群模式具备的4特点如下："><a href="#集群模式具备的4特点如下：" class="headerlink" title="集群模式具备的4特点如下："></a>集群模式具备的4特点如下：</h4><ol>
<li>采取<strong>去中心化</strong>的集群模式，将数据按<strong>槽</strong>存储分布在多个 Redis 节点上。集群共有 <strong>16384</strong> 个槽，每个节点负<br>责处理部分槽。</li>
<li>使用 CRC16 算法来计算 key 所属的槽：crc16(key,keylen) &amp; 16383。</li>
<li>所有的 Redis 节点彼此互联，通过 <strong>PING-PONG</strong> 机制来进行节点间的心跳检测。</li>
<li>分片内采用<strong>一主多从保证高可用</strong>，并提供复制和故障恢复功能。在实际使用中，通常会将主从分布在不同<br>机房，避免机房出现故障导致整个分片出问题。</li>
<li>客户端与 Redis 节点直连，不需要中间代理层（proxy）。客户端不需要连接集群所有节点，连接集群中任<br>何一个可用节点即可。</li>
</ol>
<p>通过算法设计，计算出key应该保存的位置<br>所有的存储空间计划切割成<strong>16384</strong>份，每台主机保存一部分，每份代表的是一个存储空间，不是一个key的保存空间，将key按照计算出的结果放到对应的存储空间。</p>
<h4 id="集群内部通讯设计"><a href="#集群内部通讯设计" class="headerlink" title="集群内部通讯设计"></a>集群内部通讯设计</h4><p><img src="https://i.loli.net/2021/08/04/LwtvuDC3nEzQmjl.png" alt="image-20210804171410944"></p>
<p>Key—计算槽在哪？&#x3D;&#x3D;命中？未命中？最多两次</p>
<h4 id="如何保证集群在线扩容的安全性？（Redis-集群要增加分片，槽的迁移怎么保证无损）"><a href="#如何保证集群在线扩容的安全性？（Redis-集群要增加分片，槽的迁移怎么保证无损）" class="headerlink" title="如何保证集群在线扩容的安全性？（Redis 集群要增加分片，槽的迁移怎么保证无损）"></a>如何保证集群在线扩容的安全性？（Redis 集群要增加分片，槽的迁移怎么保证无损）</h4><p>集群已经对外提供服务，原来有 3 分片，准备新增 2 个分片，怎么在不下线的情况下，无损的从原有的 3 个<br>分片指派若干个槽给这 2 个分片？</p>
<p>Redis 使用了 <strong>ASK 错误</strong>来保证在线扩容的安全性。</p>
<p>在槽的迁移过程中若有客户端访问，依旧先访问源节点，源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</p>
<p>如果没找到，说明该键可能已经被迁移到目标节点了，源节点将向客户端返回一个 ASK 错误，该错误会指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/" class="post-title-link" itemprop="url">Redis-持久化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:12:32" itemprop="dateCreated datePublished" datetime="2021-07-30T15:12:32+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Redis 的持久化机制有：<strong>RDB、AOF、混合持久化（RDB+AOF，Redis 4.0 引入）。</strong></p>
<h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><p>类似于快照。在某个时间点，<strong>将 Redis 在内存中的数据库状态（数据库的键值对等信息）保存到磁盘里面</strong>。<br>RDB 持久化功能生成的 RDB 文件是<strong>经过压缩的二进制文件。</strong></p>
<p>命令：有两个 Redis 命令可以用于生成 RDB 文件<strong>，一个是 SAVE，另一个是 BGSAVE</strong>。<br>开启：使用 save point 配置，满足 save point 条件后会触发 BGSAVE <strong>来存储一次快照</strong>。</p>
<p>save point 格式：save <seconds> <changes>，含义是 Redis 如果<strong>在 seconds 秒内数据发生了 changes 次改变，就保存快照文件。</strong></p>
<p>SAVE：生成 RDB 快照文件，<strong>但是会阻塞主进程</strong>，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。</p>
<p>BGSAVE：<strong>fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候</strong>，之后主进程可以正常处理请求。</p>
<p>fork：在 Linux 系统中，调用 fork() 时，会创建出一个新进程，称为子进程，子进程会拷贝父进程的 page table。如果进程占用的内存越大，进程的 page table 也会越大，那么 fork 也会占用更多的时间。如果 Redis 占用的内存很大，那么在 fork 子进程时，则会出现明显的停顿。</p>
<h4 id="RDB-的优点"><a href="#RDB-的优点" class="headerlink" title="RDB 的优点"></a>RDB 的优点</h4><p>RDB 文件是是经过压缩的二进制文件，<strong>占用空间很小</strong>，它保存了 Redis 某个时间点的数据集，很适合用于做备<br>份。</p>
<p>RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。</p>
<p>RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进<br>程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I&#x2F;O 操作。</p>
<p>RDB 在<strong>恢复大数据集时的速度比 AOF 的恢复速度要快</strong>。</p>
<h4 id="RDB-的缺点"><a href="#RDB-的缺点" class="headerlink" title="RDB 的缺点"></a>RDB 的缺点</h4><p>RDB 在服务器故障时<strong>容易造成数据的丢失</strong>。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。</p>
<p>RDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，<strong>fork 可能会非常耗时</strong>，造成 Redis 停<br>止处理服务 N 毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。</p>
<p>Linux fork 子进程采用的是 <strong>copy-on-write</strong> 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的 2 倍。刚 fork 时，主进程和子进程共享内存，<strong>但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改</strong>。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的 2 倍。</p>
<h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>保存 Redis 服务器所执行的所有写操作命令来记录数据库状态，并在服务器启动时，通过重新执行这些命令<br>来还原数据集。<br>开启：AOF 持久化默认是关闭的，可以通过配置：<strong>appendonly yes</strong> 开启。<br>关闭：使用配置 appendonly no 可以关闭 AOF 持久化。</p>
<p>AOF 持久化功能的实现可以分为三个步骤：<strong>命令追加、文件写入、文件同步</strong>。</p>
<p>命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态的 <strong>aof 缓冲区（aof_buf）</strong>的末尾。<br>文件写入与文件同步：可能有人不明白为什么将 aof_buf 的内容写到磁盘上需要两步操作，这边简单解释一下。</p>
<p>Linux 操作系统中为了提升性能，使用了<strong>页缓存（page cache）</strong>。当我们将 aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 page cache 中，为了将 page cache 中的数据真正落盘，需要执行 fsync &#x2F; fdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。</p>
<p>appendfsync 参数值，来决定<strong>是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件</strong>。</p>
<h4 id="appendfsync-参数有三个选项："><a href="#appendfsync-参数有三个选项：" class="headerlink" title="appendfsync 参数有三个选项："></a><strong>appendfsync 参数有三个选项：</strong></h4><p>always：<strong>每处理一个命令</strong>都将 aof_buf 缓冲区中的所有内容写入并同步到 AOF 文件，即每个命令都刷盘。</p>
<p>everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超<br>过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，<br>即<strong>每秒刷盘 1 次。</strong></p>
<p>no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作<br>系统来决定。即不执行刷盘，<strong>让操作系统自己执行刷盘。</strong></p>
<h4 id="AOF-的优点"><a href="#AOF-的优点" class="headerlink" title="AOF 的优点"></a>AOF 的优点</h4><ol>
<li><strong>AOF 比 RDB 可靠。</strong>你可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。</li>
<li><strong>AOF 文件是一个纯追加的日志文件</strong>。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘<br>已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。</li>
<li><strong>当 AOF 文件太大时，Redis 会自动在后台进行重写</strong>：重写后的新 AOF 文件包含了恢复当前数据集所需的最<br>小命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追<br>加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。</li>
<li>AOF 文件<strong>有序地保存了对数据库执行的所有写入操作以 Redis 协议的格式保存</strong>， 因此 AOF 文件的<strong>内容非</strong><br> <strong>常容易被人读懂</strong>， 对文件进行分析（parse）也很轻松。如果你不小心执行了 FLUSHALL 命令把所有数据刷<br> 掉了，但只要 AOF 文件没有被重写，那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并<br> 重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</li>
</ol>
<h4 id="AOF-的缺点"><a href="#AOF-的缺点" class="headerlink" title="AOF 的缺点"></a>AOF 的缺点</h4><p>对于相同的数据集，<strong>AOF 文件的大小一般会比 RDB 文件大。</strong></p>
<p>根据所使用的 fsync 策略，<strong>AOF 的速度可能会比 RDB 慢</strong>。通常 fsync 设置为每秒一次就能获得比较高的<br>性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。</p>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h3><p>混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化<strong>只发生于 AOF 重写</strong>过程。<br>使用了混合持久化，<strong>重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据</strong>。</p>
<p>开启：混合持久化的配置参数为 <strong>aof-use-rdb-preamble</strong>，配置为 yes 时开启混合持久化，在 redis 4 刚引入时，默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。</p>
<p>关闭：使用 aof-use-rdb-preamble no 配置即可关闭混合持久化。</p>
<p>混合持久化本质是<strong>通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区的增量命令以 AOF 方式写入到文件</strong>，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>优点：结合 RDB 和 AOF 的优点, <strong>更快的重写和恢复。</strong><br>缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。</p>
<h4 id="为什么需要-AOF-重写"><a href="#为什么需要-AOF-重写" class="headerlink" title="为什么需要 AOF 重写"></a>为什么需要 AOF 重写</h4><p>AOF 持久化是通过保存<strong>被执行的写命令</strong>来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，<strong>文件的体积也会越来越大。</strong></p>
<p>举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。<br>然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。<br>为了处理这种情况， Redis 引入了 AOF 重写：可以在不打断服务端处理请求的情况下， 对 AOF 文件进行重建<br>（rebuild）。</p>
<h4 id="介绍下-AOF-重写的过程、AOF-后台重写存在的问题、如何解决-AOF-后台重写存在的数据不一致问题"><a href="#介绍下-AOF-重写的过程、AOF-后台重写存在的问题、如何解决-AOF-后台重写存在的数据不一致问题" class="headerlink" title="介绍下 AOF 重写的过程、AOF 后台重写存在的问题、如何解决 AOF 后台重写存在的数据不一致问题"></a>介绍下 AOF 重写的过程、AOF 后台重写存在的问题、如何解决 AOF 后台重写存在的数据不一致问题</h4><p>Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件<strong>包含重建当前数据集所需的最少命令。</strong></p>
<p>具体过程是<strong>遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。</strong></p>
<p>命令：有两个 Redis 命令可以用于触发 AOF 重写，一个是 <strong>BGREWRITEAOF</strong> 、另一个是 <strong>REWRITEAOF</strong> 命令；<br>开启：AOF 重写由两个参数共同控制，auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size，同时满足这两个条件，则触发 AOF 后台重写 BGREWRITEAOF。</p>
<ol>
<li><p>&#x2F;&#x2F; 当前 AOF 文件比上次重写后的 AOF 文件大小的增长比例超过 100</p>
<p>auto-aof-rewrite-percentage 100</p>
</li>
<li><p>&#x2F;&#x2F; 当前 AOF 文件的文件大小大于 64MB</p>
<p>auto-aof-rewrite-min-size 64mb</p>
</li>
</ol>
<p>BGREWRITEAOF：fork 子进程来进行 AOF 重写，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。<br><strong>REWRITEAOF 和 BGREWRITEAOF 的关系与 SAVE 和 BGSAVE 的关系类似。</strong></p>
<h4 id="AOF-后台重写存在的问题"><a href="#AOF-后台重写存在的问题" class="headerlink" title="AOF 后台重写存在的问题"></a>AOF 后台重写存在的问题</h4><p>AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：</p>
<p>子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，<strong>新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。</strong></p>
<h4 id="如何解决-AOF-后台重写存在的数据不一致问题"><a href="#如何解决-AOF-后台重写存在的数据不一致问题" class="headerlink" title="如何解决 AOF 后台重写存在的数据不一致问题"></a>如何解决 AOF 后台重写存在的数据不一致问题</h4><p>为了解决上述问题，Redis 引入了 <strong>AOF 重写缓冲区</strong>（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。</p>
<p> 1、现有 AOF 文件的处理工作会如常进行。这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。<br> 2、从创建子进程开始，也就是 AOF 重写开始，服务器执行的所有写命令会被记录到 AOF 重写缓冲区里面。</p>
<p> 这样，<strong>当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束</strong>，则会执行以下工作：<br> 1、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。<br> 2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。</p>
<h4 id="RDB、AOF、混合持久，用哪一个？"><a href="#RDB、AOF、混合持久，用哪一个？" class="headerlink" title="RDB、AOF、混合持久，用哪一个？"></a>RDB、AOF、混合持久，用哪一个？</h4><p>如果想尽量保证数据安全性， 你应该同时使用 RDB 和 AOF 持久化功能，同时可以开启混合持久化。</p>
<p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。</p>
<p>如果你的数据是可以丢失的，则可以关闭持久化功能，在这种情况下，Redis 的性能是最高的。</p>
<p>使用 Redis 通常都是为了提升性能，而如果为了不丢失数据而将 appendfsync 设置为 always 级别时，对 Redis 的性能影响是很大的，在这种不能接受数据丢失的场景，其实可以考虑直接选择 MySQL 。</p>
<h4 id="同时开启-RDB-和-AOF，服务重启时如何加载"><a href="#同时开启-RDB-和-AOF，服务重启时如何加载" class="headerlink" title="同时开启 RDB 和 AOF，服务重启时如何加载"></a>同时开启 RDB 和 AOF，服务重启时如何加载</h4><p>简单来说，如果同时启用了 AOF 和 RDB，Redis 重新启动时，<strong>会使用 AOF 文件来重建数据集</strong>，因为通常来说， AOF的数据会更完整。</p>
<p>而在引入了混合持久化之后，使用 AOF 重建数据集时，会通过文件开头是否为“REDIS”来判断是否为混合持久化。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">Redis-线程模型,事务</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:12:19" itemprop="dateCreated datePublished" datetime="2021-07-30T15:12:19+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:56" itemprop="dateModified" datetime="2023-07-11T23:32:56+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="redis为什么快"><a href="#redis为什么快" class="headerlink" title="redis为什么快"></a>redis为什么快</h2><p><strong>1、基于内存的操作</strong><br><strong>2、使用了 I&#x2F;O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器</strong><br><strong>3、单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。</strong><br><strong>4、以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字符串、压缩列表等</strong></p>
<h3 id="完全基于内存"><a href="#完全基于内存" class="headerlink" title="完全基于内存"></a>完全基于内存</h3><p>Redis<strong>完全基于内存</strong>，大部分都是简单的存取操作，大量的时间花费在IO上。Redis绝大部分操作时间复杂度为O(1)，所以速度十分快。</p>
<h3 id="非阻塞IO、多路IO复用模型"><a href="#非阻塞IO、多路IO复用模型" class="headerlink" title="非阻塞IO、多路IO复用模型"></a>非阻塞IO、多路IO复用模型</h3><p>Redis采用<strong>多路IO复用</strong>模型，在内部采用<strong>epoll代理</strong>。多路是指多个网络连接，IO复用是指复用同一个线程。<strong>epoll会同时监察多个流的IO事件，</strong>在空闲时，当前线程进入阻塞，如果有IO事件时，线程会被唤醒，并且epoll会通知线程是哪个流发生了IO事件，然后按照顺序处理，减少了网络IO的时间消耗，避免了大量的无用操作。</p>
<h3 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h3><p>对于单线程来讲，<strong>不存在上下文切换问题，也不用考虑锁的问题，不存在加锁释放锁的操作，没有因为可能出现死锁而导致的性能消耗</strong>。虽然单线程无法发挥出多个CPU的性能，但是可以<strong>在单机开启多个Redis实例解决这个问题。</strong>reids的单线程是指<strong>处理网络请求只有一个线程</strong>。</p>
<p>每次上下文切换都需要花费几十纳秒到数微秒的CPU时间，也就是说如果<strong>频繁的进行上下文切换会导致CPU大部分时间被浪费。</strong></p>
<p>在关系型数据库中，会通过加锁来保证数据的一致性，这种锁被称为悲观锁。Redis为了近可能的减少客户端等待，使用WATCH命令对数据加锁，<strong>只会在数据被其他客户端修改时，才会通知执行WATCH的客户端</strong>，之后的事务不会执行。这种加锁方式被称为乐观锁，极大的提升了Redis的性能。</p>
<h3 id="数据结构简单"><a href="#数据结构简单" class="headerlink" title="数据结构简单"></a>数据结构简单</h3><p>数据结构设计简单，对数据的操作也简单，Redis中的数据结构是专门进行设计的。Redis的数据结构有<strong>简单动态字符串、链表、字典、跳跃表、整数集合、压缩字典。</strong></p>
<p>简单动态字符串<br>Redis并没有使用C语言的字符串，而是使用了简单动态字符串(SDS)。相对于C语言的字符串来讲，SDS记录了自身使用和未使用的长度，时间复杂度为O(1),而C语言则要遍历整个空间，时间复杂度为O(N)。<br>SDS可以通过自身长度来判断字符串是否结束，这样可以实现二进制数据的存储。</p>
<p>链表<br>Redis的链表为双端链表，链表节点带有perv和next指针，链表还带有head和tail指针，使得获取链表某节点前后置节点的时间复杂度都是O(1)。并且Redis链表无环，prev和next指针指向null，对链表的访问以null作为截至的判断条件。<br>链表中有记录自身长度的属性len，并且链表使用void*指针来保存节点值，可以通过list 结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用来保存各种不同类型的值。</p>
<p>字典<br>字典由哈希表组成，而哈希表又由哈希结点组成。</p>
<p>跳跃表<br>跳跃表是一种有序数据结构，通过在每个结点中维持多个指向其它结点的指针，从而达到快速访问结点的目的。Redis中在有序集合键和集群结点中的内部数据结构都用到了跳跃表。</p>
<p>整数集合<br>Redis用于保存整数值的集合抽象数据结构，它可以保存类型为 int16_t、int32_t 或者int64_t的整数值，并且保证集合中不会出现重复元素。</p>
<p>压缩列表<br>压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的<strong>顺序型数据结构</strong>。一个压缩列表可以包含任意个结点，每个结点可以保存一个字节数或者一个整数值。</p>
<h3 id="Redis优秀的过期策略和内存淘汰机制"><a href="#Redis优秀的过期策略和内存淘汰机制" class="headerlink" title="Redis优秀的过期策略和内存淘汰机制"></a>Redis优秀的过期策略和内存淘汰机制</h3><p><strong>定时删除</strong>：在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，<strong>对 CPU 时间最不友好。</strong></p>
<p><strong>惰性删除</strong>：<strong>放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键</strong>；如果没有过期，就返回该键。对 CPU 时间最优化，对内存最不友好。</p>
<p><strong>定期删除</strong>：<strong>每隔一段时间，默认 100ms，程序就对数据库进行一次检査，删除里面的过期键</strong>。至 于要删除多少过期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。</p>
<p>Redis 使用<strong>惰性删除和定期删除</strong></p>
<h4 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h4><p>Redis的内存淘汰机制有六种：</p>
<p>volatile-lru：内存不足时，删除<strong>设置了过期时间的键空间</strong>中最近最少使用的key<br>allkeys-lru：内存不足时，在<strong>键空间</strong>中删除最少使用的key<br>volatile-random：内存不足时，随机删除在<strong>设置了过期时间</strong>的键空间中的key<br>allkeys-random：内存不足时，随即删除在<strong>键空间</strong>中的key<br>volatile-ttl：内存不足时，在设<strong>置了过期时间</strong>的键空间中，优先移除<strong>更早过期时间的key</strong><br>noeviction：永不过期，返回错误</p>
<p><strong>还有两种4.0新增的：基于LFU.</strong></p>
<p>在以上的淘汰策略中，使用allkeys-lru较好。</p>
<h3 id="在-redis-6-0-之前，redis-的核心操作是单线程的。"><a href="#在-redis-6-0-之前，redis-的核心操作是单线程的。" class="headerlink" title="在 redis 6.0 之前，redis 的核心操作是单线程的。"></a>在 redis 6.0 之前，redis 的核心操作是单线程的。</h3><p>因为 redis 是完全基于内存操作的，通常情况下 CPU 不会是 redis 的瓶颈，redis 的瓶颈最有可能是机器内存的大小或者网络带宽。<br>既然 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。<br>而随着近些年互联网的不断发展，大家对于缓存的性能要求也越来越高了，因此 redis 也开始在逐渐往多线程方向发展。</p>
<p>最近的 <strong>6.0 版本</strong>就对核心流程引入了多线程，主要用于解决 redis 在<strong>网络 I&#x2F;O 上的性能瓶颈。而对于核心的命令</strong><br><strong>执行阶段，目前还是单线程的。</strong></p>
<h2 id="Redis-的网络事件处理器（Reactor-模式）"><a href="#Redis-的网络事件处理器（Reactor-模式）" class="headerlink" title="Redis 的网络事件处理器（Reactor 模式）"></a>Redis 的网络事件处理器（Reactor 模式）</h2><p>redis 基于 reactor 模式开发了自己的网络事件处理器，由 4 个部分组成：<strong>套接字、I&#x2F;O 多路复用程序、文件事件分 派器（dispatcher）、以及事件处理器。</strong></p>
<p><img src="https://i.loli.net/2021/08/04/fG5ONWZAVCUr69X.png" alt="image-20210804153454233"></p>
<p><strong>套接字</strong>：socket 连接，也就是客户端连接。当一个套接字准备好执行连接、写入、读取、关闭等操作时， 就会产生一个相应的文件事件。因为一个服务器通常会连接多个套接字， 所以多个文件事件有可能会并发地出现。</p>
<p><strong>I&#x2F;O 多路复用程序</strong>：提供 select、epoll、evport、kqueue 的实现，会根据当前系统自动选择最佳的方式。负责监听多个套接字，当套接字产生事件时，会向文件事件分派器传送那些产生了事件的套接字。当多个文件事件并发出现时， <strong>I&#x2F;O 多路复用程序会将所有产生事件的套接字都放到一个队列里面，</strong>然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后，才会继续传送下一个套接字。</p>
<p><strong>文件事件分派器</strong>：接收 I&#x2F;O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。</p>
<p><strong>事件处理器：</strong>事件处理器就是一个个函数， 定义了某个事件发生时， 服务器应该执行的动作。例如：建立连接、命令查询、命令写入、连接关闭等等</p>
<h2 id="Redis-事务的实现"><a href="#Redis-事务的实现" class="headerlink" title="Redis 事务的实现"></a>Redis 事务的实现</h2><p>一个事务从开始到结束通常会经历以下 3 个阶段：</p>
<p>1）事务开始：<strong>multi</strong> 命令将执行该命令的客户端从非事务状态切换至事务状态，底层通过 flags 属性标识。<br>2）命令入队：当客户端处于事务状态时，服务器会根据客户端发来的命令执行不同的操作：<br>exec、discard、watch、multi 命令会被立即执行<br>其他命令不会立即执行，而是将命令放入到一个事务队列，然后向客户端返回 QUEUED 回复。<br>3）事务执行：当一个处于事务状态的客户端向服务器发送 <strong>exec</strong> 命令时，服务器会遍历事务队列，执行队列中的所有命令，最后将结果全部返回给客户端。</p>
<p><strong>WATCH命令可以监控一个或多个键</strong>，一旦其中有一个键被修改（或删除），<strong>之后的事务就不会执行。</strong></p>
<p>监控一直持续到<strong>EXEC命令（</strong>事务中的命令是在EXEC之后才执行的，所以在MULTI命令后<strong>可以修改WATCH监控的键值</strong>）</p>
<p>不过 redis 的事务<strong>并不推荐在实际中使用</strong>，如果要使用事务，推荐使用 Lua 脚本，redis 会保证一个 Lua 脚本里的所有命令的原子性。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" class="post-title-link" itemprop="url">Redis-数据类型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:12:00" itemprop="dateCreated datePublished" datetime="2021-07-30T15:12:00+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:56" itemprop="dateModified" datetime="2023-07-11T23:32:56+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>redis总是键值对存储。</strong></p>
<p><strong>key总是string。</strong></p>
<p><strong>value有五种类型。</strong></p>
<h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p>string 数据结构是简单的 <strong>key-value</strong> 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串（simple dynamic string，SDS）</strong>。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据<strong>还可以保存二进制数据</strong>，并且**获取字符串长度复杂度为 O(1)**（C 字符串为O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。</p>
<p><img src="https://i.loli.net/2021/08/04/zkHrifPgLS46UeR.png" alt="image-20210804150655994"></p>
<p>常用命令： <strong>set,get,strlen,exists,decr,incr,setex</strong> 等等。</p>
<p>应用场景： <strong>一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。</strong></p>
<p>127.0.0.1:6379&gt; set key value #设置 key-value 类型的值<br>127.0.0.1:6379&gt; get key # 根据 key 获得对应的 value<br>127.0.0.1:6379&gt; exists key  # 判断某个 key 是否存在<br>127.0.0.1:6379&gt; strlen key # 返回 key 所储存的字符串值的长度。<br>127.0.0.1:6379&gt; del key # 删除某个 key 对应的值<br>127.0.0.1:6379&gt; get key</p>
<p>批量设置 :<br>127.0.0.1:6379&gt; mset key1 value1 key2 value2 # 批量设置 key-value 类型的值<br>127.0.0.1:6379&gt; mget key1 key2 # 批量获取多个 key 对应的 value</p>
<p>计数器（字符串的内容为整数的时候可以使用）：<br>127.0.0.1:6379&gt; set number 1<br>127.0.0.1:6379&gt; incr number # 将 key 中储存的数字值增一<br>127.0.0.1:6379&gt; get number<br>127.0.0.1:6379&gt; decr number # 将 key 中储存的数字值减一<br>127.0.0.1:6379&gt; get number</p>
<p>过期（默认为永不过期）：<br>127.0.0.1:6379&gt; <strong>expire</strong> key  60 # 数据在 60s 后过期<br>127.0.0.1:6379&gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)<br>127.0.0.1:6379&gt; ttl key # 查看数据还有多久过期</p>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list 即是 <strong>链表</strong>。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且可以灵活调整链表长度，但是链表的随机访问困难。Redis 的 list 的实现为一个 <strong>双向链表</strong>，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p>
<p>常用命令**: rpush,lpop,lpush,rpop,lrange,llen** 等。</p>
<p>应用场景: <strong>发布与订阅或者说消息队列、慢查询。</strong></p>
<p>通过 rpush&#x2F;lpop 实现队列：<br>127.0.0.1:6379&gt; rpush myList value1 # 向 list 的头部（右边）添加元素<br>127.0.0.1:6379&gt; rpush myList value2 value3 # 向list的头部（最右边）添加多个元素<br>127.0.0.1:6379&gt; lpop myList # 将 list的尾部(最左边)元素取出<br>127.0.0.1:6379&gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end<br>127.0.0.1:6379&gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一</p>
<p>通过 rpush&#x2F;rpop 实现栈：<br>127.0.0.1:6379&gt; rpush myList2 value1 value2 value3<br>127.0.0.1:6379&gt; rpop myList2 # 将 list的头部(最右边)元素取出</p>
<p>通过 lrange 查看对应下标范围的列表元素：<br>127.0.0.1:6379&gt; rpush myList value1 value2 value3<br>127.0.0.1:6379&gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end<br>127.0.0.1:6379&gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一<br>通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！</p>
<p>通过 llen 查看链表长度：<br>127.0.0.1:6379&gt; llen myList</p>
<h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p>hash 类似于 JDK1.8 前的 HashMap，**内部实现也差不多(数组 + 链表)**。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。</p>
<h4 id="渐进式rehash（）；"><a href="#渐进式rehash（）；" class="headerlink" title="渐进式rehash（）；"></a><strong>渐进式rehash（）；</strong></h4><p>hash 对象在扩容时使用了一种叫“<strong>渐进式 rehash</strong>”的方式，步骤如下：</p>
<p>1）计算新表 size（*2且为2的幂次）、掩码，为新表 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。<br>2）将 rehash <strong>索引计数器变量 rehashidx</strong> 的值设置为 0，表示 rehash 正式开始。<br>3）在 rehash 进行期间，每次对字典执行添加、删除、査找、更新操作时，程序除了执行指定的操作以外，还会触发额外的 rehash 操作，在源码中的 _dictRehashStep 方法。</p>
<p>_dictRehashStep：从名字也可以看出来，大意是 rehash 一步，也就是 rehash 一个索引位置。</p>
<p>该方法会从 <strong>ht[0] 表的 rehashidx 索引位置上开始向后查找，找到第一个不为空的索引位置，将该索引位置的所有节点 rehash 到 ht[1]，当本次 rehash 工作完成之后，将 ht[0] 索引位置为 rehashidx 的节点清空，同时将 rehashidx属性的值加一。</strong></p>
<p>4）将 rehash 分摊到每个操作上确实是非常妙的方式，但是万一此时服务器比较空闲，一直没有什么操作，难道 redis要一直持有两个哈希表吗？<br>答案当然不是的。我们知道，redis 除了文件事件外，还有时间事件，<strong>redis 会定期触发时间事件，这些时间事件用于执行一些后台操作，其中就包含 rehash 操作</strong>：当 redis 发现有字典正在进行 rehash 操作时，会花费 1 毫秒的时间，一起帮忙进行 rehash。</p>
<p>5）随着操作的不断执行，最终在某个时间点上，<strong>ht[0] 的所有键值对都会被 rehash 至 ht[1]<strong>，此时 rehash 流程完成，会执行最后的清理工作：</strong>释放 ht[0] 的空间、将 ht[0] 指向 ht[1]、重置 ht[1]、重置 rehashidx</strong></p>
<h4 id="渐进式-rehash-的优点"><a href="#渐进式-rehash-的优点" class="headerlink" title="渐进式 rehash 的优点"></a>渐进式 rehash 的优点</h4><p>渐进式 rehash 的好处在于它采取<strong>分而治之</strong>的方式，将 rehash 键值对所需的计算工作<strong>均摊到对字典的每个添加、删除、查找和更新操作上</strong>，从而避免了<strong>集中式 rehash 而带来的庞大计算量</strong>。</p>
<p>在进行渐进式 rehash 的过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间，字典的删除、査找、更新等操作会在两个哈希表上进行。例如，要在字典里面査找一个键的话，程序会先在 ht[0] 里面进行査找，如果没找到的话，就会继续到 ht[1] 里面进行査找，诸如此类。</p>
<p>另外，在渐进式 rehash 执行期间，<strong>新增的键值对会被直接保存到 ht[1], ht[0] 不再进行任何添加操作，这样就保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。</strong></p>
<p>常用命令： <strong>hset,hmset,hexists,hget,hgetall,hkeys,hvals 等</strong>。</p>
<p>应用场景: 系统中对象数据的存储。 hash 数据结构来存储用户信息，商品信息等等。</p>
<h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是一种<strong>无序集合</strong>，集合中的元素没有先后顺序。<strong>当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择</strong>，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。</p>
<p><strong>可以基于 set 轻易实现交集、并集、差集的操作。</strong></p>
<p>常用命令： <strong>sadd,spop,smembers,sismember,scard,sinterstore,sunion</strong> 等。</p>
<p>应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如<strong>共同关注、共同粉丝、共同喜好等功能。</strong><br>127.0.0.1:6379&gt; smembers mySet # 查看 set 中所有的元素<br>127.0.0.1:6379&gt; scard mySet # 查看 set 的长度<br>127.0.0.1:6379&gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素<br>127.0.0.1:6379&gt; sadd mySet2 value2 value3<br>127.0.0.1:6379&gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中</p>
<h3 id="sorted-set"><a href="#sorted-set" class="headerlink" title="sorted set"></a>sorted set</h3><p>和 set 相比，sorted set 增加了一个<strong>权重参数 score</strong>，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。</p>
<p>常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。</p>
<p>应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种<strong>礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息</strong>。</p>
<h4 id="Sorted-Set-为什么同时使用字典和跳跃表？"><a href="#Sorted-Set-为什么同时使用字典和跳跃表？" class="headerlink" title="Sorted Set 为什么同时使用字典和跳跃表？"></a>Sorted Set 为什么同时使用字典和跳跃表？</h4><p>主要是为了提升性能。</p>
<p>单独使用字典：在执行范围型操作，比如 zrank、zrange，字典需要进行排序，至少需要 O(NlogN) 的时间复杂度及额外 O(N) 的内存空间。<br>单独使用跳跃表：根据成员查找分值操作的复杂度从 O(1) 上升为 O(logN）</p>
<h4 id="Sorted-Set-为什么使用跳跃表，而不是红黑树？"><a href="#Sorted-Set-为什么使用跳跃表，而不是红黑树？" class="headerlink" title="Sorted Set 为什么使用跳跃表，而不是红黑树？"></a>Sorted Set 为什么使用跳跃表，而不是红黑树？</h4><p>主要有以下几个原因：<br>1）跳表的性能和红黑树差不多。<br>2）<strong>跳表更容易实现和调试</strong>。</p>
<h3 id="bitmap"><a href="#bitmap" class="headerlink" title="bitmap"></a>bitmap</h3><p>bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间。</p>
<p>常用命令： setbit 、getbit 、bitcount、bitop</p>
<p>应用场景： 适合需要保存状态信息（比如是否签到、是否登录…）并需要进一步对这些信息进行分析的场景。比如<strong>用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）</strong>。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Mysql-%E7%B4%A2%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Mysql-%E7%B4%A2%E5%BC%95/" class="post-title-link" itemprop="url">Mysql-索引</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:11:24" itemprop="dateCreated datePublished" datetime="2021-07-30T15:11:24+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Mysql/" itemprop="url" rel="index"><span itemprop="name">Mysql</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有:<strong>B+树和 Hash</strong>。<br>Hash 索引不支持顺序和范围查询。</p>
<h3 id="主键索引vs唯一索引"><a href="#主键索引vs唯一索引" class="headerlink" title="主键索引vs唯一索引"></a>主键索引vs唯一索引</h3><p>主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。</p>
<p>主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。</p>
<p>唯一性索引列允许空值，而主键列不允许为空值。</p>
<p>主键列在创建时，已经默认为空值 + 唯一索引了。</p>
<p>主键可以被其他表引用为外键，而唯一索引不能。</p>
<p>一个表最多只能创建一个主键，但可以创建多个唯一索引。</p>
<p>主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。</p>
<h2 id="B-树-amp-B-树两者有何异同呢？"><a href="#B-树-amp-B-树两者有何异同呢？" class="headerlink" title="B 树&amp; B+树两者有何异同呢？"></a>B 树&amp; B+树两者有何异同呢？</h2><p>B 树的所有节点<strong>既存放键(key) 也存放 数据(data)<strong>，而 B+树</strong>只有叶子节点存放 key 和 data</strong>，其他内节点只存放 key。</p>
<p>B 树的叶子节点都是独立的;</p>
<p>B+树的<strong>叶子节点有一条引用链指向与它相邻的叶子节点</strong>。</p>
<p><img src="https://i.loli.net/2021/08/04/dm9kpsbhzaX8M2D.png" alt="image-20210804144530896"></p>
<p>B 树的检索的过程相当于对范围内的每个节点的关键字做<strong>二分查找</strong>，可能还没有到达叶子节点，检索就结束了。</p>
<p>而 <strong>B+树的检索效率就很稳定</strong>了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。</p>
<p>MyISAM 引擎中，B+Tree 叶节点的 <strong>data 域存放的是数据记录的地址</strong>。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。</p>
<p>InnoDB 引擎中，其<strong>数据文件本身就是索引文件</strong>。<br>相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，<strong>因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）</strong>”，而其余的索引都作为<strong>辅助索引</strong>。</p>
<p>辅助索引的 <strong>data 域存储相应记录主键的值而不是地址</strong>，这也是和 MyISAM 不同的地方。</p>
<p>在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引。 </p>
<p>因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。</p>
<h3 id="B-树磁盘"><a href="#B-树磁盘" class="headerlink" title="B+树磁盘"></a>B+树磁盘</h3><p>所以一次访盘请求（读&#x2F;写）完成过程由三个动作组成：</p>
<p>寻道（时间）：磁头移动定位到指定磁道<br>旋转延迟（时间）：等待指定扇区从磁头下旋转经过<br>数据传输（时间）：数据在磁盘与内存之间的实际传输<br>而总时间就是 寻到时间+旋转延迟+n×数据传输时间。</p>
<p>但是这个节点到底应该多大?虽然磁盘是以<strong>扇区</strong>为大小进行读写的，但是磁盘和操作系统却是用块为单位进行交互的。<br>块的大小必须是扇区大小的2的n次方。比如<strong>4k</strong>，一个页的大小也4k。</p>
<p>所以b树基本上可以说是为机械硬盘量身定制的，<strong>b树的层数决定了在磁盘上查找的次数</strong>，而越小的次数，带来的就是更高的效率。</p>
<p>然而在固态硬盘中，虽然也是以整数倍读写，但是它并不用移动磁头之类的机械操作，固态硬盘使用闪存进行存储，所以它的寻址效率和内存是一个数量级的，使用电位进行寻址，类似内存本身每一个存储空间都有一个地址，直接通过电门运算就找到那个地址了 。</p>
<p>但是从数据结构上来说，索引毕竟是索引，肯定要比遍历快很多，<strong>所以虽然ssd的随机读写很快，但是毕竟没有内存快。所以使用b树还是很有意义</strong>，再加上很多优化的算法都是基于磁盘的，这种历史包袱也不是说丢就能丢的。</p>
<p>因为旋转的受限，所以就算是顺序读写，固态硬盘也要比机械硬盘快，但是快的不是特别明显，毕竟如果是顺序读写，都可以有预判，可以提前做优化。这也就是为什么即使是固态硬盘本身，顺序读也要比随机读快。</p>
<h2 id="为什么-MySQL-数据库要用-B-树存储索引？而不用红黑树、Hash、B-树？"><a href="#为什么-MySQL-数据库要用-B-树存储索引？而不用红黑树、Hash、B-树？" class="headerlink" title="为什么 MySQL 数据库要用 B+树存储索引？而不用红黑树、Hash、B 树？"></a>为什么 MySQL 数据库要用 B+树存储索引？而不用红黑树、Hash、B 树？</h2><p><strong>红黑树</strong>：如果在内存中，红黑树的<strong>查找效率比 B 树更高</strong>，但是涉及到磁盘操作，B 树就更优了。因为红黑树是二叉树，数据量大时树的层数很高，从树的根结点向下寻找的过程，每读 1 个节点，都相当于一次 IO 操作，因此红黑树的 <strong>I&#x2F;O 操作会比 B 树多的多</strong>。</p>
<p><strong>B 树索引</strong>：B 树索相比于 B+树，在进行范围查询时，需要做<strong>局部的中序遍历</strong>，<strong>可能要跨层访问</strong>，跨层访问代表着要进行额外的磁盘 I&#x2F;O 操作；另外，B 树的非叶子节点存放了数据记录的地址，会导致存放的节点更少，树的层数变高。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="主键索引-Primary-Key"><a href="#主键索引-Primary-Key" class="headerlink" title="主键索引(Primary Key)"></a>主键索引(Primary Key)</h3><p>数据表的主键列使用的就是主键索引。</p>
<p>一张数据表有只能有一个主键，并且主键不能为 null，不能重复。</p>
<p>在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有<strong>唯一索引</strong>的字段，如果有，则选择该字段为默认的主键，否则 <strong>InnoDB 将会自动创建一个 6Byte 的自增主键。</strong></p>
<h3 id="二级索引-辅助索引"><a href="#二级索引-辅助索引" class="headerlink" title="二级索引(辅助索引)"></a>二级索引(辅助索引)</h3><p>二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，<strong>通过二级索引，可以定位主键的位置。</strong><br>唯一索引，普通索引，前缀索引等索引属于二级索引。</p>
<h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>MyISAM: B+Tree叶节点的<strong>data域存放的是数据记录的地址</strong>。在索引检索的时候，⾸先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 <strong>data 域的值为地址</strong>读取相应的数据记录。这被称为“⾮聚簇索引”。</p>
<p>InnoDB: 其数据⽂件本身就是索引⽂件。相⽐MyISAM，<strong>索引⽂件和数据⽂件是分离的</strong>，其表数据⽂件本身就是按B+Tree组织的⼀个索引结构，<strong>树的叶节点data域保存了完整的数据记录</strong>。<strong>这个索引的key是数据表的主键</strong>，因此InnoDB表数据⽂件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。</p>
<p>⽽其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值⽽不是地址，这也是和MyISAM不同的地⽅。在根据主索引搜索时，直接找到key所在的节点即可取出数据；再根据辅助索引查找时，则需要先取出主键的值，再⾛⼀遍主索引。因此，在设计表的时候，不建议使⽤过⻓的字段作为主键，也不建议使⽤⾮单调的字段作为主键，这样会造成主索引频繁分裂。 </p>
<h3 id="聚集索引的缺点"><a href="#聚集索引的缺点" class="headerlink" title="聚集索引的缺点"></a>聚集索引的缺点</h3><p><strong>依赖于有序的数据</strong> ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 <strong>UUID</strong> 这种又长又难比较的数据，插入或查找的速度肯定比较慢。</p>
<p><strong>更新代价大</strong> ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。</p>
<p>非聚集索引的叶子节点并不一定存放数据的指针， <strong>因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。</strong></p>
<h3 id="什么是回表查询？"><a href="#什么是回表查询？" class="headerlink" title="什么是回表查询？"></a>什么是回表查询？</h3><p>InnoDB 中，对于<strong>主键索引，只需要走一遍主键索引的查询就能在叶子节点拿到数据。</strong><br>而对于普通索引，叶子节点存储的是 key + 主键值，因此需要再走一次主键索引，通过主键索引找到行记录，这就是所谓的回表查询，先定位主键值，再定位行记录。</p>
<h3 id="走普通索引，一定会出现回表查询吗？"><a href="#走普通索引，一定会出现回表查询吗？" class="headerlink" title="走普通索引，一定会出现回表查询吗？"></a>走普通索引，一定会出现回表查询吗？</h3><p>不一定，如果查询语句所要求的字段全部命中了索引，那么就不必再进行回表查询。<br>有一个 user 表，主键为 id，name 为普通索引，则再执行：<br>select id, name from user where name &#x3D;’joonwhee’ 时，通过 name 的索引就能拿到 id 和 name。</p>
<h3 id="覆盖索引。"><a href="#覆盖索引。" class="headerlink" title="覆盖索引。"></a>覆盖索引。</h3><p>当索引上<strong>包含了查询语句中的所有列</strong>时，我们无需进行回表查询就能拿到所有的请求数据，因此速度会很快。当 explain 的输出结果 Extra 字段为 <strong>Using index</strong> 时，则代表触发覆盖索引。</p>
<h3 id="联合索引（复合索引）的底层实现？最佳左前缀原则？"><a href="#联合索引（复合索引）的底层实现？最佳左前缀原则？" class="headerlink" title="联合索引（复合索引）的底层实现？最佳左前缀原则？"></a>联合索引（复合索引）的底层实现？最佳左前缀原则？</h3><p>联合索引底层还是使用 B+树索引，并且还是只有<strong>一棵树</strong>，只是此时的排序会：首先按照第一个索引排序，在第一个索引相同的情况下，再按第二个索引排序，依次类推。</p>
<p>这也是为什么有“最佳左前缀原则”的原因，<strong>因为右边（后面）的索引都是在左边（前面）的索引排序的基础上进行排序的，如果没有左边的索引，单独看右边的索引，其实是无序的</strong></p>
<h3 id="B-树中一个节点到底多大合适？"><a href="#B-树中一个节点到底多大合适？" class="headerlink" title="B+树中一个节点到底多大合适？"></a>B+树中一个节点到底多大合适？</h3><p>1 页或页的倍数最为合适。因为如果一个节点的大小小于 1 页，那么读取这个节点的时候其实也会读出 1 页，造成资源的浪费。所以为了不造成浪费，所以最后把一个节点的大小控制在 1 页、2 页、3 页等倍数页大小最为合适。</p>
<p>这里说的“页”是 MySQL 自定义的单位（和操作系统类似），MySQL 的 Innodb 引擎中 <strong>1 页的默认大小是 16k。</strong></p>
<h3 id="为什么一个节点为-1-页就够了？"><a href="#为什么一个节点为-1-页就够了？" class="headerlink" title="为什么一个节点为 1 页就够了？"></a>为什么一个节点为 1 页就够了？</h3><p>Innodb 中，B+树中的一个节点存储的内容是：</p>
<ul>
<li>非叶子节点：key + 指针</li>
<li>叶子节点：数据行（key 通常是数据的主键）<br>对于叶子节点：我们假设 1 行数据大小为 1k（对于普通业务绝对够了），那么 1 页能存 16 条数据。对于非叶子节点：key 使用 bigint 则为 8 字节，指针在 MySQL 中为 6 字节，一共是 14 字节，则 16k 能存放 16 * 1024 &#x2F; 14 &#x3D; 1170 个。那么一颗高度为 3 的 B+树能存储的数据为：1170 * 1170 * 16 &#x3D; 21902400（千万级）。</li>
</ul>
<h3 id="什么是-Buffer-Pool？"><a href="#什么是-Buffer-Pool？" class="headerlink" title="什么是 Buffer Pool？"></a>什么是 Buffer Pool？</h3><p>Buffer Pool 是 InnoDB 维护的一个<strong>缓存区域</strong>，用来<strong>缓存数据和索引在内存中</strong>，主要用来加速数据的读写，如果 BufferPool 越大，那么 MySQL 就越像一个内存数据库，默认大小为 <strong>128M</strong>。<br>InnoDB 会将那些热点数据和一些 InnoDB 认为即将访问到的数据存在 Buffer Pool 中，以提升数据的读取性能。<br>InnoDB 在修改数据时，如果数据的页在 Buffer Pool 中，则会直接修改 Buffer Pool，此时我们称这个页为脏页，InnoDB 会以一定的频率将脏页刷新到磁盘，这样可以尽量减少磁盘 I&#x2F;O，提升性能。</p>
<h3 id="非聚集索引不一定回表查询。"><a href="#非聚集索引不一定回表查询。" class="headerlink" title="非聚集索引不一定回表查询。"></a>非聚集索引不一定回表查询。</h3><p>用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。<br> SELECT name FROM table WHERE name&#x3D;’guang19’;<br>那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。</p>
<h3 id="联合索引命中规则："><a href="#联合索引命中规则：" class="headerlink" title="联合索引命中规则："></a>联合索引命中规则：</h3><ol>
<li>MySQL联合索引遵循最<strong>左前缀匹配规则</strong>，即从联合索引的最左列开始向右匹配，直到遇到匹配终止条件。</li>
<li>例如联合索引(col1, col2, col3), where条件为col1&#x3D;a AND col2&#x3D;b可命中该联合索引的(col1,col2)前缀部分, where条件为col2&#x3D;b AND col3&#x3D;c不符合最左前缀匹配，不能命中该联合索引。</li>
<li>**匹配终止条件为范围操作符(如&gt;, &lt;, between, like等)或函数等不能应用索引的情况**。例如联合索引(col1, col2, col3), where条件为col1&#x3D;a AND col2&gt;1 AND col3&#x3D;c, 在col2列上为范围查询，匹配即终止，只会匹配到col1，不能匹配到(col1, col2, col3)。</li>
<li><strong>where条件中的顺序不影响索引命中</strong>。例如联合索引(col1, col2, col3), where条件为col3&#x3D;c AND col2&#x3D;b AND col1&#x3D;a, MySQL优化器会自行进行优化，可命中联合索引(col1, col2, col3)。</li>
</ol>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="共享锁和排他锁？"><a href="#共享锁和排他锁？" class="headerlink" title="共享锁和排他锁？"></a>共享锁和排他锁？</h3><p><strong>共享锁</strong>又称为<strong>读锁，简称 S 锁</strong>，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。</p>
<p><strong>排他锁</strong>又称为<strong>写锁，简称 X 锁，</strong>顾名思义，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务可以对数据就行读取和修改。<br>常见的几种 SQL 语句的加锁情况如下：<br>select * from table：不加锁<br>update&#x2F;insert&#x2F;delete：排他锁<br> select * from table where id &#x3D; 1 for update：id 为索引，加排他锁<br> select * from table where id &#x3D; 1 lock in share mode：id 为索引，加共享锁</p>
<h3 id="MySQL-如何实现悲观锁和乐观锁？"><a href="#MySQL-如何实现悲观锁和乐观锁？" class="headerlink" title="MySQL 如何实现悲观锁和乐观锁？"></a>MySQL 如何实现悲观锁和乐观锁？</h3><p>乐观锁：<strong>更新时带上版本号（cas 更新）</strong><br>悲观锁：<strong>使用共享锁和排它锁</strong>，select…lock in share mode，select…for update。</p>
<h3 id="避免死锁？"><a href="#避免死锁？" class="headerlink" title="避免死锁？"></a>避免死锁？</h3><h5 id="事务之间对资源访问顺序的交替"><a href="#事务之间对资源访问顺序的交替" class="headerlink" title="事务之间对资源访问顺序的交替"></a>事务之间对资源访问顺序的交替</h5><p>一个用户A 访问表A（锁住了表A），然后又访问表B；另一个用户B 访问表B（锁住了表B），然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。</p>
<h5 id="并发修改同一记录"><a href="#并发修改同一记录" class="headerlink" title="并发修改同一记录"></a>并发修改同一记录</h5><p>主要是由于没有一次性申请够权限的锁导致的。</p>
<p>用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。</p>
<p>乐观锁，实现写-写并发</p>
<h4 id="何尽可能的避免死锁呢？"><a href="#何尽可能的避免死锁呢？" class="headerlink" title="何尽可能的避免死锁呢？"></a>何尽可能的避免死锁呢？</h4><p>1）以固定的顺序访问表和行。即按顺序申请锁，这样就不会造成互相等待的场面。</p>
<p>2）大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。</p>
<p>3）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。</p>
<p>4）降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。</p>
<p>5）为表添加合理的索引。如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://xieyi123456.github.io/2021/07/30/Mysql-%E4%BA%8B%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieYi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XieYi's Blog">
      <meta itemprop="description" content="think and do">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | XieYi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/30/Mysql-%E4%BA%8B%E5%8A%A1/" class="post-title-link" itemprop="url">Mysql-事务</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-30 15:11:16" itemprop="dateCreated datePublished" datetime="2021-07-30T15:11:16+08:00">2021-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-11 23:32:57" itemprop="dateModified" datetime="2023-07-11T23:32:57+08:00">2023-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Mysql/" itemprop="url" rel="index"><span itemprop="name">Mysql</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a>事务特性</h2><ul>
<li><p><strong>原子性</strong>： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</p>
</li>
<li><p><strong>一致性</strong>： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；</p>
</li>
<li><p><strong>隔离性</strong>： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</p>
</li>
<li><p><strong>持久性</strong>： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</p>
</li>
<li><p><strong>脏读（Dirty read</strong>）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。</p>
</li>
<li><p><strong>丢失修改（Lost to modify</strong>）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A&#x3D;20，事务2也读取A&#x3D;20，事务1修改A&#x3D;A-1，事务2也修改A&#x3D;A-1，最终结果A&#x3D;19，事务1的修改被丢失。</p>
</li>
<li><p><strong>不可重复读（Unrepeatableread</strong>）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。</p>
</li>
<li><p><strong>幻读（Phantom read）</strong>: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。</p>
</li>
</ul>
<h2 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h2><ul>
<li>**READ-UNCOMMITTED(读取未提交)**： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li>**READ-COMMITTED(读取已提交)**： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li><strong>REPEATABLE-READ(可重复读)：</strong> 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。</li>
<li><strong>SERIALIZABLE(可串行化)：</strong> 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ul>
<p>MySQL InnoDB 存储引擎的默认支持的隔离级别是 <strong>REPEATABLE-READ（可重读）</strong><br>与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下，<strong>允许应用使用  MVCC和 Next-key Lock锁算法来避免幻读的产生。</strong></p>
<h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><h3 id="什么是MVCC"><a href="#什么是MVCC" class="headerlink" title="什么是MVCC?"></a><strong>什么是MVCC?</strong></h3><p>MVCC MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p>
<p>MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读</p>
<h3 id="什么是当前读和快照读？"><a href="#什么是当前读和快照读？" class="headerlink" title="什么是当前读和快照读？"></a><strong>什么是当前读和快照读？</strong></h3><ul>
<li><p>当前读 像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。</p>
</li>
<li><p>快照读 像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本</p>
</li>
</ul>
<p>MVCC就是为了<strong>实现读-写冲突不加锁，</strong>而这个读指的就是<strong>快照读</strong>, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现</p>
<p><strong>当前读，快照读和MVCC的关系</strong></p>
<ul>
<li>准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。</li>
<li>而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现</li>
</ul>
<h3 id="MVCC能解决什么问题，好处是？"><a href="#MVCC能解决什么问题，好处是？" class="headerlink" title="MVCC能解决什么问题，好处是？"></a><strong>MVCC能解决什么问题，好处是？</strong></h3><p>数据库并发场景有三种，分别为：</p>
<ul>
<li>读-读：不存在任何问题，也不需要并发控制</li>
<li>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读</li>
<li>写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失</li>
</ul>
<h3 id="MVCC带来的好处是？"><a href="#MVCC带来的好处是？" class="headerlink" title="MVCC带来的好处是？"></a><strong>MVCC带来的好处是？</strong></h3><p>多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题</p>
<ul>
<li>在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能</li>
<li>同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题</li>
</ul>
<p>总之，MVCC就是不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了MVCC，所以我们可以形成两个组合：</p>
<ul>
<li>MVCC + 悲观锁 MVCC解决读写冲突，悲观锁解决写写冲突</li>
<li>MVCC + 乐观锁 MVCC解决读写冲突，乐观锁解决写写冲突 这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题</li>
</ul>
<p>在 InnoDB 存储引擎中，多版本控制 (multi versioning) 就是对非锁定读的实现。如果<strong>读取的行正在执行 DELETE 或 UPDATE 操作</strong>，这时读取操作不会去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据，<strong>对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)</strong></p>
<p>在 Repeatable Read 下 MVCC 实现了可重复读和防止部分幻读。</p>
<p>如果执行的是下列语句，就是 <strong>锁定读（Locking Reads）</strong></p>
<ul>
<li><p>select … lock in share mode</p>
</li>
<li><p>select … for update</p>
</li>
<li><p>insert、update、delete 操作</p>
<p><strong>在锁定读下，读取的是数据的最新版本</strong>，这种读也被称为 <strong>当前读</strong>（current read）。锁定读会对读取到的记录加锁。<br>在 Repeatable Read 下 MVCC 防止了部分幻读，这边的 “部分” 是指在 一致性非锁定读 情况下，只能读取到第一次查询之前所插入的数据。</p>
</li>
</ul>
<p><strong>但如果是当前读 ，每次读取的都是最新数据</strong>，这时如果两次查询中间有其它事务插入数据，就会产生幻读。</p>
<p>所以 InnoDB 在实现Repeatable Read 时，如果执行的是<strong>当前读，则会对读取的记录使用 Next-key Lock ，来防止其它事务在间隙间插入数据。</strong></p>
<h3 id="MVCC-的实现依赖于：隐藏字段、Read-View、undo-log。"><a href="#MVCC-的实现依赖于：隐藏字段、Read-View、undo-log。" class="headerlink" title="MVCC 的实现依赖于：隐藏字段、Read View、undo log。"></a><strong>MVCC 的实现依赖于：隐藏字段、Read View、undo log。</strong></h3><p>在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。</p>
<p>每个事务读到的数据版本可能是不一样的，在同一个事务中，<strong>用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改。</strong></p>
<h4 id="隐藏字段"><a href="#隐藏字段" class="headerlink" title="隐藏字段"></a>隐藏字段</h4><p>在内部，InnoDB 存储引擎为每行数据添加了三个 隐藏字段：</p>
<p><strong>DB_TRX_ID（6字节）</strong>：表示<strong>最后一次插入或更新该行的事务id</strong>。此外，delete 操作在内部被视为更新，只不过会在记录头 Record header 中的 deleted_flag 字段将其标记为已删除<br><strong>DB_ROLL_PTR（7字节）</strong> <strong>回滚指针，指向该行的 undo log</strong> 。如果该行未被更新，则为空<br><strong>DB_ROW_ID（6字节）</strong>：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该id来生成聚簇索引</p>
<h4 id="ReadView"><a href="#ReadView" class="headerlink" title="ReadView"></a>ReadView</h4><p>Read View 主要是用来做<strong>可见性判断</strong>，里面保存了 “<strong>当前对本事务不可见的其他活跃事务</strong>”</p>
<h4 id="undo-log"><a href="#undo-log" class="headerlink" title="undo-log"></a>undo-log</h4><p><strong>undo log 主要有两个作用：</strong></p>
<p>当事务回滚时用于将数据恢复到修改前的样子</p>
<p>另一个作用是 MVCC ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 <strong>undo log 读取之前的版本数据，以此实现非锁定读</strong></p>
<p>在 InnoDB 存储引擎中 undo log 分为两种： <strong>insert undo log 和 update undo log：</strong></p>
<p>不同事务或者相同事务的对同一记录行的修改，会使该<strong>记录行的 undo log 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。</strong></p>
<p>在 InnoDB 存储引擎中，创建一个新事务后，<strong>执行每个 select 语句前，都会创建一个快照（Read View），快照中保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号。</strong></p>
<p>其实简单的说保存的是系统中当前不应该被本事务看到的其他事务ID列表（即m_ids）。当用户在这个事务中要读取某个记录行的时候，InnoDB 会将该记录行的 DB_TRX_ID 与 Read View 中的一些变量及当前事务ID进行比较，<strong>判断是否满足可见性条件。</strong></p>
<p><strong>RC和RR隔离级别下MVCC的差异</strong></p>
<p>在事务隔离级别 RC 和 RR （InnoDB存储引擎的默认事务隔离级别）下， InnoDB 存储引擎使用 MVCC（非锁定一致性读），但它们<strong>生成 Read View 的时机却不同</strong></p>
<p>在 RC 隔离级别下的 <strong>每次select 查询前</strong>都生成一个Read View (m_ids列表)<br>在 RR 隔离级别下<strong>只在事务开始后 第一次select 数据前生成一个Read View（m_ids列表）</strong></p>
<h4 id="！！！！MVCC-Next-key-Lock防止幻读"><a href="#！！！！MVCC-Next-key-Lock防止幻读" class="headerlink" title="！！！！MVCC+Next-key-Lock防止幻读"></a>！！！！MVCC+Next-key-Lock防止幻读</h4><p>InnoDB存储引擎在 RR 级别下通过 MVCC和 Next-key Lock 来解决幻读问题：</p>
<p>执行普通 select，此时会以 MVCC <strong>快照读</strong>的方式读取数据</p>
<p>在<strong>快照读</strong>的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，<strong>并使用到事务提交</strong>。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”。</p>
<p>执行select…for update&#x2F;lock in share mode、insert、update、delete等当前读。</p>
<p>在<strong>当前读</strong>下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lock 来防止这种情况。<strong>当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。</strong></p>
<h4 id="InnoDB-存储引擎的锁的算法有三种："><a href="#InnoDB-存储引擎的锁的算法有三种：" class="headerlink" title="InnoDB 存储引擎的锁的算法有三种："></a>InnoDB 存储引擎的锁的算法有三种：</h4><ul>
<li>Record lock：记录锁，单个行记录上的锁</li>
<li>Gap lock：间隙锁，锁定一个范围，不包括记录本身</li>
<li>Next-key lock：record+gap 临键锁，锁定一个范围，包含记录本身</li>
</ul>
<h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>基于锁的属性分类：共享锁、排他锁。</p>
<p>基于锁的粒度分类：表锁、行锁、（记录锁、间隙锁、临键锁）</p>
<p>乐观锁，悲观锁</p>
<p>死锁</p>
<h5 id="记录锁（Record-Locks）"><a href="#记录锁（Record-Locks）" class="headerlink" title="记录锁（Record Locks）"></a>记录锁（Record Locks）</h5><p>记录锁就是为<strong>某行记录</strong>加锁，它封锁该行的索引记录：</p>
<p>– id 列为主键列或唯一索引列<br>SELECT * FROM t_user WHERE id &#x3D; 1 <strong>FOR UPDATE;</strong><br>id 为 1 的记录行会被锁住。</p>
<p>需要注意的是：<strong>id 列必须为唯一索引列或主键列</strong>，<strong>否则上述语句加的锁就会变成临键锁。</strong></p>
<p>同时查询语句必须为精准匹配（&#x3D;），不能为 &gt;、&lt;、like等，否则也会退化成临键锁。</p>
<p>我们也可以在通过 主键索引 与 唯一索引 对数据行进行 UPDATE 操作时，也会对该行数据加记录锁：</p>
<p>– id 列为主键列或唯一索引列<br>UPDATE t_user SET age &#x3D; 50 WHERE id &#x3D; 1;</p>
<h5 id="间隙锁（Gap-Locks）"><a href="#间隙锁（Gap-Locks）" class="headerlink" title="间隙锁（Gap Locks）"></a>间隙锁（Gap Locks）</h5><p>间隙锁基于<strong>非唯一索引</strong>，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的Next-Key Locking 算法，请务必牢记：<strong>使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。</strong></p>
<p>SELECT * FROM t_user WHERE id BETWEN 1 AND 10 FOR UPDATE;<br>即所有在（1，10）区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。</p>
<p>除了手动加锁外，在执行完某些 SQL后，InnoDB也会自动加间隙锁。</p>
<h5 id="临键锁（Next-Key-Locks）"><a href="#临键锁（Next-Key-Locks）" class="headerlink" title="临键锁（Next-Key Locks）"></a>临键锁（Next-Key Locks）</h5><p>临键锁是一种特殊的间隙锁，也可以理解为一种特殊的算法。<strong>通过临建锁可以解决幻读的问题。</strong>每个数据行上的<strong>非唯一索引列</strong>上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段<strong>左开右闭</strong>区间的数据。需要强调的一点是，<strong>InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。</strong></p>
<p>比如：表信息 t_user(id PK, age KEY, name)</p>
<p><img src="https://i.loli.net/2021/08/18/PQEZqVyf8vijJlU.png" alt="image-20210818113227557"></p>
<p>在事务 A 中执行如下命令：</p>
<p>– 根据非唯一索引列 UPDATE 某条记录<br>UPDATE t_user SET name &#x3D; Vladimir WHERE age &#x3D; 24;<br>– 或根据非唯一索引列 锁住某条记录<br>SELECT * FROM t_user WHERE age &#x3D; 24 FOR UPDATE;<br>不管执行了上述 SQL 中的哪一句，之后如果在事务 B 中执行以下命令，则该命令会被阻塞：</p>
<p>INSERT INTO t_user VALUES(100, 26, ‘tian’);</p>
<p>很明显，事务 A 在对 age 为 24 的列进行 UPDATE 操作的同时，也获取了 (24, 32] 这个区间内的临键锁。</p>
<p>不仅如此，在执行以下 SQL 时，也会陷入阻塞等待：</p>
<p>INSERT INTO table VALUES(100, 30, ‘zhang’);</p>
<p>那最终我们就可以得知，在根据非唯一索引 对记录行进行 UPDATE \ FOR UPDATE \ LOCK IN SHARE MODE 操作时，<strong>InnoDB 会获取该记录行的 临键锁 ，并同时获取该记录行下一个区间的间隙锁。</strong></p>
<p>即事务 A在执行了上述的 SQL 后，最终被锁住的记录区间为 (10, 32)。</p>
<h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p><img src="https://i.loli.net/2021/08/18/wcGgvB3aXy8nOA1.png" alt="image-20210818113411266"></p>
<p>从死锁的定义来看，MySQL 出现死锁的几个要素为：</p>
<p>两个或者两个以上事务<br>每个事务都已经持有锁并且申请新的锁<br>锁资源同时只能被同一个事务持有或者不兼容<br>事务之间因为持有锁和申请锁导致彼此循环等待</p>
<p><strong>死锁分析思路</strong><br>大致分为两个步骤：</p>
<p>查看<strong>死锁日志</strong>时，首先看一下<strong>发生死锁的事务等待获取锁的语句都是啥。</strong><br>找到发生死锁的事务中所有的语句之后，对照着事务获取到的锁和正在等待的锁的信息来分析死锁发生过程。</p>
<p><strong>如何预防死锁?</strong></p>
<p>innodb_lock_wait_timeout 等待锁超时回滚事务</p>
<p>直观方法是在两个事务相互等待时，<strong>当一个等待时间超过设置的某一阀值时，对其中一个事务进行回滚，另一个事务就能继续执行。</strong></p>
<p>wait-for graph算法来主动进行死锁检测</p>
<p>每当加锁请求无法立即满足需要并进入等待时，wait-for graph算法都会被触发。</p>
<p>wait-for graph要求数据库保存以下两种信息：</p>
<p><strong>锁的信息链表</strong><br><strong>事务等待链表</strong></p>
<p>那么如何解决死锁？</p>
<p><strong>1.等待事务超时，主动回滚。</strong></p>
<p><strong>2.进行死锁检查，主动回滚某条事务，让别的事务能继续走下去。</strong></p>
<p>下面提供一种方法，解决死锁的状态:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;--查看正在被锁的事务</span><br><span class="line"></span><br><span class="line">kill trx_mysql_thread_id；--（上图trx_mysql_thread_id列的值）</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">XieYi</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">263k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:59</span>
  </span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>-->

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  




<script src="/js/third-party/comments/livere.js"></script>

</body>
</html>
